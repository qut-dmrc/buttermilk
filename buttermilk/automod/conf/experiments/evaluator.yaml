name: evaluator
num_runs: 1
concurrent: 1
max_batch: 1
parameters: null
init:
  template: evaluate
# model: ["haiku"]
model:
    #   # - o1-preview
  - llama31_70b
    #   - llama31_8b
    #   # - llama31_405b
  - gpt4o
    #   - opus
  - sonnet
    #   - haiku
  - gemini15pro
save:
  destination: bq
  dataset: 'dmrc-analysis.toxicity.step'
  schema: buttermilk/schemas/step.json
data:
  - type: job
    name: answer
    dataset: dmrc-analysis.toxicity.step_extracted
    last_n_days: 3
    aggregate: false
    filter:
      step: judge
      agent:
      source:
    group:
      step: step
      record_id: record_id
      agent: agent
    columns:
      expected: expected
      id: job_id
      predicted: predicted
      answer:
        interpretation: outputs.interpretation
        reasoning: outputs.reasons
        conclusion: outputs.conclusion
        labels: labels
        scores: scores

