# defaults:
#   - _self_

trans:
  _target_: buttermilk.runner.moa.MoA
  source: trans journalists guidelines assessment
  save: ${save}

  steps:
    - name: fetch
      agent: Fetch
      description: fetch urls and stored records for the chat
      data:
        - name: tja_train
          type: file
          path: gs://prosocial-dev/data/tja_train.jsonl
          index:
            - record_id
      inputs:
        prompt: q

    - name: context_owl
      description: Spots little things that are easy to miss.
      agent: LLMAgent
      num_runs: 1
      save: ${save}
      variants:
        template: owl
        watch: 
          - ambiguity
        model: ${llms.general}
      inputs:
        record: record

    - name: judge
      description: Applies criteria to content.
      agent: LLMAgent
      num_runs: 2
      variants:
        template: judge
        criteria:
          - trans_simplified
          - cte
          - tja
          - glaad
          - hrc
          - trans_factored
        formatting: json_rules
        model: ${llms.judgers}
      inputs:
        record: record
        feedback: context_owl

    - name: feedback
      description: QA for mistakes.
      agent: LLMAgent
      num_runs: 1
      save: ${save}
      variants:
        template: feedback
        model: ${llms.general}
      inputs:
        history: context

    - name: synth
      agent: LLMAgent
      description: Synthesizes draft answers.
      num_runs: 1
      save: ${save}
      variants:
        model: ${llms.synthesisers}
        template: synthesise_judger
        instructions: >
          Carefully apply EACH of the CRITERIA in order and provide a COMPLETE and SPECIFIC explanation about whether the particular rule has been violated and how. Use quotes from the content where necessary to support your analysis.
        criteria: trans_simplified
        formatting: json_rules
      inputs:
        content: content
        answers: judge
        feedback: 
          - context_owl
          - feedback

    - name: eval
      agent: LLMAgent
      num_runs: 1
      description: show differences between answers
      variants:
        template: differences
        criteria: >
          Evaluate how well the provided content aligns with journalistic standards
          and best practices for reporting on stories related to trans people.
        model: ${llms.synthesisers}
      inputs:
        content: content
        answers:
          - judge
          - synth

    - name: scorer
      agent: LLMAgent
      num_runs: 1
      description: score against ground truth
      variants:
        template: evaluate
        model: ${llms.synthesisers}
        answer:
          - judger
          - synth
      inputs:
        instructions: >
          The analyst was tasked with evaluating how well the provided content 
          aligned with journalistic standards and best practices for reporting
          on stories related to trans people.
        expected: record.ground_truth
