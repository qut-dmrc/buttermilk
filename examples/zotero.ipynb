{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from buttermilk.utils.nb import *\n",
    "import nest_asyncio\n",
    "from typing import cast\n",
    "\n",
    "# Apply nest_asyncio to handle potential event loop issues in notebooks\n",
    "nest_asyncio.apply()\n",
    "import chromadb\n",
    "\n",
    "# Add this to the first cell or a new cell before getting the collection\n",
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from typing import cast\n",
    "\n",
    "# Apply nest_asyncio to handle potential event loop issues in notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "PERSIST_DIR = \"/home/nic/data/prosocial_zot/files\"\n",
    "COLLECTION_NAME = \"prosocial_zot\"\n",
    "MODEL_NAME = \"text-embedding-large-exp-03-07\"  # From your vector.py\n",
    "TASK_FOR_QUERY = \"RETRIEVAL_QUERY\"  # Use RETRIEVAL_QUERY for query embedding\n",
    "DIMENSIONALITY = 3072  # From your vector.py\n",
    "embedding_model = TextEmbeddingModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "client = chromadb.PersistentClient(path=PERSIST_DIR)\n",
    "\n",
    "class VertexAIEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input) -> Embeddings:\n",
    "        kwargs = dict(output_dimensionality=DIMENSIONALITY, auto_truncate=False)\n",
    "        results = embedding_model.get_embeddings(texts=input)\n",
    "        return [cast(list[float], r.values) for r in results]\n",
    "\n",
    "vertex_ef = VertexAIEmbeddingFunction()\n",
    "collection = client.get_collection(name=COLLECTION_NAME, embedding_function=vertex_ef)\n",
    "print(f\"Retrieved collection '{COLLECTION_NAME}' with Vertex AI embedding function.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fd33d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your query text\n",
    "query_text = (\n",
    "    \"bias metrics in nlp are sensitive to power and hierarchy and positionality\"\n",
    ")\n",
    "\n",
    "# Query the collection\n",
    "results = collection.query(\n",
    "    query_texts=[query_text],\n",
    "    n_results=20,\n",
    "    include=[\n",
    "        \"documents\",\n",
    "        \"metadatas\",\n",
    "        \"distances\",\n",
    "    ],  # Include documents and optionally metadata/distances\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21666247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic\n",
    "\n",
    "\n",
    "class RefResult(pydantic.BaseModel):\n",
    "    id: str\n",
    "    full_text: str\n",
    "    uri: str | None\n",
    "    chunk_index: int\n",
    "    citation: str\n",
    "    document_id: str\n",
    "    document_title: str\n",
    "    doi_or_url: str\n",
    "    _extra_zotero_data: str\n",
    "\n",
    "\n",
    "def mk_result(results, index) -> RefResult:\n",
    "    result = {\n",
    "        x: results[x][0][index]\n",
    "        for x in [\n",
    "            \"ids\",\n",
    "            \"metadatas\",\n",
    "            \"documents\",\n",
    "        ]\n",
    "        if results[x]\n",
    "    }\n",
    "    meta = {k: v for k, v in result[\"metadatas\"].items() if k in RefResult.model_fields}\n",
    "    return RefResult(\n",
    "        id=result[\"ids\"],\n",
    "        full_text=result[\"documents\"],\n",
    "        uri=result.get(\"uri\", \"\"),\n",
    "        **meta,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "694ce8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"id\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"3459810b-b699-48ed-bd1d-91592571438d\"</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"full_text\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"EU High-Level Expert Group on AI. (2019). Ethics guidelines for trustworthy AI. https://ec.europa.eu/newsroom/\\n\\ndae/document.cfm?doc_id=60419\\n\\n\\f14 of 19\\n\\nHOVY and PRABHUMOYE\\n\\nFlek, L. (2020). Returning the N to NLP: Towards contextually personalized classification models. Proceedings of \\nthe 58th Annual Meeting of the Association for Computational Linguistics, 7828–7838. Online: Association for \\nComputational Linguistics. https://www.aclweb.org/anthology/2020.acl-main.700\\n\\nFont, J. E., &amp; Costa-jussà, M. R. (2019). Equalizing gender bias in neural machine translation with word embed-\\ndings techniques. Proceedings of the First Workshop on Gender Bias in Natural Language Processing, 147–154. \\nFlorence, Italy: Association for Computational Linguistics. https://www.aclweb.org/anthology/W19-3821\\nFornaciari, T., Uma, A., Paun, S., Plank, B., Hovy, D., &amp; Poesio, M. (2021). Beyond black &amp; white: Leveraging an-\\nnotator disagreement via soft-label multi-task learning. Proceedings of the 2021 Conference of the North Amer-\\nican  Chapter  of  the  Association  for  Computational  Linguistics:  Human  Language  Technologies,  2591–2597. \\nOnline: Association for Computational Linguistics. https://www.aclweb.org/anthology/2021.naacl-main.204\\nFort, K., Adda, G., &amp; Cohen, K. B. (2011). Last words: Amazon Mechanical Turk: Gold mine or coal mine? Com-\\n\\nputational Linguistics, 37, 413–420. https://www.aclweb.org/anthology/J11-2010\\n\\nFriedler, S. A., Scheidegger, C., &amp; Venkatasubramanian, S. (2021). The (im) possibility of fairness: Different value \\nsystems require different mechanisms for fair decision making. Communications of the ACM, 64, 136–143.\\nFromreide, H., Hovy, D., &amp; Søgaard, A. (2014). Crowdsourcing and annotating NER for Twitter #drift. Proceedings \\nof  the  Ninth  International  Conference  on  Language  Resources  and  Evaluation  (LREC’14),  2544–2547.  Rey-\\nkjavik, Iceland: European Language Resources Association (ELRA). http://www.lrec-conf.org/proceedings/\\nlrec2014/pdf/421_Paper.pdf\\n\\nGarg, N., Schiebinger, L., Jurafsky, D., &amp; Zou, J. (2018). Word embeddings quantify 100 years of gender and ethnic \\n\\nstereotypes. Proceedings of the National Academy of Sciences, 115, E3635–E3644.\\n\\nGarimella, A., Banea, C., Hovy, D., &amp; Mihalcea, R. (2019). Women's syntactic resilience and men's grammatical \\nluck: Gender-bias in part-of-speech tagging and dependency parsing. Proceedings of the 57th Annual Meeting \\nof the Association for Computational Linguistics, 3493–3498. Florence, Italy: Association for Computational \\nLinguistics. https://www.aclweb.org/anthology/P19-1339\\n\\nGoldstein, D. G., &amp; Gigerenzer, G. (2002). Models of ecological rationality: The recognition heuristic. Psychological \\n\\nReview, 109, 75–90.\\n\\nGonen, H., &amp; Goldberg, Y. (2019). Lipstick on a pig: Debiasing methods cover up systematic gender biases in word \\nembeddings but do not remove them. Proceedings of the 2019 Conference of the North American Chapter of the \\nAssociation for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), \\n609–614. https://www.aclweb.org/anthology/N19-1061\\n\\nGrouin, C., Griffon, N., &amp; Névéol, A. (2015). Is it possible to recover personal health information from an auto-\\nmatically de-identified corpus of French EHRs? Proceedings of the Sixth International Workshop on Health \\nText Mining and Information Analysis, 31–39. Lisbon, Portugal: Association for Computational Linguistics. \\nhttps://www.aclweb.org/anthology/W15-2604\\n\\nGururangan, S., Swayamdipta, S., Levy, O., Schwartz, R., Bowman, S. R., &amp; Smith, N. A. (2018). Annotation arti-\\n\\nfacts in natural language inference data. In NAACL-HLT (2).\\n\\nHarwell, D. (2018). The accent gap. Why some accents don’t work on Alexa or Google Home. The Washington Post. \\n\\nhttps://www.washingtonpost.com/graphics/2018/business/alexa-does-not-understand-your-accent/\\n\\nHavens, L., Terras, M., Bach, B., &amp; Alex, B. (2020). Situated data, situated systems: A methodology to engage with \\npower relations in natural language processing research. Proceedings of the Second Workshop on Gender Bias \\nin Natural Language Processing, 107–124. Barcelona, Spain (Online): Association for Computational Linguis-\\ntics. https://www.aclweb.org/anthology/2020.gebnlp-1.10\\n\\nHenrich, J., Heine, S. J., &amp; Norenzayan, A. (2010). The weirdest people in the world? Behavioral and Brain Sciences, \\n\\n33, 61–83.\\n\\nHovy, D. (2015). Demographic factors improve classification performance. Proceedings of the 53rd Annual Meeting \\nof the Association for Computational Linguistics and the 7th International Joint Conference on Natural Lan-\\nguage Processing (Volume 1: Long Papers), 752–762. Beijing, China: Association for Computational Linguis-\\ntics. https://www.aclweb.org/anthology/P15-1073\\n\\nHovy, D., Berg-Kirkpatrick, T., Vaswani, A., &amp; Hovy, E. (2013). Learning whom to trust with mace. Proceedings of \\nthe 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human \\nLanguage Technologies, 1120–1130.\\n\\nHovy, D., Bianchi, F., &amp; Fornaciari, T. (2020). “you sound just like your father” commercial machine translation \\nsystems include stylistic biases. Proceedings of the 58th Annual Meeting of the Association for Computational \\n\\n\\fHOVY and PRABHUMOYE\\n\\n15 of 19\\n\\nLinguistics, 1686–1690. Online: Association for Computational Linguistics. https://www.aclweb.org/anthol-\\nogy/2020.acl-main.154\\n\\nHovy, D., &amp; Søgaard, A. (2015). Tagging performance correlates with author age. Proceedings of the 53rd Annual \\nMeeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural \\nLanguage Processing (Volume 2: Short Papers), 483–488.\\n\\nHovy, D., &amp; Spruit, S. L. (2016). The social impact of natural language processing. Proceedings of the 54th Annual \\nMeeting of the Association for Computational Linguistics (Volume 2: Short Papers), 591–598. Berlin, Germany: \\nAssociation for Computational Linguistics. https://www.aclweb.org/anthology/P16-2096\\n\\nHovy, D., &amp; Yang, D. (2021). The importance of modeling social factors of language: Theory and practice. Proceed-\\nings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: \\nHuman Language Technologies, 588–602. Online: Association for Computational Linguistics. https://www.\\naclweb.org/anthology/2021.naacl-main.49\\n\\nHovy, D., Spruit, S., Mitchell, M., Bender, E. M., Strube, M., &amp; Wallach, H. (Eds.). (2017). Proceedings of the First \\nACL Workshop  on  Ethics  in  Natural  Language  Processing. Valencia,  Spain:  Association  for  Computational \\nLinguistics. https://www.aclweb.org/anthology/W17-1600\\n\\nHoward, A., &amp; Borenstein, J. (2018). The ugly truth about ourselves and our robot creations: The problem of bias \\n\\nand social inequity. Science and Engineering Ethics, 24, 1521–1536.\\n\\nHutchinson, B., Smart, A., Hanna, A., Denton, E., Greer, C., Kjartansson, O., Barnes, P., &amp; Mitchell, M. (2021). To-\\nwards accountability for machine learning datasets: Practices from software engineering and infrastructure. \\nProceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 560–575.\\n\\nJebbara, S., &amp; Cimiano, P. (2019). Zero-shot cross-lingual opinion target extraction. Proceedings of the 2019 Con-\\nference  of  the  North  American  Chapter  of  the  Association  for  Computational  Linguistics:  Human  Language \\nTechnologies, Volume 1 (Long and Short Papers), 2486–2495. Minneapolis, Minnesota: Association for Com-\\nputational Linguistics. https://www.aclweb.org/anthology/N19-1257\\n\\nJohannsen, A., Hovy, D., &amp; Søgaard, A. (2015). Cross-lingual syntactic variation over age and gender. Proceedings \\nof the Nineteenth Conference on Computational Natural Language Learning, 103–112. Beijing, China: Associ-\\nation for Computational Linguistics. https://www.aclweb.org/anthology/K15-1011\\n\\nJørgensen,  A.,  Hovy,  D.,  &amp;  Søgaard,  A.  (2015).  Challenges  of  studying  and  processing  dialects  in  social  media. \\n\\nProceedings of the Workshop on Noisy User-generated Text, 9–18.\\n\\nJoshi, P., Santy, S., Budhiraja, A., Bali, K., &amp; Choudhury, M. (2020). The state and fate of linguistic diversity and \\ninclusion  in  the  NLP  world.  Proceedings  of  the  58th  Annual  Meeting  of  the  Association  for  Computational \\nLinguistics, 6282–6293. Online: Association for Computational Linguistics. https://www.aclweb.org/anthol-\\nogy/2020.acl-main.560\\n\\nJurgens, D., Tsvetkov, Y., &amp; Jurafsky, D. (2017). Writer profiling without the writer's text. In G. L. Ciampaglia, A. \\n\\nMashhadi, &amp; T. Yasseri (Eds.), Social informatics (pp. 537–558). Springer International Publishing.\\n\\nKennedy, B., Jin, X., Mostafazadeh Davani, A., Dehghani, M., &amp; Ren, X. (2020). Contextualizing hate speech clas-\\nsifiers with post-hoc explanation. Proceedings of the 58th Annual Meeting of the Association for Computational \\nLinguistics, 5435–5442. Online: Association for Computational Linguistics. https://www.aclweb.org/anthol-\\nogy/2020.acl-main.483\"</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"uri\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"chunk_index\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"citation\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Hovy, D., &amp; Prabhumoye, S. (2021). Five sources of bias in natural language processing. *Language and Linguistics Compass*, *15*(7), e12432. https://doi.org/10.1111/lnc3.12432\"</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"document_id\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"8S6C9EF9\"</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"document_title\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Five sources of bias in natural language processing\"</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"doi_or_url\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"10.1111/lnc3.12432\"</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"id\"\u001b[0m: \u001b[32m\"3459810b-b699-48ed-bd1d-91592571438d\"\u001b[0m,\n",
       "  \u001b[1;34m\"full_text\"\u001b[0m: \u001b[32m\"EU High-Level Expert Group on AI. (2019). Ethics guidelines for trustworthy AI. https://ec.europa.eu/newsroom/\\n\\ndae/document.cfm?doc_id=60419\\n\\n\\f14 of 19\\n\\nHOVY and PRABHUMOYE\\n\\nFlek, L. (2020). Returning the N to NLP: Towards contextually personalized classification models. Proceedings of \\nthe 58th Annual Meeting of the Association for Computational Linguistics, 7828–7838. Online: Association for \\nComputational Linguistics. https://www.aclweb.org/anthology/2020.acl-main.700\\n\\nFont, J. E., & Costa-jussà, M. R. (2019). Equalizing gender bias in neural machine translation with word embed-\\ndings techniques. Proceedings of the First Workshop on Gender Bias in Natural Language Processing, 147–154. \\nFlorence, Italy: Association for Computational Linguistics. https://www.aclweb.org/anthology/W19-3821\\nFornaciari, T., Uma, A., Paun, S., Plank, B., Hovy, D., & Poesio, M. (2021). Beyond black & white: Leveraging an-\\nnotator disagreement via soft-label multi-task learning. Proceedings of the 2021 Conference of the North Amer-\\nican  Chapter  of  the  Association  for  Computational  Linguistics:  Human  Language  Technologies,  2591–2597. \\nOnline: Association for Computational Linguistics. https://www.aclweb.org/anthology/2021.naacl-main.204\\nFort, K., Adda, G., & Cohen, K. B. (2011). Last words: Amazon Mechanical Turk: Gold mine or coal mine? Com-\\n\\nputational Linguistics, 37, 413–420. https://www.aclweb.org/anthology/J11-2010\\n\\nFriedler, S. A., Scheidegger, C., & Venkatasubramanian, S. (2021). The (im) possibility of fairness: Different value \\nsystems require different mechanisms for fair decision making. Communications of the ACM, 64, 136–143.\\nFromreide, H., Hovy, D., & Søgaard, A. (2014). Crowdsourcing and annotating NER for Twitter #drift. Proceedings \\nof  the  Ninth  International  Conference  on  Language  Resources  and  Evaluation  (LREC’14),  2544–2547.  Rey-\\nkjavik, Iceland: European Language Resources Association (ELRA). http://www.lrec-conf.org/proceedings/\\nlrec2014/pdf/421_Paper.pdf\\n\\nGarg, N., Schiebinger, L., Jurafsky, D., & Zou, J. (2018). Word embeddings quantify 100 years of gender and ethnic \\n\\nstereotypes. Proceedings of the National Academy of Sciences, 115, E3635–E3644.\\n\\nGarimella, A., Banea, C., Hovy, D., & Mihalcea, R. (2019). Women's syntactic resilience and men's grammatical \\nluck: Gender-bias in part-of-speech tagging and dependency parsing. Proceedings of the 57th Annual Meeting \\nof the Association for Computational Linguistics, 3493–3498. Florence, Italy: Association for Computational \\nLinguistics. https://www.aclweb.org/anthology/P19-1339\\n\\nGoldstein, D. G., & Gigerenzer, G. (2002). Models of ecological rationality: The recognition heuristic. Psychological \\n\\nReview, 109, 75–90.\\n\\nGonen, H., & Goldberg, Y. (2019). Lipstick on a pig: Debiasing methods cover up systematic gender biases in word \\nembeddings but do not remove them. Proceedings of the 2019 Conference of the North American Chapter of the \\nAssociation for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), \\n609–614. https://www.aclweb.org/anthology/N19-1061\\n\\nGrouin, C., Griffon, N., & Névéol, A. (2015). Is it possible to recover personal health information from an auto-\\nmatically de-identified corpus of French EHRs? Proceedings of the Sixth International Workshop on Health \\nText Mining and Information Analysis, 31–39. Lisbon, Portugal: Association for Computational Linguistics. \\nhttps://www.aclweb.org/anthology/W15-2604\\n\\nGururangan, S., Swayamdipta, S., Levy, O., Schwartz, R., Bowman, S. R., & Smith, N. A. (2018). Annotation arti-\\n\\nfacts in natural language inference data. In NAACL-HLT (2).\\n\\nHarwell, D. (2018). The accent gap. Why some accents don’t work on Alexa or Google Home. The Washington Post. \\n\\nhttps://www.washingtonpost.com/graphics/2018/business/alexa-does-not-understand-your-accent/\\n\\nHavens, L., Terras, M., Bach, B., & Alex, B. (2020). Situated data, situated systems: A methodology to engage with \\npower relations in natural language processing research. Proceedings of the Second Workshop on Gender Bias \\nin Natural Language Processing, 107–124. Barcelona, Spain (Online): Association for Computational Linguis-\\ntics. https://www.aclweb.org/anthology/2020.gebnlp-1.10\\n\\nHenrich, J., Heine, S. J., & Norenzayan, A. (2010). The weirdest people in the world? Behavioral and Brain Sciences, \\n\\n33, 61–83.\\n\\nHovy, D. (2015). Demographic factors improve classification performance. Proceedings of the 53rd Annual Meeting \\nof the Association for Computational Linguistics and the 7th International Joint Conference on Natural Lan-\\nguage Processing (Volume 1: Long Papers), 752–762. Beijing, China: Association for Computational Linguis-\\ntics. https://www.aclweb.org/anthology/P15-1073\\n\\nHovy, D., Berg-Kirkpatrick, T., Vaswani, A., & Hovy, E. (2013). Learning whom to trust with mace. Proceedings of \\nthe 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human \\nLanguage Technologies, 1120–1130.\\n\\nHovy, D., Bianchi, F., & Fornaciari, T. (2020). “you sound just like your father” commercial machine translation \\nsystems include stylistic biases. Proceedings of the 58th Annual Meeting of the Association for Computational \\n\\n\\fHOVY and PRABHUMOYE\\n\\n15 of 19\\n\\nLinguistics, 1686–1690. Online: Association for Computational Linguistics. https://www.aclweb.org/anthol-\\nogy/2020.acl-main.154\\n\\nHovy, D., & Søgaard, A. (2015). Tagging performance correlates with author age. Proceedings of the 53rd Annual \\nMeeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural \\nLanguage Processing (Volume 2: Short Papers), 483–488.\\n\\nHovy, D., & Spruit, S. L. (2016). The social impact of natural language processing. Proceedings of the 54th Annual \\nMeeting of the Association for Computational Linguistics (Volume 2: Short Papers), 591–598. Berlin, Germany: \\nAssociation for Computational Linguistics. https://www.aclweb.org/anthology/P16-2096\\n\\nHovy, D., & Yang, D. (2021). The importance of modeling social factors of language: Theory and practice. Proceed-\\nings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: \\nHuman Language Technologies, 588–602. Online: Association for Computational Linguistics. https://www.\\naclweb.org/anthology/2021.naacl-main.49\\n\\nHovy, D., Spruit, S., Mitchell, M., Bender, E. M., Strube, M., & Wallach, H. (Eds.). (2017). Proceedings of the First \\nACL Workshop  on  Ethics  in  Natural  Language  Processing. Valencia,  Spain:  Association  for  Computational \\nLinguistics. https://www.aclweb.org/anthology/W17-1600\\n\\nHoward, A., & Borenstein, J. (2018). The ugly truth about ourselves and our robot creations: The problem of bias \\n\\nand social inequity. Science and Engineering Ethics, 24, 1521–1536.\\n\\nHutchinson, B., Smart, A., Hanna, A., Denton, E., Greer, C., Kjartansson, O., Barnes, P., & Mitchell, M. (2021). To-\\nwards accountability for machine learning datasets: Practices from software engineering and infrastructure. \\nProceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 560–575.\\n\\nJebbara, S., & Cimiano, P. (2019). Zero-shot cross-lingual opinion target extraction. Proceedings of the 2019 Con-\\nference  of  the  North  American  Chapter  of  the  Association  for  Computational  Linguistics:  Human  Language \\nTechnologies, Volume 1 (Long and Short Papers), 2486–2495. Minneapolis, Minnesota: Association for Com-\\nputational Linguistics. https://www.aclweb.org/anthology/N19-1257\\n\\nJohannsen, A., Hovy, D., & Søgaard, A. (2015). Cross-lingual syntactic variation over age and gender. Proceedings \\nof the Nineteenth Conference on Computational Natural Language Learning, 103–112. Beijing, China: Associ-\\nation for Computational Linguistics. https://www.aclweb.org/anthology/K15-1011\\n\\nJørgensen,  A.,  Hovy,  D.,  &  Søgaard,  A.  (2015).  Challenges  of  studying  and  processing  dialects  in  social  media. \\n\\nProceedings of the Workshop on Noisy User-generated Text, 9–18.\\n\\nJoshi, P., Santy, S., Budhiraja, A., Bali, K., & Choudhury, M. (2020). The state and fate of linguistic diversity and \\ninclusion  in  the  NLP  world.  Proceedings  of  the  58th  Annual  Meeting  of  the  Association  for  Computational \\nLinguistics, 6282–6293. Online: Association for Computational Linguistics. https://www.aclweb.org/anthol-\\nogy/2020.acl-main.560\\n\\nJurgens, D., Tsvetkov, Y., & Jurafsky, D. (2017). Writer profiling without the writer's text. In G. L. Ciampaglia, A. \\n\\nMashhadi, & T. Yasseri (Eds.), Social informatics (pp. 537–558). Springer International Publishing.\\n\\nKennedy, B., Jin, X., Mostafazadeh Davani, A., Dehghani, M., & Ren, X. (2020). Contextualizing hate speech clas-\\nsifiers with post-hoc explanation. Proceedings of the 58th Annual Meeting of the Association for Computational \\nLinguistics, 5435–5442. Online: Association for Computational Linguistics. https://www.aclweb.org/anthol-\\nogy/2020.acl-main.483\"\u001b[0m,\n",
       "  \u001b[1;34m\"uri\"\u001b[0m: \u001b[32m\"\"\u001b[0m,\n",
       "  \u001b[1;34m\"chunk_index\"\u001b[0m: \u001b[1;36m8\u001b[0m,\n",
       "  \u001b[1;34m\"citation\"\u001b[0m: \u001b[32m\"Hovy, D., & Prabhumoye, S. (2021). Five sources of bias in natural language processing. *Language and Linguistics Compass*, *15*(7), e12432. https://doi.org/10.1111/lnc3.12432\"\u001b[0m,\n",
       "  \u001b[1;34m\"document_id\"\u001b[0m: \u001b[32m\"8S6C9EF9\"\u001b[0m,\n",
       "  \u001b[1;34m\"document_title\"\u001b[0m: \u001b[32m\"Five sources of bias in natural language processing\"\u001b[0m,\n",
       "  \u001b[1;34m\"doi_or_url\"\u001b[0m: \u001b[32m\"10.1111/lnc3.12432\"\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console.print_json(data=mk_result(results, 3).model_dump())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf55a0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"ids\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"3459810b-b699-48ed-bd1d-91592571438d\"</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"metadatas\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"chunk_index\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,\n",
       "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"citation\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Hovy, D., &amp; Prabhumoye, S. (2021). Five sources of bias in natural language processing. *Language and Linguistics Compass*, *15*(7), e12432. https://doi.org/10.1111/lnc3.12432\"</span>,\n",
       "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"document_id\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"8S6C9EF9\"</span>,\n",
       "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"document_title\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Five sources of bias in natural language processing\"</span>,\n",
       "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"doi_or_url\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"10.1111/lnc3.12432\"</span>,\n",
       "    <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"zotero_data\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"{\\\"key\\\": \\\"8S6C9EF9\\\", \\\"version\\\": 37517, \\\"itemType\\\": \\\"journalArticle\\\", \\\"title\\\": \\\"Five sources of bias in natural language processing\\\", \\\"creators\\\": [{\\\"creatorType\\\": \\\"author\\\", \\\"firstName\\\": \\\"Dirk\\\", \\\"lastName\\\": \\\"Hovy\\\"}, {\\\"creatorType\\\": \\\"author\\\", \\\"firstName\\\": \\\"Shrimai\\\", \\\"lastName\\\": \\\"Prabhumoye\\\"}], \\\"abstractNote\\\": \\\"Recently, there has been an increased interest in demographically grounded bias in natural language processing (NLP) applications. Much of the recent work has focused on describing bias and providing an overview of bias in a larger context. Here, we provide a simple, actionable summary of this recent work. We outline five sources where bias can occur in NLP systems: (1) the data, (2) the annotation process, (3) the input representations, (4) the models, and finally (5) the research design (or how we conceptualize our research). We explore each of the bias sources in detail in this article, including examples and links to related work, as well as potential counter-measures.\\\", \\\"publicationTitle\\\": \\\"Language and Linguistics Compass\\\", \\\"volume\\\": \\\"15\\\", \\\"issue\\\": \\\"8\\\", \\\"pages\\\": \\\"e12432\\\", \\\"date\\\": \\\"2021\\\", \\\"series\\\": \\\"\\\", \\\"seriesTitle\\\": \\\"\\\", \\\"seriesText\\\": \\\"\\\", \\\"journalAbbreviation\\\": \\\"\\\", \\\"language\\\": \\\"en\\\", \\\"DOI\\\": \\\"10.1111/lnc3.12432\\\", \\\"ISSN\\\": \\\"1749-818X\\\", \\\"shortTitle\\\": \\\"\\\", \\\"url\\\": \\\"https://onlinelibrary.wiley.com/doi/abs/10.1111/lnc3.12432\\\", \\\"accessDate\\\": \\\"2024-07-04T12:35:01Z\\\", \\\"archive\\\": \\\"\\\", \\\"archiveLocation\\\": \\\"\\\", \\\"libraryCatalog\\\": \\\"Wiley Online Library\\\", \\\"callNumber\\\": \\\"\\\", \\\"rights\\\": \\\"© 2021 The Authors. Language and Linguistics Compass published by John Wiley &amp; Sons Ltd.\\\", \\\"extra\\\": \\\"_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/lnc3.12432\\\", \\\"tags\\\": [], \\\"collections\\\": [\\\"NQDTJJDN\\\"], \\\"relations\\\": {}, \\\"dateAdded\\\": \\\"2024-07-04T12:35:02Z\\\", \\\"dateModified\\\": \\\"2024-07-04T12:35:02Z\\\"}\"</span>\n",
       "  <span style=\"font-weight: bold\">}</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"documents\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"EU High-Level Expert Group on AI. (2019). Ethics guidelines for trustworthy AI. https://ec.europa.eu/newsroom/\\n\\ndae/document.cfm?doc_id=60419\\n\\n\\f14 of 19\\n\\nHOVY and PRABHUMOYE\\n\\nFlek, L. (2020). Returning the N to NLP: Towards contextually personalized classification models. Proceedings of \\nthe 58th Annual Meeting of the Association for Computational Linguistics, 7828–7838. Online: Association for \\nComputational Linguistics. https://www.aclweb.org/anthology/2020.acl-main.700\\n\\nFont, J. E., &amp; Costa-jussà, M. R. (2019). Equalizing gender bias in neural machine translation with word embed-\\ndings techniques. Proceedings of the First Workshop on Gender Bias in Natural Language Processing, 147–154. \\nFlorence, Italy: Association for Computational Linguistics. https://www.aclweb.org/anthology/W19-3821\\nFornaciari, T., Uma, A., Paun, S., Plank, B., Hovy, D., &amp; Poesio, M. (2021). Beyond black &amp; white: Leveraging an-\\nnotator disagreement via soft-label multi-task learning. Proceedings of the 2021 Conference of the North Amer-\\nican  Chapter  of  the  Association  for  Computational  Linguistics:  Human  Language  Technologies,  2591–2597. \\nOnline: Association for Computational Linguistics. https://www.aclweb.org/anthology/2021.naacl-main.204\\nFort, K., Adda, G., &amp; Cohen, K. B. (2011). Last words: Amazon Mechanical Turk: Gold mine or coal mine? Com-\\n\\nputational Linguistics, 37, 413–420. https://www.aclweb.org/anthology/J11-2010\\n\\nFriedler, S. A., Scheidegger, C., &amp; Venkatasubramanian, S. (2021). The (im) possibility of fairness: Different value \\nsystems require different mechanisms for fair decision making. Communications of the ACM, 64, 136–143.\\nFromreide, H., Hovy, D., &amp; Søgaard, A. (2014). Crowdsourcing and annotating NER for Twitter #drift. Proceedings \\nof  the  Ninth  International  Conference  on  Language  Resources  and  Evaluation  (LREC’14),  2544–2547.  Rey-\\nkjavik, Iceland: European Language Resources Association (ELRA). http://www.lrec-conf.org/proceedings/\\nlrec2014/pdf/421_Paper.pdf\\n\\nGarg, N., Schiebinger, L., Jurafsky, D., &amp; Zou, J. (2018). Word embeddings quantify 100 years of gender and ethnic \\n\\nstereotypes. Proceedings of the National Academy of Sciences, 115, E3635–E3644.\\n\\nGarimella, A., Banea, C., Hovy, D., &amp; Mihalcea, R. (2019). Women's syntactic resilience and men's grammatical \\nluck: Gender-bias in part-of-speech tagging and dependency parsing. Proceedings of the 57th Annual Meeting \\nof the Association for Computational Linguistics, 3493–3498. Florence, Italy: Association for Computational \\nLinguistics. https://www.aclweb.org/anthology/P19-1339\\n\\nGoldstein, D. G., &amp; Gigerenzer, G. (2002). Models of ecological rationality: The recognition heuristic. Psychological \\n\\nReview, 109, 75–90.\\n\\nGonen, H., &amp; Goldberg, Y. (2019). Lipstick on a pig: Debiasing methods cover up systematic gender biases in word \\nembeddings but do not remove them. Proceedings of the 2019 Conference of the North American Chapter of the \\nAssociation for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), \\n609–614. https://www.aclweb.org/anthology/N19-1061\\n\\nGrouin, C., Griffon, N., &amp; Névéol, A. (2015). Is it possible to recover personal health information from an auto-\\nmatically de-identified corpus of French EHRs? Proceedings of the Sixth International Workshop on Health \\nText Mining and Information Analysis, 31–39. Lisbon, Portugal: Association for Computational Linguistics. \\nhttps://www.aclweb.org/anthology/W15-2604\\n\\nGururangan, S., Swayamdipta, S., Levy, O., Schwartz, R., Bowman, S. R., &amp; Smith, N. A. (2018). Annotation arti-\\n\\nfacts in natural language inference data. In NAACL-HLT (2).\\n\\nHarwell, D. (2018). The accent gap. Why some accents don’t work on Alexa or Google Home. The Washington Post. \\n\\nhttps://www.washingtonpost.com/graphics/2018/business/alexa-does-not-understand-your-accent/\\n\\nHavens, L., Terras, M., Bach, B., &amp; Alex, B. (2020). Situated data, situated systems: A methodology to engage with \\npower relations in natural language processing research. Proceedings of the Second Workshop on Gender Bias \\nin Natural Language Processing, 107–124. Barcelona, Spain (Online): Association for Computational Linguis-\\ntics. https://www.aclweb.org/anthology/2020.gebnlp-1.10\\n\\nHenrich, J., Heine, S. J., &amp; Norenzayan, A. (2010). The weirdest people in the world? Behavioral and Brain Sciences, \\n\\n33, 61–83.\\n\\nHovy, D. (2015). Demographic factors improve classification performance. Proceedings of the 53rd Annual Meeting \\nof the Association for Computational Linguistics and the 7th International Joint Conference on Natural Lan-\\nguage Processing (Volume 1: Long Papers), 752–762. Beijing, China: Association for Computational Linguis-\\ntics. https://www.aclweb.org/anthology/P15-1073\\n\\nHovy, D., Berg-Kirkpatrick, T., Vaswani, A., &amp; Hovy, E. (2013). Learning whom to trust with mace. Proceedings of \\nthe 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human \\nLanguage Technologies, 1120–1130.\\n\\nHovy, D., Bianchi, F., &amp; Fornaciari, T. (2020). “you sound just like your father” commercial machine translation \\nsystems include stylistic biases. Proceedings of the 58th Annual Meeting of the Association for Computational \\n\\n\\fHOVY and PRABHUMOYE\\n\\n15 of 19\\n\\nLinguistics, 1686–1690. Online: Association for Computational Linguistics. https://www.aclweb.org/anthol-\\nogy/2020.acl-main.154\\n\\nHovy, D., &amp; Søgaard, A. (2015). Tagging performance correlates with author age. Proceedings of the 53rd Annual \\nMeeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural \\nLanguage Processing (Volume 2: Short Papers), 483–488.\\n\\nHovy, D., &amp; Spruit, S. L. (2016). The social impact of natural language processing. Proceedings of the 54th Annual \\nMeeting of the Association for Computational Linguistics (Volume 2: Short Papers), 591–598. Berlin, Germany: \\nAssociation for Computational Linguistics. https://www.aclweb.org/anthology/P16-2096\\n\\nHovy, D., &amp; Yang, D. (2021). The importance of modeling social factors of language: Theory and practice. Proceed-\\nings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: \\nHuman Language Technologies, 588–602. Online: Association for Computational Linguistics. https://www.\\naclweb.org/anthology/2021.naacl-main.49\\n\\nHovy, D., Spruit, S., Mitchell, M., Bender, E. M., Strube, M., &amp; Wallach, H. (Eds.). (2017). Proceedings of the First \\nACL Workshop  on  Ethics  in  Natural  Language  Processing. Valencia,  Spain:  Association  for  Computational \\nLinguistics. https://www.aclweb.org/anthology/W17-1600\\n\\nHoward, A., &amp; Borenstein, J. (2018). The ugly truth about ourselves and our robot creations: The problem of bias \\n\\nand social inequity. Science and Engineering Ethics, 24, 1521–1536.\\n\\nHutchinson, B., Smart, A., Hanna, A., Denton, E., Greer, C., Kjartansson, O., Barnes, P., &amp; Mitchell, M. (2021). To-\\nwards accountability for machine learning datasets: Practices from software engineering and infrastructure. \\nProceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 560–575.\\n\\nJebbara, S., &amp; Cimiano, P. (2019). Zero-shot cross-lingual opinion target extraction. Proceedings of the 2019 Con-\\nference  of  the  North  American  Chapter  of  the  Association  for  Computational  Linguistics:  Human  Language \\nTechnologies, Volume 1 (Long and Short Papers), 2486–2495. Minneapolis, Minnesota: Association for Com-\\nputational Linguistics. https://www.aclweb.org/anthology/N19-1257\\n\\nJohannsen, A., Hovy, D., &amp; Søgaard, A. (2015). Cross-lingual syntactic variation over age and gender. Proceedings \\nof the Nineteenth Conference on Computational Natural Language Learning, 103–112. Beijing, China: Associ-\\nation for Computational Linguistics. https://www.aclweb.org/anthology/K15-1011\\n\\nJørgensen,  A.,  Hovy,  D.,  &amp;  Søgaard,  A.  (2015).  Challenges  of  studying  and  processing  dialects  in  social  media. \\n\\nProceedings of the Workshop on Noisy User-generated Text, 9–18.\\n\\nJoshi, P., Santy, S., Budhiraja, A., Bali, K., &amp; Choudhury, M. (2020). The state and fate of linguistic diversity and \\ninclusion  in  the  NLP  world.  Proceedings  of  the  58th  Annual  Meeting  of  the  Association  for  Computational \\nLinguistics, 6282–6293. Online: Association for Computational Linguistics. https://www.aclweb.org/anthol-\\nogy/2020.acl-main.560\\n\\nJurgens, D., Tsvetkov, Y., &amp; Jurafsky, D. (2017). Writer profiling without the writer's text. In G. L. Ciampaglia, A. \\n\\nMashhadi, &amp; T. Yasseri (Eds.), Social informatics (pp. 537–558). Springer International Publishing.\\n\\nKennedy, B., Jin, X., Mostafazadeh Davani, A., Dehghani, M., &amp; Ren, X. (2020). Contextualizing hate speech clas-\\nsifiers with post-hoc explanation. Proceedings of the 58th Annual Meeting of the Association for Computational \\nLinguistics, 5435–5442. Online: Association for Computational Linguistics. https://www.aclweb.org/anthol-\\nogy/2020.acl-main.483\"</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"ids\"\u001b[0m: \u001b[32m\"3459810b-b699-48ed-bd1d-91592571438d\"\u001b[0m,\n",
       "  \u001b[1;34m\"metadatas\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "    \u001b[1;34m\"chunk_index\"\u001b[0m: \u001b[1;36m8\u001b[0m,\n",
       "    \u001b[1;34m\"citation\"\u001b[0m: \u001b[32m\"Hovy, D., & Prabhumoye, S. (2021). Five sources of bias in natural language processing. *Language and Linguistics Compass*, *15*(7), e12432. https://doi.org/10.1111/lnc3.12432\"\u001b[0m,\n",
       "    \u001b[1;34m\"document_id\"\u001b[0m: \u001b[32m\"8S6C9EF9\"\u001b[0m,\n",
       "    \u001b[1;34m\"document_title\"\u001b[0m: \u001b[32m\"Five sources of bias in natural language processing\"\u001b[0m,\n",
       "    \u001b[1;34m\"doi_or_url\"\u001b[0m: \u001b[32m\"10.1111/lnc3.12432\"\u001b[0m,\n",
       "    \u001b[1;34m\"zotero_data\"\u001b[0m: \u001b[32m\"{\\\"key\\\": \\\"8S6C9EF9\\\", \\\"version\\\": 37517, \\\"itemType\\\": \\\"journalArticle\\\", \\\"title\\\": \\\"Five sources of bias in natural language processing\\\", \\\"creators\\\": [{\\\"creatorType\\\": \\\"author\\\", \\\"firstName\\\": \\\"Dirk\\\", \\\"lastName\\\": \\\"Hovy\\\"}, {\\\"creatorType\\\": \\\"author\\\", \\\"firstName\\\": \\\"Shrimai\\\", \\\"lastName\\\": \\\"Prabhumoye\\\"}], \\\"abstractNote\\\": \\\"Recently, there has been an increased interest in demographically grounded bias in natural language processing (NLP) applications. Much of the recent work has focused on describing bias and providing an overview of bias in a larger context. Here, we provide a simple, actionable summary of this recent work. We outline five sources where bias can occur in NLP systems: (1) the data, (2) the annotation process, (3) the input representations, (4) the models, and finally (5) the research design (or how we conceptualize our research). We explore each of the bias sources in detail in this article, including examples and links to related work, as well as potential counter-measures.\\\", \\\"publicationTitle\\\": \\\"Language and Linguistics Compass\\\", \\\"volume\\\": \\\"15\\\", \\\"issue\\\": \\\"8\\\", \\\"pages\\\": \\\"e12432\\\", \\\"date\\\": \\\"2021\\\", \\\"series\\\": \\\"\\\", \\\"seriesTitle\\\": \\\"\\\", \\\"seriesText\\\": \\\"\\\", \\\"journalAbbreviation\\\": \\\"\\\", \\\"language\\\": \\\"en\\\", \\\"DOI\\\": \\\"10.1111/lnc3.12432\\\", \\\"ISSN\\\": \\\"1749-818X\\\", \\\"shortTitle\\\": \\\"\\\", \\\"url\\\": \\\"https://onlinelibrary.wiley.com/doi/abs/10.1111/lnc3.12432\\\", \\\"accessDate\\\": \\\"2024-07-04T12:35:01Z\\\", \\\"archive\\\": \\\"\\\", \\\"archiveLocation\\\": \\\"\\\", \\\"libraryCatalog\\\": \\\"Wiley Online Library\\\", \\\"callNumber\\\": \\\"\\\", \\\"rights\\\": \\\"© 2021 The Authors. Language and Linguistics Compass published by John Wiley & Sons Ltd.\\\", \\\"extra\\\": \\\"_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/lnc3.12432\\\", \\\"tags\\\": [], \\\"collections\\\": [\\\"NQDTJJDN\\\"], \\\"relations\\\": {}, \\\"dateAdded\\\": \\\"2024-07-04T12:35:02Z\\\", \\\"dateModified\\\": \\\"2024-07-04T12:35:02Z\\\"}\"\u001b[0m\n",
       "  \u001b[1m}\u001b[0m,\n",
       "  \u001b[1;34m\"documents\"\u001b[0m: \u001b[32m\"EU High-Level Expert Group on AI. (2019). Ethics guidelines for trustworthy AI. https://ec.europa.eu/newsroom/\\n\\ndae/document.cfm?doc_id=60419\\n\\n\\f14 of 19\\n\\nHOVY and PRABHUMOYE\\n\\nFlek, L. (2020). Returning the N to NLP: Towards contextually personalized classification models. Proceedings of \\nthe 58th Annual Meeting of the Association for Computational Linguistics, 7828–7838. Online: Association for \\nComputational Linguistics. https://www.aclweb.org/anthology/2020.acl-main.700\\n\\nFont, J. E., & Costa-jussà, M. R. (2019). Equalizing gender bias in neural machine translation with word embed-\\ndings techniques. Proceedings of the First Workshop on Gender Bias in Natural Language Processing, 147–154. \\nFlorence, Italy: Association for Computational Linguistics. https://www.aclweb.org/anthology/W19-3821\\nFornaciari, T., Uma, A., Paun, S., Plank, B., Hovy, D., & Poesio, M. (2021). Beyond black & white: Leveraging an-\\nnotator disagreement via soft-label multi-task learning. Proceedings of the 2021 Conference of the North Amer-\\nican  Chapter  of  the  Association  for  Computational  Linguistics:  Human  Language  Technologies,  2591–2597. \\nOnline: Association for Computational Linguistics. https://www.aclweb.org/anthology/2021.naacl-main.204\\nFort, K., Adda, G., & Cohen, K. B. (2011). Last words: Amazon Mechanical Turk: Gold mine or coal mine? Com-\\n\\nputational Linguistics, 37, 413–420. https://www.aclweb.org/anthology/J11-2010\\n\\nFriedler, S. A., Scheidegger, C., & Venkatasubramanian, S. (2021). The (im) possibility of fairness: Different value \\nsystems require different mechanisms for fair decision making. Communications of the ACM, 64, 136–143.\\nFromreide, H., Hovy, D., & Søgaard, A. (2014). Crowdsourcing and annotating NER for Twitter #drift. Proceedings \\nof  the  Ninth  International  Conference  on  Language  Resources  and  Evaluation  (LREC’14),  2544–2547.  Rey-\\nkjavik, Iceland: European Language Resources Association (ELRA). http://www.lrec-conf.org/proceedings/\\nlrec2014/pdf/421_Paper.pdf\\n\\nGarg, N., Schiebinger, L., Jurafsky, D., & Zou, J. (2018). Word embeddings quantify 100 years of gender and ethnic \\n\\nstereotypes. Proceedings of the National Academy of Sciences, 115, E3635–E3644.\\n\\nGarimella, A., Banea, C., Hovy, D., & Mihalcea, R. (2019). Women's syntactic resilience and men's grammatical \\nluck: Gender-bias in part-of-speech tagging and dependency parsing. Proceedings of the 57th Annual Meeting \\nof the Association for Computational Linguistics, 3493–3498. Florence, Italy: Association for Computational \\nLinguistics. https://www.aclweb.org/anthology/P19-1339\\n\\nGoldstein, D. G., & Gigerenzer, G. (2002). Models of ecological rationality: The recognition heuristic. Psychological \\n\\nReview, 109, 75–90.\\n\\nGonen, H., & Goldberg, Y. (2019). Lipstick on a pig: Debiasing methods cover up systematic gender biases in word \\nembeddings but do not remove them. Proceedings of the 2019 Conference of the North American Chapter of the \\nAssociation for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), \\n609–614. https://www.aclweb.org/anthology/N19-1061\\n\\nGrouin, C., Griffon, N., & Névéol, A. (2015). Is it possible to recover personal health information from an auto-\\nmatically de-identified corpus of French EHRs? Proceedings of the Sixth International Workshop on Health \\nText Mining and Information Analysis, 31–39. Lisbon, Portugal: Association for Computational Linguistics. \\nhttps://www.aclweb.org/anthology/W15-2604\\n\\nGururangan, S., Swayamdipta, S., Levy, O., Schwartz, R., Bowman, S. R., & Smith, N. A. (2018). Annotation arti-\\n\\nfacts in natural language inference data. In NAACL-HLT (2).\\n\\nHarwell, D. (2018). The accent gap. Why some accents don’t work on Alexa or Google Home. The Washington Post. \\n\\nhttps://www.washingtonpost.com/graphics/2018/business/alexa-does-not-understand-your-accent/\\n\\nHavens, L., Terras, M., Bach, B., & Alex, B. (2020). Situated data, situated systems: A methodology to engage with \\npower relations in natural language processing research. Proceedings of the Second Workshop on Gender Bias \\nin Natural Language Processing, 107–124. Barcelona, Spain (Online): Association for Computational Linguis-\\ntics. https://www.aclweb.org/anthology/2020.gebnlp-1.10\\n\\nHenrich, J., Heine, S. J., & Norenzayan, A. (2010). The weirdest people in the world? Behavioral and Brain Sciences, \\n\\n33, 61–83.\\n\\nHovy, D. (2015). Demographic factors improve classification performance. Proceedings of the 53rd Annual Meeting \\nof the Association for Computational Linguistics and the 7th International Joint Conference on Natural Lan-\\nguage Processing (Volume 1: Long Papers), 752–762. Beijing, China: Association for Computational Linguis-\\ntics. https://www.aclweb.org/anthology/P15-1073\\n\\nHovy, D., Berg-Kirkpatrick, T., Vaswani, A., & Hovy, E. (2013). Learning whom to trust with mace. Proceedings of \\nthe 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human \\nLanguage Technologies, 1120–1130.\\n\\nHovy, D., Bianchi, F., & Fornaciari, T. (2020). “you sound just like your father” commercial machine translation \\nsystems include stylistic biases. Proceedings of the 58th Annual Meeting of the Association for Computational \\n\\n\\fHOVY and PRABHUMOYE\\n\\n15 of 19\\n\\nLinguistics, 1686–1690. Online: Association for Computational Linguistics. https://www.aclweb.org/anthol-\\nogy/2020.acl-main.154\\n\\nHovy, D., & Søgaard, A. (2015). Tagging performance correlates with author age. Proceedings of the 53rd Annual \\nMeeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural \\nLanguage Processing (Volume 2: Short Papers), 483–488.\\n\\nHovy, D., & Spruit, S. L. (2016). The social impact of natural language processing. Proceedings of the 54th Annual \\nMeeting of the Association for Computational Linguistics (Volume 2: Short Papers), 591–598. Berlin, Germany: \\nAssociation for Computational Linguistics. https://www.aclweb.org/anthology/P16-2096\\n\\nHovy, D., & Yang, D. (2021). The importance of modeling social factors of language: Theory and practice. Proceed-\\nings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: \\nHuman Language Technologies, 588–602. Online: Association for Computational Linguistics. https://www.\\naclweb.org/anthology/2021.naacl-main.49\\n\\nHovy, D., Spruit, S., Mitchell, M., Bender, E. M., Strube, M., & Wallach, H. (Eds.). (2017). Proceedings of the First \\nACL Workshop  on  Ethics  in  Natural  Language  Processing. Valencia,  Spain:  Association  for  Computational \\nLinguistics. https://www.aclweb.org/anthology/W17-1600\\n\\nHoward, A., & Borenstein, J. (2018). The ugly truth about ourselves and our robot creations: The problem of bias \\n\\nand social inequity. Science and Engineering Ethics, 24, 1521–1536.\\n\\nHutchinson, B., Smart, A., Hanna, A., Denton, E., Greer, C., Kjartansson, O., Barnes, P., & Mitchell, M. (2021). To-\\nwards accountability for machine learning datasets: Practices from software engineering and infrastructure. \\nProceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 560–575.\\n\\nJebbara, S., & Cimiano, P. (2019). Zero-shot cross-lingual opinion target extraction. Proceedings of the 2019 Con-\\nference  of  the  North  American  Chapter  of  the  Association  for  Computational  Linguistics:  Human  Language \\nTechnologies, Volume 1 (Long and Short Papers), 2486–2495. Minneapolis, Minnesota: Association for Com-\\nputational Linguistics. https://www.aclweb.org/anthology/N19-1257\\n\\nJohannsen, A., Hovy, D., & Søgaard, A. (2015). Cross-lingual syntactic variation over age and gender. Proceedings \\nof the Nineteenth Conference on Computational Natural Language Learning, 103–112. Beijing, China: Associ-\\nation for Computational Linguistics. https://www.aclweb.org/anthology/K15-1011\\n\\nJørgensen,  A.,  Hovy,  D.,  &  Søgaard,  A.  (2015).  Challenges  of  studying  and  processing  dialects  in  social  media. \\n\\nProceedings of the Workshop on Noisy User-generated Text, 9–18.\\n\\nJoshi, P., Santy, S., Budhiraja, A., Bali, K., & Choudhury, M. (2020). The state and fate of linguistic diversity and \\ninclusion  in  the  NLP  world.  Proceedings  of  the  58th  Annual  Meeting  of  the  Association  for  Computational \\nLinguistics, 6282–6293. Online: Association for Computational Linguistics. https://www.aclweb.org/anthol-\\nogy/2020.acl-main.560\\n\\nJurgens, D., Tsvetkov, Y., & Jurafsky, D. (2017). Writer profiling without the writer's text. In G. L. Ciampaglia, A. \\n\\nMashhadi, & T. Yasseri (Eds.), Social informatics (pp. 537–558). Springer International Publishing.\\n\\nKennedy, B., Jin, X., Mostafazadeh Davani, A., Dehghani, M., & Ren, X. (2020). Contextualizing hate speech clas-\\nsifiers with post-hoc explanation. Proceedings of the 58th Annual Meeting of the Association for Computational \\nLinguistics, 5435–5442. Online: Association for Computational Linguistics. https://www.aclweb.org/anthol-\\nogy/2020.acl-main.483\"\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 3\n",
    "\n",
    "console.print_json(data=result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "23888ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ids', 'embeddings', 'documents', 'uris', 'data', 'metadatas', 'distances', 'included'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76050e99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
