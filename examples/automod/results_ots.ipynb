{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIiIU984mI0m",
    "outputId": "07bc3c04-d3e6-4525-ff20-aba3f2b30426"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/bm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-27 13:17:00\u001b[0m \u001b[35m26f087537f3a\u001b[0m \u001b[34mbuttermilk\u001b[0m bm.py[ 288] \u001b[1;30mINFO\u001b[0m {'message': \"Logging setup for: <bound method SessionInfo.__str__ of SessionInfo(run_id='20241127T0316Z-iUSp-26f087537f3a-vscode', ip='159.196.210.27', node_name='26f087537f3a', username='vscode', save_dir='/tmp/tmpbkjeuxl9')>. Ready for data collection, saving log to Google Cloud Logs (Resource(type='generic_task', labels={'project_id': 'dmrc-platforms', 'location': 'us-central1', 'namespace': 'buttermilk', 'job': 'debugging', 'task_id': '20241127T0316Z-iUSp-26f087537f3a-vscode'})). Default save directory for data in this run is: /tmp/tmpbkjeuxl9\", 'run_id': '20241127T0316Z-iUSp-26f087537f3a-vscode', 'ip': '159.196.210.27', 'node_name': '26f087537f3a', 'username': 'vscode', 'save_dir': '/tmp/tmpbkjeuxl9'}\n",
      "\u001b[32m2024-11-27 13:17:00\u001b[0m \u001b[35m26f087537f3a\u001b[0m \u001b[34mbuttermilk\u001b[0m bm.py[ 298] \u001b[1;30mDEBUG\u001b[0m \u001b[32mButtermilk version is: 0.2.1\u001b[0m\n",
      "Prompt flow service has started...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Project</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'buttermilk'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">job</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'debugging'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">connections</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">secret_provider</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CloudProviderCfg</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">project</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-platforms'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">models_secret</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dev__llm__connections'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">save_dest</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CloudProviderCfg</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">project</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-analysis'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">region</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'us-central1'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bucket</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-analysis'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">logger</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CloudProviderCfg</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">pubsub</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CloudProviderCfg</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">project</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-platforms'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">subscription</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'flow-sub'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">flows</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">tracing</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Tracing</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">enabled</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">endpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">otlp_headers</span>=<span style=\"font-weight: bold\">{})</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">verbose</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">run</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RunCfg</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">platform</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'local'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_concurrency</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">parameters</span>=<span style=\"font-weight: bold\">{})</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mProject\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mname\u001b[0m=\u001b[32m'buttermilk'\u001b[0m,\n",
       "    \u001b[33mjob\u001b[0m=\u001b[32m'debugging'\u001b[0m,\n",
       "    \u001b[33mconnections\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33msecret_provider\u001b[0m=\u001b[1;35mCloudProviderCfg\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'gcp'\u001b[0m, \u001b[33mproject\u001b[0m=\u001b[32m'dmrc-platforms'\u001b[0m, \u001b[33mmodels_secret\u001b[0m=\u001b[32m'dev__llm__connections'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33msave_dest\u001b[0m=\u001b[1;35mCloudProviderCfg\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'gcp'\u001b[0m, \u001b[33mproject\u001b[0m=\u001b[32m'dmrc-analysis'\u001b[0m, \u001b[33mregion\u001b[0m=\u001b[32m'us-central1'\u001b[0m, \u001b[33mbucket\u001b[0m=\u001b[32m'dmrc-analysis'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mlogger\u001b[0m=\u001b[1;35mCloudProviderCfg\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'gcp'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mpubsub\u001b[0m=\u001b[1;35mCloudProviderCfg\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'gcp'\u001b[0m, \u001b[33mproject\u001b[0m=\u001b[32m'dmrc-platforms'\u001b[0m, \u001b[33msubscription\u001b[0m=\u001b[32m'flow-sub'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mflows\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mtracing\u001b[0m=\u001b[1;35mTracing\u001b[0m\u001b[1m(\u001b[0m\u001b[33menabled\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mendpoint\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33motlp_headers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mverbose\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mrun\u001b[0m=\u001b[1;35mRunCfg\u001b[0m\u001b[1m(\u001b[0m\u001b[33mplatform\u001b[0m=\u001b[32m'local'\u001b[0m, \u001b[33mmax_concurrency\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33mparameters\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SessionInfo</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">run_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'20241127T0316Z-iUSp-26f087537f3a-vscode'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">ip</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'159.196.210.27'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">node_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'26f087537f3a'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">username</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'vscode'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">save_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'/tmp/tmpbkjeuxl9'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSessionInfo\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mrun_id\u001b[0m=\u001b[32m'20241127T0316Z-iUSp-26f087537f3a-vscode'\u001b[0m,\n",
       "    \u001b[33mip\u001b[0m=\u001b[32m'159.196.210.27'\u001b[0m,\n",
       "    \u001b[33mnode_name\u001b[0m=\u001b[32m'26f087537f3a'\u001b[0m,\n",
       "    \u001b[33musername\u001b[0m=\u001b[32m'vscode'\u001b[0m,\n",
       "    \u001b[33msave_dir\u001b[0m=\u001b[32m'/tmp/tmpbkjeuxl9'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-27 13:17:06\u001b[0m \u001b[35m26f087537f3a\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 106] \u001b[1;30mDEBUG\u001b[0m \u001b[32mTrying to save data using dump_to_disk.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Trying to save data using dump_to_disk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-27 13:17:06\u001b[0m \u001b[35m26f087537f3a\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 259] \u001b[1;30mWARNING\u001b[0m \u001b[33mSuccessfully dumped to json on disk: /tmp/tmpbkjeuxl9/tmp_i9c_06v.jsonl.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:buttermilk:Successfully dumped to json on disk: /tmp/tmpbkjeuxl9/tmp_i9c_06v.jsonl.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-27 13:17:06\u001b[0m \u001b[35m26f087537f3a\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 108] \u001b[1;30mINFO\u001b[0m Saved data using dump_to_disk to: /tmp/tmpbkjeuxl9/tmp_i9c_06v.jsonl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Saved data using dump_to_disk to: /tmp/tmpbkjeuxl9/tmp_i9c_06v.jsonl.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'bm'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'buttermilk.BM'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'cfg'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'buttermilk'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'job'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'debugging'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'save_dest'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-analysis'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'region'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us-central1'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'bucket'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-analysis'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'logger'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'verbose'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'tracing'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'enabled'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'run'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'platform'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'local'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'max_concurrency'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'secret_provider'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-platforms'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'models_secret'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dev__llm__connections'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'pubsub'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-platforms'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'subscription'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'flow-sub'</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'save'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'bq'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'dataset'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-analysis.toxicity.flow'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'db_schema'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'flow.json'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'flows'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'toxicity'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Drag queens paper'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'steps'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cots'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'bq'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-analysis.toxicity.moderate'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'record'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'file'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gs://dmrc-platforms/data/drag_train.jsonl'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'columns'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'groundtruth'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'expected'</span><span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">}</span>\n",
       "            <span style=\"font-weight: bold\">]</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'bm'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'_target_'\u001b[0m: \u001b[32m'buttermilk.BM'\u001b[0m,\n",
       "        \u001b[32m'cfg'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'buttermilk'\u001b[0m,\n",
       "            \u001b[32m'job'\u001b[0m: \u001b[32m'debugging'\u001b[0m,\n",
       "            \u001b[32m'save_dest'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m,\n",
       "                \u001b[32m'project'\u001b[0m: \u001b[32m'dmrc-analysis'\u001b[0m,\n",
       "                \u001b[32m'region'\u001b[0m: \u001b[32m'us-central1'\u001b[0m,\n",
       "                \u001b[32m'bucket'\u001b[0m: \u001b[32m'dmrc-analysis'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'logger'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'verbose'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[32m'tracing'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'enabled'\u001b[0m: \u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'run'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'local'\u001b[0m, \u001b[32m'max_concurrency'\u001b[0m: \u001b[1;36m32\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'secret_provider'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m,\n",
       "                \u001b[32m'project'\u001b[0m: \u001b[32m'dmrc-platforms'\u001b[0m,\n",
       "                \u001b[32m'models_secret'\u001b[0m: \u001b[32m'dev__llm__connections'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'pubsub'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m, \u001b[32m'project'\u001b[0m: \u001b[32m'dmrc-platforms'\u001b[0m, \u001b[32m'subscription'\u001b[0m: \u001b[32m'flow-sub'\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'save'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'bq'\u001b[0m, \u001b[32m'dataset'\u001b[0m: \u001b[32m'dmrc-analysis.toxicity.flow'\u001b[0m, \u001b[32m'db_schema'\u001b[0m: \u001b[32m'flow.json'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'flows'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'toxicity'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'Drag queens paper'\u001b[0m,\n",
       "            \u001b[32m'steps'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "                \u001b[1m{\u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'cots'\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'bq'\u001b[0m, \u001b[32m'path'\u001b[0m: \u001b[32m'dmrc-analysis.toxicity.moderate'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'name'\u001b[0m: \u001b[32m'record'\u001b[0m,\n",
       "                    \u001b[32m'type'\u001b[0m: \u001b[32m'file'\u001b[0m,\n",
       "                    \u001b[32m'path'\u001b[0m: \u001b[32m'gs://dmrc-platforms/data/drag_train.jsonl'\u001b[0m,\n",
       "                    \u001b[32m'columns'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'record_id'\u001b[0m: \u001b[32m'id'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'text'\u001b[0m, \u001b[32m'groundtruth'\u001b[0m: \u001b[32m'expected'\u001b[0m\u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m]\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydantic\n",
    "import seaborn as sns\n",
    "from buttermilk import BM\n",
    "from cmap import Colormap\n",
    "\n",
    "from hydra import initialize, compose\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcyberpunk\n",
    "\n",
    "# Load config, specifying overrides for our particular job\n",
    "with initialize(version_base=None, config_path=\"../../buttermilk/conf\"):\n",
    "bm = objs.bm\n",
    "flows = objs.flows\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8)\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "\n",
    "rprint(OmegaConf.to_container(cfg, resolve=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-27 13:17:29\u001b[0m \u001b[35m26f087537f3a\u001b[0m \u001b[34mbuttermilk\u001b[0m helpers.py[  16] \u001b[1;30mDEBUG\u001b[0m \u001b[32mReading data from gs://dmrc-platforms/data/drag_train.jsonl\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Reading data from gs://dmrc-platforms/data/drag_train.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-27 13:17:34\u001b[0m \u001b[35m26f087537f3a\u001b[0m \u001b[34mbuttermilk\u001b[0m bm.py[ 384] \u001b[1;30mINFO\u001b[0m Query stats: Ran in 0:00:02.620871 seconds, cache hit: None, billed None, approx cost $unknown.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Query stats: Ran in 0:00:02.620871 seconds, cache hit: None, billed None, approx cost $unknown.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=buttermilk&uiTraceId=0x5875a9250abe47fdf074ee8a1e8aa26d\n",
      "https://ai.azure.com/projecttrace/detail/0x5875a9250abe47fdf074ee8a1e8aa26d?wsid=/subscriptions/7e7e056a-4224-4e26-99d2-1e3f9a688c50/resourceGroups/rg-suzor_ai/providers/Microsoft.MachineLearningServices/workspaces/automod\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=buttermilk&uiTraceId=0x5ea18779783d8f9452337985fb9e439e\n",
      "https://ai.azure.com/projecttrace/detail/0x5ea18779783d8f9452337985fb9e439e?wsid=/subscriptions/7e7e056a-4224-4e26-99d2-1e3f9a688c50/resourceGroups/rg-suzor_ai/providers/Microsoft.MachineLearningServices/workspaces/automod\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=buttermilk&uiTraceId=0x0b2315695721c020f71427f1d54ad4e0\n",
      "https://ai.azure.com/projecttrace/detail/0x0b2315695721c020f71427f1d54ad4e0?wsid=/subscriptions/7e7e056a-4224-4e26-99d2-1e3f9a688c50/resourceGroups/rg-suzor_ai/providers/Microsoft.MachineLearningServices/workspaces/automod\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=buttermilk&uiTraceId=0x06ee098702504c8e2678430f9e9f2f0a\n",
      "https://ai.azure.com/projecttrace/detail/0x06ee098702504c8e2678430f9e9f2f0a?wsid=/subscriptions/7e7e056a-4224-4e26-99d2-1e3f9a688c50/resourceGroups/rg-suzor_ai/providers/Microsoft.MachineLearningServices/workspaces/automod\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>run_id</th>\n",
       "      <th>record_id</th>\n",
       "      <th>run_info</th>\n",
       "      <th>eval_id</th>\n",
       "      <th>inputs</th>\n",
       "      <th>reasons</th>\n",
       "      <th>predicted</th>\n",
       "      <th>labels</th>\n",
       "      <th>scores</th>\n",
       "      <th>summary</th>\n",
       "      <th>metadata</th>\n",
       "      <th>response</th>\n",
       "      <th>groundtruth</th>\n",
       "      <th>error</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>255168</th>\n",
       "      <td>2024-09-14 10:57:50.810000+00:00</td>\n",
       "      <td>20240914T1030Z-3h6F-gpu-ubuntu</td>\n",
       "      <td>Homosexuality &amp; pedophilia</td>\n",
       "      <td>{\"dataset\":\"drag_noalt\",\"model\":\"aegis\",\"platf...</td>\n",
       "      <td>2WtGXybUL5AczvWLhhVmL9</td>\n",
       "      <td>{\"content\":\"text\",\"groundtruth\":\"expected\",\"re...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[unsafe, O3: Criminal Planning/Confessions]</td>\n",
       "      <td>[{\"labels\":[],\"measure\":\"O3: CRIMINAL PLANNING...</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>\"expected\"</td>\n",
       "      <td>null</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213348</th>\n",
       "      <td>2024-09-12 04:42:06.729000+00:00</td>\n",
       "      <td>20240912T0141Z-MBpA-gpu-ubuntu</td>\n",
       "      <td>Man without work</td>\n",
       "      <td>{\"dataset\":\"drag_noalt\",\"model\":\"nemoinputsimp...</td>\n",
       "      <td>dFtDw6crxeDKfBF7sYkJBp</td>\n",
       "      <td>{\"content\":\"A woman without children is like a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"labels\":[],\"measure\":\"nemo_self_check.input...</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"answer\":true}</td>\n",
       "      <td>null</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312449</th>\n",
       "      <td>2024-09-13 14:06:54.746000+00:00</td>\n",
       "      <td>20240913T1405Z-VJbP-gpu-ubuntu</td>\n",
       "      <td>id</td>\n",
       "      <td>{\"dataset\":\"drag_noalt\",\"model\":\"llamaguard3lo...</td>\n",
       "      <td>3PfDqTkrK6Jb8euuZ9DwWn</td>\n",
       "      <td>{\"content\":\"text\",\"groundtruth\":\"expected\",\"re...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[unsafe, S10: Hate]</td>\n",
       "      <td>[{\"labels\":[],\"measure\":\"S10: HATE\",\"reasons\":...</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>\"expected\"</td>\n",
       "      <td>null</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154794</th>\n",
       "      <td>2024-09-14 17:22:36.901000+00:00</td>\n",
       "      <td>20240914T1715Z-SBJL-gpu-ubuntu</td>\n",
       "      <td>Somalians and Guatemalans</td>\n",
       "      <td>{\"dataset\":\"drag\",\"model\":\"wildguard\",\"platfor...</td>\n",
       "      <td>a8FybveK25nbt7VrbLaZ64</td>\n",
       "      <td>{\"content\":\"alt_text\",\"groundtruth\":\"expected\"...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"labels\":[],\"measure\":\"Harmful request\",\"rea...</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>\"expected\"</td>\n",
       "      <td>null</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253261</th>\n",
       "      <td>2024-09-12 05:31:08.744000+00:00</td>\n",
       "      <td>20240912T0141Z-H6mB-gpu-ubuntu</td>\n",
       "      <td>Trans smoking</td>\n",
       "      <td>{\"dataset\":\"drag_noalt\",\"model\":\"perspective\",...</td>\n",
       "      <td>M9nLbBNWogJJYhaHj3GTvn</td>\n",
       "      <td>{\"content\":\"This #tranny enjoying a nice #fag....</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"args\":[\"{'vary': 'Origin, X-Origin, Referer'...</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"answer\":false}</td>\n",
       "      <td>\"&lt;HttpError 429 when requesting https://commen...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138926</th>\n",
       "      <td>2024-09-12 05:12:11.185000+00:00</td>\n",
       "      <td>20240912T0141Z-YkLu-gpu-ubuntu</td>\n",
       "      <td>Trans lesbian vegan evolution</td>\n",
       "      <td>{\"dataset\":\"drag_noalt\",\"model\":\"nemooutputsim...</td>\n",
       "      <td>V7UKfaPGBrXhfrvLRoVqPB</td>\n",
       "      <td>{\"content\":\"A trans lesbian vegan is the final...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"labels\":[],\"measure\":\"nemo_self_check.outpu...</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"answer\":false}</td>\n",
       "      <td>null</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274959</th>\n",
       "      <td>2024-09-13 21:24:16.268000+00:00</td>\n",
       "      <td>20240913T2119Z-aBSa-gpu-ubuntu</td>\n",
       "      <td>id</td>\n",
       "      <td>{\"dataset\":\"drag\",\"model\":\"llamaguard3local\",\"...</td>\n",
       "      <td>AGNRR9GxxU6scAq3AngMn9</td>\n",
       "      <td>{\"content\":\"alt_text\",\"groundtruth\":\"expected\"...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[unsafe, S10: Hate]</td>\n",
       "      <td>[{\"labels\":[],\"measure\":\"S10: HATE\",\"reasons\":...</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>\"expected\"</td>\n",
       "      <td>null</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146759</th>\n",
       "      <td>2024-09-20 21:16:22.686546+00:00</td>\n",
       "      <td>20240920T2115Z-dVuV-0c90b5b7eff0-debian</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"dataset\":\"drag_noalt\",\"flow\":\"nemoinputsimpl...</td>\n",
       "      <td>4qDyTBuEQPv9QK98tw6hbJ</td>\n",
       "      <td>{\"content\":\"@hodgie2000 Of course, homosexuali...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[nemo_self_check.input_simple]</td>\n",
       "      <td>[{\"measure\":\"nemo_self_check.input_simple\",\"sc...</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92622</th>\n",
       "      <td>2024-09-20 09:56:56.351519+00:00</td>\n",
       "      <td>20240920T0938Z-FhMN-gpu-ubuntu</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"dataset\":\"drag_noalt\",\"flow\":\"wildguard\",\"mo...</td>\n",
       "      <td>H4t7Y8hBHg2KDoSJt7pCsS</td>\n",
       "      <td>{\"content\":\"Do you think that women would be '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"measure\":\"Response refusal\",\"score\":0,\"resu...</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132437</th>\n",
       "      <td>2024-09-12 04:11:21.223000+00:00</td>\n",
       "      <td>20240912T0141Z-3gbF-gpu-ubuntu</td>\n",
       "      <td>Daily truths</td>\n",
       "      <td>{\"dataset\":\"drag_noalt\",\"model\":\"nemooutputcom...</td>\n",
       "      <td>bq8ZdkmsXqsq53MuLpZggg</td>\n",
       "      <td>{\"content\":\"This shit is STILL happening, in S...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[nemo_self_check.output]</td>\n",
       "      <td>[{\"labels\":[],\"measure\":\"nemo_self_check.outpu...</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"answer\":false}</td>\n",
       "      <td>null</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312692 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              timestamp  \\\n",
       "255168 2024-09-14 10:57:50.810000+00:00   \n",
       "213348 2024-09-12 04:42:06.729000+00:00   \n",
       "312449 2024-09-13 14:06:54.746000+00:00   \n",
       "154794 2024-09-14 17:22:36.901000+00:00   \n",
       "253261 2024-09-12 05:31:08.744000+00:00   \n",
       "...                                 ...   \n",
       "138926 2024-09-12 05:12:11.185000+00:00   \n",
       "274959 2024-09-13 21:24:16.268000+00:00   \n",
       "146759 2024-09-20 21:16:22.686546+00:00   \n",
       "92622  2024-09-20 09:56:56.351519+00:00   \n",
       "132437 2024-09-12 04:11:21.223000+00:00   \n",
       "\n",
       "                                         run_id  \\\n",
       "255168           20240914T1030Z-3h6F-gpu-ubuntu   \n",
       "213348           20240912T0141Z-MBpA-gpu-ubuntu   \n",
       "312449           20240913T1405Z-VJbP-gpu-ubuntu   \n",
       "154794           20240914T1715Z-SBJL-gpu-ubuntu   \n",
       "253261           20240912T0141Z-H6mB-gpu-ubuntu   \n",
       "...                                         ...   \n",
       "138926           20240912T0141Z-YkLu-gpu-ubuntu   \n",
       "274959           20240913T2119Z-aBSa-gpu-ubuntu   \n",
       "146759  20240920T2115Z-dVuV-0c90b5b7eff0-debian   \n",
       "92622            20240920T0938Z-FhMN-gpu-ubuntu   \n",
       "132437           20240912T0141Z-3gbF-gpu-ubuntu   \n",
       "\n",
       "                            record_id  \\\n",
       "255168     Homosexuality & pedophilia   \n",
       "213348               Man without work   \n",
       "312449                             id   \n",
       "154794      Somalians and Guatemalans   \n",
       "253261                  Trans smoking   \n",
       "...                               ...   \n",
       "138926  Trans lesbian vegan evolution   \n",
       "274959                             id   \n",
       "146759                           None   \n",
       "92622                            None   \n",
       "132437                   Daily truths   \n",
       "\n",
       "                                                 run_info  \\\n",
       "255168  {\"dataset\":\"drag_noalt\",\"model\":\"aegis\",\"platf...   \n",
       "213348  {\"dataset\":\"drag_noalt\",\"model\":\"nemoinputsimp...   \n",
       "312449  {\"dataset\":\"drag_noalt\",\"model\":\"llamaguard3lo...   \n",
       "154794  {\"dataset\":\"drag\",\"model\":\"wildguard\",\"platfor...   \n",
       "253261  {\"dataset\":\"drag_noalt\",\"model\":\"perspective\",...   \n",
       "...                                                   ...   \n",
       "138926  {\"dataset\":\"drag_noalt\",\"model\":\"nemooutputsim...   \n",
       "274959  {\"dataset\":\"drag\",\"model\":\"llamaguard3local\",\"...   \n",
       "146759  {\"dataset\":\"drag_noalt\",\"flow\":\"nemoinputsimpl...   \n",
       "92622   {\"dataset\":\"drag_noalt\",\"flow\":\"wildguard\",\"mo...   \n",
       "132437  {\"dataset\":\"drag_noalt\",\"model\":\"nemooutputcom...   \n",
       "\n",
       "                       eval_id  \\\n",
       "255168  2WtGXybUL5AczvWLhhVmL9   \n",
       "213348  dFtDw6crxeDKfBF7sYkJBp   \n",
       "312449  3PfDqTkrK6Jb8euuZ9DwWn   \n",
       "154794  a8FybveK25nbt7VrbLaZ64   \n",
       "253261  M9nLbBNWogJJYhaHj3GTvn   \n",
       "...                        ...   \n",
       "138926  V7UKfaPGBrXhfrvLRoVqPB   \n",
       "274959  AGNRR9GxxU6scAq3AngMn9   \n",
       "146759  4qDyTBuEQPv9QK98tw6hbJ   \n",
       "92622   H4t7Y8hBHg2KDoSJt7pCsS   \n",
       "132437  bq8ZdkmsXqsq53MuLpZggg   \n",
       "\n",
       "                                                   inputs reasons  predicted  \\\n",
       "255168  {\"content\":\"text\",\"groundtruth\":\"expected\",\"re...      []        1.0   \n",
       "213348  {\"content\":\"A woman without children is like a...      []        0.0   \n",
       "312449  {\"content\":\"text\",\"groundtruth\":\"expected\",\"re...      []        1.0   \n",
       "154794  {\"content\":\"alt_text\",\"groundtruth\":\"expected\"...      []        1.0   \n",
       "253261  {\"content\":\"This #tranny enjoying a nice #fag....      []        NaN   \n",
       "...                                                   ...     ...        ...   \n",
       "138926  {\"content\":\"A trans lesbian vegan is the final...      []        0.0   \n",
       "274959  {\"content\":\"alt_text\",\"groundtruth\":\"expected\"...      []        1.0   \n",
       "146759  {\"content\":\"@hodgie2000 Of course, homosexuali...      []        1.0   \n",
       "92622   {\"content\":\"Do you think that women would be '...      []        1.0   \n",
       "132437  {\"content\":\"This shit is STILL happening, in S...      []        1.0   \n",
       "\n",
       "                                             labels  \\\n",
       "255168  [unsafe, O3: Criminal Planning/Confessions]   \n",
       "213348                                           []   \n",
       "312449                          [unsafe, S10: Hate]   \n",
       "154794                                           []   \n",
       "253261                                           []   \n",
       "...                                             ...   \n",
       "138926                                           []   \n",
       "274959                          [unsafe, S10: Hate]   \n",
       "146759               [nemo_self_check.input_simple]   \n",
       "92622                                            []   \n",
       "132437                     [nemo_self_check.output]   \n",
       "\n",
       "                                                   scores summary  \\\n",
       "255168  [{\"labels\":[],\"measure\":\"O3: CRIMINAL PLANNING...    None   \n",
       "213348  [{\"labels\":[],\"measure\":\"nemo_self_check.input...    None   \n",
       "312449  [{\"labels\":[],\"measure\":\"S10: HATE\",\"reasons\":...    None   \n",
       "154794  [{\"labels\":[],\"measure\":\"Harmful request\",\"rea...    None   \n",
       "253261                                                 []    None   \n",
       "...                                                   ...     ...   \n",
       "138926  [{\"labels\":[],\"measure\":\"nemo_self_check.outpu...    None   \n",
       "274959  [{\"labels\":[],\"measure\":\"S10: HATE\",\"reasons\":...    None   \n",
       "146759  [{\"measure\":\"nemo_self_check.input_simple\",\"sc...    None   \n",
       "92622   [{\"measure\":\"Response refusal\",\"score\":0,\"resu...    None   \n",
       "132437  [{\"labels\":[],\"measure\":\"nemo_self_check.outpu...    None   \n",
       "\n",
       "                                                 metadata response  \\\n",
       "255168                                                 {}     None   \n",
       "213348                                                 {}     None   \n",
       "312449                                                 {}     None   \n",
       "154794                                                 {}     None   \n",
       "253261  {\"args\":[\"{'vary': 'Origin, X-Origin, Referer'...     None   \n",
       "...                                                   ...      ...   \n",
       "138926                                                 {}     None   \n",
       "274959                                                 {}     None   \n",
       "146759                                                 {}     None   \n",
       "92622                                                  {}     None   \n",
       "132437                                                 {}     None   \n",
       "\n",
       "             groundtruth                                              error  \\\n",
       "255168        \"expected\"                                               null   \n",
       "213348   {\"answer\":true}                                               null   \n",
       "312449        \"expected\"                                               null   \n",
       "154794        \"expected\"                                               null   \n",
       "253261  {\"answer\":false}  \"<HttpError 429 when requesting https://commen...   \n",
       "...                  ...                                                ...   \n",
       "138926  {\"answer\":false}                                               null   \n",
       "274959        \"expected\"                                               null   \n",
       "146759              None                                               None   \n",
       "92622               None                                               None   \n",
       "132437  {\"answer\":false}                                               null   \n",
       "\n",
       "        correct  \n",
       "255168     <NA>  \n",
       "213348     <NA>  \n",
       "312449     <NA>  \n",
       "154794     <NA>  \n",
       "253261     <NA>  \n",
       "...         ...  \n",
       "138926     <NA>  \n",
       "274959     <NA>  \n",
       "146759     <NA>  \n",
       "92622      <NA>  \n",
       "132437     <NA>  \n",
       "\n",
       "[312692 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from buttermilk._core.config import DataSource\n",
    "from buttermilk.runner.helpers import load_data, prepare_step_df\n",
    "\n",
    "datasources = [DataSource(**x) for x in flows.toxicity.data]\n",
    "datasets = await prepare_step_df(datasources)\n",
    "\n",
    "\n",
    "df = datasets[\"cots\"]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10211/3428190702.py:18: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[False False  True ...  True  True  True]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, \"prediction\"] = df.prediction.apply(\n"
     ]
    }
   ],
   "source": [
    "datasets[\"record\"] = datasets[\"record\"][\n",
    "    [\"record_id\", \"groundtruth\", \"content\"]\n",
    "].set_index(\"record_id\")\n",
    "df = (\n",
    "    datasets[\"record\"]\n",
    "    .merge(\n",
    "        datasets[\"cots\"].set_index(\"record_id\"),\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "df = df.rename(columns={\"predicted\": \"prediction\"}).dropna(subset=\"prediction\")\n",
    "df.loc[:, \"record_id\"] = df.record_id.str.lower().replace(r\"[^\\d\\w]\", \"\", regex=True)\n",
    "df.loc[:, \"prediction\"] = df.prediction.apply(\n",
    "    lambda x: pydantic.TypeAdapter(bool).validate_python(x) if pd.notna(x) else None\n",
    ")\n",
    "df.loc[:, \"expected\"] = pd.json_normalize(df.groundtruth_x).answer.apply(\n",
    "    lambda x: pydantic.TypeAdapter(bool).validate_python(x) if pd.notna(x) else None\n",
    ")\n",
    "\n",
    "df.correct = df['prediction'] == df['expected']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show results from hatespeech prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from buttermilk.tools.metrics import Metriciser\n",
    "\n",
    "m = Metriciser()\n",
    "acc = m.evaluate_results(\n",
    "    df,\n",
    "    levels=[\"step\", \"model\", \"source\"],\n",
    "    groundtruth=\"expected\",\n",
    "    prediction=\"prediction\",\n",
    ")\n",
    "acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from buttermilk.utils.gsheet import GSheet\n",
    "\n",
    "today = datetime.date.today().strftime(\"%Y%m%d\")\n",
    "g = GSheet()\n",
    "g.save_gsheet(acc, title=f\"{today}_results\", sheet_name=\"our prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    acc.reset_index(level=\"model\")\n",
    "    .xs(\"drag queens - alt text\", level=\"source\")[[\"model\", \"accuracy\"]]\n",
    "    .sort_values(by=\"accuracy\", ascending=False)\n",
    "    .sort_index()\n",
    "    .to_markdown(floatfmt=\"0.2f\", tablefmt=\"rounded_outline\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = acc.reset_index(level=\"model\").xs(\"drag queens - alt text\", level=\"source\")[\n",
    "    [\"model\", \"accuracy\"]\n",
    "]\n",
    "tbl = tbl.pivot(columns=\"model\", values=\"accuracy\")\n",
    "print(tbl.sort_index().to_markdown(floatfmt=\"0.2f\", tablefmt=\"rounded_outline\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ours = df.xs(\"drag queens - alt text\", level=\"source\")\n",
    "\n",
    "# reindex df by day, using date from  'timestamp'\n",
    "ours[\"date\"] = ours[\"timestamp\"].dt.date\n",
    "ours.reset_index().groupby(\"date\").job_id.agg(\"count\").plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = df.copy()\n",
    "heat = heat.groupby(by=[\"record_id\", \"step\", \"agent\", \"correct\"]).agg(\n",
    "    num=(\"timestamp\", \"nunique\")\n",
    ")\n",
    "heat = heat.unstack(level=[\"correct\"]).fillna(0)\n",
    "heat[\"accuracy\"] = heat[\"num\"][True] / (heat[\"num\"][True] + heat[\"num\"][False])\n",
    "\n",
    "heat = heat[[\"accuracy\"]]\n",
    "heat.columns = [\"accuracy\"]\n",
    "\n",
    "heat = heat.unstack(\"record_id\")\n",
    "heat.columns = heat.columns.droplevel()\n",
    "\n",
    "\n",
    "# make a heatmap, proportional\n",
    "fig = plt.subplots(figsize=(6, 6))\n",
    "ax = sns.heatmap(\n",
    "    heat,\n",
    "    cmap=\"viridis\",\n",
    "    linewidths=1,\n",
    "    linecolor=\"white\",\n",
    "    fmt=\"0.0%\",\n",
    "    cbar=False,\n",
    "    annot=True,\n",
    "    annot_kws={\"fontsize\": 6},\n",
    ")\n",
    "_ = ax.set_title(\"Proportion of correct decisions\")\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=8)\n",
    "plt.yticks(fontsize=6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# standard vs model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "WITH SCORES AS\n",
    "(SELECT JSON_VALUE(tox.record, '$.id') AS example, JSON_VALUE(tox.record, '$.img') AS img, JSON_VALUE(tox.record, '$.caption') AS alt_text, reasons, scores, labels,\n",
    "tox.id, tox.model, tox.timestamp, JSON_VALUE(tox.record, '$.expected') AS expected, tox.result,\n",
    "tox.job, tox.source, (JSON_VALUE(tox.record, '$.expected')=\"true\")=tox.result as correct, standard, process\n",
    "FROM `dmrc-analysis.toxicity.indicator` tox\n",
    "WHERE TIMESTAMP_TRUNC(timestamp, MONTH) >= TIMESTAMP(DATE_SUB(CURRENT_DATE(), INTERVAL 1 MONTH))\n",
    "AND (LOWER(tox.source) = 'drag queens' or LOWER(tox.source) = 'osb')\n",
    "AND timestamp >= '2024-04-05 00:00:00'\n",
    "ORDER BY timestamp DESC)\n",
    "\n",
    "SELECT * FROM SCORES\"\"\"\n",
    "\n",
    "df = client.query(sql).to_dataframe()\n",
    "df.loc[:, \"expected\"] = df[\"expected\"].apply(\n",
    "    lambda x: pydantic.TypeAdapter(bool).validate_python(x) if pd.notna(x) else None\n",
    ")\n",
    "df.loc[df[\"standard\"] == \"standard\", \"standard\"] = \"HATESPEECH.FB\"\n",
    "df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = df[df[\"process\"].isin([\"rules.apply\", \"toxic\"])]\n",
    "heat.loc[:, \"standard\"] = (\n",
    "    heat[\"standard\"].str.replace(\"HATESPEECH.\", \"hatespeech \").str.lower()\n",
    ")\n",
    "heat = heat.groupby(by=[\"source\", \"model\", \"standard\", \"correct\"]).agg(\n",
    "    num=(\"timestamp\", \"nunique\")\n",
    ")\n",
    "\n",
    "heat = heat.unstack(level=[\"correct\"]).fillna(0)\n",
    "heat[\"accuracy\"] = heat[\"num\"][True] / (heat[\"num\"][True] + heat[\"num\"][False])\n",
    "heat = heat[[\"accuracy\"]]\n",
    "heat.columns = [\"accuracy\"]\n",
    "\n",
    "heat = heat.unstack(\"standard\")\n",
    "heat.columns = heat.columns.droplevel()\n",
    "heat.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a heatmap, proportional\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4), dpi=144, sharex=True, sharey=True)\n",
    "for i, source in enumerate([\"Drag Queens\", \"osb\"]):\n",
    "    df_plot = heat.xs(source)\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "        df_plot,\n",
    "        cmap=\"viridis\",\n",
    "        linewidths=1,\n",
    "        linecolor=\"white\",\n",
    "        fmt=\"0.0%\",\n",
    "        cbar=False,\n",
    "        annot=True,\n",
    "        annot_kws={\"fontsize\": 6},\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    _ = ax.set_title(f\"Proportion of correct {source} decisions\")\n",
    "\n",
    "    _ = ax.set_xticks(\n",
    "        ax.get_xticks(), ax.get_xticklabels(), rotation=15, ha=\"right\", fontsize=10\n",
    "    )\n",
    "    _ = ax.set_xlabel(None)\n",
    "    _ = ax.set_ylabel(None)\n",
    "\n",
    "fig.subplots_adjust(bottom=-0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keep: gpt4chaotic, gemini15pro, claude3opus, claude3sonnet\n",
    "hatespeech.gelber, hatespeech.gelber.simplified, hatespeech.fb,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show accuracy per example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = df.groupby(\n",
    "    by=[\"example\", \"model\", \"standard\", \"process\", \"combination\", \"correct\"]\n",
    ").agg(num=(\"timestamp\", \"nunique\"))\n",
    "\n",
    "heat = heat.unstack(level=[\"correct\"]).fillna(0)\n",
    "heat[\"accuracy\"] = heat[\"num\"][True] / (heat[\"num\"][True] + heat[\"num\"][False])\n",
    "heat = heat[[\"accuracy\"]]\n",
    "heat.columns = [\"accuracy\"]\n",
    "\n",
    "heat = heat.reset_index(level=[1, 2, 3], drop=True)\n",
    "heat = heat.unstack(\"combination\")\n",
    "heat.columns = heat.columns.droplevel()\n",
    "heat.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a heatmap, proportional\n",
    "fig = plt.subplots(figsize=(12, 8))\n",
    "ax = sns.heatmap(\n",
    "    heat,\n",
    "    cmap=\"viridis\",\n",
    "    linewidths=1,\n",
    "    linecolor=\"white\",\n",
    "    fmt=\"0.0%\",\n",
    "    annot=False,\n",
    "    annot_kws={\"fontsize\": 4},\n",
    ")\n",
    "_ = ax.set_title(\"Proportion of correct decisions\")\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=6)\n",
    "plt.yticks(fontsize=6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot performance across multiple examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = df.groupby(by=[\"model\", \"standard\", \"expected\", \"result\"]).agg(\n",
    "    num=(\"timestamp\", \"nunique\")\n",
    ")\n",
    "\n",
    "heat = heat.unstack(level=[\"result\", \"expected\"]).fillna(0)\n",
    "\n",
    "heat = heat[heat.columns.sort_values()]\n",
    "heat.columns = [\"TN\", \"FN\", \"FP\", \"TP\"]\n",
    "\n",
    "# calculate overall accuracy\n",
    "heat[\"accuracy\"] = (heat[\"TP\"] + heat[\"TN\"]) / heat.sum(axis=\"columns\")\n",
    "\n",
    "# calculate precision, recall, f1\n",
    "heat[\"precision\"] = heat[\"TP\"] / (heat[\"TP\"] + heat[\"FP\"])\n",
    "heat[\"recall\"] = heat[\"TP\"] / (heat[\"TP\"] + heat[\"FN\"])\n",
    "heat[\"f1\"] = (\n",
    "    2 * (heat[\"precision\"] * heat[\"recall\"]) / (heat[\"precision\"] + heat[\"recall\"])\n",
    ")\n",
    "\n",
    "# distribution of performance\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 3))\n",
    "ax = sns.histplot(heat[\"accuracy\"], bins=20, ax=axes[0], color=\"pink\")\n",
    "ax = sns.histplot(heat[\"f1\"], bins=20, ax=axes[1], color=\"purple\")\n",
    "ax = sns.histplot(heat[\"precision\"], bins=20, ax=axes[2], color=\"r\")\n",
    "ax = sns.histplot(heat[\"recall\"], bins=20, ax=axes[3], color=\"g\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = heat.unstack(\"model\")[[\"f1\", \"precision\", \"recall\"]]\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
    "\n",
    "for ax, col in zip(axes, [\"f1\", \"precision\", \"recall\"]):\n",
    "    ax = sns.heatmap(\n",
    "        df_plot[col],\n",
    "        cmap=\"viridis\",\n",
    "        cbar=None,\n",
    "        linewidths=1,\n",
    "        linecolor=\"white\",\n",
    "        fmt=\"0.0%\",\n",
    "        annot=True,\n",
    "        annot_kws={\"fontsize\": 12},\n",
    "        ax=ax,\n",
    "    )\n",
    "    _ = ax.set_title(f\"{col} by model and prompt standard\")\n",
    "\n",
    "    _ = ax.set_xticks(\n",
    "        ax.get_xticks(), ax.get_xticklabels(), rotation=15, ha=\"right\", fontsize=10\n",
    "    )\n",
    "    _ = ax.set_xlabel(None)\n",
    "    _ = ax.set_ylabel(None)\n",
    "\n",
    "fig.subplots_adjust(bottom=-0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check heatmap per llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.reset_index().pivot_table(\n",
    "    index=[\"example\", \"model\"],\n",
    "    columns=\"correct\",\n",
    "    values=\"timestamp\",\n",
    "    aggfunc=\"nunique\",\n",
    ")\n",
    "df_plot[\"proportion\"] = (df_plot[True] / (df_plot[True] + df_plot[False])).fillna(0)\n",
    "df_plot = df_plot[[\"proportion\"]].unstack(level=[1])\n",
    "\n",
    "\n",
    "# make a heatmap, proportional\n",
    "\n",
    "fig = plt.subplots(figsize=(12, 8))\n",
    "ax = sns.heatmap(\n",
    "    df_plot,\n",
    "    cmap=\"viridis\",\n",
    "    linewidths=1,\n",
    "    linecolor=\"white\",\n",
    "    fmt=\".0%\",\n",
    "    annot=True,\n",
    "    annot_kws={\"fontsize\": 4},\n",
    ")\n",
    "_ = ax.set_title(\"Proportion of correct decisions\")\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=6)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show select aggregated stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fix, axes = plt.subplots(4, 4, figsize=(16, 12), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (idx, row) in enumerate(heat.iterrows()):\n",
    "    ax = axes[i]\n",
    "    cm = np.array([row[[\"TN\", \"FP\"]].values, row[[\"FN\", \"TP\"]].values])\n",
    "\n",
    "    ax.set_title(f\"{idx}\")\n",
    "\n",
    "    ax = sns.heatmap(cm, annot=False, fmt=\"0.0f\", cmap=\"Blues\", ax=ax, cbar=False)\n",
    "\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(heat.columns, group_counts)]\n",
    "    labels = np.asarray(labels).reshape(2, 2)\n",
    "    for i, y in enumerate(labels):\n",
    "        for j, x in enumerate(y):\n",
    "            ax.text(x=j + 0.5, y=i + 0.5, s=x, ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "# Adjust the space between subplots\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "bm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
