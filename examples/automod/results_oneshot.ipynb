{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIiIU984mI0m",
    "outputId": "07bc3c04-d3e6-4525-ff20-aba3f2b30426"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/bm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-05 09:16:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m buttermilk.py[ 297] \u001b[1;30mINFO\u001b[0m {'message': \"Logging setup for: 20241104T2316Z-YiS9-J5HW6L4KT6-suzor. Ready for data collection, saving log to Google Cloud Logs (Resource(type='generic_task', labels={'project_id': 'dmrc-platforms', 'location': 'us-central1', 'namespace': 'automod', 'job': 'results_oneshot', 'task_id': '20241104T2316Z-YiS9-J5HW6L4KT6-suzor'})). Default save directory for data in this run is: gs://dmrc-analysis/runs/automod/results_oneshot/20241104T2316Z-YiS9-J5HW6L4KT6-suzor\", 'project': 'automod', 'job': 'results_oneshot', 'run_id': '20241104T2316Z-YiS9-J5HW6L4KT6-suzor', 'save_dir': 'gs://dmrc-analysis/runs/automod/results_oneshot/20241104T2316Z-YiS9-J5HW6L4KT6-suzor', 'ip': '159.196.210.27', 'node_name': 'J5HW6L4KT6', 'username': 'suzor'}\n",
      "\u001b[32m2024-11-05 09:16:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m buttermilk.py[ 305] \u001b[1;30mDEBUG\u001b[0m \u001b[32mButtermilk version is: 0.2.0\u001b[0m\n",
      "Prompt flow service has started...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'job'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'dataset'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-analysis.toxicity.flow'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'last_n_days'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'max_records_per_group'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'filter'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'group'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'record.record_id'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'job_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'job_id'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'columns'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'job'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'run_info.job'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'run_info.project'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.model'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template_vars.criteria'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'record.content'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prediction'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.prediction'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.reasons'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'labels'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.labels'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'outputs'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'record'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'record'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'expected'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'record.groundtruth.answer'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'drag'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'drag queens - alt text'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'file'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'uri'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gs://dmrc-platforms/data/drag_train.jsonl'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'columns'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'alt_text'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'groundtruth'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'expected'</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'judger'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'job'\u001b[0m,\n",
       "        \u001b[32m'dataset'\u001b[0m: \u001b[32m'dmrc-analysis.toxicity.flow'\u001b[0m,\n",
       "        \u001b[32m'last_n_days'\u001b[0m: \u001b[1;36m14\u001b[0m,\n",
       "        \u001b[32m'max_records_per_group'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "        \u001b[32m'filter'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'group'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'record_id'\u001b[0m: \u001b[32m'record.record_id'\u001b[0m, \u001b[32m'job_id'\u001b[0m: \u001b[32m'job_id'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'columns'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'timestamp'\u001b[0m: \u001b[32m'timestamp'\u001b[0m,\n",
       "            \u001b[32m'job'\u001b[0m: \u001b[32m'run_info.job'\u001b[0m,\n",
       "            \u001b[32m'project'\u001b[0m: \u001b[32m'run_info.project'\u001b[0m,\n",
       "            \u001b[32m'model'\u001b[0m: \u001b[32m'agent_info.model'\u001b[0m,\n",
       "            \u001b[32m'template'\u001b[0m: \u001b[32m'agent_info.template'\u001b[0m,\n",
       "            \u001b[32m'criteria'\u001b[0m: \u001b[32m'agent_info.template_vars.criteria'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m'record.content'\u001b[0m,\n",
       "            \u001b[32m'prediction'\u001b[0m: \u001b[32m'outputs.prediction'\u001b[0m,\n",
       "            \u001b[32m'reasons'\u001b[0m: \u001b[32m'outputs.reasons'\u001b[0m,\n",
       "            \u001b[32m'labels'\u001b[0m: \u001b[32m'outputs.labels'\u001b[0m,\n",
       "            \u001b[32m'outputs'\u001b[0m: \u001b[32m'outputs'\u001b[0m,\n",
       "            \u001b[32m'record'\u001b[0m: \u001b[32m'record'\u001b[0m,\n",
       "            \u001b[32m'parameters'\u001b[0m: \u001b[32m'parameters'\u001b[0m,\n",
       "            \u001b[32m'agent_info'\u001b[0m: \u001b[32m'agent_info'\u001b[0m,\n",
       "            \u001b[32m'expected'\u001b[0m: \u001b[32m'record.groundtruth.answer'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'drag'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'name'\u001b[0m: \u001b[32m'drag queens - alt text'\u001b[0m,\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'file'\u001b[0m,\n",
       "        \u001b[32m'uri'\u001b[0m: \u001b[32m'gs://dmrc-platforms/data/drag_train.jsonl'\u001b[0m,\n",
       "        \u001b[32m'columns'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'record_id'\u001b[0m: \u001b[32m'id'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'alt_text'\u001b[0m, \u001b[32m'groundtruth'\u001b[0m: \u001b[32m'expected'\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydantic\n",
    "import seaborn as sns\n",
    "from buttermilk import BM\n",
    "from cmap import Colormap\n",
    "from rich import print as rprint\n",
    "\n",
    "from buttermilk import BM\n",
    "import os\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Load config, specifying overrides for our particular job\n",
    "with initialize(version_base=None, config_path=\"./conf\"):\n",
    "    cfg = compose(config_name='config',\n",
    "                  overrides=[\"+data=[judger,drag]\", \"+step=ordinary\", \"+save=bq\", \"job=results_oneshot\"])\n",
    "\n",
    "bm = BM(cfg=cfg)\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8)\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "\n",
    "rprint(OmegaConf.to_container(bm.cfg.data, resolve=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-05 09:16:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m buttermilk.py[ 376] \u001b[1;30mINFO\u001b[0m Query stats: Ran in 0:00:03.110136 seconds, cache hit: False, billed 10.49 MB, approx cost $5.2e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Query stats: Ran in 0:00:03.110136 seconds, cache hit: False, billed 10.49 MB, approx cost $5.2e-06.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['content'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbuttermilk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_data, prepare_step_data\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_step_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m df\n",
      "File \u001b[0;32m~/src/buttermilk/buttermilk/runner/helpers.py:174\u001b[0m, in \u001b[0;36mprepare_step_data\u001b[0;34m(data_config)\u001b[0m\n\u001b[1;32m    171\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m group_and_filter_jobs(existing_df\u001b[38;5;241m=\u001b[39mdataset, data\u001b[38;5;241m=\u001b[39mdf, group\u001b[38;5;241m=\u001b[39msrc\u001b[38;5;241m.\u001b[39mgroup, columns\u001b[38;5;241m=\u001b[39msrc\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# add index, but don't remove record_id form the columns\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecord_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# shuffle\u001b[39;00m\n\u001b[1;32m    177\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/bm/lib/python3.11/site-packages/pandas/core/frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3898\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3899\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/bm/lib/python3.11/site-packages/pandas/core/indexes/base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/bm/lib/python3.11/site-packages/pandas/core/indexes/base.py:6179\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['content'] not in index\""
     ]
    }
   ],
   "source": [
    "from buttermilk.runner.helpers import load_data, prepare_step_data\n",
    "\n",
    "df = prepare_step_data(bm.cfg.data).sort_values(by=[\"timestamp\"], ascending=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f\"\"\"SELECT * FROM `{cfg.data.destination}`\"\"\"\n",
    "df = bm.run_query(sql)\n",
    "\n",
    "source = df.source.explode()\n",
    "df = df.drop(columns='source').join(source)\n",
    "\n",
    "df.loc[:, \"record_id\"] = df.record_id.str.lower().replace(\n",
    "    r\"[^\\d\\w]\", \"\", regex=True\n",
    ")\n",
    "\n",
    "df = df.dropna(subset='prediction')\n",
    "df.loc[:, \"record_id\"] = df.record_id.str.lower().replace(\n",
    "    r\"[^\\d\\w]\", \"\", regex=True\n",
    ")\n",
    "df.loc[:, 'prediction'] = df.prediction.apply(lambda x: pydantic.TypeAdapter(bool).validate_python(x) if pd.notna(x) else None)\n",
    "df.loc[:, 'expected'] = df.expected.apply(lambda x: pydantic.TypeAdapter(bool).validate_python(x) if pd.notna(x) else None)\n",
    "\n",
    "df = df.set_index([\"record_id\", \"source\", \"step\",\"model\"])\n",
    "\n",
    "df.loc[:, \"step_info\"] = df.step_info.apply(json.loads)\n",
    "\n",
    "if 'agent_info' in df.columns:\n",
    "    df.loc[:, \"agent_info\"] = df.agent_info.apply(json.loads)\n",
    "if 'run_info' in df.columns:\n",
    "    df.loc[:, \"run_info\"] = df.run_info.apply(json.loads)\n",
    "\n",
    "\n",
    "df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show results from hatespeech prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from buttermilk.tools.metrics import Metriciser\n",
    "m = Metriciser()\n",
    "acc = m.evaluate_results(df, levels=[\"step\",\"model\",\"source\"], groundtruth='expected', prediction='prediction')\n",
    "acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from buttermilk.utils.gsheet import GSheet\n",
    "today = datetime.date.today().strftime(\"%Y%m%d\")\n",
    "g = GSheet()\n",
    "g.save_gsheet(acc, title=f'{today}_results', sheet_name='our prompt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc.reset_index(level='model').xs(\"drag queens - alt text\", level='source')[['model','accuracy']].sort_values(by='accuracy', ascending=False).sort_index().to_markdown(floatfmt=\"0.2f\", tablefmt=\"rounded_outline\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = acc.reset_index(level='model').xs(\"drag queens - alt text\", level='source')[['model','accuracy']]\n",
    "tbl = tbl.pivot(columns='model', values='accuracy')\n",
    "print(tbl.sort_index().to_markdown(floatfmt=\"0.2f\", tablefmt=\"rounded_outline\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ours = df.xs('drag queens - alt text', level='source')\n",
    "\n",
    "# reindex df by day, using date from  'timestamp'\n",
    "ours['date'] = ours['timestamp'].dt.date\n",
    "ours.reset_index().groupby('date').job_id.agg('count').plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = df.copy()\n",
    "heat = heat.groupby(\n",
    "    by=[\"record_id\", \"step\", \"agent\", \"correct\"]\n",
    ").agg(num=(\"timestamp\", \"nunique\"))\n",
    "heat = heat.unstack(level=[\"correct\"]).fillna(0)\n",
    "heat[\"accuracy\"] = heat[\"num\"][True] / (heat[\"num\"][True] + heat[\"num\"][False])\n",
    "\n",
    "heat = heat[[\"accuracy\"]]\n",
    "heat.columns = [\"accuracy\"]\n",
    "\n",
    "heat = heat.unstack(\"record_id\")\n",
    "heat.columns = heat.columns.droplevel()\n",
    "\n",
    "\n",
    "# make a heatmap, proportional\n",
    "fig = plt.subplots(figsize=(6,6))\n",
    "ax = sns.heatmap(\n",
    "    heat,\n",
    "    cmap=\"viridis\",\n",
    "    linewidths=1,\n",
    "    linecolor=\"white\",\n",
    "    fmt=\"0.0%\",\n",
    "    cbar=False,\n",
    "    annot=True,\n",
    "    annot_kws={\"fontsize\": 6},\n",
    ")\n",
    "_ = ax.set_title(\"Proportion of correct decisions\")\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=8)\n",
    "plt.yticks(fontsize=6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# standard vs model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "WITH SCORES AS\n",
    "(SELECT JSON_VALUE(tox.record, '$.id') AS example, JSON_VALUE(tox.record, '$.img') AS img, JSON_VALUE(tox.record, '$.caption') AS alt_text, reasons, scores, labels,\n",
    "tox.id, tox.model, tox.timestamp, JSON_VALUE(tox.record, '$.expected') AS expected, tox.result,\n",
    "tox.job, tox.source, (JSON_VALUE(tox.record, '$.expected')=\"true\")=tox.result as correct, standard, process\n",
    "FROM `dmrc-analysis.toxicity.indicator` tox\n",
    "WHERE TIMESTAMP_TRUNC(timestamp, MONTH) >= TIMESTAMP(DATE_SUB(CURRENT_DATE(), INTERVAL 1 MONTH))\n",
    "AND (LOWER(tox.source) = 'drag queens' or LOWER(tox.source) = 'osb')\n",
    "AND timestamp >= '2024-04-05 00:00:00'\n",
    "ORDER BY timestamp DESC)\n",
    "\n",
    "SELECT * FROM SCORES\"\"\"\n",
    "\n",
    "df = client.query(sql).to_dataframe()\n",
    "df.loc[:, \"expected\"] = df[\"expected\"].apply(lambda x: pydantic.TypeAdapter(bool).validate_python(x) if pd.notna(x) else None)\n",
    "df.loc[df['standard']=='standard','standard'] = \"HATESPEECH.FB\"\n",
    "df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = df[df[\"process\"].isin([\"rules.apply\", \"toxic\"])]\n",
    "heat.loc[:, 'standard'] = heat['standard'].str.replace('HATESPEECH.', 'hatespeech ').str.lower()\n",
    "heat = heat.groupby(\n",
    "    by=[\"source\", \"model\", \"standard\", \"correct\"]\n",
    ").agg(num=(\"timestamp\", \"nunique\"))\n",
    "\n",
    "heat = heat.unstack(level=[\"correct\"]).fillna(0)\n",
    "heat[\"accuracy\"] = heat[\"num\"][True] / (heat[\"num\"][True] + heat[\"num\"][False])\n",
    "heat = heat[[\"accuracy\"]]\n",
    "heat.columns = [\"accuracy\"]\n",
    "\n",
    "heat = heat.unstack(\"standard\")\n",
    "heat.columns = heat.columns.droplevel()\n",
    "heat.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make a heatmap, proportional\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4), dpi=144, sharex=True, sharey=True)\n",
    "for i, source in enumerate(['Drag Queens', 'osb']):\n",
    "    df_plot = heat.xs(source)\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "        df_plot,\n",
    "        cmap=\"viridis\",\n",
    "        linewidths=1,\n",
    "        linecolor=\"white\",\n",
    "        fmt=\"0.0%\",\n",
    "        cbar=False,\n",
    "        annot=True,\n",
    "        annot_kws={\"fontsize\": 6},\n",
    "        ax=axes[i]\n",
    "    )\n",
    "    _ = ax.set_title(f\"Proportion of correct {source} decisions\")\n",
    "\n",
    "    _ = ax.set_xticks(ax.get_xticks(), ax.get_xticklabels(), rotation=15, ha='right', fontsize=10)\n",
    "    _ = ax.set_xlabel(None)\n",
    "    _ = ax.set_ylabel(None)\n",
    "\n",
    "fig.subplots_adjust(bottom=-0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keep: gpt4chaotic, gemini15pro, claude3opus,  claude3sonnet\n",
    "hatespeech.gelber, hatespeech.gelber.simplified, hatespeech.fb, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show accuracy per example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = df.groupby(by=[\"example\", \"model\", \"standard\", \"process\", \"combination\", \"correct\"]).agg(\n",
    "    num=(\"timestamp\", \"nunique\")\n",
    ")\n",
    "\n",
    "heat = heat.unstack(level=[\"correct\"]).fillna(0)\n",
    "heat['accuracy'] = heat['num'][True] / (heat['num'][True] + heat['num'][False])\n",
    "heat = heat[['accuracy']]\n",
    "heat.columns = ['accuracy']\n",
    "\n",
    "heat = heat.reset_index(level=[1, 2, 3], drop=True)\n",
    "heat = heat.unstack('combination')\n",
    "heat.columns = heat.columns.droplevel()\n",
    "heat.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a heatmap, proportional\n",
    "fig = plt.subplots(figsize=(12, 8))\n",
    "ax = sns.heatmap(\n",
    "    heat,\n",
    "    cmap=\"viridis\",\n",
    "    linewidths=1,\n",
    "    linecolor=\"white\",\n",
    "    fmt=\"0.0%\",\n",
    "    annot=False,\n",
    "    annot_kws={\"fontsize\": 4},\n",
    ")\n",
    "_ = ax.set_title(\"Proportion of correct decisions\")\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=6)\n",
    "plt.yticks(fontsize=6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot performance across multiple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = df.groupby(by=[ \"model\", \"standard\", \"expected\", \"result\"]).agg(\n",
    "    num=(\"timestamp\", \"nunique\")\n",
    ")\n",
    "\n",
    "heat = heat.unstack(level=[\"result\",\"expected\"]).fillna(0)\n",
    "\n",
    "heat = heat[heat.columns.sort_values()]\n",
    "heat.columns = [\"TN\", \"FN\", \"FP\", \"TP\"]\n",
    "\n",
    "# calculate overall accuracy\n",
    "heat['accuracy'] = (heat['TP'] + heat['TN']) / heat.sum(axis='columns')\n",
    "\n",
    "# calculate precision, recall, f1\n",
    "heat[\"precision\"] = heat[\"TP\"] / (heat[\"TP\"] + heat[\"FP\"])\n",
    "heat[\"recall\"] = heat[\"TP\"] / (heat[\"TP\"] + heat[\"FN\"])\n",
    "heat[\"f1\"] = (\n",
    "    2 * (heat[\"precision\"] * heat[\"recall\"]) / (heat[\"precision\"] + heat[\"recall\"])\n",
    ")\n",
    "\n",
    "# distribution of performance\n",
    "fig, axes = plt.subplots(1,4, figsize=(16,3))\n",
    "ax = sns.histplot(heat[\"accuracy\"], bins=20, ax=axes[0], color='pink')\n",
    "ax = sns.histplot(heat[\"f1\"], bins=20, ax=axes[1], color='purple')\n",
    "ax = sns.histplot(heat[\"precision\"], bins=20, ax=axes[2], color='r')\n",
    "ax = sns.histplot(heat[\"recall\"], bins=20, ax=axes[3], color='g')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = heat.unstack(\"model\")[['f1', 'precision', 'recall']]\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(12, 10))\n",
    "\n",
    "for ax, col in zip(axes, ['f1', 'precision', 'recall']):\n",
    "    ax = sns.heatmap(\n",
    "        df_plot[col],\n",
    "        cmap=\"viridis\",\n",
    "        cbar=None,\n",
    "        linewidths=1,\n",
    "        linecolor=\"white\",\n",
    "        fmt=\"0.0%\",\n",
    "        annot=True,\n",
    "        annot_kws={\"fontsize\": 12},\n",
    "        ax=ax\n",
    "    )\n",
    "    _ = ax.set_title(f\"{col} by model and prompt standard\")\n",
    "\n",
    "    _ = ax.set_xticks(ax.get_xticks(), ax.get_xticklabels(), rotation=15, ha='right', fontsize=10)\n",
    "    _ = ax.set_xlabel(None)\n",
    "    _ = ax.set_ylabel(None)\n",
    "\n",
    "fig.subplots_adjust(bottom=-0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check heatmap per llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_plot = df.reset_index().pivot_table(\n",
    "    index=[\"example\", \"model\"],\n",
    "    columns=\"correct\",\n",
    "    values=\"timestamp\",\n",
    "    aggfunc=\"nunique\",\n",
    ")\n",
    "df_plot[\"proportion\"] = (df_plot[True] / (df_plot[True] + df_plot[False])).fillna(0)\n",
    "df_plot = df_plot[[\"proportion\"]].unstack(level=[1])\n",
    "\n",
    "\n",
    "# make a heatmap, proportional\n",
    "\n",
    "fig = plt.subplots(figsize=(12, 8))\n",
    "ax = sns.heatmap(\n",
    "    df_plot,\n",
    "    cmap=\"viridis\",\n",
    "    linewidths=1,\n",
    "    linecolor=\"white\",\n",
    "    fmt=\".0%\",\n",
    "    annot=True,\n",
    "    annot_kws={\"fontsize\": 4},\n",
    ")\n",
    "_ = ax.set_title(\"Proportion of correct decisions\")\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=6)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show select aggregated stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fix, axes = plt.subplots(4, 4, figsize=(16, 12), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (idx, row) in enumerate(heat.iterrows()):\n",
    "    ax = axes[i]\n",
    "    cm = np.array([row[[\"TN\", \"FP\"]].values, row[[\"FN\", \"TP\"]].values])\n",
    "\n",
    "    ax.set_title(f\"{idx}\")\n",
    "\n",
    "    ax = sns.heatmap(cm, annot=False, fmt=\"0.0f\", cmap=\"Blues\", ax=ax, cbar=False)\n",
    "\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(heat.columns, group_counts)]\n",
    "    labels = np.asarray(labels).reshape(2, 2)\n",
    "    for i, y in enumerate(labels):\n",
    "        for j, x in enumerate(y):\n",
    "            ax.text(x=j + 0.5, y=i + 0.5, s=x, ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "# Adjust the space between subplots\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "bm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
