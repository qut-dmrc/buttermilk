{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/bm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:31:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m buttermilk.py[ 297] \u001b[1;30mINFO\u001b[0m {'message': \"Logging setup for: 20241106T0231Z-AviX-J5HW6L4KT6-suzor. Ready for data collection, saving log to Google Cloud Logs (Resource(type='generic_task', labels={'project_id': 'dmrc-platforms', 'location': 'us-central1', 'namespace': 'automod', 'job': 'score', 'task_id': '20241106T0231Z-AviX-J5HW6L4KT6-suzor'})). Default save directory for data in this run is: gs://dmrc-analysis/runs/automod/score/20241106T0231Z-AviX-J5HW6L4KT6-suzor\", 'project': 'automod', 'job': 'score', 'run_id': '20241106T0231Z-AviX-J5HW6L4KT6-suzor', 'save_dir': 'gs://dmrc-analysis/runs/automod/score/20241106T0231Z-AviX-J5HW6L4KT6-suzor', 'ip': '159.196.210.27', 'node_name': 'J5HW6L4KT6', 'username': 'suzor'}\n",
      "\u001b[32m2024-11-06 12:31:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m buttermilk.py[ 305] \u001b[1;30mDEBUG\u001b[0m \u001b[32mButtermilk version is: 0.2.0\u001b[0m\n",
      "Prompt flow service has started...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'automod'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'job'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'notebook'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'secret_provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'azure'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'logger'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'tracing'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'verbose'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'models_secret'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'models'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'save_dest'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'save_dir'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-analysis'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'region'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us-central1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'bucket'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-analysis'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'azure'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'vault'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://suzorvault.vault.azure.net/'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'resource_group'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'rg-suzor_ai'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'aws'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'secret_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'secret'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'region'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us-east-1'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'step'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'num_runs'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'concurrent'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'agent'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'lc'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'trans_cte'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'trans_tja'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'trans_glaad'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'trans_hrc'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'trans_simplified'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'trans_factored'</span>\n",
       "                <span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'formatting'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'json_rules'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'haiku'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'llama31_70b'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gpt4o'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sonnet'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gemini15pro'</span><span style=\"font-weight: bold\">]</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'synth'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'num_runs'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'concurrent'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'agent'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'lc_judge'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'synthesise'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'trans_simplified'</span><span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'formatting'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'json_rules'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'haiku'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gpt4o'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sonnet'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gemini15pro'</span><span style=\"font-weight: bold\">]</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'answers'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'answers'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'meta'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'meta'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'previous runs'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'job'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'dataset'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-analysis.toxicity.flow'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'max_records_per_group'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'filter'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'NOTNULL'</span><span style=\"font-weight: bold\">]}</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'group'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'record.record_id'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.flow'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template_vars.criteria'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'parameters.model'</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'columns'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'answers'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'job_id'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.reasons'</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'meta'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.flow'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template_vars.criteria'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'parameters.model'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'prediction'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.prediction'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'labels'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.labels'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'confidence'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.confidence'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">}</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'eval'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'num_runs'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'concurrent'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'agent'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'lc'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'differences'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'trans_simplified'</span><span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'haiku'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gpt4o'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sonnet'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gemini15pro'</span><span style=\"font-weight: bold\">]</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'answers'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'answers'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'meta'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'meta'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'previous runs and synth'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'job'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'dataset'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-analysis.toxicity.flow'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'max_records_per_group'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'filter'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.flow'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'synth'</span><span style=\"font-weight: bold\">]}</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'group'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'parameters.model'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'record.record_id'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.flow'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template_vars.criteria'</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'columns'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'answers'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'job_id'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.flow'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.reasons'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'meta'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.flow'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template_vars.criteria'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'parameters.model'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'prediction'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.prediction'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'labels'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.labels'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'confidence'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.confidence'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">}</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'run'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'platform'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'local'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'trans'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans news articles'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'file'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'uri'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gs://dmrc-platforms/data/tja_train.jsonl'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'columns'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'save'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'bq'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'destination'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-analysis.toxicity.flow'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'schema'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'flow.json'</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'name'\u001b[0m: \u001b[32m'automod'\u001b[0m,\n",
       "    \u001b[32m'job'\u001b[0m: \u001b[32m'score'\u001b[0m,\n",
       "    \u001b[32m'source'\u001b[0m: \u001b[32m'notebook'\u001b[0m,\n",
       "    \u001b[32m'secret_provider'\u001b[0m: \u001b[32m'azure'\u001b[0m,\n",
       "    \u001b[32m'logger'\u001b[0m: \u001b[32m'gcp'\u001b[0m,\n",
       "    \u001b[32m'tracing'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'verbose'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'models_secret'\u001b[0m: \u001b[32m'models'\u001b[0m,\n",
       "    \u001b[32m'save_dest'\u001b[0m: \u001b[32m'gcp'\u001b[0m,\n",
       "    \u001b[32m'save_dir'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'gcp'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'project'\u001b[0m: \u001b[32m'dmrc-analysis'\u001b[0m, \u001b[32m'region'\u001b[0m: \u001b[32m'us-central1'\u001b[0m, \u001b[32m'bucket'\u001b[0m: \u001b[32m'dmrc-analysis'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'azure'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'vault'\u001b[0m: \u001b[32m'https://suzorvault.vault.azure.net/'\u001b[0m, \u001b[32m'resource_group'\u001b[0m: \u001b[32m'rg-suzor_ai'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'aws'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'secret_name'\u001b[0m: \u001b[32m'secret'\u001b[0m, \u001b[32m'region'\u001b[0m: \u001b[32m'us-east-1'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'step'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m,\n",
       "            \u001b[32m'num_runs'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "            \u001b[32m'concurrent'\u001b[0m: \u001b[1;36m20\u001b[0m,\n",
       "            \u001b[32m'agent'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'name'\u001b[0m: \u001b[32m'lc'\u001b[0m,\n",
       "                \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m,\n",
       "                \u001b[32m'criteria'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "                    \u001b[32m'trans_cte'\u001b[0m,\n",
       "                    \u001b[32m'trans_tja'\u001b[0m,\n",
       "                    \u001b[32m'trans_glaad'\u001b[0m,\n",
       "                    \u001b[32m'trans_hrc'\u001b[0m,\n",
       "                    \u001b[32m'trans_simplified'\u001b[0m,\n",
       "                    \u001b[32m'trans_factored'\u001b[0m\n",
       "                \u001b[1m]\u001b[0m,\n",
       "                \u001b[32m'formatting'\u001b[0m: \u001b[32m'json_rules'\u001b[0m,\n",
       "                \u001b[32m'model'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'haiku'\u001b[0m, \u001b[32m'llama31_70b'\u001b[0m, \u001b[32m'gpt4o'\u001b[0m, \u001b[32m'sonnet'\u001b[0m, \u001b[32m'gemini15pro'\u001b[0m\u001b[1m]\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'parameters'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'record_id'\u001b[0m: \u001b[32m'record_id'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'content'\u001b[0m, \u001b[32m'title'\u001b[0m: \u001b[32m'title'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'flow'\u001b[0m: \u001b[32m'synth'\u001b[0m,\n",
       "            \u001b[32m'num_runs'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "            \u001b[32m'concurrent'\u001b[0m: \u001b[1;36m20\u001b[0m,\n",
       "            \u001b[32m'agent'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'name'\u001b[0m: \u001b[32m'lc_judge'\u001b[0m,\n",
       "                \u001b[32m'template'\u001b[0m: \u001b[32m'synthesise'\u001b[0m,\n",
       "                \u001b[32m'criteria'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'trans_simplified'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                \u001b[32m'formatting'\u001b[0m: \u001b[32m'json_rules'\u001b[0m,\n",
       "                \u001b[32m'model'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'haiku'\u001b[0m, \u001b[32m'gpt4o'\u001b[0m, \u001b[32m'sonnet'\u001b[0m, \u001b[32m'gemini15pro'\u001b[0m\u001b[1m]\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'parameters'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'answers'\u001b[0m: \u001b[32m'answers'\u001b[0m, \u001b[32m'meta'\u001b[0m: \u001b[32m'meta'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'judger'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'name'\u001b[0m: \u001b[32m'previous runs'\u001b[0m,\n",
       "                    \u001b[32m'type'\u001b[0m: \u001b[32m'job'\u001b[0m,\n",
       "                    \u001b[32m'dataset'\u001b[0m: \u001b[32m'dmrc-analysis.toxicity.flow'\u001b[0m,\n",
       "                    \u001b[32m'max_records_per_group'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "                    \u001b[32m'filter'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'agent_info.flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'outputs.reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'NOTNULL'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[32m'group'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'record_id'\u001b[0m: \u001b[32m'record.record_id'\u001b[0m,\n",
       "                        \u001b[32m'flow'\u001b[0m: \u001b[32m'agent_info.flow'\u001b[0m,\n",
       "                        \u001b[32m'template'\u001b[0m: \u001b[32m'agent_info.template'\u001b[0m,\n",
       "                        \u001b[32m'criteria'\u001b[0m: \u001b[32m'agent_info.template_vars.criteria'\u001b[0m,\n",
       "                        \u001b[32m'model'\u001b[0m: \u001b[32m'parameters.model'\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m,\n",
       "                    \u001b[32m'columns'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'answers'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'id'\u001b[0m: \u001b[32m'job_id'\u001b[0m,\n",
       "                            \u001b[32m'model'\u001b[0m: \u001b[32m'model'\u001b[0m,\n",
       "                            \u001b[32m'criteria'\u001b[0m: \u001b[32m'criteria'\u001b[0m,\n",
       "                            \u001b[32m'template'\u001b[0m: \u001b[32m'template'\u001b[0m,\n",
       "                            \u001b[32m'flow'\u001b[0m: \u001b[32m'flow'\u001b[0m,\n",
       "                            \u001b[32m'reasons'\u001b[0m: \u001b[32m'outputs.reasons'\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m,\n",
       "                        \u001b[32m'meta'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'flow'\u001b[0m: \u001b[32m'agent_info.flow'\u001b[0m,\n",
       "                            \u001b[32m'template'\u001b[0m: \u001b[32m'agent_info.template'\u001b[0m,\n",
       "                            \u001b[32m'criteria'\u001b[0m: \u001b[32m'agent_info.template_vars.criteria'\u001b[0m,\n",
       "                            \u001b[32m'model'\u001b[0m: \u001b[32m'parameters.model'\u001b[0m,\n",
       "                            \u001b[32m'prediction'\u001b[0m: \u001b[32m'outputs.prediction'\u001b[0m,\n",
       "                            \u001b[32m'labels'\u001b[0m: \u001b[32m'outputs.labels'\u001b[0m,\n",
       "                            \u001b[32m'confidence'\u001b[0m: \u001b[32m'outputs.confidence'\u001b[0m,\n",
       "                            \u001b[32m'timestamp'\u001b[0m: \u001b[32m'timestamp'\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'flow'\u001b[0m: \u001b[32m'eval'\u001b[0m,\n",
       "            \u001b[32m'num_runs'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "            \u001b[32m'concurrent'\u001b[0m: \u001b[1;36m20\u001b[0m,\n",
       "            \u001b[32m'agent'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'name'\u001b[0m: \u001b[32m'lc'\u001b[0m,\n",
       "                \u001b[32m'template'\u001b[0m: \u001b[32m'differences'\u001b[0m,\n",
       "                \u001b[32m'criteria'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'trans_simplified'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                \u001b[32m'model'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'haiku'\u001b[0m, \u001b[32m'gpt4o'\u001b[0m, \u001b[32m'sonnet'\u001b[0m, \u001b[32m'gemini15pro'\u001b[0m\u001b[1m]\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'parameters'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'answers'\u001b[0m: \u001b[32m'answers'\u001b[0m, \u001b[32m'meta'\u001b[0m: \u001b[32m'meta'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'judger'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'name'\u001b[0m: \u001b[32m'previous runs and synth'\u001b[0m,\n",
       "                    \u001b[32m'type'\u001b[0m: \u001b[32m'job'\u001b[0m,\n",
       "                    \u001b[32m'dataset'\u001b[0m: \u001b[32m'dmrc-analysis.toxicity.flow'\u001b[0m,\n",
       "                    \u001b[32m'max_records_per_group'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "                    \u001b[32m'filter'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'agent_info.flow'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'judger'\u001b[0m, \u001b[32m'synth'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[32m'group'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'model'\u001b[0m: \u001b[32m'parameters.model'\u001b[0m,\n",
       "                        \u001b[32m'record_id'\u001b[0m: \u001b[32m'record.record_id'\u001b[0m,\n",
       "                        \u001b[32m'flow'\u001b[0m: \u001b[32m'agent_info.flow'\u001b[0m,\n",
       "                        \u001b[32m'template'\u001b[0m: \u001b[32m'agent_info.template'\u001b[0m,\n",
       "                        \u001b[32m'criteria'\u001b[0m: \u001b[32m'agent_info.template_vars.criteria'\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m,\n",
       "                    \u001b[32m'columns'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'answers'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'id'\u001b[0m: \u001b[32m'job_id'\u001b[0m,\n",
       "                            \u001b[32m'flow'\u001b[0m: \u001b[32m'agent_info.flow'\u001b[0m,\n",
       "                            \u001b[32m'reasons'\u001b[0m: \u001b[32m'outputs.reasons'\u001b[0m,\n",
       "                            \u001b[32m'model'\u001b[0m: \u001b[32m'model'\u001b[0m,\n",
       "                            \u001b[32m'criteria'\u001b[0m: \u001b[32m'criteria'\u001b[0m,\n",
       "                            \u001b[32m'template'\u001b[0m: \u001b[32m'template'\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m,\n",
       "                        \u001b[32m'meta'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'flow'\u001b[0m: \u001b[32m'agent_info.flow'\u001b[0m,\n",
       "                            \u001b[32m'template'\u001b[0m: \u001b[32m'agent_info.template'\u001b[0m,\n",
       "                            \u001b[32m'criteria'\u001b[0m: \u001b[32m'agent_info.template_vars.criteria'\u001b[0m,\n",
       "                            \u001b[32m'model'\u001b[0m: \u001b[32m'parameters.model'\u001b[0m,\n",
       "                            \u001b[32m'prediction'\u001b[0m: \u001b[32m'outputs.prediction'\u001b[0m,\n",
       "                            \u001b[32m'labels'\u001b[0m: \u001b[32m'outputs.labels'\u001b[0m,\n",
       "                            \u001b[32m'confidence'\u001b[0m: \u001b[32m'outputs.confidence'\u001b[0m,\n",
       "                            \u001b[32m'timestamp'\u001b[0m: \u001b[32m'timestamp'\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'run'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'local'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'trans'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'trans news articles'\u001b[0m,\n",
       "            \u001b[32m'type'\u001b[0m: \u001b[32m'file'\u001b[0m,\n",
       "            \u001b[32m'uri'\u001b[0m: \u001b[32m'gs://dmrc-platforms/data/tja_train.jsonl'\u001b[0m,\n",
       "            \u001b[32m'columns'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'record_id'\u001b[0m: \u001b[32m'id'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'text'\u001b[0m, \u001b[32m'title'\u001b[0m: \u001b[32m'name'\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'save'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'bq'\u001b[0m, \u001b[32m'destination'\u001b[0m: \u001b[32m'dmrc-analysis.toxicity.flow'\u001b[0m, \u001b[32m'schema'\u001b[0m: \u001b[32m'flow.json'\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from buttermilk import BM\n",
    "from promptflow.tracing import trace, start_trace\n",
    "from rich import print as rprint\n",
    "\n",
    "import os\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Load config, specifying overrides for our particular job\n",
    "with initialize(version_base=None, config_path=\"./conf\"):\n",
    "    cfg = compose(config_name='config',\n",
    "                  overrides=[\"+data=trans\", \"+step=trans\", \"+save=bq\", \"job=score\",\"source=notebook\"])\n",
    "\n",
    "# Load the main ButterMilk singleton instance\n",
    "# This takes care of credentials, save paths, and other defaults\n",
    "bm = BM(cfg=cfg)\n",
    "\n",
    "# Print config\n",
    "rprint(OmegaConf.to_container(bm.cfg, resolve=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step assesses content against our criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an orchestrator to conduct all combinations of jobs we want to run\n",
    "from buttermilk.runner.orchestrator import MultiFlowOrchestrator\n",
    "orchestrator = MultiFlowOrchestrator(step=cfg.step[0], data=cfg.data, save=cfg.save, source=cfg.source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:15:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job cLWruB8mzRSZNGYQ7mHPPV.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job cLWruB8mzRSZNGYQ7mHPPV.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:00\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job XSG8q7NYvpXe6Egjd6J538.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job XSG8q7NYvpXe6Egjd6J538.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job dxFeXFd8b23dkKuyt9ASr4.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job dxFeXFd8b23dkKuyt9ASr4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job h2yUoJ6ii2YUwdJ5cgvF8z.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job h2yUoJ6ii2YUwdJ5cgvF8z.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job 53roc2dk5JgdJpRKHL4w8p.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job 53roc2dk5JgdJpRKHL4w8p.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job JfkvvzGyWazCE7VeNAoPdZ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job JfkvvzGyWazCE7VeNAoPdZ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job 57DFDLQVdgLoDMTXx5dqgN.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job 57DFDLQVdgLoDMTXx5dqgN.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job HL5jomi8aeeHVUPR8RWQP4.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job HL5jomi8aeeHVUPR8RWQP4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job aw5XUVNj4Npjgjra7eY6pi.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job aw5XUVNj4Npjgjra7eY6pi.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job QLps4nSkZ8rePzvwaSjEkD.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job QLps4nSkZ8rePzvwaSjEkD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job J9c3extkYp7rz79foP5Mud.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job J9c3extkYp7rz79foP5Mud.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job HPzxnLTV29tQpyZZNS3zqL.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job HPzxnLTV29tQpyZZNS3zqL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job BvhWs8pSrsMkSmnvraqyCz.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job BvhWs8pSrsMkSmnvraqyCz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job LGy5Lik33erZZY5wFLHLjJ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job LGy5Lik33erZZY5wFLHLjJ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job 7QnTxYgeVJXnBxyCbbuaPp.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job 7QnTxYgeVJXnBxyCbbuaPp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job EcWp7EsGugcWd5x3Dyqkg6.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job EcWp7EsGugcWd5x3Dyqkg6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job nVWYR9kDTCwjc8cMbMwosS.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job nVWYR9kDTCwjc8cMbMwosS.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job fZPBVFDncBy4k9XAwknyiy.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job fZPBVFDncBy4k9XAwknyiy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job 2uSTV8fpvrfLeRWbPZg4Co.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job 2uSTV8fpvrfLeRWbPZg4Co.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job 4RqF8a9sfvVT2aty8vbrM7.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job 4RqF8a9sfvVT2aty8vbrM7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x6834095d7a656943108d1e84fd24e6ab\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xf18cb89aba1622f3e4d0456833fe3d4a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x23146f9a4f6a6208a7ccc0e70677690f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xb2de2b7be7690b0d894dc0931601e26e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x7a830fc7284d144f3aea8559a267f590\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x8517cb5879d3f5498f994a1354eb54bf\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x815ffe1ffc5e6ea3766370137fa70770\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xf0d0167f11ebb98ac7b19d81d000d356\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x54f43324387a72f5a82683de421bcc04\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x9e0c59b2ff77fef2540baadd20ba7911\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xc006efd0bad4c3ea0b3fad8d8f1c04b3\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x97f9c59ea30999a4e33604f44e00211d\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xc371b3ff9ebe3379535f08eea0b0bd8e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xbb43175dd5e09c4cd65ac21fa5b041e3\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x8547e7efe787550902c8d992de33535b\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x51778613a4cc168e8bb98e73d0cd2059\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x5e68f186f3d389a1f87d459f4c287354\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x528d851c57a8e3976bcef8e04162b4e0\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x16c85236b59ea0654500665e26d59c5a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x6c039670eeadcea5b9a3f2503ae29258\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x47ed4023ff74fdf57d645c1a88e0f3ad\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xa819d777d071007007ab24a197e68cf8\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x435dc40af383b2eea32149bfdcf3096e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x42a17c898944dbfc6cb6c0a763081704\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x6692188b2d3cf884acc0ba9c41246487\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xdaf7a0f4844108ee4a81f47e5ff02523\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x6e70c83ee5acd497780d0a33f2ebe165\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xa3f70cfd82a55058afac30ea24bd2aa1\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x71f0d3a9d2111f0c14632597223ec98f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x915e891474940d641274a2f972fecc6e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x8cff3a0885fbcb12eb07e59357317455\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x183b2e6307833857c75d86d424807aca\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x538c3a2775eb84ad7b28410d5108f18c\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x0607c7c517c604c7305e074e5fa5d0f5\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xf9f5bf4a009b464511f24ee1985bd542\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xbfe682e853b5af3a7bb2496e6b71c863\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x54bfe1d8d01272f731a0f8052cad3a87\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x5d9ebcb84b5d290efbcfcf5f0a7c525b\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x601a034e0058d3518e31165039dd851a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x7400f4a9a400993861347b44ce6394b9\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x5733bd3879a0028cbb8304f847791e8b\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x347ab7b428a3c7f1b88a0571765550aa\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x739290b3d656e829de96ea7d8f055ddc\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xe31248df1b396de61c21b8b119f42acc\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xcdb1c426168d88a0cc7eb0fbbf333811\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xbc458fab92ea68680feb22a026a9e6a4\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x9102cdf6e696027285f214245508e9fd\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xe3eb3c51a6d7353caab84590e91f9d69\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x11342e3f156c9497a936ceea528cb32c\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xb4de88157b679d27235688a04b60b929\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x8097d12f0142700570db4023509c16e8\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x3bef64b0337ab18f51085ca7b62f0bf7\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x3b8873e1c37edc090e7c231ef2cd5ff4\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xedd238d2f3d0c15cf99fc206d87a5ff9\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x27b225ef23a6d1d82dcdc85961413b08\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x514b1b74a3ce6c3311e032fa1a337d5f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xb18ab72c28bd6bfe7ecc699b4bb6822e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x205486a0ed7e3d12acf73a357e8efe7a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x0745aeb3f55b5228e91940416faaa111\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xef93a6ed6360eb911498d8f777fbef4e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xfb113dc0da63117ed91ea4ff82875964\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x767108412b1bbde2fa7be38c79d27664\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x7c5c38eb39587f68381c7dbe3e6fd20a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xb4dff1529e0e1a826029e59593ade46f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x23ec0131c1e2f8c84673e42674accd2f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xc04ffdafaf43ade17df4814b197be0e4\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x0ea33e210e7101f0680591bbef77bac7\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x8939748dd7ac15e6ddafc75eba0229d8\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x626dd2bfd2aa05774b2a6f5ce56eac5c\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xd38c417a51f85c2073ebef8ecd80eee0\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x0dadee33bcacac95143864f00ee34dcd\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x670d2ff16363401c722e77a285beca09\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x56011145133bf0dda5db0f192b0dd9f2\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xc5567487048e0f64b0fa5dd71860c936\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x34bae6bab7bd52e32a11fb0b5e152118\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x12ea0cb8198fcb57ec687028047b7fa8\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x8cf2f411d79cc2fff4357f4793097f31\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x23b6a2af482404f3b41f18f77d014a0e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xd0f9811d9629ecd414e5afd4f60ec318\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x44ce530045acd87afcea4426b8d61659\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x3efc5e8ff92cebec471f97a3cd2e2d1e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xfbb39ab2c741b17e0bd550f1e0a9ecd8\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x0c42c1cadbac668de2ece67335cfb8e4\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xd82c53ca30185ae136b0fa9bbd896184\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x6165b1d8e203136d45e9b92395cb5719\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x668227aa59bbd7ce03ae269a7322b6a9\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x2910fda8dad8d4c3cac3b7fec1e1c234\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xe72565ddf4ae3e5e65b8c20f7c5a19e8\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xd3f4bd3a858c7c758e6edc682cc5be71\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x4e4be74c6376cb49b25e1760ce882c32\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xa9b77435bac17434b53adf7eb3db46d0\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xc9063d8853858d0cf6184a244e717aa3\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xe77e8ea2c36cd360e18d269c2ccd65d5\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xa1a137dd0931a5281d9ff1d4d40cb24a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xefbc2ff22190b2b7ef7f6569ebbdf6e2\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x5990e5b8160a217cc688f8685ac85e6d\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xe2a4d658e99035a191c93ec7be519e59\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x037bbf68b314051b67b3805532376db9\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x90e254228748034ea67e2d4396bd63cc\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x5c10a1afd9d873b28a24d35a04611224\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xd7ff1fc8d1d517d11f919e22d6a7dcc4\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xe6b3c7a54b9aee78b2439d5292211b82\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x37f31b00b4837c4ca7482f926f22f074\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xd2e7dd958469881aaa1b04ff27bc9de9\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x7592479ec09068c9752e777ce7ff0851\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xb5ee98d337b2d5ee7e728fd7046f10e5\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xb47bf9d7d8658789ce7767e29a887b70\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xe363786636595d9091ee56ea456aa846\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x14fec51931555d2f70bc3d3706404ba0\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x964ca07ba480417223139d8d7dabaaf5\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x48e00e027314967bed7a39f069829008\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x664fd15bbd5f40cb2baaa697c3741175\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x53b9251b9c73015e3438b1b40501b251\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x382559834934ffdf43cb6546719031e5\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xf80606d7edf8836a19a179125f5f1b8a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x95549e474f6b7ca91a8d74b735d3a9f3\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x75bdba1f04d261041bb512918d32ab72\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x916fafd3f60bb74b810ae195a9a3e551\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x36aed29d31af58fadc8d743d32a364fa\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x78ff8ce60306d6dbd4e0a81d5102a048\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xac754e16a320626da51810c05322489b\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x47a8bf36db93fdf7d10c7de66a857750\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xf2567fa0ff2a6aa3634d6bdccb23bc05\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x881c4d9c270bbb274991437c89e96d91\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x2ce817b8f5774f980dd1284d3b391065\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x3ce682c25badc6ad219300a1c34a94f4\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x18e8f42405ec9025b6e1c60152450883\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xbdb2b94438c53b9b9f8f753134afa060\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x8d713f0e86a679add592b0e1e7845b5b\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xa2eb1e4946e828ffbdc556bd25abca34\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x09d71666c44ccfe43f3dddc880e05202\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xa01cd22f44b1071475b68ef8e8aaf476\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x736748a111c711180b1a73b59c598e6c\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x8616c46dd786e74ec4af022c3e4adc7c\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xc51c806c6b43a4d2fe990e660343238e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xf5e7e6f5b00ca9a0c89edb8234a09981\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x74bb4fd9ccc73b3901517870b0bb646e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x5fae3c7640d1050808f4b48ad22fb01a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x8b41dc9ce78797d803b22371550dbd4a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xe276affc3f5d1a185202a7ac08284631\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xeb371045fa1ae1743e03fb69961d9985\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x6b7a85d415e69405185026e643c77b44\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xdbc9c00452f6014b1ac22451d1396469\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x1c9bf15d19ebecebe2a5954cd315cf46\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xbec6097fe986b3c5c618e6b18dfdd45e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xc35567acd9cfb576418ee0601756f8ba\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x66fb35954a5a57dca6fadc89ad8b453c\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x6f0a78cad65a6978e93528452c764ab7\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xc96dd2b7d8beba8751cdf44b14ab4816\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x2bf0bf71f4d40af596a8217efa5b04f3\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xa34c0a1698d233a2012530472ddce83f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x534b81cb4cf2161b133a85639bfa2796\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xb69366afb94e39a2cf0aefb7b02a4d98\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x6faafd55eada83307971e67befbd4f4a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x326ecae42b9a8783fdea56f8be6c3778\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x1c307bf467618d3ec0ffbe7f732e809f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x7b92f8aabefbb3764aef7b1a56d91462\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x264ce96edb604ad3fa928c87183bd167\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x75f96000bb57d516394b880392d08095\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x6b7bf46767aff9f3d2b7d67dfe224d1c\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x94e3bab81709efeef75f2fc5eb71ed61\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xd7bea0d75a97fa71ad2bda078e00c01b\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xe7f7d7d6225b57c0492cf8a9aa2e1c96\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x67a28fa192e9d5cc4b21e58f299f8554\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x8252920efb53d5b00a036f46df925ec8\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xde51c75826eb2db2ea0bcb6a6d210742\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x1fc17d93f358286009ca5647852ed11f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xbf3239d028d00d9dbf76ea7773bf3b1f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x0ac93f4be3a65698c99f7b62bb2effc2\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x01580a3dcd0c7484948ccc6084c57c74\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xeb99cdc24557baf119fb30bf82bcceff\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x7cf6590d64128c38a8a4b5e28e41c0ac\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x7ff9080dcbaafbcd00b55876da763837\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xde2b82cddd643176635599d45ade4d5a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x3109a7e09ecc2b062a98521180e9d5e5\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xb6256091e9243713351fc60282cd9c86\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xcc2f218b2f5336e4b217db6d6eef1c8a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x4be0d53c836ba7a8b784dcd669691e2e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xaaf86bef75461d949b808e457fe74705\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x9a079b4f9734d4f630aee48dd62a58aa\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xeeaf1ef6311cfcfc0819588071ff8b46\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xeb6e6318aa6f2555331797798e31757f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x856b81378222d684844920024d3d0809\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x4bf94e7e46b5ee1b84ea3deb87dc8cd1\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x2b0b585d540c32c61912020bb31ce6f2\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xdadbe82f863c4893a47d0d6dee4e1afd\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x997213931e42e03a5a14971a4bcffa6e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xcf2576c59c6537cd64ad47a38cafdaec\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x00cbdc505479fe7285176e9f45f1cf46\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xb84f0855a13dc86b868b5fab0f1bb1d7\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x58d5a5d1ff86e1347a8cc3702b648102\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xd529e4d5e8e7a0aab1ed773e84d486b4\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x58be59afe1f577b5d6d3259aa590fdf6\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x0f839eef17ee4a6b6e830b8e133d7f56\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x99881054bdfc96f86550c814ab254bef\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x430a85b1be7f3b0a0975b9a202b05f48\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x56cea1162c0770a4e6d68b358ceadba8\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xd33eb7b80502adaf2347ec2c2c1a1311\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x1cc8337509d7fc923c39555dbbf7ee0b\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x277c3f508627efa4b374d2786b86fbcc\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xab9d3abc4a761383cbf4f772b04be366\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xbbff58ec415a43f55c5c5e21755a4545\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x29e5cad2440ad0296264d8bd7e397992\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x8bd5e7a49099320efd27beede454fad0\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xaca8c38f8de8e452e2203fc9574df79f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x70ae47c3337f0ca8f4d1fb0164565775\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xc7dff8e4c2917bc78d8f0b31b2addf45\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xae4dcf18a85b1af14a5e4e02e27f0a47\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x656559c2be1399ceef264c2baacde288\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x70767aa71ce12e5e92e4e9b754ff9a66\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x2d4d10ca9c7779aec400fa80a4b8adfd\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x0422a384351dae159760e13317532c43\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x6b92be16df29abe624c30b894b68329b\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x8531c273a6029a2012cbe15f852b2e91\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x358bb9758fe5a61fb46b0be3b85a97ec\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x0642b08e3d9c3fc3787ce781ad6a8dc6\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xd7820c2b0c3368b59d8c4c07794a3ac5\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xf1c88185d240c9ed137adc58315468df\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x967c8888915510abd11f5aece4cc9e9d\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x0ff27f70fa6706e044f69083aefaf2f6\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x864ae8dd51f8fb3292502613310efd7d\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x0f8662229ce5371d6e02b895a02df41d\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x26b6c1a0abf3c51115f258d9ad5b1207\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x1b2a98e3bf7558cea042f1d9f1d84c61\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x7cf1a212d9cf8a9545762b8bd2ac4c8d\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xcd81450a652280a75e0438a0490ebb3c\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x4245720f913ab12c11606c288e49fc5f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xc10481d76afd5ee3d5fca27263dcf530\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x683318e4be514c61ab7f5b56973cb234\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x400bf8f5daf49b1d50d9ca71ac84a464\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xa64da38008a08880b27c74aab8cc02f6\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xda7f8decb6a0eaf5b00604c83815ebf5\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x94b287abff5f841ebb20de4b3ab62b7c\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x49b059a68d8b9360fc53bb2a15198880\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x53fc17ae34c8ffd0a89d85f72ddf4471\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xe8087fcb68f18e3c3fd6c3bf3114bb77\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x5127b0f64e20b9c2010131148fab827d\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xed9df3a3a82f8f4736ad789b267c8f47\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x97612097f2e5ae99831925d525c4368b\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xb32b1a49b165fe089827dede7c4635f0\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xf368dfb3e7d20241d5f2d83811ded890\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x377e62a18dff2d716af1c425c4ce980a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xd58e771af49172014cf8ad4d3cfdbe6f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x9cfbcc17457361ab5af8a885c79720c2\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xf4efee029466f3890afbc0387a48be71\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x3771e8e11a881dc9836a0aeebb9ac866\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x50d27ee335ae3a4f1623756e42f384d7\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xd461b1e9e9ea8592c4b53fb23191bd54\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x9a709c317b63e25a2f0460226926525e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x4a25ec289754032cb18ffa0485047061\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x838482c86fdb207040780cb224db61e9\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x46b179bae6db125e7d0b98c1504b8f4e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xe94f21d40f169bdbc56b2c91c93def0f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xc8350e00463a45e5c7f6f1832882de1f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xb2319ddd1b0633d406b2ca918d985262\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xbfa6e18cce4aa1722ffe51d3029b831c\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xfee4bc209165d44fe86145e3953989ea\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x28514930a805f6da06d470c0e6f94fd3\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xce1b9cfbfcd7698ee1408ed2efccaccc\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xed28d96f6e7164dbc93963fe657b0419\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x5e78f04b29507d27795ca1490c29d6b4\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x85a68effe7103e7617d761beaff6d47f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xe58b3139a168035d47c32227279bca6c\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x9d7cae8db3a071d4781d3fa8069753c5\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x2a60c08afd23bbbddc222fb5424034b3\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xcd5285e9fb71d1644effb81ec89d50db\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xdd6c0331155ba29413414d79df3c0412\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xdc0e9b6f8d62f0a60110958df52b1edd\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xf89426b487b5402b9c00b943b050241c\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x85147228230ab187cd83ed73073791c8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 67.10 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 67.10 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Y63Jb8 completed job cLWruB8mzRSZNGYQ7mHPPV successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Y63Jb8 completed job cLWruB8mzRSZNGYQ7mHPPV successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 64.08 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 64.08 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Y63Jb8 completed job h2yUoJ6ii2YUwdJ5cgvF8z successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Y63Jb8 completed job h2yUoJ6ii2YUwdJ5cgvF8z successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 66.81 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 66.81 seconds\n",
      "I0000 00:00:1730855915.327291 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Y63Jb8 completed job XSG8q7NYvpXe6Egjd6J538 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Y63Jb8 completed job XSG8q7NYvpXe6Egjd6J538 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 63.27 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 63.27 seconds\n",
      "I0000 00:00:1730855917.739350 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_XZwVr8 completed job QLps4nSkZ8rePzvwaSjEkD successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_XZwVr8 completed job QLps4nSkZ8rePzvwaSjEkD successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 70.96 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 70.96 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Y63Jb8 completed job dxFeXFd8b23dkKuyt9ASr4 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Y63Jb8 completed job dxFeXFd8b23dkKuyt9ASr4 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job YB4Z5Du3NQUempEnFu4dHc.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job YB4Z5Du3NQUempEnFu4dHc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job Qgi5p3fnPShknhHsTNBf2X.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job Qgi5p3fnPShknhHsTNBf2X.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job eQxSgghpeXdWoXo62iexuh.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job eQxSgghpeXdWoXo62iexuh.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job gMpQ2ztNHAeamezPaa4Bv4.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job gMpQ2ztNHAeamezPaa4Bv4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job fWqy7b8vrhTMHH2L2YiJw4.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job fWqy7b8vrhTMHH2L2YiJw4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 73.68 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 73.68 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_XZwVr8 completed job HPzxnLTV29tQpyZZNS3zqL successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_XZwVr8 completed job HPzxnLTV29tQpyZZNS3zqL successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 77.44 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 77.44 seconds\n",
      "I0000 00:00:1730855932.243629 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_XZwVr8 completed job J9c3extkYp7rz79foP5Mud successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_XZwVr8 completed job J9c3extkYp7rz79foP5Mud successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job JSmi3ZMA3PFVa6Ahe2V4Pt.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job JSmi3ZMA3PFVa6Ahe2V4Pt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job au2yh7SCwA554Zbced6diJ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job au2yh7SCwA554Zbced6diJ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 86.70 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 86.70 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MLvzy7 completed job 2uSTV8fpvrfLeRWbPZg4Co successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MLvzy7 completed job 2uSTV8fpvrfLeRWbPZg4Co successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job iz5ZSzhxx2xj7uXs4tsRKE.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job iz5ZSzhxx2xj7uXs4tsRKE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 89.51 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 89.51 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MLvzy7 completed job 4RqF8a9sfvVT2aty8vbrM7 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MLvzy7 completed job 4RqF8a9sfvVT2aty8vbrM7 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 97.55 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 97.55 seconds\n",
      "I0000 00:00:1730855953.055125 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_XZwVr8 completed job BvhWs8pSrsMkSmnvraqyCz successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_XZwVr8 completed job BvhWs8pSrsMkSmnvraqyCz successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job aCzJSiwe2BXrrtYtzFXoze.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job aCzJSiwe2BXrrtYtzFXoze.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job jgSUYsRrKUqzh2cRWTNKzD.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job jgSUYsRrKUqzh2cRWTNKzD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 31.09 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 31.09 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_XZwVr8 completed job EcWp7EsGugcWd5x3Dyqkg6 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_XZwVr8 completed job EcWp7EsGugcWd5x3Dyqkg6 successfully.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job jvJLvWhMxQTSFGNZYKMpbo.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job jvJLvWhMxQTSFGNZYKMpbo.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 39.94 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 39.94 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_XZwVr8 completed job 7QnTxYgeVJXnBxyCbbuaPp successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_XZwVr8 completed job 7QnTxYgeVJXnBxyCbbuaPp successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job PpiGK775bA6eRBpu8DpX8e.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job PpiGK775bA6eRBpu8DpX8e.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 64.03 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 64.03 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Y63Jb8 completed job 53roc2dk5JgdJpRKHL4w8p successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Y63Jb8 completed job 53roc2dk5JgdJpRKHL4w8p successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job Vsxk6umGsVoegJ85r929vN.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job Vsxk6umGsVoegJ85r929vN.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 66.85 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 66.85 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_XZwVr8 completed job LGy5Lik33erZZY5wFLHLjJ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_XZwVr8 completed job LGy5Lik33erZZY5wFLHLjJ successfully.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job fChArPAKhm6yDCEDFq8btB.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job fChArPAKhm6yDCEDFq8btB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 69.30 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 69.30 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:53\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MLvzy7 completed job Qgi5p3fnPShknhHsTNBf2X successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MLvzy7 completed job Qgi5p3fnPShknhHsTNBf2X successfully.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job PAxZfpLHrkrMFVfzvqCBKh.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job PAxZfpLHrkrMFVfzvqCBKh.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 72.24 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 72.24 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MLvzy7 completed job YB4Z5Du3NQUempEnFu4dHc successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MLvzy7 completed job YB4Z5Du3NQUempEnFu4dHc successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job AUNA6ujTciFxLZmuPqejAb.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job AUNA6ujTciFxLZmuPqejAb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 46.26 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 46.26 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_XZwVr8 completed job nVWYR9kDTCwjc8cMbMwosS successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_XZwVr8 completed job nVWYR9kDTCwjc8cMbMwosS successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_hyJL3P with job BzPGqaspXeMLWHrZdsbXpV.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_hyJL3P with job BzPGqaspXeMLWHrZdsbXpV.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 86.19 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 86.19 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Y63Jb8 completed job JfkvvzGyWazCE7VeNAoPdZ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Y63Jb8 completed job JfkvvzGyWazCE7VeNAoPdZ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_hyJL3P with job UdVHmPWtCyJLHkRtDPxVjp.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_hyJL3P with job UdVHmPWtCyJLHkRtDPxVjp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 88.73 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 88.73 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Y63Jb8 completed job HL5jomi8aeeHVUPR8RWQP4 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Y63Jb8 completed job HL5jomi8aeeHVUPR8RWQP4 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_hyJL3P with job DushFYBE2asAkCZD4Hsux9.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_hyJL3P with job DushFYBE2asAkCZD4Hsux9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n",
      "I0000 00:00:1730856019.541340 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 65.75 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 65.75 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856021.740277 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856022.169509 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MLvzy7 completed job gMpQ2ztNHAeamezPaa4Bv4 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MLvzy7 completed job gMpQ2ztNHAeamezPaa4Bv4 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 53.70 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 53.70 seconds\n",
      "I0000 00:00:1730856023.738860 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856024.160099 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_XZwVr8 completed job fZPBVFDncBy4k9XAwknyiy successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_XZwVr8 completed job fZPBVFDncBy4k9XAwknyiy successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_hyJL3P with job 6F7FeNmTMU2wK2dXbCLEUj.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_hyJL3P with job 6F7FeNmTMU2wK2dXbCLEUj.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_hyJL3P with job ePyQaumq3rPQoFopd6asLr.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_hyJL3P with job ePyQaumq3rPQoFopd6asLr.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 75.64 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 75.64 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856026.061792 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856026.522947 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MLvzy7 completed job eQxSgghpeXdWoXo62iexuh successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MLvzy7 completed job eQxSgghpeXdWoXo62iexuh successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_hyJL3P with job 42ixayuufEdNLmVS2nhBWM.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_hyJL3P with job 42ixayuufEdNLmVS2nhBWM.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 106.79 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 106.79 seconds\n",
      "I0000 00:00:1730856029.547994 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856029.948072 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Y63Jb8 completed job 57DFDLQVdgLoDMTXx5dqgN successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Y63Jb8 completed job 57DFDLQVdgLoDMTXx5dqgN successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_hyJL3P with job J6SqUtdwyQX5uuLk5hWCYa.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_hyJL3P with job J6SqUtdwyQX5uuLk5hWCYa.\n",
      "I0000 00:00:1730856032.423297 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 55.30 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 55.30 seconds\n",
      "I0000 00:00:1730856044.605633 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856045.292649 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Y63Jb8 completed job aw5XUVNj4Npjgjra7eY6pi successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Y63Jb8 completed job aw5XUVNj4Npjgjra7eY6pi successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_hyJL3P with job ToZEDB4C9vjvMLWDdVR5r9.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_hyJL3P with job ToZEDB4C9vjvMLWDdVR5r9.\n",
      "I0000 00:00:1730856048.799701 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 43.55 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 43.55 seconds\n",
      "I0000 00:00:1730856053.368211 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856053.969095 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:55\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:55\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:55\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_hyJL3P completed job BzPGqaspXeMLWHrZdsbXpV successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_hyJL3P completed job BzPGqaspXeMLWHrZdsbXpV successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:55\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:55\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_hyJL3P with job mttqu2kBWFiV4v6BmMjSqD.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_hyJL3P with job mttqu2kBWFiV4v6BmMjSqD.\n",
      "I0000 00:00:1730856057.471605 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 49.77 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 49.77 seconds\n",
      "I0000 00:00:1730856062.464046 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856063.066456 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_hyJL3P completed job UdVHmPWtCyJLHkRtDPxVjp successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_hyJL3P completed job UdVHmPWtCyJLHkRtDPxVjp successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 50.87 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 50.87 seconds\n",
      "I0000 00:00:1730856064.769885 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856065.351039 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_hyJL3P completed job DushFYBE2asAkCZD4Hsux9 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_hyJL3P completed job DushFYBE2asAkCZD4Hsux9 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gthKhq with job aAi6N3BwR7YCQw6MpmhN2M.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gthKhq with job aAi6N3BwR7YCQw6MpmhN2M.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gthKhq with job YSE79HGCrTWB4qLWxdh8n9.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gthKhq with job YSE79HGCrTWB4qLWxdh8n9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 70.08 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 70.08 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856068.161931 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856068.528659 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MLvzy7 completed job JSmi3ZMA3PFVa6Ahe2V4Pt successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MLvzy7 completed job JSmi3ZMA3PFVa6Ahe2V4Pt successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gthKhq with job Kq25tJhvUCA7yWjtfzFJbS.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gthKhq with job Kq25tJhvUCA7yWjtfzFJbS.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 76.16 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 76.16 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856070.510367 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856070.986827 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MLvzy7 completed job fWqy7b8vrhTMHH2L2YiJw4 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MLvzy7 completed job fWqy7b8vrhTMHH2L2YiJw4 successfully.\n",
      "I0000 00:00:1730856073.639047 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gthKhq with job FhXQWDfzidJv4LRR8qHPJb.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gthKhq with job FhXQWDfzidJv4LRR8qHPJb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 50.50 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 50.50 seconds\n",
      "I0000 00:00:1730856077.460854 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856077.895090 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_hyJL3P completed job 6F7FeNmTMU2wK2dXbCLEUj successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_hyJL3P completed job 6F7FeNmTMU2wK2dXbCLEUj successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gthKhq with job gLeZRhxMEsjAvvga4wBY2j.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gthKhq with job gLeZRhxMEsjAvvga4wBY2j.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 210] \u001b[1;30mERROR\u001b[0m \u001b[31mError invoking chain with sonnet: Connection error. after 110.34 seconds. e.args=('Connection error.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:buttermilk:Error invoking chain with sonnet: Connection error. after 110.34 seconds. e.args=('Connection error.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 130.31 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 130.31 seconds\n",
      "I0000 00:00:1730856080.764400 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856081.154189 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_NuPAyP completed job iz5ZSzhxx2xj7uXs4tsRKE successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_NuPAyP completed job iz5ZSzhxx2xj7uXs4tsRKE successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gthKhq with job ZHzpcXsYnweuMnp4X2eqmY.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gthKhq with job ZHzpcXsYnweuMnp4X2eqmY.\n",
      "I0000 00:00:1730856084.383304 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 131.30 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 131.30 seconds\n",
      "I0000 00:00:1730856086.789361 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856087.254421 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_NuPAyP completed job jgSUYsRrKUqzh2cRWTNKzD successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_NuPAyP completed job jgSUYsRrKUqzh2cRWTNKzD successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 133.45 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 133.45 seconds\n",
      "I0000 00:00:1730856088.930954 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856089.413395 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_NuPAyP completed job aCzJSiwe2BXrrtYtzFXoze successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_NuPAyP completed job aCzJSiwe2BXrrtYtzFXoze successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gthKhq with job JpxupjnPYG6NmyZihMCmWY.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gthKhq with job JpxupjnPYG6NmyZihMCmWY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gthKhq with job XueJB4nVBeVEMy7rhikGDV.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gthKhq with job XueJB4nVBeVEMy7rhikGDV.\n",
      "I0000 00:00:1730856093.328220 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 71.37 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 71.37 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856097.432216 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856097.858204 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MLvzy7 completed job au2yh7SCwA554Zbced6diJ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MLvzy7 completed job au2yh7SCwA554Zbced6diJ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gthKhq with job QiUmvriG6ocU3MX3RNCxU9.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gthKhq with job QiUmvriG6ocU3MX3RNCxU9.\n",
      "I0000 00:00:1730856100.039821 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 47.87 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 47.87 seconds\n",
      "I0000 00:00:1730856103.750964 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856104.198147 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_hyJL3P completed job ePyQaumq3rPQoFopd6asLr successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_hyJL3P completed job ePyQaumq3rPQoFopd6asLr successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6r8oBs with job TtaZ9sDc9XyEHHYswHqWA2.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6r8oBs with job TtaZ9sDc9XyEHHYswHqWA2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n",
      "I0000 00:00:1730856107.294219 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 43.08 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 43.08 seconds\n",
      "I0000 00:00:1730856110.466777 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856110.947648 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_hyJL3P completed job 42ixayuufEdNLmVS2nhBWM successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_hyJL3P completed job 42ixayuufEdNLmVS2nhBWM successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6r8oBs with job CMb354zAGBpdpt8SKQk4x9.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6r8oBs with job CMb354zAGBpdpt8SKQk4x9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:53\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 45.61 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 45.61 seconds\n",
      "I0000 00:00:1730856113.746869 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856114.193261 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:55\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:55\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:55\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_hyJL3P completed job J6SqUtdwyQX5uuLk5hWCYa successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_hyJL3P completed job J6SqUtdwyQX5uuLk5hWCYa successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6r8oBs with job 4iswRmki8ys3SHLBrgiJt5.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6r8oBs with job 4iswRmki8ys3SHLBrgiJt5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:21:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n",
      "I0000 00:00:1730856117.728939 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856123.356596 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 46.79 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 46.79 seconds\n",
      "I0000 00:00:1730856127.794082 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856128.272232 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_hyJL3P completed job ToZEDB4C9vjvMLWDdVR5r9 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_hyJL3P completed job ToZEDB4C9vjvMLWDdVR5r9 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6r8oBs with job HS5AQgDyjhm4dENSChxQN3.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6r8oBs with job HS5AQgDyjhm4dENSChxQN3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 63.71 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 63.71 seconds\n",
      "I0000 00:00:1730856131.160406 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856131.603482 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gthKhq completed job aAi6N3BwR7YCQw6MpmhN2M successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gthKhq completed job aAi6N3BwR7YCQw6MpmhN2M successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 63.09 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 63.09 seconds\n",
      "I0000 00:00:1730856133.601083 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856134.196810 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gthKhq completed job Kq25tJhvUCA7yWjtfzFJbS successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gthKhq completed job Kq25tJhvUCA7yWjtfzFJbS successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6r8oBs with job Y4SnmZ7SADH4t4veW7myDY.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6r8oBs with job Y4SnmZ7SADH4t4veW7myDY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6r8oBs with job jAeCHPChheWUiBKDLVHtmb.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6r8oBs with job jAeCHPChheWUiBKDLVHtmb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 68.73 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 68.73 seconds\n",
      "I0000 00:00:1730856136.195154 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856136.624895 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:17\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gthKhq completed job YSE79HGCrTWB4qLWxdh8n9 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gthKhq completed job YSE79HGCrTWB4qLWxdh8n9 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6r8oBs with job YqfLCn7ofJfpBDHdSGfZCK.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6r8oBs with job YqfLCn7ofJfpBDHdSGfZCK.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 62.93 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 62.93 seconds\n",
      "I0000 00:00:1730856138.579792 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856139.045472 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gthKhq completed job FhXQWDfzidJv4LRR8qHPJb successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gthKhq completed job FhXQWDfzidJv4LRR8qHPJb successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6r8oBs with job UJzisKGa7BFdxNQxExPP3R.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6r8oBs with job UJzisKGa7BFdxNQxExPP3R.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 58.04 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 58.04 seconds\n",
      "I0000 00:00:1730856141.129296 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856141.431688 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_NuPAyP completed job PpiGK775bA6eRBpu8DpX8e successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_NuPAyP completed job PpiGK775bA6eRBpu8DpX8e successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 51.60 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 51.60 seconds\n",
      "I0000 00:00:1730856143.063908 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856143.477676 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_NuPAyP completed job Vsxk6umGsVoegJ85r929vN successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_NuPAyP completed job Vsxk6umGsVoegJ85r929vN successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 53.56 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 53.56 seconds\n",
      "I0000 00:00:1730856145.038718 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856145.656754 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_NuPAyP completed job fChArPAKhm6yDCEDFq8btB successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_NuPAyP completed job fChArPAKhm6yDCEDFq8btB successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6r8oBs with job SJ5epKyMvZQ96qRcXikoL3.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6r8oBs with job SJ5epKyMvZQ96qRcXikoL3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cuQN3M with job naHpmBzRSa9cCNzgEyS785.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cuQN3M with job naHpmBzRSa9cCNzgEyS785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cuQN3M with job jQZSyBQbn9bmMhn9UWX9cY.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cuQN3M with job jQZSyBQbn9bmMhn9UWX9cY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 40.78 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 40.78 seconds\n",
      "I0000 00:00:1730856147.405634 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856147.927072 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_hyJL3P completed job mttqu2kBWFiV4v6BmMjSqD successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_hyJL3P completed job mttqu2kBWFiV4v6BmMjSqD successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cuQN3M with job S2rrRJJte3tQpmUQRgxhq7.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cuQN3M with job S2rrRJJte3tQpmUQRgxhq7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 33.54 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 33.54 seconds\n",
      "I0000 00:00:1730856149.645630 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6r8oBs completed job 4iswRmki8ys3SHLBrgiJt5 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6r8oBs completed job 4iswRmki8ys3SHLBrgiJt5 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cuQN3M with job ksZK49VQtFfTDqeVRaLFpo.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cuQN3M with job ksZK49VQtFfTDqeVRaLFpo.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 20.84 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 20.84 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gthKhq completed job ZHzpcXsYnweuMnp4X2eqmY successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gthKhq completed job ZHzpcXsYnweuMnp4X2eqmY successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cuQN3M with job Z2t7WdGUoejAbBLXebv3Ni.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cuQN3M with job Z2t7WdGUoejAbBLXebv3Ni.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 23.08 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 23.08 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gthKhq completed job gLeZRhxMEsjAvvga4wBY2j successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gthKhq completed job gLeZRhxMEsjAvvga4wBY2j successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 15.11 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 15.11 seconds\n",
      "I0000 00:00:1730856162.422361 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_NuPAyP completed job AUNA6ujTciFxLZmuPqejAb successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_NuPAyP completed job AUNA6ujTciFxLZmuPqejAb successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 25.93 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 25.93 seconds\n",
      "I0000 00:00:1730856164.506070 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gthKhq completed job JpxupjnPYG6NmyZihMCmWY successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gthKhq completed job JpxupjnPYG6NmyZihMCmWY successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 25.80 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 25.80 seconds\n",
      "I0000 00:00:1730856166.866198 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gthKhq completed job XueJB4nVBeVEMy7rhikGDV successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gthKhq completed job XueJB4nVBeVEMy7rhikGDV successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cuQN3M with job Pa83CiajYFRP8gG9dcjabd.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cuQN3M with job Pa83CiajYFRP8gG9dcjabd.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cuQN3M with job SaKs3Hvqos5WkVDiGEJeAR.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cuQN3M with job SaKs3Hvqos5WkVDiGEJeAR.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cuQN3M with job AZJ8h9aGCeEoSwhzLB59ng.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cuQN3M with job AZJ8h9aGCeEoSwhzLB59ng.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cuQN3M with job YwZkx33qZBuZ9VTcvgj79Q.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cuQN3M with job YwZkx33qZBuZ9VTcvgj79Q.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 21.81 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 21.81 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cuQN3M completed job jQZSyBQbn9bmMhn9UWX9cY successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cuQN3M completed job jQZSyBQbn9bmMhn9UWX9cY successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_im3cQQ with job HBfvoJbuw4imx65qudbKhP.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_im3cQQ with job HBfvoJbuw4imx65qudbKhP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 25.03 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 25.03 seconds\n",
      "I0000 00:00:1730856172.331264 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_NuPAyP completed job PAxZfpLHrkrMFVfzvqCBKh successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_NuPAyP completed job PAxZfpLHrkrMFVfzvqCBKh successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_im3cQQ with job Qkhxim4siU3gQtbp2VjrPi.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_im3cQQ with job Qkhxim4siU3gQtbp2VjrPi.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 43.23 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 43.23 seconds\n",
      "I0000 00:00:1730856174.363821 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_NuPAyP completed job jvJLvWhMxQTSFGNZYKMpbo successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_NuPAyP completed job jvJLvWhMxQTSFGNZYKMpbo successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 29.21 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 29.21 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856176.553295 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cuQN3M completed job naHpmBzRSa9cCNzgEyS785 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cuQN3M completed job naHpmBzRSa9cCNzgEyS785 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:22:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 27.05 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 27.05 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856178.977428 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:00\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cuQN3M completed job ksZK49VQtFfTDqeVRaLFpo successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cuQN3M completed job ksZK49VQtFfTDqeVRaLFpo successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_im3cQQ with job knfmPiwjXecet9ygPzVahq.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_im3cQQ with job knfmPiwjXecet9ygPzVahq.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_im3cQQ with job NJmZYNS69fSKiBJPxnSjdF.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_im3cQQ with job NJmZYNS69fSKiBJPxnSjdF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_im3cQQ with job ehGBXLrLuncsZ6N9riLHr3.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_im3cQQ with job ehGBXLrLuncsZ6N9riLHr3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 32.20 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 32.20 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856181.753330 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cuQN3M completed job S2rrRJJte3tQpmUQRgxhq7 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cuQN3M completed job S2rrRJJte3tQpmUQRgxhq7 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 24.98 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 24.98 seconds\n",
      "I0000 00:00:1730856184.221687 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gthKhq completed job QiUmvriG6ocU3MX3RNCxU9 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gthKhq completed job QiUmvriG6ocU3MX3RNCxU9 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_im3cQQ with job QtRcGR2UmeXgu47cNSfaxi.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_im3cQQ with job QtRcGR2UmeXgu47cNSfaxi.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_im3cQQ with job G47VXzzw2BndGvLtCG9wzk.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_im3cQQ with job G47VXzzw2BndGvLtCG9wzk.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 56.24 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 56.24 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6r8oBs completed job HS5AQgDyjhm4dENSChxQN3 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6r8oBs completed job HS5AQgDyjhm4dENSChxQN3 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_im3cQQ with job Rz3p3fxZdD4Lcnj5yntZMf.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_im3cQQ with job Rz3p3fxZdD4Lcnj5yntZMf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 16.76 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 16.76 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cuQN3M completed job Z2t7WdGUoejAbBLXebv3Ni successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cuQN3M completed job Z2t7WdGUoejAbBLXebv3Ni successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_im3cQQ with job SJnR8ehW8bLNMLteZiREjR.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_im3cQQ with job SJnR8ehW8bLNMLteZiREjR.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 40.17 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 40.17 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6r8oBs completed job Y4SnmZ7SADH4t4veW7myDY successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6r8oBs completed job Y4SnmZ7SADH4t4veW7myDY successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_9ue3pE with job 83Ka5kU2vXRXGiM5jE5cTz.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_9ue3pE with job 83Ka5kU2vXRXGiM5jE5cTz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 88.93 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 88.93 seconds\n",
      "I0000 00:00:1730856195.776841 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856196.132225 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:17\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6r8oBs completed job TtaZ9sDc9XyEHHYswHqWA2 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6r8oBs completed job TtaZ9sDc9XyEHHYswHqWA2 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_9ue3pE with job GgALRknoPbSgbEpRp37C4g.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_9ue3pE with job GgALRknoPbSgbEpRp37C4g.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 25.88 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 25.88 seconds\n",
      "I0000 00:00:1730856198.169002 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856198.607602 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_im3cQQ completed job HBfvoJbuw4imx65qudbKhP successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_im3cQQ completed job HBfvoJbuw4imx65qudbKhP successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_9ue3pE with job H3UahgNust3mX4gQ2kaPSt.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_9ue3pE with job H3UahgNust3mX4gQ2kaPSt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 18.68 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 18.68 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856200.391930 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856200.838191 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cuQN3M completed job Pa83CiajYFRP8gG9dcjabd successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cuQN3M completed job Pa83CiajYFRP8gG9dcjabd successfully.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_9ue3pE with job bTUTgnvWFcZyn2C6WVg55T.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_9ue3pE with job bTUTgnvWFcZyn2C6WVg55T.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 10.76 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 10.76 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856202.814662 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856203.230998 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cuQN3M completed job YwZkx33qZBuZ9VTcvgj79Q successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cuQN3M completed job YwZkx33qZBuZ9VTcvgj79Q successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_9ue3pE with job 8Hi3VdoudFibz4dYWFvNLV.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_9ue3pE with job 8Hi3VdoudFibz4dYWFvNLV.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 30.90 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 30.90 seconds\n",
      "I0000 00:00:1730856205.260533 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856205.863355 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_im3cQQ completed job Qkhxim4siU3gQtbp2VjrPi successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_im3cQQ completed job Qkhxim4siU3gQtbp2VjrPi successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 26.12 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 26.12 seconds\n",
      "I0000 00:00:1730856208.511751 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856208.967904 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_im3cQQ completed job knfmPiwjXecet9ygPzVahq successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_im3cQQ completed job knfmPiwjXecet9ygPzVahq successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_9ue3pE with job maMJzARu5BePc5Huj5PZiL.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_9ue3pE with job maMJzARu5BePc5Huj5PZiL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_9ue3pE with job CcM5TWCCc8guvoHCwCnjUZ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_9ue3pE with job CcM5TWCCc8guvoHCwCnjUZ.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 29.21 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 29.21 seconds\n",
      "I0000 00:00:1730856210.936738 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856211.351823 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:32\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_im3cQQ completed job NJmZYNS69fSKiBJPxnSjdF successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_im3cQQ completed job NJmZYNS69fSKiBJPxnSjdF successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_9ue3pE with job 2jefuEhpYJg5U9FU4p84wP.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_9ue3pE with job 2jefuEhpYJg5U9FU4p84wP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 31.53 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 31.53 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856213.280292 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856213.712126 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cuQN3M completed job SaKs3Hvqos5WkVDiGEJeAR successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cuQN3M completed job SaKs3Hvqos5WkVDiGEJeAR successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 29.20 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 29.20 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856215.590758 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856216.180775 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cuQN3M completed job AZJ8h9aGCeEoSwhzLB59ng successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cuQN3M completed job AZJ8h9aGCeEoSwhzLB59ng successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_9ue3pE with job L8QCnhHe4kKNcQqbszWBiF.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_9ue3pE with job L8QCnhHe4kKNcQqbszWBiF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kr3RPS with job V7YtCdvwYM79y84859iF8d.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kr3RPS with job V7YtCdvwYM79y84859iF8d.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 23.36 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 23.36 seconds\n",
      "I0000 00:00:1730856218.310824 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856218.809070 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6r8oBs completed job YqfLCn7ofJfpBDHdSGfZCK successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6r8oBs completed job YqfLCn7ofJfpBDHdSGfZCK successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 25.82 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 25.82 seconds\n",
      "I0000 00:00:1730856221.490013 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856221.885165 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_9ue3pE completed job 83Ka5kU2vXRXGiM5jE5cTz successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_9ue3pE completed job 83Ka5kU2vXRXGiM5jE5cTz successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 23.56 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 23.56 seconds\n",
      "I0000 00:00:1730856223.932166 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856224.522572 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_9ue3pE completed job H3UahgNust3mX4gQ2kaPSt successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_9ue3pE completed job H3UahgNust3mX4gQ2kaPSt successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kr3RPS with job HZAprkfKADotLdbJBiUzTG.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kr3RPS with job HZAprkfKADotLdbJBiUzTG.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kr3RPS with job 2VB4NunB5NnVzF6RwxZdYj.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kr3RPS with job 2VB4NunB5NnVzF6RwxZdYj.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kr3RPS with job A2ks7EmojQZTHacu67BTff.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kr3RPS with job A2ks7EmojQZTHacu67BTff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 26.30 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 26.30 seconds\n",
      "I0000 00:00:1730856226.645593 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856227.048210 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_im3cQQ completed job ehGBXLrLuncsZ6N9riLHr3 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_im3cQQ completed job ehGBXLrLuncsZ6N9riLHr3 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 17.95 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 17.95 seconds\n",
      "I0000 00:00:1730856229.524410 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856230.109012 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_im3cQQ completed job QtRcGR2UmeXgu47cNSfaxi successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_im3cQQ completed job QtRcGR2UmeXgu47cNSfaxi successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kr3RPS with job h5mPzryHAGPJfJopjCWTSJ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kr3RPS with job h5mPzryHAGPJfJopjCWTSJ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kr3RPS with job ai9agxYGrkYrHRk92YXEmA.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kr3RPS with job ai9agxYGrkYrHRk92YXEmA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 21.20 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 21.20 seconds\n",
      "I0000 00:00:1730856232.100286 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856232.531907 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:53\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_im3cQQ completed job G47VXzzw2BndGvLtCG9wzk successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_im3cQQ completed job G47VXzzw2BndGvLtCG9wzk successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 31.66 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 31.66 seconds\n",
      "I0000 00:00:1730856234.470713 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856234.909930 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_9ue3pE completed job bTUTgnvWFcZyn2C6WVg55T successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_9ue3pE completed job bTUTgnvWFcZyn2C6WVg55T successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kr3RPS with job V6fDAtsgfwHTFSCCAUZvRD.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kr3RPS with job V6fDAtsgfwHTFSCCAUZvRD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kr3RPS with job kEcDUMCFh8fqmAz7XN2uPQ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kr3RPS with job kEcDUMCFh8fqmAz7XN2uPQ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 38.77 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 38.77 seconds\n",
      "I0000 00:00:1730856236.918296 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856237.335624 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_9ue3pE completed job GgALRknoPbSgbEpRp37C4g successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_9ue3pE completed job GgALRknoPbSgbEpRp37C4g successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kr3RPS with job f5riF3VDBua97xSz5AjiLh.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kr3RPS with job f5riF3VDBua97xSz5AjiLh.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:23:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 41.15 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 41.15 seconds\n",
      "I0000 00:00:1730856239.274102 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856239.693079 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:00\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6r8oBs completed job UJzisKGa7BFdxNQxExPP3R successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6r8oBs completed job UJzisKGa7BFdxNQxExPP3R successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_WZUkKS with job QvqzKrSHdp4XN9S4cwvXwK.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_WZUkKS with job QvqzKrSHdp4XN9S4cwvXwK.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 15.04 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 15.04 seconds\n",
      "I0000 00:00:1730856241.540336 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856241.961928 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_9ue3pE completed job 8Hi3VdoudFibz4dYWFvNLV successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_9ue3pE completed job 8Hi3VdoudFibz4dYWFvNLV successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_WZUkKS with job Hn3mXdNZHWBLxP2vAiWy6B.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_WZUkKS with job Hn3mXdNZHWBLxP2vAiWy6B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 17.43 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 17.43 seconds\n",
      "I0000 00:00:1730856244.008104 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856244.634855 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kr3RPS completed job A2ks7EmojQZTHacu67BTff successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kr3RPS completed job A2ks7EmojQZTHacu67BTff successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 19.76 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 19.76 seconds\n",
      "I0000 00:00:1730856246.773012 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856247.214412 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kr3RPS completed job HZAprkfKADotLdbJBiUzTG successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kr3RPS completed job HZAprkfKADotLdbJBiUzTG successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 30.56 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 30.56 seconds\n",
      "I0000 00:00:1730856248.825591 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856249.203921 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kr3RPS completed job V7YtCdvwYM79y84859iF8d successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kr3RPS completed job V7YtCdvwYM79y84859iF8d successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_WZUkKS with job UDfuRMx9nnAP2VmuNLgbwT.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_WZUkKS with job UDfuRMx9nnAP2VmuNLgbwT.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_WZUkKS with job HpRADonBmKN865wZH3ouvW.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_WZUkKS with job HpRADonBmKN865wZH3ouvW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_WZUkKS with job fyTXAiQfxLqDJaDXobyJ4t.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_WZUkKS with job fyTXAiQfxLqDJaDXobyJ4t.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 24.40 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 24.40 seconds\n",
      "I0000 00:00:1730856250.905002 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856251.218389 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kr3RPS completed job 2VB4NunB5NnVzF6RwxZdYj successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kr3RPS completed job 2VB4NunB5NnVzF6RwxZdYj successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_WZUkKS with job iXVoHqNVKCTE6cKMLPufMB.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_WZUkKS with job iXVoHqNVKCTE6cKMLPufMB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 210] \u001b[1;30mERROR\u001b[0m \u001b[31mError invoking chain with llama31_70b: The read operation timed out after 140.03 seconds. e.args=('The read operation timed out',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:buttermilk:Error invoking chain with llama31_70b: The read operation timed out after 140.03 seconds. e.args=('The read operation timed out',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 26.26 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 26.26 seconds\n",
      "I0000 00:00:1730856252.825998 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856253.264828 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_9ue3pE completed job maMJzARu5BePc5Huj5PZiL successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_9ue3pE completed job maMJzARu5BePc5Huj5PZiL successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_WZUkKS with job 2XByL8zYDciEaYBEQHTE8o.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_WZUkKS with job 2XByL8zYDciEaYBEQHTE8o.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 5.76 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 5.76 seconds\n",
      "I0000 00:00:1730856258.565876 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856259.030692 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kr3RPS completed job kEcDUMCFh8fqmAz7XN2uPQ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kr3RPS completed job kEcDUMCFh8fqmAz7XN2uPQ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_WZUkKS with job PbPbQJGtsHwrJ54ivK9bNH.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_WZUkKS with job PbPbQJGtsHwrJ54ivK9bNH.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 9.80 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 9.80 seconds\n",
      "I0000 00:00:1730856260.625676 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856261.057874 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kr3RPS completed job V6fDAtsgfwHTFSCCAUZvRD successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kr3RPS completed job V6fDAtsgfwHTFSCCAUZvRD successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 11.79 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 11.79 seconds\n",
      "I0000 00:00:1730856262.556186 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856263.105691 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kr3RPS completed job h5mPzryHAGPJfJopjCWTSJ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kr3RPS completed job h5mPzryHAGPJfJopjCWTSJ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 13.96 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 13.96 seconds\n",
      "I0000 00:00:1730856264.752156 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856265.147506 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kr3RPS completed job ai9agxYGrkYrHRk92YXEmA successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kr3RPS completed job ai9agxYGrkYrHRk92YXEmA successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_WZUkKS with job 5iocrTXk73upBcdoqjKuGA.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_WZUkKS with job 5iocrTXk73upBcdoqjKuGA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kdgyPX with job ZwjLZN7r3fXBj4vs3pQjNn.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kdgyPX with job ZwjLZN7r3fXBj4vs3pQjNn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kdgyPX with job CTKQifX27FsiqKBKS25W4v.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kdgyPX with job CTKQifX27FsiqKBKS25W4v.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 53.55 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 53.55 seconds\n",
      "I0000 00:00:1730856266.823258 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856267.260359 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_im3cQQ completed job Rz3p3fxZdD4Lcnj5yntZMf successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_im3cQQ completed job Rz3p3fxZdD4Lcnj5yntZMf successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 18.47 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 18.47 seconds\n",
      "I0000 00:00:1730856269.252877 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856269.689777 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_WZUkKS completed job UDfuRMx9nnAP2VmuNLgbwT successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_WZUkKS completed job UDfuRMx9nnAP2VmuNLgbwT successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 34.46 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 34.46 seconds\n",
      "I0000 00:00:1730856271.321141 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856271.754849 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:32\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_9ue3pE completed job CcM5TWCCc8guvoHCwCnjUZ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_9ue3pE completed job CcM5TWCCc8guvoHCwCnjUZ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 41.58 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 41.58 seconds\n",
      "I0000 00:00:1730856273.677551 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856274.111402 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_im3cQQ completed job SJnR8ehW8bLNMLteZiREjR successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_im3cQQ completed job SJnR8ehW8bLNMLteZiREjR successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kdgyPX with job KewwasgRkGfXJD5WzKtW98.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kdgyPX with job KewwasgRkGfXJD5WzKtW98.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kdgyPX with job 22QE4RxrdwBUGetL9wxuZ5.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kdgyPX with job 22QE4RxrdwBUGetL9wxuZ5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kdgyPX with job aEHF3apQdEpLfmLPx6XC2M.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kdgyPX with job aEHF3apQdEpLfmLPx6XC2M.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kdgyPX with job JcKGxVgYwHAkDcDbefc3wk.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kdgyPX with job JcKGxVgYwHAkDcDbefc3wk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 15.59 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 15.59 seconds\n",
      "I0000 00:00:1730856276.198691 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856276.786933 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kr3RPS completed job f5riF3VDBua97xSz5AjiLh successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kr3RPS completed job f5riF3VDBua97xSz5AjiLh successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kdgyPX with job CbgdgubJW4EEjuF7Rv2jB6.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kdgyPX with job CbgdgubJW4EEjuF7Rv2jB6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 36.85 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 36.85 seconds\n",
      "I0000 00:00:1730856278.351894 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856278.785862 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_WZUkKS completed job QvqzKrSHdp4XN9S4cwvXwK successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_WZUkKS completed job QvqzKrSHdp4XN9S4cwvXwK successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kdgyPX with job 96z4Rjip8SjktTxwRt2Fec.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kdgyPX with job 96z4Rjip8SjktTxwRt2Fec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 41.06 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 41.06 seconds\n",
      "I0000 00:00:1730856280.333992 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856280.755486 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_9ue3pE completed job 2jefuEhpYJg5U9FU4p84wP successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_9ue3pE completed job 2jefuEhpYJg5U9FU4p84wP successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 38.80 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 38.80 seconds\n",
      "I0000 00:00:1730856282.779631 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856283.233807 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_9ue3pE completed job L8QCnhHe4kKNcQqbszWBiF successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_9ue3pE completed job L8QCnhHe4kKNcQqbszWBiF successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_kdgyPX with job UZuY4hi5Zv3E8GUrUY5Sqz.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_kdgyPX with job UZuY4hi5Zv3E8GUrUY5Sqz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_ZBfaV6 with job iV5ZwqdVTrFJtvpyRTqknk.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_ZBfaV6 with job iV5ZwqdVTrFJtvpyRTqknk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 41.26 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 41.26 seconds\n",
      "I0000 00:00:1730856285.257592 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_WZUkKS completed job Hn3mXdNZHWBLxP2vAiWy6B successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_WZUkKS completed job Hn3mXdNZHWBLxP2vAiWy6B successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 36.48 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 36.48 seconds\n",
      "I0000 00:00:1730856287.299012 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_WZUkKS completed job HpRADonBmKN865wZH3ouvW successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_WZUkKS completed job HpRADonBmKN865wZH3ouvW successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_ZBfaV6 with job S7bSLHmE8pnndXvnfTE7iY.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_ZBfaV6 with job S7bSLHmE8pnndXvnfTE7iY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_ZBfaV6 with job WAZMWmpBxdgUVGDJ8LvYDp.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_ZBfaV6 with job WAZMWmpBxdgUVGDJ8LvYDp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 27.24 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 27.24 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kdgyPX completed job ZwjLZN7r3fXBj4vs3pQjNn successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kdgyPX completed job ZwjLZN7r3fXBj4vs3pQjNn successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_ZBfaV6 with job W3LD6ddLCsEjjXMxbwZExT.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_ZBfaV6 with job W3LD6ddLCsEjjXMxbwZExT.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:24:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 22.98 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 22.98 seconds\n",
      "I0000 00:00:1730856299.144559 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:00\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_WZUkKS completed job fyTXAiQfxLqDJaDXobyJ4t successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_WZUkKS completed job fyTXAiQfxLqDJaDXobyJ4t successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_ZBfaV6 with job 5CKEJbGgyxK5gqY8xjWDMM.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_ZBfaV6 with job 5CKEJbGgyxK5gqY8xjWDMM.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 11.97 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 11.97 seconds\n",
      "I0000 00:00:1730856301.291657 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_ZBfaV6 completed job S7bSLHmE8pnndXvnfTE7iY successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_ZBfaV6 completed job S7bSLHmE8pnndXvnfTE7iY successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 19.01 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 19.01 seconds\n",
      "I0000 00:00:1730856304.224294 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_ZBfaV6 completed job iV5ZwqdVTrFJtvpyRTqknk successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_ZBfaV6 completed job iV5ZwqdVTrFJtvpyRTqknk successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 16.91 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 16.91 seconds\n",
      "I0000 00:00:1730856306.246731 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_ZBfaV6 completed job WAZMWmpBxdgUVGDJ8LvYDp successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_ZBfaV6 completed job WAZMWmpBxdgUVGDJ8LvYDp successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_ZBfaV6 with job YQAKLK9KjuEM9rgRp6EFUs.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_ZBfaV6 with job YQAKLK9KjuEM9rgRp6EFUs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_ZBfaV6 with job npJxehjt8VrSkKrmigCDq2.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_ZBfaV6 with job npJxehjt8VrSkKrmigCDq2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_ZBfaV6 with job WrMfq3bLUvAPMGAoWrmhDG.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_ZBfaV6 with job WrMfq3bLUvAPMGAoWrmhDG.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 41.51 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 41.51 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856308.290615 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kdgyPX completed job CTKQifX27FsiqKBKS25W4v successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kdgyPX completed job CTKQifX27FsiqKBKS25W4v successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 34.10 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 34.10 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856310.192852 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kdgyPX completed job KewwasgRkGfXJD5WzKtW98 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kdgyPX completed job KewwasgRkGfXJD5WzKtW98 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_ZBfaV6 with job C7daVwSa7Mp5ijLQKVVUDC.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_ZBfaV6 with job C7daVwSa7Mp5ijLQKVVUDC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gskCMv with job GSMTxcnWdFtNSSymzjQooq.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gskCMv with job GSMTxcnWdFtNSSymzjQooq.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 36.14 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 36.14 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856312.343013 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kdgyPX completed job 22QE4RxrdwBUGetL9wxuZ5 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kdgyPX completed job 22QE4RxrdwBUGetL9wxuZ5 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gskCMv with job K5vpsy7v4JMW9DXmaemKqE.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gskCMv with job K5vpsy7v4JMW9DXmaemKqE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856314.533812 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 29.75 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 29.75 seconds\n",
      "I0000 00:00:1730856314.973031 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856317.474401 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6r8oBs completed job CMb354zAGBpdpt8SKQk4x9 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6r8oBs completed job CMb354zAGBpdpt8SKQk4x9 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 30.12 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 30.12 seconds\n",
      "I0000 00:00:1730856319.433867 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856319.959063 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "E0000 00:00:1730856320.079822 28238687 ssl_transport_security_utils.cc:116] Corruption detected.\n",
      "E0000 00:00:1730856320.079856 28238687 ssl_transport_security_utils.cc:73] error:100003fc:SSL routines:OPENSSL_internal:SSLV3_ALERT_BAD_RECORD_MAC\n",
      "E0000 00:00:1730856320.079858 28238687 secure_endpoint.cc:300] Decryption error: TSI_DATA_CORRUPTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_WZUkKS completed job 2XByL8zYDciEaYBEQHTE8o successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_WZUkKS completed job 2XByL8zYDciEaYBEQHTE8o successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 132.57 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 132.57 seconds\n",
      "I0000 00:00:1730856321.572528 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856322.117819 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6r8oBs completed job jAeCHPChheWUiBKDLVHtmb successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6r8oBs completed job jAeCHPChheWUiBKDLVHtmb successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gskCMv with job jWQMZXJGBUY2YGX46uM6et.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gskCMv with job jWQMZXJGBUY2YGX46uM6et.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gskCMv with job j4wyNL3Hx5Hp2cUhmRjFcS.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gskCMv with job j4wyNL3Hx5Hp2cUhmRjFcS.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gskCMv with job 3AYhxU4se794sMJrtJLfqE.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gskCMv with job 3AYhxU4se794sMJrtJLfqE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 25.05 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 25.05 seconds\n",
      "I0000 00:00:1730856324.092739 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856324.508260 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_ZBfaV6 completed job W3LD6ddLCsEjjXMxbwZExT successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_ZBfaV6 completed job W3LD6ddLCsEjjXMxbwZExT successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gskCMv with job dsL52ubCJuCQ2De2M62Pao.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gskCMv with job dsL52ubCJuCQ2De2M62Pao.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 27.08 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 27.08 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856326.104210 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856326.556758 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kdgyPX completed job aEHF3apQdEpLfmLPx6XC2M successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kdgyPX completed job aEHF3apQdEpLfmLPx6XC2M successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gskCMv with job axaPoNo3s25gipgjRTR23V.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gskCMv with job axaPoNo3s25gipgjRTR23V.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 47.90 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 47.90 seconds\n",
      "I0000 00:00:1730856328.225704 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856328.648900 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_WZUkKS completed job iXVoHqNVKCTE6cKMLPufMB successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_WZUkKS completed job iXVoHqNVKCTE6cKMLPufMB successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gskCMv with job D6y3zMWyp8Q9jpy6QtW4SR.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gskCMv with job D6y3zMWyp8Q9jpy6QtW4SR.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 40.86 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 40.86 seconds\n",
      "I0000 00:00:1730856330.187562 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856330.570041 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:32\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:32\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_WZUkKS completed job PbPbQJGtsHwrJ54ivK9bNH successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_WZUkKS completed job PbPbQJGtsHwrJ54ivK9bNH successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:32\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_gskCMv with job aNWD98EmwuPrhU6bVAWonp.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_gskCMv with job aNWD98EmwuPrhU6bVAWonp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:32\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 30.89 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 30.89 seconds\n",
      "I0000 00:00:1730856332.179594 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856332.623925 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_WZUkKS completed job 5iocrTXk73upBcdoqjKuGA successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_WZUkKS completed job 5iocrTXk73upBcdoqjKuGA successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 21.86 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 21.86 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856334.684876 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856335.092548 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kdgyPX completed job JcKGxVgYwHAkDcDbefc3wk successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kdgyPX completed job JcKGxVgYwHAkDcDbefc3wk successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 28.52 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 28.52 seconds\n",
      "I0000 00:00:1730856336.780958 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856337.161556 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_ZBfaV6 completed job 5CKEJbGgyxK5gqY8xjWDMM successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_ZBfaV6 completed job 5CKEJbGgyxK5gqY8xjWDMM successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 26.43 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 26.43 seconds\n",
      "I0000 00:00:1730856338.740719 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856339.182447 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gskCMv completed job GSMTxcnWdFtNSSymzjQooq successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gskCMv completed job GSMTxcnWdFtNSSymzjQooq successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_8HjjAw with job Et7UnCiLZG3HSJMKahmPmZ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_8HjjAw with job Et7UnCiLZG3HSJMKahmPmZ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_8HjjAw with job VrYLFCnP9mU5UN2ASVQMME.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_8HjjAw with job VrYLFCnP9mU5UN2ASVQMME.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_8HjjAw with job Sq8TBfYbALr3BcBktk6Pgb.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_8HjjAw with job Sq8TBfYbALr3BcBktk6Pgb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_8HjjAw with job YWZZJbT3CtpCQQfuNszeNN.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_8HjjAw with job YWZZJbT3CtpCQQfuNszeNN.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 26.40 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 26.40 seconds\n",
      "I0000 00:00:1730856340.822185 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856341.272913 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gskCMv completed job K5vpsy7v4JMW9DXmaemKqE successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gskCMv completed job K5vpsy7v4JMW9DXmaemKqE successfully.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_8HjjAw with job TqhqkcLoAkUSWCv25LFaCL.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_8HjjAw with job TqhqkcLoAkUSWCv25LFaCL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 17.02 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 17.02 seconds\n",
      "I0000 00:00:1730856343.119009 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856343.491442 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_ZBfaV6 completed job WrMfq3bLUvAPMGAoWrmhDG successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_ZBfaV6 completed job WrMfq3bLUvAPMGAoWrmhDG successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 36.80 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 36.80 seconds\n",
      "I0000 00:00:1730856345.620880 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856346.062421 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_ZBfaV6 completed job YQAKLK9KjuEM9rgRp6EFUs successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_ZBfaV6 completed job YQAKLK9KjuEM9rgRp6EFUs successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 39.35 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 39.35 seconds\n",
      "I0000 00:00:1730856347.641283 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856348.219483 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_ZBfaV6 completed job npJxehjt8VrSkKrmigCDq2 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_ZBfaV6 completed job npJxehjt8VrSkKrmigCDq2 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_8HjjAw with job 38QssGSVGWzbvqZyLVpQSB.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_8HjjAw with job 38QssGSVGWzbvqZyLVpQSB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 21.70 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 21.70 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856349.911272 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856350.296775 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kdgyPX completed job UZuY4hi5Zv3E8GUrUY5Sqz successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kdgyPX completed job UZuY4hi5Zv3E8GUrUY5Sqz successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_8HjjAw with job YTaNvj6zMpcC9zY35QWaRm.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_8HjjAw with job YTaNvj6zMpcC9zY35QWaRm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_8HjjAw with job WBmtcQCr6v8C4Gk8wrmDPZ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_8HjjAw with job WBmtcQCr6v8C4Gk8wrmDPZ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 125.41 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 125.41 seconds\n",
      "I0000 00:00:1730856351.882339 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856352.265756 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:53\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6r8oBs completed job SJ5epKyMvZQ96qRcXikoL3 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6r8oBs completed job SJ5epKyMvZQ96qRcXikoL3 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_8HjjAw with job SavP96B2TkYu6ogRdotGUF.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_8HjjAw with job SavP96B2TkYu6ogRdotGUF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6kcnfX with job 4c4Zp8RokUKk85kJDhQ8oN.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6kcnfX with job 4c4Zp8RokUKk85kJDhQ8oN.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 30.16 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 30.16 seconds\n",
      "I0000 00:00:1730856354.233362 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856354.808530 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gskCMv completed job jWQMZXJGBUY2YGX46uM6et successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gskCMv completed job jWQMZXJGBUY2YGX46uM6et successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6kcnfX with job 4rMNUjwZtAqAH7SoKSwCZL.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6kcnfX with job 4rMNUjwZtAqAH7SoKSwCZL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 32.46 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 32.46 seconds\n",
      "I0000 00:00:1730856356.549832 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856357.006515 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gskCMv completed job j4wyNL3Hx5Hp2cUhmRjFcS successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gskCMv completed job j4wyNL3Hx5Hp2cUhmRjFcS successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:25:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 15.71 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 15.71 seconds\n",
      "I0000 00:00:1730856358.554995 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856358.978950 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:00\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:00\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:00\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gskCMv completed job dsL52ubCJuCQ2De2M62Pao successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gskCMv completed job dsL52ubCJuCQ2De2M62Pao successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:00\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 19.80 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 19.80 seconds\n",
      "I0000 00:00:1730856360.607797 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856360.957683 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gskCMv completed job 3AYhxU4se794sMJrtJLfqE successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gskCMv completed job 3AYhxU4se794sMJrtJLfqE successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6kcnfX with job fQxDKGmT4BPTzLf6w333mR.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6kcnfX with job fQxDKGmT4BPTzLf6w333mR.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6kcnfX with job XdWfmmYNJhCYpkBhZt4UfV.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6kcnfX with job XdWfmmYNJhCYpkBhZt4UfV.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6kcnfX with job 3RXVsLGN7RGajnY8Ed2ZuC.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6kcnfX with job 3RXVsLGN7RGajnY8Ed2ZuC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 50.18 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 50.18 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856362.478256 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856363.118376 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kdgyPX completed job CbgdgubJW4EEjuF7Rv2jB6 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kdgyPX completed job CbgdgubJW4EEjuF7Rv2jB6 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6kcnfX with job frMzvDB7QmgVuQjkdM59Zn.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6kcnfX with job frMzvDB7QmgVuQjkdM59Zn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 50.30 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 50.30 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856364.715979 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856365.170363 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_kdgyPX completed job 96z4Rjip8SjktTxwRt2Fec successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_kdgyPX completed job 96z4Rjip8SjktTxwRt2Fec successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6kcnfX with job MNCh5vQjoZWTfMWKYwPsyb.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6kcnfX with job MNCh5vQjoZWTfMWKYwPsyb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 26.02 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 26.02 seconds\n",
      "I0000 00:00:1730856366.808744 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856367.292452 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_ZBfaV6 completed job C7daVwSa7Mp5ijLQKVVUDC successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_ZBfaV6 completed job C7daVwSa7Mp5ijLQKVVUDC successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6kcnfX with job emVgyJacDov6Q7XGPp69ff.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6kcnfX with job emVgyJacDov6Q7XGPp69ff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 12.44 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 12.44 seconds\n",
      "I0000 00:00:1730856368.939039 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856369.418847 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gskCMv completed job axaPoNo3s25gipgjRTR23V successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gskCMv completed job axaPoNo3s25gipgjRTR23V successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_6kcnfX with job aUmLSFzwiAKexZepwft7Wq.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_6kcnfX with job aUmLSFzwiAKexZepwft7Wq.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 31.41 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 31.41 seconds\n",
      "I0000 00:00:1730856372.252763 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856372.679040 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_8HjjAw completed job YWZZJbT3CtpCQQfuNszeNN successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_8HjjAw completed job YWZZJbT3CtpCQQfuNszeNN successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_musMfx with job k7jV5rkhxprCgmNRwQow49.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_musMfx with job k7jV5rkhxprCgmNRwQow49.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 33.58 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 33.58 seconds\n",
      "I0000 00:00:1730856374.376013 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856374.757684 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_8HjjAw completed job Sq8TBfYbALr3BcBktk6Pgb successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_8HjjAw completed job Sq8TBfYbALr3BcBktk6Pgb successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_musMfx with job CSJuSuMgyzYZXPAEtGZRJj.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_musMfx with job CSJuSuMgyzYZXPAEtGZRJj.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 22.12 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 22.12 seconds\n",
      "I0000 00:00:1730856376.421537 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856376.784091 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6kcnfX completed job 4c4Zp8RokUKk85kJDhQ8oN successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6kcnfX completed job 4c4Zp8RokUKk85kJDhQ8oN successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_musMfx with job 9crc8jNbWdkaXbapraQyuK.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_musMfx with job 9crc8jNbWdkaXbapraQyuK.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 37.67 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 37.67 seconds\n",
      "I0000 00:00:1730856378.437879 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856379.070664 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_8HjjAw completed job Et7UnCiLZG3HSJMKahmPmZ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_8HjjAw completed job Et7UnCiLZG3HSJMKahmPmZ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_musMfx with job DenKv2AJjmSSkfYo4obo56.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_musMfx with job DenKv2AJjmSSkfYo4obo56.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 24.27 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 24.27 seconds\n",
      "I0000 00:00:1730856380.779965 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856381.170644 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6kcnfX completed job 4rMNUjwZtAqAH7SoKSwCZL successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6kcnfX completed job 4rMNUjwZtAqAH7SoKSwCZL successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 41.94 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 41.94 seconds\n",
      "I0000 00:00:1730856382.748407 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856383.337889 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_8HjjAw completed job VrYLFCnP9mU5UN2ASVQMME successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_8HjjAw completed job VrYLFCnP9mU5UN2ASVQMME successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 10.74 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 10.74 seconds\n",
      "I0000 00:00:1730856385.425109 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856385.888346 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_8HjjAw completed job TqhqkcLoAkUSWCv25LFaCL successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_8HjjAw completed job TqhqkcLoAkUSWCv25LFaCL successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 25.05 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 25.05 seconds\n",
      "I0000 00:00:1730856387.490486 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856387.953425 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gskCMv completed job D6y3zMWyp8Q9jpy6QtW4SR successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gskCMv completed job D6y3zMWyp8Q9jpy6QtW4SR successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_musMfx with job QLnMcToY8vwWxzM4yFRFYP.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_musMfx with job QLnMcToY8vwWxzM4yFRFYP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_musMfx with job k68iSuvLALJXmsrHAdu7Ve.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_musMfx with job k68iSuvLALJXmsrHAdu7Ve.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_musMfx with job 9ybBuHRNJGhGSMYWSBgddV.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_musMfx with job 9ybBuHRNJGhGSMYWSBgddV.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_musMfx with job EtfRoimgzfsFP8BFq6n2yy.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_musMfx with job EtfRoimgzfsFP8BFq6n2yy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 13.33 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 13.33 seconds\n",
      "I0000 00:00:1730856389.633404 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856390.129544 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_8HjjAw completed job 38QssGSVGWzbvqZyLVpQSB successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_8HjjAw completed job 38QssGSVGWzbvqZyLVpQSB successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_musMfx with job ZPc5S2Np5nRSrPVRyHW8cv.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_musMfx with job ZPc5S2Np5nRSrPVRyHW8cv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 29.29 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 29.29 seconds\n",
      "I0000 00:00:1730856391.766094 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856392.358715 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6kcnfX completed job XdWfmmYNJhCYpkBhZt4UfV successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6kcnfX completed job XdWfmmYNJhCYpkBhZt4UfV successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Vtaaxx with job dxLrUUUJa2BBxnUNvvdUwE.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Vtaaxx with job dxLrUUUJa2BBxnUNvvdUwE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 31.59 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 31.59 seconds\n",
      "I0000 00:00:1730856394.060836 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856394.493296 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_gskCMv completed job aNWD98EmwuPrhU6bVAWonp successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_gskCMv completed job aNWD98EmwuPrhU6bVAWonp successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 33.68 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 33.68 seconds\n",
      "I0000 00:00:1730856396.128051 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6kcnfX completed job fQxDKGmT4BPTzLf6w333mR successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6kcnfX completed job fQxDKGmT4BPTzLf6w333mR successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Vtaaxx with job fwAK2RFe5fFRvKr9kgjhct.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Vtaaxx with job fwAK2RFe5fFRvKr9kgjhct.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Vtaaxx with job 8DhFjJbedSPYrxiUcKi7VD.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Vtaaxx with job 8DhFjJbedSPYrxiUcKi7VD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 17.55 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 17.55 seconds\n",
      "I0000 00:00:1730856398.273033 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_8HjjAw completed job YTaNvj6zMpcC9zY35QWaRm successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_8HjjAw completed job YTaNvj6zMpcC9zY35QWaRm successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Vtaaxx with job VLprnnGaitX7iXNLQ6dysY.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Vtaaxx with job VLprnnGaitX7iXNLQ6dysY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 22.26 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 22.26 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6kcnfX completed job 3RXVsLGN7RGajnY8Ed2ZuC successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6kcnfX completed job 3RXVsLGN7RGajnY8Ed2ZuC successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Vtaaxx with job LBm4gUT2mvFbbbM9dYJeDP.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Vtaaxx with job LBm4gUT2mvFbbbM9dYJeDP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 13.76 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 13.76 seconds\n",
      "I0000 00:00:1730856403.412943 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_8HjjAw completed job WBmtcQCr6v8C4Gk8wrmDPZ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_8HjjAw completed job WBmtcQCr6v8C4Gk8wrmDPZ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Vtaaxx with job Ret7kiCU3LPdkG5LFtGVBZ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Vtaaxx with job Ret7kiCU3LPdkG5LFtGVBZ.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 27.20 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 27.20 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856405.634574 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_musMfx completed job 9crc8jNbWdkaXbapraQyuK successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_musMfx completed job 9crc8jNbWdkaXbapraQyuK successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 27.18 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 27.18 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856407.912980 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_musMfx completed job DenKv2AJjmSSkfYo4obo56 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_musMfx completed job DenKv2AJjmSSkfYo4obo56 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Vtaaxx with job nPSrpSXE8qWxZsCcEdUdRU.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Vtaaxx with job nPSrpSXE8qWxZsCcEdUdRU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Vtaaxx with job 2zHzANXmXYnNYdGK2WRMNR.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Vtaaxx with job 2zHzANXmXYnNYdGK2WRMNR.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 20.34 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 20.34 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6kcnfX completed job frMzvDB7QmgVuQjkdM59Zn successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6kcnfX completed job frMzvDB7QmgVuQjkdM59Zn successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Vtaaxx with job dURXz5oTMt4Wm6MqQ4veJA.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Vtaaxx with job dURXz5oTMt4Wm6MqQ4veJA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 22.91 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 22.91 seconds\n",
      "I0000 00:00:1730856412.534915 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_8HjjAw completed job SavP96B2TkYu6ogRdotGUF successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_8HjjAw completed job SavP96B2TkYu6ogRdotGUF successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_VQK4TL with job FJDeXKjPEAgLnkRcb935aC.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_VQK4TL with job FJDeXKjPEAgLnkRcb935aC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 38.45 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 38.45 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856414.766803 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_musMfx completed job CSJuSuMgyzYZXPAEtGZRJj successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_musMfx completed job CSJuSuMgyzYZXPAEtGZRJj successfully.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_VQK4TL with job Se6Rm7CCTvbyWVyXN5P7Du.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_VQK4TL with job Se6Rm7CCTvbyWVyXN5P7Du.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856417.274108 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 43.40 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 43.40 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856417.741282 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856418.143318 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_musMfx completed job k7jV5rkhxprCgmNRwQow49 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_musMfx completed job k7jV5rkhxprCgmNRwQow49 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_VQK4TL with job WrnxuXKBtxiceoj5abaSnk.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_VQK4TL with job WrnxuXKBtxiceoj5abaSnk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:26:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 9.94 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 9.94 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856419.815911 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856420.241233 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_musMfx completed job k68iSuvLALJXmsrHAdu7Ve successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_musMfx completed job k68iSuvLALJXmsrHAdu7Ve successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_VQK4TL with job BBeYeRFP2JSfTZuHoBCjLy.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_VQK4TL with job BBeYeRFP2JSfTZuHoBCjLy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 12.24 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 12.24 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856422.122701 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856422.558138 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_musMfx completed job QLnMcToY8vwWxzM4yFRFYP successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_musMfx completed job QLnMcToY8vwWxzM4yFRFYP successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_VQK4TL with job XNGbYS2XPCCYjsYATiKVes.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_VQK4TL with job XNGbYS2XPCCYjsYATiKVes.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 25.84 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 25.84 seconds\n",
      "I0000 00:00:1730856424.133836 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856424.609848 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Vtaaxx completed job 8DhFjJbedSPYrxiUcKi7VD successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Vtaaxx completed job 8DhFjJbedSPYrxiUcKi7VD successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_VQK4TL with job jJemEpkyrTXQ8MLCi9Lja4.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_VQK4TL with job jJemEpkyrTXQ8MLCi9Lja4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 25.82 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 25.82 seconds\n",
      "I0000 00:00:1730856426.464440 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856426.919195 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Vtaaxx completed job VLprnnGaitX7iXNLQ6dysY successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Vtaaxx completed job VLprnnGaitX7iXNLQ6dysY successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 30.79 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 30.79 seconds\n",
      "I0000 00:00:1730856429.060366 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856429.576316 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Vtaaxx completed job fwAK2RFe5fFRvKr9kgjhct successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Vtaaxx completed job fwAK2RFe5fFRvKr9kgjhct successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_VQK4TL with job L3BHxhHnK2xZ5tx7S3vod8.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_VQK4TL with job L3BHxhHnK2xZ5tx7S3vod8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_VQK4TL with job CSnghGgHjf67eZtSo97cxM.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_VQK4TL with job CSnghGgHjf67eZtSo97cxM.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 33.09 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 33.09 seconds\n",
      "I0000 00:00:1730856431.349915 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856431.826914 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6kcnfX completed job emVgyJacDov6Q7XGPp69ff successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6kcnfX completed job emVgyJacDov6Q7XGPp69ff successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 30.05 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 30.05 seconds\n",
      "I0000 00:00:1730856433.423199 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856433.907896 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6kcnfX completed job aUmLSFzwiAKexZepwft7Wq successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6kcnfX completed job aUmLSFzwiAKexZepwft7Wq successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 41.46 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 41.46 seconds\n",
      "I0000 00:00:1730856435.531258 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856436.045144 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:17\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:17\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Vtaaxx completed job dxLrUUUJa2BBxnUNvvdUwE successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Vtaaxx completed job dxLrUUUJa2BBxnUNvvdUwE successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_VQK4TL with job TjJTLWnZU9iaA86e7N8VFw.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_VQK4TL with job TjJTLWnZU9iaA86e7N8VFw.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GDybdp with job n23MHqkNHPHoh7AUKV7E4t.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GDybdp with job n23MHqkNHPHoh7AUKV7E4t.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GDybdp with job jPhRtfGDpidXBctih9zG7t.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GDybdp with job jPhRtfGDpidXBctih9zG7t.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 20.93 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 20.93 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856438.104053 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856438.483297 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_musMfx completed job 9ybBuHRNJGhGSMYWSBgddV successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_musMfx completed job 9ybBuHRNJGhGSMYWSBgddV successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GDybdp with job 7zSg2VXiHC5JnFY8vsaKzd.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GDybdp with job 7zSg2VXiHC5JnFY8vsaKzd.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 47.51 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 47.51 seconds\n",
      "I0000 00:00:1730856441.500389 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856441.978132 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_6kcnfX completed job MNCh5vQjoZWTfMWKYwPsyb successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_6kcnfX completed job MNCh5vQjoZWTfMWKYwPsyb successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GDybdp with job jyW3RLxNP6xK73JmD75jUi.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GDybdp with job jyW3RLxNP6xK73JmD75jUi.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 28.76 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 28.76 seconds\n",
      "I0000 00:00:1730856443.523928 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856443.963030 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_VQK4TL completed job FJDeXKjPEAgLnkRcb935aC successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_VQK4TL completed job FJDeXKjPEAgLnkRcb935aC successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 25.79 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 25.79 seconds\n",
      "I0000 00:00:1730856445.600559 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856445.987422 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_VQK4TL completed job WrnxuXKBtxiceoj5abaSnk successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_VQK4TL completed job WrnxuXKBtxiceoj5abaSnk successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 25.48 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 25.48 seconds\n",
      "I0000 00:00:1730856447.521440 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856447.997878 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_VQK4TL completed job BBeYeRFP2JSfTZuHoBCjLy successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_VQK4TL completed job BBeYeRFP2JSfTZuHoBCjLy successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 32.32 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 32.32 seconds\n",
      "I0000 00:00:1730856449.562651 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856449.999148 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_VQK4TL completed job Se6Rm7CCTvbyWVyXN5P7Du successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_VQK4TL completed job Se6Rm7CCTvbyWVyXN5P7Du successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GDybdp with job 9oMHGmL96skrucg6Pnhj4P.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GDybdp with job 9oMHGmL96skrucg6Pnhj4P.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GDybdp with job LMkCd8iEpCXQxFPHdMcrhp.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GDybdp with job LMkCd8iEpCXQxFPHdMcrhp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GDybdp with job Hf3mP8kdgAH7SMc74SWir7.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GDybdp with job Hf3mP8kdgAH7SMc74SWir7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GDybdp with job 6xQ5VdEz9kPWoLfHhCAerd.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GDybdp with job 6xQ5VdEz9kPWoLfHhCAerd.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 32.09 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 32.09 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856451.883310 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856452.384026 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_musMfx completed job EtfRoimgzfsFP8BFq6n2yy successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_musMfx completed job EtfRoimgzfsFP8BFq6n2yy successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GDybdp with job TWXmKfvfjqMdaxniTBzxmx.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GDybdp with job TWXmKfvfjqMdaxniTBzxmx.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 27.62 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 27.62 seconds\n",
      "I0000 00:00:1730856454.070671 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856454.733074 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Vtaaxx completed job LBm4gUT2mvFbbbM9dYJeDP successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Vtaaxx completed job LBm4gUT2mvFbbbM9dYJeDP successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coh2D6 with job 6Uqw3cWBLEGTz2cvj9iE5V.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coh2D6 with job 6Uqw3cWBLEGTz2cvj9iE5V.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 16.41 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 16.41 seconds\n",
      "I0000 00:00:1730856459.922967 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856460.334651 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GDybdp completed job jyW3RLxNP6xK73JmD75jUi successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GDybdp completed job jyW3RLxNP6xK73JmD75jUi successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coh2D6 with job fLoc6337PkBemfoCkjda6K.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coh2D6 with job fLoc6337PkBemfoCkjda6K.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 24.07 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 24.07 seconds\n",
      "I0000 00:00:1730856462.836756 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856463.331602 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GDybdp completed job jPhRtfGDpidXBctih9zG7t successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GDybdp completed job jPhRtfGDpidXBctih9zG7t successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 26.79 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 26.79 seconds\n",
      "I0000 00:00:1730856464.866609 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856465.385440 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GDybdp completed job n23MHqkNHPHoh7AUKV7E4t successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GDybdp completed job n23MHqkNHPHoh7AUKV7E4t successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 15.10 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 15.10 seconds\n",
      "I0000 00:00:1730856466.943440 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856467.356610 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_VQK4TL completed job XNGbYS2XPCCYjsYATiKVes successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_VQK4TL completed job XNGbYS2XPCCYjsYATiKVes successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coh2D6 with job NBcysBWefCfYBrZvmNvrLK.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coh2D6 with job NBcysBWefCfYBrZvmNvrLK.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coh2D6 with job fjqumbFaGkCVYzY4QMSjAf.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coh2D6 with job fjqumbFaGkCVYzY4QMSjAf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coh2D6 with job KwyQv4hUkg6zesH2tdZDtA.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coh2D6 with job KwyQv4hUkg6zesH2tdZDtA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 27.64 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 27.64 seconds\n",
      "I0000 00:00:1730856469.099261 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856469.515541 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GDybdp completed job 7zSg2VXiHC5JnFY8vsaKzd successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GDybdp completed job 7zSg2VXiHC5JnFY8vsaKzd successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coh2D6 with job n7mKKtt8YBiWWrpFL7DppU.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coh2D6 with job n7mKKtt8YBiWWrpFL7DppU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 49.01 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 49.01 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856471.572108 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856471.999686 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:53\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:53\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:53\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_musMfx completed job ZPc5S2Np5nRSrPVRyHW8cv successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_musMfx completed job ZPc5S2Np5nRSrPVRyHW8cv successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:53\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coh2D6 with job CvECq5K2X9YTDddC2mfzj4.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coh2D6 with job CvECq5K2X9YTDddC2mfzj4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:53\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 35.55 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 35.55 seconds\n",
      "I0000 00:00:1730856473.624318 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856474.047419 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:55\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:55\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:55\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Vtaaxx completed job 2zHzANXmXYnNYdGK2WRMNR successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Vtaaxx completed job 2zHzANXmXYnNYdGK2WRMNR successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:55\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 23.78 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 23.78 seconds\n",
      "I0000 00:00:1730856476.185711 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856476.807451 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_VQK4TL completed job jJemEpkyrTXQ8MLCi9Lja4 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_VQK4TL completed job jJemEpkyrTXQ8MLCi9Lja4 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:27:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 22.01 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 22.01 seconds\n",
      "I0000 00:00:1730856478.381134 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856478.970273 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:00\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:00\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:00\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Vtaaxx completed job dURXz5oTMt4Wm6MqQ4veJA successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Vtaaxx completed job dURXz5oTMt4Wm6MqQ4veJA successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:00\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 49.30 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 49.30 seconds\n",
      "I0000 00:00:1730856480.640702 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856481.231071 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Vtaaxx completed job Ret7kiCU3LPdkG5LFtGVBZ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Vtaaxx completed job Ret7kiCU3LPdkG5LFtGVBZ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coh2D6 with job RA9u8fiMYJH3mhqpbzpCKV.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coh2D6 with job RA9u8fiMYJH3mhqpbzpCKV.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coh2D6 with job feCwFLY2n3cQXK55eKXJHE.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coh2D6 with job feCwFLY2n3cQXK55eKXJHE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GC5qNQ with job etdTLmbiq9TwcWiHPtn2cS.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GC5qNQ with job etdTLmbiq9TwcWiHPtn2cS.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GC5qNQ with job gCxNAJiWMFfyqNa48WhfX3.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GC5qNQ with job gCxNAJiWMFfyqNa48WhfX3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 30.84 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 30.84 seconds\n",
      "I0000 00:00:1730856483.251901 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856483.629663 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_VQK4TL completed job CSnghGgHjf67eZtSo97cxM successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_VQK4TL completed job CSnghGgHjf67eZtSo97cxM successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 53.97 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 53.97 seconds\n",
      "I0000 00:00:1730856485.344010 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856485.771999 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Vtaaxx completed job nPSrpSXE8qWxZsCcEdUdRU successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Vtaaxx completed job nPSrpSXE8qWxZsCcEdUdRU successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 35.44 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 35.44 seconds\n",
      "I0000 00:00:1730856487.325534 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856487.821224 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_VQK4TL completed job L3BHxhHnK2xZ5tx7S3vod8 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_VQK4TL completed job L3BHxhHnK2xZ5tx7S3vod8 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GC5qNQ with job 7iAU2nihU5BEwghbxo3DPH.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GC5qNQ with job 7iAU2nihU5BEwghbxo3DPH.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GC5qNQ with job 5KEdudAFtpesMkjjDN58kn.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GC5qNQ with job 5KEdudAFtpesMkjjDN58kn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GC5qNQ with job 9qZNtCmSi4VKGb4E4d4qg3.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GC5qNQ with job 9qZNtCmSi4VKGb4E4d4qg3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 33.29 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 33.29 seconds\n",
      "I0000 00:00:1730856489.675613 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856490.246672 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coh2D6 completed job 6Uqw3cWBLEGTz2cvj9iE5V successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coh2D6 completed job 6Uqw3cWBLEGTz2cvj9iE5V successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 29.77 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 29.77 seconds\n",
      "I0000 00:00:1730856492.343001 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856492.785979 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GDybdp completed job 9oMHGmL96skrucg6Pnhj4P successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GDybdp completed job 9oMHGmL96skrucg6Pnhj4P successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GC5qNQ with job aF3HLZdkiGfP84vHKvcEzm.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GC5qNQ with job aF3HLZdkiGfP84vHKvcEzm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GC5qNQ with job D3vpgpnSCW2QjbuUV9NGw3.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GC5qNQ with job D3vpgpnSCW2QjbuUV9NGw3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 32.48 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 32.48 seconds\n",
      "I0000 00:00:1730856494.531238 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856494.965575 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coh2D6 completed job fLoc6337PkBemfoCkjda6K successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coh2D6 completed job fLoc6337PkBemfoCkjda6K successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GC5qNQ with job PNxWscF8ye9YY7g6V2SCvk.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GC5qNQ with job PNxWscF8ye9YY7g6V2SCvk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 27.56 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 27.56 seconds\n",
      "I0000 00:00:1730856496.577332 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856497.020423 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coh2D6 completed job fjqumbFaGkCVYzY4QMSjAf successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coh2D6 completed job fjqumbFaGkCVYzY4QMSjAf successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 29.55 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 29.55 seconds\n",
      "I0000 00:00:1730856499.084803 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856499.544061 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GDybdp completed job LMkCd8iEpCXQxFPHdMcrhp successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GDybdp completed job LMkCd8iEpCXQxFPHdMcrhp successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 32.00 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 32.00 seconds\n",
      "I0000 00:00:1730856501.098136 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856501.459883 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_VQK4TL completed job TjJTLWnZU9iaA86e7N8VFw successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_VQK4TL completed job TjJTLWnZU9iaA86e7N8VFw successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_GC5qNQ with job 4j2QLZRSJ6nxHb7oD7K4Hh.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_GC5qNQ with job 4j2QLZRSJ6nxHb7oD7K4Hh.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cq9q4r with job jWwh6TeopBtNKXNdYdiTn7.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cq9q4r with job jWwh6TeopBtNKXNdYdiTn7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cq9q4r with job QVNPS2VEBjGHVbyiW42svG.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cq9q4r with job QVNPS2VEBjGHVbyiW42svG.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 34.05 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 34.05 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coh2D6 completed job NBcysBWefCfYBrZvmNvrLK successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coh2D6 completed job NBcysBWefCfYBrZvmNvrLK successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cq9q4r with job FRcj9yCqytSKo3Wu3N697f.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cq9q4r with job FRcj9yCqytSKo3Wu3N697f.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 11.22 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 11.22 seconds\n",
      "I0000 00:00:1730856505.702809 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GDybdp completed job TWXmKfvfjqMdaxniTBzxmx successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GDybdp completed job TWXmKfvfjqMdaxniTBzxmx successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cq9q4r with job BSBakCEb3TzMYj6PgVbtnG.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cq9q4r with job BSBakCEb3TzMYj6PgVbtnG.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 40.78 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 40.78 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GDybdp completed job 6xQ5VdEz9kPWoLfHhCAerd successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GDybdp completed job 6xQ5VdEz9kPWoLfHhCAerd successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cq9q4r with job LYrWnvFoVGhXMQwBujHvG4.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cq9q4r with job LYrWnvFoVGhXMQwBujHvG4.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 21.53 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 21.53 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coh2D6 completed job KwyQv4hUkg6zesH2tdZDtA successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coh2D6 completed job KwyQv4hUkg6zesH2tdZDtA successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cq9q4r with job 2jzLo8u6HQFwDpzkP2SpCf.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cq9q4r with job 2jzLo8u6HQFwDpzkP2SpCf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 12.93 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 12.93 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cq9q4r completed job FRcj9yCqytSKo3Wu3N697f successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Cq9q4r completed job FRcj9yCqytSKo3Wu3N697f successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 52.29 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 52.29 seconds\n",
      "I0000 00:00:1730856521.296067 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GDybdp completed job Hf3mP8kdgAH7SMc74SWir7 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GDybdp completed job Hf3mP8kdgAH7SMc74SWir7 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 15.45 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 15.45 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cq9q4r completed job BSBakCEb3TzMYj6PgVbtnG successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Cq9q4r completed job BSBakCEb3TzMYj6PgVbtnG successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cq9q4r with job cQQC2ez8tvwqnwSfNyQ6iH.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cq9q4r with job cQQC2ez8tvwqnwSfNyQ6iH.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cq9q4r with job D9RnwtQ2dURAWTKTSuLLgM.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cq9q4r with job D9RnwtQ2dURAWTKTSuLLgM.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cq9q4r with job g5fcXc54DwdCegXHsLhnU3.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cq9q4r with job g5fcXc54DwdCegXHsLhnU3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 36.38 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 36.38 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856526.046306 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GC5qNQ completed job 7iAU2nihU5BEwghbxo3DPH successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GC5qNQ completed job 7iAU2nihU5BEwghbxo3DPH successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 45.32 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 45.32 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856528.028538 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GC5qNQ completed job etdTLmbiq9TwcWiHPtn2cS successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GC5qNQ completed job etdTLmbiq9TwcWiHPtn2cS successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 47.34 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 47.34 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856530.054292 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GC5qNQ completed job gCxNAJiWMFfyqNa48WhfX3 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GC5qNQ completed job gCxNAJiWMFfyqNa48WhfX3 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cgwvg8 with job m2dZCtNfMCbJ6Gi67E2muj.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cgwvg8 with job m2dZCtNfMCbJ6Gi67E2muj.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cgwvg8 with job JBVzZ767whNsCXAooj7tTa.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cgwvg8 with job JBVzZ767whNsCXAooj7tTa.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cgwvg8 with job TGVFXuZqEZ3cJshKVwAEZ5.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cgwvg8 with job TGVFXuZqEZ3cJshKVwAEZ5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 29.70 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 29.70 seconds\n",
      "I0000 00:00:1730856532.741674 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856533.187465 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cq9q4r completed job QVNPS2VEBjGHVbyiW42svG successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Cq9q4r completed job QVNPS2VEBjGHVbyiW42svG successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cgwvg8 with job ftzvjxAzZx3aPnYMbxp7AF.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cgwvg8 with job ftzvjxAzZx3aPnYMbxp7AF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 31.84 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 31.84 seconds\n",
      "I0000 00:00:1730856534.806935 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856535.285550 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coh2D6 completed job CvECq5K2X9YTDddC2mfzj4 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coh2D6 completed job CvECq5K2X9YTDddC2mfzj4 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 40.42 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 40.42 seconds\n",
      "I0000 00:00:1730856536.991775 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856537.446798 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coh2D6 completed job n7mKKtt8YBiWWrpFL7DppU successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coh2D6 completed job n7mKKtt8YBiWWrpFL7DppU successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cgwvg8 with job 5uCanUWxJBCrqdjF7DFUbo.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cgwvg8 with job 5uCanUWxJBCrqdjF7DFUbo.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cgwvg8 with job g7UVY2gWcXvAD7hzKzkCnH.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cgwvg8 with job g7UVY2gWcXvAD7hzKzkCnH.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:28:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 35.97 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 35.97 seconds\n",
      "I0000 00:00:1730856538.996290 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856539.512476 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:00\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cq9q4r completed job jWwh6TeopBtNKXNdYdiTn7 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Cq9q4r completed job jWwh6TeopBtNKXNdYdiTn7 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 35.42 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 35.42 seconds\n",
      "I0000 00:00:1730856541.055949 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856541.621319 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coh2D6 completed job RA9u8fiMYJH3mhqpbzpCKV successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coh2D6 completed job RA9u8fiMYJH3mhqpbzpCKV successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cgwvg8 with job TsjctZgWjrbRfxVfWtu8pV.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cgwvg8 with job TsjctZgWjrbRfxVfWtu8pV.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cgwvg8 with job MPVUX3AeNTfsYGqxWi6ebx.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cgwvg8 with job MPVUX3AeNTfsYGqxWi6ebx.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 53.43 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 53.43 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856543.106817 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856543.527751 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GC5qNQ completed job 5KEdudAFtpesMkjjDN58kn successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GC5qNQ completed job 5KEdudAFtpesMkjjDN58kn successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Cgwvg8 with job 8TavF5dPz4xW8xSXEiUMnr.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Cgwvg8 with job 8TavF5dPz4xW8xSXEiUMnr.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 13.18 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 13.18 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856545.273880 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856545.728956 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GC5qNQ completed job 9qZNtCmSi4VKGb4E4d4qg3 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GC5qNQ completed job 9qZNtCmSi4VKGb4E4d4qg3 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cKvQ4B with job NSSKwz49o6MQXmFRo8dQso.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cKvQ4B with job NSSKwz49o6MQXmFRo8dQso.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 15.50 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 15.50 seconds\n",
      "I0000 00:00:1730856547.610357 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856548.193089 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cgwvg8 completed job m2dZCtNfMCbJ6Gi67E2muj successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Cgwvg8 completed job m2dZCtNfMCbJ6Gi67E2muj successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cKvQ4B with job LNMKLiwjxCh2ZifTAbHLhg.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cKvQ4B with job LNMKLiwjxCh2ZifTAbHLhg.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 17.64 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 17.64 seconds\n",
      "I0000 00:00:1730856550.313401 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856550.767473 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cgwvg8 completed job JBVzZ767whNsCXAooj7tTa successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1730856552.393680 28162159 ssl_transport_security_utils.cc:116] Corruption detected.\n",
      "E0000 00:00:1730856552.393696 28162159 ssl_transport_security_utils.cc:73] error:100003fc:SSL routines:OPENSSL_internal:SSLV3_ALERT_BAD_RECORD_MAC\n",
      "E0000 00:00:1730856552.393697 28162159 secure_endpoint.cc:300] Decryption error: TSI_DATA_CORRUPTED\n",
      "DEBUG:buttermilk:Agent lc_Cgwvg8 completed job JBVzZ767whNsCXAooj7tTa successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cKvQ4B with job o33nsuBdUzcDCtmSjk2qmJ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cKvQ4B with job o33nsuBdUzcDCtmSjk2qmJ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 7.23 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 7.23 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856552.448960 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856552.787198 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GC5qNQ completed job PNxWscF8ye9YY7g6V2SCvk successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GC5qNQ completed job PNxWscF8ye9YY7g6V2SCvk successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cKvQ4B with job MAE9Mh7VoXBqc6JDdHoicX.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cKvQ4B with job MAE9Mh7VoXBqc6JDdHoicX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 36.01 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 36.01 seconds\n",
      "I0000 00:00:1730856554.581219 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856554.936934 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coh2D6 completed job feCwFLY2n3cQXK55eKXJHE successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coh2D6 completed job feCwFLY2n3cQXK55eKXJHE successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cKvQ4B with job 3d3ciEYn6f4R58PrFqruQq.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cKvQ4B with job 3d3ciEYn6f4R58PrFqruQq.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 24.38 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 24.38 seconds\n",
      "I0000 00:00:1730856556.523919 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856556.976273 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cgwvg8 completed job TGVFXuZqEZ3cJshKVwAEZ5 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Cgwvg8 completed job TGVFXuZqEZ3cJshKVwAEZ5 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cKvQ4B with job YAEiEQJFVGcPmMZF7k47tU.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cKvQ4B with job YAEiEQJFVGcPmMZF7k47tU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 32.44 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 32.44 seconds\n",
      "I0000 00:00:1730856558.470024 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856558.975558 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cq9q4r completed job 2jzLo8u6HQFwDpzkP2SpCf successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Cq9q4r completed job 2jzLo8u6HQFwDpzkP2SpCf successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cKvQ4B with job NAmfzgzNGYfUi3AiV88biy.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cKvQ4B with job NAmfzgzNGYfUi3AiV88biy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 34.57 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 34.57 seconds\n",
      "I0000 00:00:1730856560.592283 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856561.008465 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cq9q4r completed job LYrWnvFoVGhXMQwBujHvG4 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Cq9q4r completed job LYrWnvFoVGhXMQwBujHvG4 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 14.92 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 14.92 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856562.477127 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856562.866654 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GC5qNQ completed job 4j2QLZRSJ6nxHb7oD7K4Hh successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GC5qNQ completed job 4j2QLZRSJ6nxHb7oD7K4Hh successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 32.34 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 32.34 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856564.462835 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856564.965462 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GC5qNQ completed job aF3HLZdkiGfP84vHKvcEzm successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GC5qNQ completed job aF3HLZdkiGfP84vHKvcEzm successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cKvQ4B with job 26xvGMeQmvMLrAMJFde2J9.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cKvQ4B with job 26xvGMeQmvMLrAMJFde2J9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_cKvQ4B with job ffCtdDYwAsf2FkJkdFmrE3.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_cKvQ4B with job ffCtdDYwAsf2FkJkdFmrE3.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MZhvfj with job JHncXdYh8CKTWiKEMbniV6.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MZhvfj with job JHncXdYh8CKTWiKEMbniV6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 31.83 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 31.83 seconds\n",
      "I0000 00:00:1730856566.637771 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856567.093058 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cgwvg8 completed job ftzvjxAzZx3aPnYMbxp7AF successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Cgwvg8 completed job ftzvjxAzZx3aPnYMbxp7AF successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 19.05 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 19.05 seconds\n",
      "I0000 00:00:1730856569.292959 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856569.806883 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cKvQ4B completed job LNMKLiwjxCh2ZifTAbHLhg successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cKvQ4B completed job LNMKLiwjxCh2ZifTAbHLhg successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 28.28 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 28.28 seconds\n",
      "I0000 00:00:1730856571.366596 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856571.830179 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cq9q4r completed job D9RnwtQ2dURAWTKTSuLLgM successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Cq9q4r completed job D9RnwtQ2dURAWTKTSuLLgM successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MZhvfj with job PWiC455eL76UgXynbYJKpb.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MZhvfj with job PWiC455eL76UgXynbYJKpb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MZhvfj with job aoPS7GEgxf2Rq7QVL6o3uJ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MZhvfj with job aoPS7GEgxf2Rq7QVL6o3uJ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MZhvfj with job AhKCni6LTFu7QhMkPoMr6v.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MZhvfj with job AhKCni6LTFu7QhMkPoMr6v.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 41.29 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 41.29 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856574.005367 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856574.354172 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_GC5qNQ completed job D3vpgpnSCW2QjbuUV9NGw3 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_GC5qNQ completed job D3vpgpnSCW2QjbuUV9NGw3 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 41.17 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 41.17 seconds\n",
      "I0000 00:00:1730856575.963079 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856576.365412 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cq9q4r completed job cQQC2ez8tvwqnwSfNyQ6iH successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Cq9q4r completed job cQQC2ez8tvwqnwSfNyQ6iH successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 30.34 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 30.34 seconds\n",
      "I0000 00:00:1730856577.929396 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856578.416898 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cKvQ4B completed job NSSKwz49o6MQXmFRo8dQso successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cKvQ4B completed job NSSKwz49o6MQXmFRo8dQso successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 27.51 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 27.51 seconds\n",
      "I0000 00:00:1730856579.922519 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856580.365968 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cgwvg8 completed job g7UVY2gWcXvAD7hzKzkCnH successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Cgwvg8 completed job g7UVY2gWcXvAD7hzKzkCnH successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 32.23 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 32.23 seconds\n",
      "I0000 00:00:1730856581.923398 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856582.371745 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cgwvg8 completed job 5uCanUWxJBCrqdjF7DFUbo successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Cgwvg8 completed job 5uCanUWxJBCrqdjF7DFUbo successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MZhvfj with job nE6fRRzEap7pd6c6MmiAfg.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MZhvfj with job nE6fRRzEap7pd6c6MmiAfg.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MZhvfj with job JrouWX47Q3o5TrKEE2EBJk.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MZhvfj with job JrouWX47Q3o5TrKEE2EBJk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MZhvfj with job 4M3iZMbTfBCrwtPunPgpVh.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MZhvfj with job 4M3iZMbTfBCrwtPunPgpVh.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MZhvfj with job SP5WURPDRPNemWMuCW565u.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MZhvfj with job SP5WURPDRPNemWMuCW565u.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MZhvfj with job 9cQsaQo796jAauxFkskjYH.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MZhvfj with job 9cQsaQo796jAauxFkskjYH.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 17.45 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 17.45 seconds\n",
      "I0000 00:00:1730856584.048630 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856584.423699 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MZhvfj completed job JHncXdYh8CKTWiKEMbniV6 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MZhvfj completed job JHncXdYh8CKTWiKEMbniV6 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Bw5tjq with job hJTT5cnk2qMZADoDQzY8Da.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Bw5tjq with job hJTT5cnk2qMZADoDQzY8Da.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 27.58 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 27.58 seconds\n",
      "I0000 00:00:1730856586.046726 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856586.481035 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cgwvg8 completed job TsjctZgWjrbRfxVfWtu8pV successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Cgwvg8 completed job TsjctZgWjrbRfxVfWtu8pV successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 27.62 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 27.62 seconds\n",
      "I0000 00:00:1730856588.205197 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856588.622633 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cq9q4r completed job g5fcXc54DwdCegXHsLhnU3 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Cq9q4r completed job g5fcXc54DwdCegXHsLhnU3 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Bw5tjq with job DHGEiKGBKtovxJK6nEYP7v.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Bw5tjq with job DHGEiKGBKtovxJK6nEYP7v.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Bw5tjq with job 9hA8CupN8rSW44tH9T9SPb.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Bw5tjq with job 9hA8CupN8rSW44tH9T9SPb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 21.15 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 21.15 seconds\n",
      "I0000 00:00:1730856594.498117 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856595.092941 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cgwvg8 completed job MPVUX3AeNTfsYGqxWi6ebx successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Cgwvg8 completed job MPVUX3AeNTfsYGqxWi6ebx successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Bw5tjq with job LhMEwM6XQRP56YEtwrDbZL.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Bw5tjq with job LhMEwM6XQRP56YEtwrDbZL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 44.40 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 44.40 seconds\n",
      "I0000 00:00:1730856597.375603 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856597.871618 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cKvQ4B completed job o33nsuBdUzcDCtmSjk2qmJ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cKvQ4B completed job o33nsuBdUzcDCtmSjk2qmJ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:29:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 44.96 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 44.96 seconds\n",
      "I0000 00:00:1730856599.443314 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856599.899337 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cKvQ4B completed job MAE9Mh7VoXBqc6JDdHoicX successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cKvQ4B completed job MAE9Mh7VoXBqc6JDdHoicX successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 17.59 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 17.59 seconds\n",
      "I0000 00:00:1730856601.547768 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856602.048427 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cKvQ4B completed job YAEiEQJFVGcPmMZF7k47tU successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cKvQ4B completed job YAEiEQJFVGcPmMZF7k47tU successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 30.22 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 30.22 seconds\n",
      "I0000 00:00:1730856603.595650 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856604.022118 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cKvQ4B completed job 3d3ciEYn6f4R58PrFqruQq successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cKvQ4B completed job 3d3ciEYn6f4R58PrFqruQq successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Bw5tjq with job hzvLmAGFrHv7oc6TzZeAbA.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Bw5tjq with job hzvLmAGFrHv7oc6TzZeAbA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Bw5tjq with job h2M8QtbXBvdUqYxBipvric.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Bw5tjq with job h2M8QtbXBvdUqYxBipvric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Bw5tjq with job VZkFLsuUVz3qaJ3pRNhEKb.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Bw5tjq with job VZkFLsuUVz3qaJ3pRNhEKb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Bw5tjq with job aMirkyavouYekrVBC5BY4Q.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Bw5tjq with job aMirkyavouYekrVBC5BY4Q.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 15.36 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 15.36 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856606.166441 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856606.509112 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Bw5tjq completed job DHGEiKGBKtovxJK6nEYP7v successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Bw5tjq completed job DHGEiKGBKtovxJK6nEYP7v successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 17.87 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 17.87 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856608.155727 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856608.609009 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Bw5tjq completed job 9hA8CupN8rSW44tH9T9SPb successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Bw5tjq completed job 9hA8CupN8rSW44tH9T9SPb successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Bw5tjq with job TDd2JNwFLbd3KS6m2qk8xJ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Bw5tjq with job TDd2JNwFLbd3KS6m2qk8xJ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coLf2m with job RFwaJsELru6PXz9vz7emJ4.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coLf2m with job RFwaJsELru6PXz9vz7emJ4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 37.21 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 37.21 seconds\n",
      "I0000 00:00:1730856610.616582 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856610.975290 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MZhvfj completed job aoPS7GEgxf2Rq7QVL6o3uJ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MZhvfj completed job aoPS7GEgxf2Rq7QVL6o3uJ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coLf2m with job ccKtqehjMxWt7Zna8ME4jm.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coLf2m with job ccKtqehjMxWt7Zna8ME4jm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 39.17 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 39.17 seconds\n",
      "I0000 00:00:1730856613.243327 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856613.691990 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MZhvfj completed job PWiC455eL76UgXynbYJKpb successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MZhvfj completed job PWiC455eL76UgXynbYJKpb successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 29.25 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 29.25 seconds\n",
      "I0000 00:00:1730856615.249998 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856615.732933 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:17\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:17\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:17\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MZhvfj completed job nE6fRRzEap7pd6c6MmiAfg successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MZhvfj completed job nE6fRRzEap7pd6c6MmiAfg successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:17\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 43.97 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 43.97 seconds\n",
      "I0000 00:00:1730856617.369575 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856617.818681 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MZhvfj completed job AhKCni6LTFu7QhMkPoMr6v successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MZhvfj completed job AhKCni6LTFu7QhMkPoMr6v successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coLf2m with job fKHwv6V43NrargLiTXTxPj.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coLf2m with job fKHwv6V43NrargLiTXTxPj.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coLf2m with job 4LMeLTFHGJE2qYEgvsGsnc.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coLf2m with job 4LMeLTFHGJE2qYEgvsGsnc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coLf2m with job WeLVHHHcu5kq8j69weLeXG.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coLf2m with job WeLVHHHcu5kq8j69weLeXG.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:19\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 35.50 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 35.50 seconds\n",
      "I0000 00:00:1730856619.462205 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856619.888875 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Cgwvg8 completed job 8TavF5dPz4xW8xSXEiUMnr successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Cgwvg8 completed job 8TavF5dPz4xW8xSXEiUMnr successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coLf2m with job fnmG7W7Mp68D86hCpHnqoB.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coLf2m with job fnmG7W7Mp68D86hCpHnqoB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 24.70 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 24.70 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856621.483575 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Bw5tjq completed job LhMEwM6XQRP56YEtwrDbZL successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Bw5tjq completed job LhMEwM6XQRP56YEtwrDbZL successfully.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coLf2m with job GYbkjmGDCmZ9u66GPebNTf.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coLf2m with job GYbkjmGDCmZ9u66GPebNTf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 37.65 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 37.65 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856623.751696 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Bw5tjq completed job hJTT5cnk2qMZADoDQzY8Da successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Bw5tjq completed job hJTT5cnk2qMZADoDQzY8Da successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coLf2m with job 6YK46HTtJmNPc4br8gWpYi.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coLf2m with job 6YK46HTtJmNPc4br8gWpYi.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 15.54 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 15.54 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856625.930351 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Bw5tjq completed job hzvLmAGFrHv7oc6TzZeAbA successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Bw5tjq completed job hzvLmAGFrHv7oc6TzZeAbA successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 17.90 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 17.90 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Bw5tjq completed job h2M8QtbXBvdUqYxBipvric successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Bw5tjq completed job h2M8QtbXBvdUqYxBipvric successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_coLf2m with job iD34puaMoSxQWG768B2dXi.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_coLf2m with job iD34puaMoSxQWG768B2dXi.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_JsEd9i with job aGWNGGryJznBqpFhktiuhQ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_JsEd9i with job aGWNGGryJznBqpFhktiuhQ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n",
      "I0000 00:00:1730856631.087109 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 5.72 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 5.72 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856631.541253 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856631.934383 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Bw5tjq completed job aMirkyavouYekrVBC5BY4Q successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Bw5tjq completed job aMirkyavouYekrVBC5BY4Q successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_JsEd9i with job C3QdVTNGoGP469SZMCQsdB.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_JsEd9i with job C3QdVTNGoGP469SZMCQsdB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 9.85 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 9.85 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856633.535036 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856633.983483 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Bw5tjq completed job VZkFLsuUVz3qaJ3pRNhEKb successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Bw5tjq completed job VZkFLsuUVz3qaJ3pRNhEKb successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_JsEd9i with job 5yHRLzDtDWu6JnMgbR8kjv.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_JsEd9i with job 5yHRLzDtDWu6JnMgbR8kjv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 25.09 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 25.09 seconds\n",
      "I0000 00:00:1730856636.126971 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856636.615706 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coLf2m completed job RFwaJsELru6PXz9vz7emJ4 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coLf2m completed job RFwaJsELru6PXz9vz7emJ4 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_JsEd9i with job 8bc3dGXFVqBTcwT4w4NWzY.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_JsEd9i with job 8bc3dGXFVqBTcwT4w4NWzY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 32.61 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 32.61 seconds\n",
      "I0000 00:00:1730856638.223104 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856638.701632 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cKvQ4B completed job 26xvGMeQmvMLrAMJFde2J9 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cKvQ4B completed job 26xvGMeQmvMLrAMJFde2J9 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 34.68 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 34.68 seconds\n",
      "I0000 00:00:1730856640.275843 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856640.806441 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cKvQ4B completed job NAmfzgzNGYfUi3AiV88biy successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cKvQ4B completed job NAmfzgzNGYfUi3AiV88biy successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_JsEd9i with job Kgb9jnGVhu5inZLWKpMrDL.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_JsEd9i with job Kgb9jnGVhu5inZLWKpMrDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_JsEd9i with job L69vaSDRcwJvTPrQfAXuMM.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_JsEd9i with job L69vaSDRcwJvTPrQfAXuMM.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 29.82 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 29.82 seconds\n",
      "I0000 00:00:1730856642.347767 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856642.818871 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MZhvfj completed job JrouWX47Q3o5TrKEE2EBJk successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MZhvfj completed job JrouWX47Q3o5TrKEE2EBJk successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 31.72 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 31.72 seconds\n",
      "I0000 00:00:1730856644.257510 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856644.727914 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coLf2m completed job ccKtqehjMxWt7Zna8ME4jm successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coLf2m completed job ccKtqehjMxWt7Zna8ME4jm successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_JsEd9i with job 7AdXQXHinfh39372DwREGu.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_JsEd9i with job 7AdXQXHinfh39372DwREGu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_JsEd9i with job HVFGxoxmR5DN3gj4aS5C7o.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_JsEd9i with job HVFGxoxmR5DN3gj4aS5C7o.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 26.91 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 26.91 seconds\n",
      "I0000 00:00:1730856646.322236 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856646.739135 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coLf2m completed job fKHwv6V43NrargLiTXTxPj successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coLf2m completed job fKHwv6V43NrargLiTXTxPj successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 28.94 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 28.94 seconds\n",
      "I0000 00:00:1730856648.371631 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856648.788794 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coLf2m completed job 4LMeLTFHGJE2qYEgvsGsnc successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coLf2m completed job 4LMeLTFHGJE2qYEgvsGsnc successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 16.87 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 16.87 seconds\n",
      "I0000 00:00:1730856650.380293 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856650.812388 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_JsEd9i completed job C3QdVTNGoGP469SZMCQsdB successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_JsEd9i completed job C3QdVTNGoGP469SZMCQsdB successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 46.72 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 46.72 seconds\n",
      "I0000 00:00:1730856652.346131 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856652.819388 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_cKvQ4B completed job ffCtdDYwAsf2FkJkdFmrE3 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_cKvQ4B completed job ffCtdDYwAsf2FkJkdFmrE3 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_JsEd9i with job 8kKpcZvkmJLBLhyjwjNxCv.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_JsEd9i with job 8kKpcZvkmJLBLhyjwjNxCv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 35.13 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 35.13 seconds\n",
      "I0000 00:00:1730856655.079989 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856655.695374 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MZhvfj completed job 4M3iZMbTfBCrwtPunPgpVh successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MZhvfj completed job 4M3iZMbTfBCrwtPunPgpVh successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 37.81 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 37.81 seconds\n",
      "I0000 00:00:1730856657.238682 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856657.664862 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MZhvfj completed job SP5WURPDRPNemWMuCW565u successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MZhvfj completed job SP5WURPDRPNemWMuCW565u successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:30:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 39.82 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 39.82 seconds\n",
      "I0000 00:00:1730856659.805576 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856660.275982 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MZhvfj completed job 9cQsaQo796jAauxFkskjYH successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MZhvfj completed job 9cQsaQo796jAauxFkskjYH successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 30.78 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 30.78 seconds\n",
      "I0000 00:00:1730856661.839585 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856662.298128 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_JsEd9i completed job aGWNGGryJznBqpFhktiuhQ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_JsEd9i completed job aGWNGGryJznBqpFhktiuhQ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 25.72 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 25.72 seconds\n",
      "I0000 00:00:1730856663.920450 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856664.431038 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_JsEd9i completed job 8bc3dGXFVqBTcwT4w4NWzY successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_JsEd9i completed job 8bc3dGXFVqBTcwT4w4NWzY successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 30.60 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 30.60 seconds\n",
      "I0000 00:00:1730856666.171333 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856666.679101 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_JsEd9i completed job 5yHRLzDtDWu6JnMgbR8kjv successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_JsEd9i completed job 5yHRLzDtDWu6JnMgbR8kjv successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 37.26 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 37.26 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856668.289129 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856668.762174 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Bw5tjq completed job TDd2JNwFLbd3KS6m2qk8xJ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Bw5tjq completed job TDd2JNwFLbd3KS6m2qk8xJ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 32.21 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 32.21 seconds\n",
      "I0000 00:00:1730856670.383393 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856670.858808 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coLf2m completed job WeLVHHHcu5kq8j69weLeXG successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coLf2m completed job WeLVHHHcu5kq8j69weLeXG successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 26.10 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 26.10 seconds\n",
      "I0000 00:00:1730856672.434176 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856672.874477 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coLf2m completed job fnmG7W7Mp68D86hCpHnqoB successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coLf2m completed job fnmG7W7Mp68D86hCpHnqoB successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 19.97 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 19.97 seconds\n",
      "I0000 00:00:1730856675.011839 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856675.388631 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:17\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:17\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_JsEd9i completed job Kgb9jnGVhu5inZLWKpMrDL successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_JsEd9i completed job Kgb9jnGVhu5inZLWKpMrDL successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:17\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 9.54 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 9.54 seconds\n",
      "I0000 00:00:1730856685.430011 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coLf2m completed job iD34puaMoSxQWG768B2dXi successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coLf2m completed job iD34puaMoSxQWG768B2dXi successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 18.78 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 18.78 seconds\n",
      "I0000 00:00:1730856687.063832 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856687.497808 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_JsEd9i completed job HVFGxoxmR5DN3gj4aS5C7o successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_JsEd9i completed job HVFGxoxmR5DN3gj4aS5C7o successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 12.01 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 12.01 seconds\n",
      "I0000 00:00:1730856689.115438 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856689.562944 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_JsEd9i completed job 8kKpcZvkmJLBLhyjwjNxCv successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_JsEd9i completed job 8kKpcZvkmJLBLhyjwjNxCv successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 36.71 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 36.71 seconds\n",
      "I0000 00:00:1730856691.719190 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856692.180904 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coLf2m completed job GYbkjmGDCmZ9u66GPebNTf successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coLf2m completed job GYbkjmGDCmZ9u66GPebNTf successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 25.48 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 25.48 seconds\n",
      "I0000 00:00:1730856693.727748 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856694.160787 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_JsEd9i completed job L69vaSDRcwJvTPrQfAXuMM successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_JsEd9i completed job L69vaSDRcwJvTPrQfAXuMM successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 41.27 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 41.27 seconds\n",
      "I0000 00:00:1730856695.753098 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856696.358091 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_coLf2m completed job 6YK46HTtJmNPc4br8gWpYi successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_coLf2m completed job 6YK46HTtJmNPc4br8gWpYi successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 29.60 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 29.60 seconds\n",
      "I0000 00:00:1730856697.856868 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856698.320681 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_JsEd9i completed job 7AdXQXHinfh39372DwREGu successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_JsEd9i completed job 7AdXQXHinfh39372DwREGu successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[ 106] \u001b[1;30mINFO\u001b[0m Completed run 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Completed run 1 of 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:31:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[ 110] \u001b[1;30mINFO\u001b[0m All tasks have completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:All tasks have completed.\n"
     ]
    }
   ],
   "source": [
    "await orchestrator.run_tasks()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second step is a synthesis of previous draft answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:33:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m buttermilk.py[ 376] \u001b[1;30mINFO\u001b[0m Query stats: Ran in 0:00:06.161060 seconds, cache hit: False, billed 15.73 MB, approx cost $7.9e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Query stats: Ran in 0:00:06.161060 seconds, cache hit: False, billed 15.73 MB, approx cost $7.9e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 350 entries, ('transgender_paralympian_dailymail', 'judger', 'judge', 'trans_tja', 'llama31_70b') to ('transgender_paralympian_BBC', 'judger', 'judge', 'trans_hrc', 'gpt4o')\n",
      "Data columns (total 22 columns):\n",
      " #   Column      Non-Null Count  Dtype              \n",
      "---  ------      --------------  -----              \n",
      " 0   id          350 non-null    object             \n",
      " 1   timestamp   350 non-null    datetime64[us, UTC]\n",
      " 2   run_info    350 non-null    object             \n",
      " 3   agent_info  350 non-null    object             \n",
      " 4   source      350 non-null    object             \n",
      " 5   record      350 non-null    object             \n",
      " 6   parameters  350 non-null    object             \n",
      " 7   outputs     350 non-null    object             \n",
      " 8   error       0 non-null      object             \n",
      " 9   metadata    350 non-null    object             \n",
      " 10  prompt      350 non-null    object             \n",
      " 11  record_id   350 non-null    object             \n",
      " 12  flow        350 non-null    object             \n",
      " 13  template    350 non-null    object             \n",
      " 14  criteria    350 non-null    object             \n",
      " 15  model       350 non-null    object             \n",
      " 16  reasons     350 non-null    object             \n",
      " 17  prediction  335 non-null    object             \n",
      " 18  labels      350 non-null    object             \n",
      " 19  confidence  335 non-null    object             \n",
      " 20  answers     350 non-null    object             \n",
      " 21  meta        350 non-null    object             \n",
      "dtypes: datetime64[us, UTC](1), object(21)\n",
      "memory usage: 63.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Create an orchestrator to conduct all combinations of jobs we want to run\n",
    "from buttermilk.runner.orchestrator import MultiFlowOrchestrator\n",
    "orchestrator = MultiFlowOrchestrator(step=cfg.step[1], data=cfg.data, save=cfg.save, source=cfg.source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">list</span><span style=\"font-weight: bold\">([{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'J6SqUtdwyQX5uuLk5hWCYa'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gemini15pro'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_cte'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The article discusses the murder of Tai'Vion Lathan, a Black transgender woman, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">highlighting the increased violence faced by the transgender community, particularly transgender women of color.  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">It uses Lathan's correct name and pronouns throughout the piece. The article aims to raise awareness about this </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">issue and advocate for justice and policy change to protect transgender individuals. The article's tone is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">respectful and aims to humanize Lathan, emphasizing her personality, family, and aspirations.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The content </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">consistently uses Tai'Vion Lathan's chosen name and pronouns (she/her) throughout the article, as requested by her </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">family. This aligns with the provided guidelines from the Associated Press Stylebook and the New York Times Style </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Book.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article specifically discusses the violence faced by transgender people, especially transgender women </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of color. It highlights the statistics on transgender homicides and discusses the broader context of legislative </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">attacks on transgender rights and healthcare. The language used is respectful and aims to raise awareness of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">issue.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article focuses on the tragic murder of a transgender woman and the broader issues faced by the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender community. By highlighting Lathan's personal life, aspirations, and the grief of her family, the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">article humanizes her and counters the dehumanization often experienced by transgender individuals.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">promotes respect and understanding of transgender people by using accurate terminology and highlighting the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">importance of recognizing their full humanity, beyond their gender identity. It also advocates for justice and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">policy change to protect transgender individuals from violence and discrimination.'</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'Qgi5p3fnPShknhHsTNBf2X'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt4o'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_cte'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'The content is a news report covering the death of TaiVion Lathan, a transgender woman, who was </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">murdered in Baltimore. It discusses the circumstances of her death, the grief of her family, and provides </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">statistics on violence against transgender individuals, especially Black transgender women.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"According to the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">guidelines, the pronouns and names used should be those preferred by the individual. The content uses 'TaiVion </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan,' also known as 'Tai' and uses 'her' and 'she' pronouns throughout, indicating adherence to this guideline </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as there are no signs to contrary regarding Lathan's preferred pronouns.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The content does cite TaiVion Lathan's</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender status, but it is pertinent to the context, as the article addresses violence against transgender </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">individuals and highlights ongoing societal issues faced by this community. Therefore, this mention is justified as</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">it provides context that is necessary for understanding the motive of the crime and its broader social </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">implications.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"According to the guidelines, terminology related to transgender individuals should be used </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sensitively and accurately. Terms like 'transgender woman' are used in the article, which aligns correctly with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">guideline terminology.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article provides national context concerning issues faced by transgender people, such</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as violence and anti-trans legislation, which align with key issues identified within the guidelines. It </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sensitively incorporates this information to elevate public awareness of the broader context in which TaiVion </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan's murder occurred.\"</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'h2yUoJ6ii2YUwdJ5cgvF8z'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'haiku'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_cte'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The content provided is a news article reporting on the tragic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">murder of a 24-year-old transgender woman named Tai'Vion Lathan in Baltimore, Maryland. The article provides </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">details about Lathan's life, the circumstances of her death, and the broader context of violence faced by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender people, especially transgender women of color. The article highlights the alarming rates of violence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and homicide targeting the transgender community, and calls for justice, transparency, and an end to the harmful </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rhetoric and policies that contribute to this ongoing crisis.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article clearly identifies Tai'Vion Lathan as </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a transgender woman and uses her correct name and pronouns throughout. This is in line with best practices for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reporting on transgender individuals, as outlined in the Associated Press Stylebook and New York Times Style Book, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">which recommend using a person's preferred name and pronouns.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article also provides important context about </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the broader challenges and barriers faced by transgender people, including lack of access to healthcare, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">difficulties updating identity documents, employment discrimination, and vulnerability to violence. These details </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">help situate Lathan's tragic death within the systemic issues and discrimination that transgender individuals, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">especially transgender women of color, continue to face.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article highlights the alarming statistics around </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">violence targeting transgender people, noting that at least 24 transgender and gender-expansive people have been </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">killed in the US so far in 2024, with a disproportionate impact on Black transgender women. This data is sourced </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from the Human Rights Campaign, a reputable LGBTQ+ advocacy organization.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Overall, the article appears to be a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sensitive and well-researched report on the death of Tai'Vion Lathan, presenting the facts in a way that honors her</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">memory, acknowledges the broader context of violence facing the transgender community, and calls for justice and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">action to address this ongoing crisis.\"</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'J9c3extkYp7rz79foP5Mud'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'llama31_70b'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'trans_cte'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The content appears to be a news article about the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">murder of a 24-year-old transgender woman named Tai'Vion Lathan in Baltimore. The article provides details about </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the victim's life, the circumstances of her death, and the investigation into the crime. The tone of the article is</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">informative and somber, with a focus on highlighting the tragedy of the event and the need for justice.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">article uses the name and pronouns that the victim's family and friends use to refer to her, which is consistent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with the policy guidelines for reporting on transgender individuals. The article also provides context about the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">victim's life and identity, including her interests and plans for the future.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article quotes individuals who</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knew the victim and advocates for the transgender community, which adds depth and perspective to the story. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">quotes also highlight the impact of the victim's death on her loved ones and the broader community.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">provides information about the investigation into the crime and the efforts of law enforcement to solve the case. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The article also mentions the reward being offered for information leading to an arrest and the efforts of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">community advocates to raise awareness about the case.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article does not contain any language or content that</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is derogatory or discriminatory towards transgender individuals. The tone is respectful and sensitive to the victim</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and her community.'</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'jvJLvWhMxQTSFGNZYKMpbo'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'sonnet'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_cte'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"This is a news article reporting on the murder of Tai'Vion Lathan, a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">24-year-old Black transgender woman in Baltimore. The article provides details about her life, personality, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relationships, while also contextualizing her death within the broader pattern of violence against transgender </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">people, particularly trans women of color.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article exemplifies best practices in reporting on transgender </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">individuals by consistently using Lathan's correct name and pronouns (she/her) throughout. Family members and other</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sources are quoted using appropriate pronouns and her chosen name, showing respect for her identity.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">appropriately addresses the pertinence of Lathan's transgender status by connecting it to broader patterns of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">violence against transgender people, particularly women of color. It includes relevant statistics and context about</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anti-trans violence and legislation, making her identity relevant to understanding the broader social context of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">her death.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The coverage humanizes Lathan by focusing on her personal qualities, aspirations, and relationships, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rather than sensationalizing her identity or death. Her great aunt's quote specifically addresses the importance of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">seeing beyond the 'transgender' label to recognize Lathan's full humanity.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The reporting follows journalistic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">best practices by including broader context about violence against transgender people, relevant statistics, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">expert perspectives while maintaining focus on Lathan as an individual. It appropriately balances personal details </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with broader social implications.'</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'L69vaSDRcwJvTPrQfAXuMM'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gemini15pro'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'trans_factored'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The article reports on the murder of TaiVion</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan, a Black transgender woman, in Baltimore. It highlights the increasing violence against transgender </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">individuals, especially Black transgender women, in the US, connecting it to the rise of anti-trans legislation and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rhetoric. The article emphasizes the need to remember Lathan's humanity and not reduce her identity to her being </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article explicitly states Lathan\\'s transgender identity, which is essential to understanding </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the context of the violence she faced and the broader issue of violence against transgender people, particularly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Black transgender women. This does not violate the \"UNNECESSARY IDENTIFICATION\" rule, as her identity is central to</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the story and sheds light on a systemic issue.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article consistently uses Lathan\\'s chosen name and pronouns.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">It also respects her identity by quoting her great aunt\\'s plea to remember her as a person beyond her transgender </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">identity. Thus, the \"USES INCORRECT NAME OR PRONOUNS\" rule is not violated.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article uses accurate and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">respectful language, referring to Lathan as a \"transgender woman\" and using her chosen name and pronouns. It </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">doesn\\'t use outdated or offensive terms, nor does it compare her to \"real\" or \"biological\" women. Therefore, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">there\\'s no violation of the \"USES INACCURATE PHRASES / DESCRIPTORS\" rule.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article avoids politicized </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">phrases like \"gender ideology\" or \"trans agenda.\" Instead, it focuses on the violence and discrimination faced by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender individuals, citing statistics and quoting advocates. Hence, it doesn\\'t violate the \"USES POLITICISED </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">PHRASES\" rule.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article does not perpetuate harmful narratives about transgender people. It highlights the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">systemic violence against them and avoids associating transgender identity with negative connotations like </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"grooming\" or suggesting it\\'s a trend or a response to trauma. Thus, no violation of \"USES HARMFUL NARRATIVES\" is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">observed.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article does not make assumptions about anyone\\'s gender identity but reports the facts of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan\\'s case accurately. Therefore, the \"ASSUMES GENDER IDENTITY\" rule is not violated.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article doesn\\'t </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">focus on Lathan\\'s medical history or transition details. It focuses on her life, personality, and the tragedy of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">her death. Hence, it doesn\\'t violate the \"INAPPROPRIATE MEDICALISATION\" rule.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article effectively frames </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the violence against Lathan within the context of systemic violence and discrimination against transgender people, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">especially Black transgender women. It highlights the increased vulnerability of this community to hate crimes, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">poverty, and homelessness, advocating for a systemic understanding of the issue. Thus, it doesn\\'t violate the \"NOT</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">FRAMED AS SYSTEMIC\" rule.'</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'LhMEwM6XQRP56YEtwrDbZL'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt4o'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_factored'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'The content centers around the murder of TaiVion Lathan, a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender woman, in Baltimore and addresses larger issues of violence against transgender individuals, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">particularly women of color.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The content does mention Lathans transgender status; however, it is relevant to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the story, as the article discusses the broader context of violence against transgender individuals, making this </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">identification essential and not unnecessary.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article uses TaiVion Lathan's chosen name and pronouns </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">consistently and correctly, demonstrating respect for her identity by not using any incorrect name or pronouns.\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"The language employed in the content is accurate and respectful, avoiding outdated or inaccurate descriptors. It </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">uses terms like 'transgender' appropriately without employing potentially misleading phrases like 'identifies </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as.'\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article refrains from using politically charged or harmful language when discussing transgender issues,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">focusing instead on the violence faced by transgender individuals and the political factors that may contribute to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">these challenges.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Harmful narratives are largely avoided in the coverage, as the article emphasizes systemic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">issues affecting the transgender community rather than scapegoating or stereotyping. It references structural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">discrimination and the increased vulnerability of transgender individuals due to societal factors.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The content </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">does not make assumptions about gender identity beyond what is clearly specified, focusing instead on reported </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">facts and commentary from relevant parties, thus avoiding stigmatizing language.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Inappropriate medicalization is</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">avoided as the focus is on Lathan's life, the circumstances of her death, and the systemic issues facing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender individuals, rather than unnecessarily emphasizing medical aspects of her gender identity.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">article frames the violence against Lathan within systemic issues, referencing statistics on violence against the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender community and advocacy calls for justice and law enforcement prioritization, suggesting a broader </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pattern of discrimination and violence.'</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'N4HjvnrKBPYiz2smuo9sVe'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'haiku'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'trans_factored'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The content provided appears to be a news </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">article reporting on the tragic murder of a 24-year-old transgender woman named Tai'Vion Lathan in Baltimore, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Maryland. The article provides details about Lathan's life, the circumstances of her death, and the broader context</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of violence faced by the transgender community, especially transgender women of color. The article aims to honor </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan's memory and advocate for justice and transparency in the investigation of her killing.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">adheres to the policy criteria by using Lathan's correct name and pronouns, and avoiding unnecessary identification</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of her transgender identity. It describes her as a 'person' and 'beautiful person' rather than solely defining her </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">by her gender identity. The article also acknowledges the systemic violence and discrimination faced by the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender community, particularly the disproportionately high rates of violence against transgender women of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">color.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article avoids using politicized or inaccurate phrases, such as 'gender ideology' or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'detransitioner', and does not suggest Lathan's identity is a mental disorder or a response to trauma. Instead, it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">frames her death as part of the broader epidemic of violence against transgender individuals.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article does </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">not make assumptions about Lathan's gender identity, and appropriately refers to her as a transgender woman. It </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">also refrains from unnecessarily focusing on or sensationalizing medical aspects of her identity or transition.\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"Overall, the article appears to be a respectful and responsible reporting of Lathan's tragic death, highlighting </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the broader systemic issues facing the transgender community while centering her humanity and the loss felt by her </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">loved ones.\"</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'SP5WURPDRPNemWMuCW565u'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'llama31_70b'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_factored'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The content is a news article reporting on the murder of a 24-year-old </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender woman, Tai'Vion Lathan, in Baltimore. The article provides context about Lathan's life, her family, and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the circumstances of her death. The tone of the article is informative and somber, with a focus on highlighting the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">violence and discrimination faced by the transgender community.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article uses respectful language when </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">referring to Lathan, using her chosen name and pronouns. It also avoids sensationalizing or exploiting her death, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">instead focusing on the impact of her loss on her family and community.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article provides statistics and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context about the violence faced by transgender people, particularly transgender women of color. It highlights the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">importance of addressing this issue and holding perpetrators accountable.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article includes quotes from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan's family and community members, which adds a personal touch and emphasizes the human impact of her death. It</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">also includes a quote from a transgender advocate, which provides additional context and perspective on the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">issue.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article does not use politicized or inflammatory language, and instead focuses on presenting a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">factual and respectful account of Lathan's death and its impact on the community.\"</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'6YK46HTtJmNPc4br8gWpYi'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'sonnet'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_factored'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"This is a news article reporting the murder of Tai'Vion Lathan, a 24-year-old Black transgender woman </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in Baltimore. The article focuses on her life, family's grief, and places her death in the broader context of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">violence against transgender people, particularly trans women of color.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article appropriately identifies </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan's transgender identity as it's relevant to both the pattern of violence against trans women and the systemic</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">issues facing the community. The disclosure appears consensual given family members' direct quotes and advocacy.\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"The article consistently uses correct pronouns (she/her) and her chosen name throughout. Family members' quotes </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">demonstrate respect for her identity while emphasizing her humanity beyond her transgender identity.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language used is accurate and respectful, avoiding problematic terms or phrases. The article appropriately </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">discusses transgender identity and violence without sensationalizing or using politicized language.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">effectively frames the issue systemically, providing statistics on anti-trans violence, discussing broader </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">political context, and including perspectives from advocacy organizations. It highlights the disproportionate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">impact on Black trans women and trans women of color.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article appropriately avoids unnecessary medical </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">details or assumptions about gender identity, focusing instead on Lathan as a person and the broader social context</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of anti-trans violence.'</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'j4wyNL3Hx5Hp2cUhmRjFcS'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gemini15pro'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_glaad'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The article discusses the tragic murder of Tai'Vion Lathan, a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">24-year-old Black transgender woman in Baltimore. It highlights the increasing violence against transgender people,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">particularly Black transgender women, and connects this violence to the hostile political climate and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">discriminatory legislation targeting the transgender community.  The article uses respectful language, emphasizing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan's humanity and individuality beyond her gender identity, while also providing context about the broader </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">issues faced by transgender individuals.  It includes quotes from Lathan's family, community advocates, and other </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender individuals, centering their perspectives on the tragedy and its implications.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">consistently uses Tai'Vion Lathan's chosen name and correct pronouns (she/her) throughout. It also avoids using her</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">birth name, respecting her identity.  This adheres to the guideline of always using a transgender person's chosen </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">name and pronouns.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article avoids using any offensive or outdated terminology.  It does not use terms like </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"sex change\" or \"born a man.\" Instead, it uses respectful and accurate language when referring to Lathan\\'s gender </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">identity, such as \"transgender woman.\" This is consistent with the guidelines to use accurate terminology and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">respectful language.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article avoids focusing solely on Lathan's transition or medical history. It highlights</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">her personality, interests, and aspirations, demonstrating a commitment to portraying her as a whole person rather </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">than reducing her identity to her transgender status.  This goes beyond the transition narrative and focuses on her</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">life and the impact of her death on her loved ones and community.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article includes statistics and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information about the broader issues facing transgender people, such as violence, discrimination, and the impact of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anti-trans legislation. This provides important context and educates readers about the challenges faced by the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender community.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article avoids sensationalizing Lathan\\'s story. It doesn\\'t include \"before and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">after\" photos or other clichd imagery that could reduce her to stereotypes. It focuses instead on the human impact</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of her death and the need for justice. This avoids sensationalizing her story and respects her as a person.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">article centers the voices of transgender people, including quotes from Lathan's family, community advocates, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">other transgender individuals in Baltimore.  It allows them to speak for themselves about the impact of violence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and discrimination, rather than relying solely on non-transgender voices.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article briefly mentions </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">statistics about violence against transgender people, particularly Black transgender women, and the increasing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">number of anti-trans bills introduced across the country.  This information is relevant and emphasizes the larger </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context of violence and discrimination that transgender individuals face, especially considering the rise in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anti-trans legislation.  It relates her story to a larger context of societal discrimination.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">focuses on the impact of Lathan\\'s death on her loved ones and the community. It respectfully quotes her great </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aunt, who urges people to remember Lathan\\'s humanity beyond her gender identity, and her great-aunt Mary Robinson </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">who stated that \"All life is valued.\" The article also includes quotes from Desiree Bandz, a transgender woman in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Baltimore, who speaks about her fears and concerns for her safety in the current political climate. This centering </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of personal experiences and emotional impact aligns with the guidelines to present transgender people as whole </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">individuals with families, aspirations, and communities.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article fulfills all the criteria for respectful </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and accurate reporting on transgender people. It uses accurate terminology, avoids offensive language and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">stereotypes, centers transgender voices, provides relevant context about the broader issues affecting the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">community, and respects Lathan's humanity and individuality. It also connects her story to the larger issue of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">violence and discrimination against transgender people.\"</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'KewwasgRkGfXJD5WzKtW98'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt4o'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_glaad'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The content reports on the tragic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">death of TaiVion Lathan, a transgender woman, emphasizing her personal attributes, the circumstances of her death,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and the broader context of violence faced by transgender people. It is presented in a respectful manner, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">highlighting the individual's humanity and the systemic issues faced by transgender people.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article avoids </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">using defamatory or offensive terms and respects TaiVion Lathan's chosen name and pronouns throughout. There are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">no instances of deadnaming, and the language used does not cast doubt on her gender identity.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The content does </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">not sensationalize TaiVion's identity; it integrates her story within the larger context of violence against the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender community, without resorting to clichs or inaccurate representations of transgender lives.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'There is</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a notable emphasis on violence against transgender people and the legislative climate contributing to their </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">vulnerabilities. This aligns with the guidelines to address social issues affecting transgender communities.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'No </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">unnecessary focus on medical aspects of transitioning or sensationalized visuals is present in the article. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">focus is on the broader societal issues and the impact of violence and legislation.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The content includes input </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from transgender voices and advocacy groups, providing insight into the challenges faced by the community and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reinforcing the importance of justice and societal change.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article provides a comprehensive view that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">extends beyond TaiVions transgender identity by explaining broader systemic issues such as violence and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">legislative backlash that affect transgender communities.'</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'QKfj3BcdQQHNPoLoQiKqCV'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'haiku'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_glaad'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The content provided describes the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tragic death of Tai'Vion Lathan, a 24-year-old transgender woman who was found fatally shot in an alley in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Baltimore. The article provides details about Lathan's life, her family's mourning, and the broader context of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">violence against transgender individuals, especially transgender women of color. The content does not appear to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">contain any inappropriate or defamatory material, and instead aims to respectfully honor Lathan's memory and raise </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">awareness about the ongoing challenges and risks faced by the transgender community.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article uses Tai'Vion </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan's chosen name and correct pronouns (she/her) throughout, which aligns with the policy guidelines on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">respecting transgender individuals' names and pronouns. There is no indication that the article 'deadnames' Lathan </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">or uses any other disrespectful language.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article also provides relevant context about the disproportionate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rates of violence and discrimination experienced by transgender people, especially transgender women of color. This</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">helps readers understand the broader societal issues that contribute to tragedies like Lathan's death.\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"Furthermore, the article includes quotes from Lathan's family members and community advocates who emphasize the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">need to remember Lathan as a full, complex person and not solely define her by her gender identity. This approach </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is consistent with the policy guidelines on moving beyond reductive 'transition narratives' and instead integrating</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender individuals into stories that reflect the diversity of their lives and experiences.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Overall, the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">content appears to be a respectful and thoughtful portrayal of Tai'Vion Lathan's life and death, while also raising</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">awareness about the urgent need to address the violence and discrimination faced by transgender people. The article</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aligns with the policy guidelines in its use of language, framing, and contextual information.\"</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'2XByL8zYDciEaYBEQHTE8o'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'llama31_70b'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_glaad'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The content is a news article about the murder of a 24-year-old transgender woman, Tai'Vion Lathan, in</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Baltimore. The article provides details about Lathan's life, her family's reaction to her death, and the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">investigation into her murder.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article highlights the high rate of violence against transgender people, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">particularly Black transgender women, and the lack of justice and transparency in many of these cases.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">article also mentions the introduction of legislation seeking to restrict transgender health care and rights, which</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is seen as contributing to the violence and marginalization of transgender people.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article quotes a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">representative from the Human Rights Campaign, who emphasizes the need to end the harmful rhetoric and policies </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that make it less safe for transgender people to live and thrive.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article also includes a personal account </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from a 30-year-old transgender woman living in Baltimore, who expresses her fear and distress about Lathan's death </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and the overall safety of transgender people in America.\"</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'WrMfq3bLUvAPMGAoWrmhDG'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'sonnet'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_glaad'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"This is a news article about the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">murder of Tai'Vion Lathan, a 24-year-old transgender woman who was found fatally shot in Baltimore. The article </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">focuses on her life, her personality, and her family's grief while also contextualizing her death within the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">broader pattern of violence against transgender people, particularly Black trans women.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article follows best</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">practices for transgender coverage by consistently using Lathan's correct name and pronouns (she/her) throughout. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">It avoids deadnaming or inappropriate questions about medical transition, focusing instead on her life, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">personality, and relationships.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article appropriately integrates expert voices from the transgender </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">community, including the Human Rights Campaign's trans justice initiative director and another trans woman from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Baltimore. It provides relevant context about violence against trans people and current anti-trans legislation.\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"The piece effectively humanizes Lathan through family quotes and personal details while avoiding sensationalistic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">elements. Her great aunt's quote specifically addresses the importance of seeing Lathan as a complete person beyond</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">her transgender identity.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The story responsibly includes current statistics and context about anti-trans </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">violence, particularly affecting Black trans women, while also providing practical information about the ongoing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">investigation and how to submit tips.'</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'jJemEpkyrTXQ8MLCi9Lja4'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gemini15pro'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'trans_hrc'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The article discusses the murder of Tai'Vion </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan, a 24-year-old Black transgender woman, in Baltimore. It highlights the increasing violence against </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender people, especially Black transgender women, and the context of discriminatory legislation. The article </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aims to raise awareness about this issue and advocate for respect and safety for transgender individuals.  It is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">important to analyze the language used to determine if it adheres to guidelines for respectful reporting on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender people.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article consistently uses Tai\\'Vion Lathan\\'s chosen name and pronouns (she/her), </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">respecting her gender identity.  It also shares her personal story, hobbies, and aspirations, which demonstrates </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">adherence to guidance about putting the person at the center of the story rather than just their identity. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">article also avoids contrasting transgender women with \"real\" or \"biological\" women.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article accurately </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">describes the meaning of \"transgender,\" aligning with established definitions such as the one provided by the HRC. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">It explicitly states that Lathan \"was a person, and a beautiful person at that,\" reinforcing the idea that her </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">identity does not make her less human.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article uses language that clarifies the difference between gender </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">identity, gender expression, and sexual orientation. While the article does not explicitly discuss these terms in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">detail, its overall approach reflects an understanding of these concepts by focusing on Lathan's gender identity </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and lived experiences as a trans woman, without delving into irrelevant aspects like sexual orientation.  This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">adheres to the guidelines.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article discusses Lathan\\'s transition with respect and sensitivity.  It does not</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">disclose details about her medical history or transition process without consent, adhering to the guidelines around</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">privacy. The narrative emphasizes that \"transitioning is a very personal process, and everyone has a right to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">privacy,\" in accordance with the provided criteria.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article acknowledges that transition does not always </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">involve surgery.  It states that Lathan was about to start school to become a nurse, showcasing aspects of her life</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">beyond her transition.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article avoids disrespectful language by never contrasting transgender people with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"real\" or \"biological\" men and women.  This aligns with the provided guidelines and fosters an inclusive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">narrative.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article avoids focusing solely on Lathan's transition. It depicts her as a multifaceted </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">individual with passions, relationships, and dreams.  It shares details about her hobbies, love for family and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">goals. This holistic approach is consistent with the HRC's guidelines.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article discusses the broader context</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of violence against transgender people, the disproportionate impact on Black transgender women, and the connection </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to discriminatory legislation.  This information creates a comprehensive understanding of the issue, rather than </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">just presenting the murder in isolation.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'In conclusion, the article adheres to the provided guidelines for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reporting on transgender people. It uses respectful language, avoids harmful stereotypes, and focuses on the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">individual while providing appropriate context.'</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'9ybBuHRNJGhGSMYWSBgddV'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt4o'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'trans_hrc'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'The content is a news article reporting on the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">murder of TaiVion Lathan, a Black transgender woman, in Baltimore. It provides details about her as a person, the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">circumstances of her death, and the broader societal issues affecting the transgender community, particularly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anti-trans violence and discrimination.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article properly understands and uses the term 'transgender.' It </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">refers to TaiVion Lathan with appropriate gendered terms like 'transgender woman' and uses her preferred name and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pronouns throughout the piece. It does not misuse terms or suggest 'transgendered,' adhering to preferred language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">guidelines.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The content makes a clear distinction between gender identity and sexual orientation. It discusses </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan's gender identity as a transgender woman, focusing on societal challenges faced by transgender individuals, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">without making assumptions about her sexual orientation, showing understanding of the difference.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">does not delve deeply into Lathans transition process; however, the focus on her identity and the violence against</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">trans individuals respects the personal nature of transitioning. There are no inappropriate comments regarding </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">medical or social transition processes, respecting the privacy of the individual.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Names and pronouns are used </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">respectfully throughout the article, aligning with number five of the guidelines. Lathan is referred to by her </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">chosen name, 'Tai, and female pronouns, without any instances of deadnaming or misgendering.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The content </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">discusses broader societal issues faced by transgender individuals in the United States, such as violence, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">legislation, and discrimination. It contextualizes Lathans murder within these larger realities, reflecting on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">systemic issues without victim-blaming or misrepresenting her life.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"There is no language in the article </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">contrasting Lathans identity with 'real' or 'biological' women, avoiding harmful false comparisons. The narrative </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">respects her identity as a transgender woman without undermining her authenticity.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article focuses on Lathan</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as a person, detailing her relationships, interests, and aspirations. It highlights her familys grief and the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">communitys response, presenting her as a multifaceted individual rather than just focusing on her transgender </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">identity.'</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Wwp4eDzZnGtayfAP6fXBnm'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'haiku'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_hrc'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The content provided appears to be a news article reporting on the tragic murder of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a 24-year-old transgender woman named Tai'Vion Lathan in Baltimore, Maryland. The article provides details about </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan's life and personality, the circumstances of her death, the broader context of violence against transgender </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">individuals in the United States, and the reactions and efforts of her family, community, and local authorities. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The tone is somber and respectful, focusing on honoring Lathan's memory and advocating for justice and safety for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the transgender community.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article appears to adhere to the guidelines outlined in the provided criteria. It</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">uses the appropriate terminology to refer to Lathan, including her name, pronouns, and gender identity. It provides</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context about the reality of many transgender people's lived experiences, including the disproportionate violence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and discrimination they face. The article avoids framing Lathan's identity in a way that would be considered </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">disrespectful or dehumanizing.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article also highlights the broader social and political factors that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">contribute to the vulnerability of transgender individuals, such as the introduction of anti-transgender </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">legislation at the federal and state levels. It includes quotes from Lathan's loved ones and community advocates </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that emphasize the need for justice, transparency, and efforts to end the harmful rhetoric and policies that put </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender lives at risk.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Overall, the article appears to be a thoughtful and sensitive portrayal of Lathan's </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">life and death, as well as the ongoing challenges and dangers faced by the transgender community. The content </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aligns with the guidelines set forth in the criteria, respecting Lathan's identity and centering her humanity, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">while also providing important context and calls to action.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Based on the analysis above, I conclude that the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">content does not violate the policy or guidelines provided, and instead represents a conscientious and responsible </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">approach to reporting on the tragic loss of a transgender individual's life.\"</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fQxDKGmT4BPTzLf6w333mR'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'llama31_70b'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_hrc'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The content </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">appears to be a news article reporting on the murder of a 24-year-old transgender woman named Tai'Vion Lathan in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Baltimore. The article provides context about Lathan's life, her family's reaction to her death, and the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">investigation into her murder. It also highlights the wider issue of violence against transgender people, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">particularly transgender women of color, and the impact of anti-trans legislation on the community.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">uses respectful language when referring to Lathan, using her preferred name and pronouns. It also avoids </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sensationalism and instead focuses on telling Lathan's story and highlighting the human impact of her death.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">article provides context about the broader issue of violence against transgender people, citing statistics and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">expert opinions. It also highlights the impact of anti-trans legislation on the community and the need for greater </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">awareness and understanding.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article quotes Lathan's family members and friends, as well as advocates for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the transgender community, to provide a more personal and nuanced perspective on the issue. It also includes </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information about resources and support for the community, such as a GoFundMe campaign to support Lathan's family </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and a hotline for LGBTQ+ people in Baltimore.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Overall, the article appears to be a thoughtful and respectful </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">report on a tragic event, and it provides a clear and concise explanation of the issue and its impact on the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">community.'</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'8DhFjJbedSPYrxiUcKi7VD'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'sonnet'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_hrc'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"This is a news article about the murder of Tai'Vion Lathan, a 24-year-old Black </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender woman in Baltimore. The article primarily focuses on her life, personality, and the impact of her death</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">on her family and community, while also providing context about broader violence against transgender people and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">current political climate affecting trans rights.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article exemplifies respectful coverage by centering </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan's humanity and relationships, using her correct name and pronouns throughout, and including meaningful </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">quotes from family members that emphasize her personhood beyond her transgender identity. This aligns with criteria</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">#5 and #8.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The reporting appropriately provides context about violence against transgender people, particularly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">trans women of color, and connects to broader societal issues (criteria #6). It avoids harmful tropes like </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">suggesting criminal involvement or deception, and doesn't include deadnaming or misgendering.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">effectively balances personal details about Lathan with broader statistical and social context about anti-trans </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">violence and discrimination, following best practices for comprehensive reporting on transgender issues. It </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">includes perspectives from family, advocacy organizations, and other trans community members.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The coverage </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">demonstrates sensitivity to privacy concerns while still providing newsworthy information about an active criminal </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">investigation. The reporting adheres to all major guidelines about respectful coverage of transgender people and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">violence against the trans community.'</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'TsjctZgWjrbRfxVfWtu8pV'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gemini15pro'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'trans_simplified'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The article discusses the murder of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">TaiVion Lathan, a Black transgender woman, in Baltimore. It highlights the increasing violence against transgender</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">people, especially Black transgender women, and connects this violence to the rise of anti-trans legislation. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">article aims to raise awareness about the issue and humanize Lathan by sharing details about her life and family's </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">grief.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article consistently uses Lathan's chosen name, TaiVion, and her correct pronouns (she/her). It does</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">not identify her as transgender unless it provides necessary context, such as when discussing the broader issue of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">violence against transgender people.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article explicitly avoids outing Lathan by not revealing any private </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information that she had not already made public.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article does not use any offensive terms to refer to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan or other transgender people. Instead, it uses respectful and accurate language.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article avoids </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language that perpetuates negative stereotypes or casts doubt on a person\\'s gender identity. For example, it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">avoids using phrases like \"identifies as\" or putting quotation marks around Lathan\\'s name or pronouns.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">article does not use any lesser-known terminology related to body parts or biological functions.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">does not publish false narratives about transgender people. Instead, it highlights the violence they face due to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">harmful rhetoric and legislation, citing data from reputable sources like the Human Rights Campaign and Trans </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Legislation Tracker.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article avoids cliches and focuses on Lathan's life and personality rather than her </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">medical transition. It highlights her hobbies, family relationships, and aspirations of becoming a nurse.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">article acknowledges the systemic prejudice and discrimination faced by transgender people and how this can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">contribute to their vulnerability to violence and poverty. It mentions that 54% of transgender people have </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">experienced some form of intimate partner violence.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Overall, the article adheres to all the provided guidelines </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for reporting on transgender individuals. It uses respectful language, provides relevant context, and avoids </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">harmful stereotypes and false narratives.'</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7iAU2nihU5BEwghbxo3DPH'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt4o'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'trans_simplified'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'The content centers around the murder of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">TaiVion Lathan, a transgender woman, and its impact on her family, the community, and broader society. It </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">discusses systemic issues related to violence against transgender people and legislative challenges faced by the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender community.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The piece respects the guidelines by consistently using TaiVion Lathans chosen name and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">appropriate pronouns throughout the article, ensuring the transgender identity of the individual is acknowledged </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">respectfully.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article identifies Lathan as transgender as a necessary and relevant context for understanding</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the broader issue of violence against transgender individuals. It does not appear to 'out' Lathan unnecessarily; </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">instead, the article includes her identity to highlight systemic violence faced by trans individuals, which aligns </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with the guideline.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'There is no use of offensive terms, nor language that perpetuates negative or incorrect </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">perceptions of gender identities. The content remains respectful and avoids diminishing a persons gender identity,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">thereby adhering to the policy.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The narrative avoids focusing predominantly on medical transition and instead </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">centers on the individual's personal life, relationships, and the tragic event of her murder. The story provides a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">comprehensive social context, mentioning the specific risks faced by transgender individuals without </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sensationalizing their medical or personal histories.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article includes an analysis of systemic patterns of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">prejudice and discrimination, such as the higher risk of violence faced by transgender people, especially trans </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">women of color, and mentions these in relation to broader legislative challenges and social rhetoric.'</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'Twc5veUrBja2D49CqzL9Vh'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'haiku'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_simplified'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The provided content appears to be a news article reporting on the tragic death of a 24-year-old </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender woman named Tai'Vion Lathan, who was fatally shot in Baltimore. The article provides details about </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan's life, her family's mourning, the broader context of violence against transgender individuals, and the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ongoing investigation into her death. It highlights the disproportionate impact of anti-transgender violence, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">particularly on transgender people of color, and the need for greater justice and accountability. The article </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">strikes a respectful and empathetic tone in discussing Lathan's life and the challenges faced by the transgender </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">community.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article adheres to the guidelines by consistently using Tai'Vion Lathan's chosen name and correct</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pronouns (she/her) throughout. It avoids offensive terminology, does not out Lathan as transgender unless relevant </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for context, and does not make comparisons or use language that casts doubt on her gender identity. The article </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">provides the necessary context about Lathan's life and the broader issues of violence against transgender </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">individuals.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article also highlights the need for greater transparency and accountability in investigating </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">crimes against transgender individuals, noting that many such cases often go unsolved. It amplifies the voices of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan's family and other transgender community members, emphasizing the devastating impact of this loss and the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ongoing fears and vulnerability experienced by the transgender population.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Overall, the article appears to be a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">thoughtful and respectful reporting of Tai'Vion Lathan's tragic death, while also drawing attention to the systemic</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">issues of prejudice, discrimination, and violence that transgender individuals, especially transgender people of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">color, face. The content adheres to the provided guidelines and presents the information in a way that is sensitive</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and centers the humanity of the victim.\"</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'6Uqw3cWBLEGTz2cvj9iE5V'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'llama31_70b'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'trans_simplified'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The content provided is a news article </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reporting on the murder of a 24-year-old transgender woman, Tai'Vion Lathan, in Baltimore. The article includes </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">quotes from Lathan's family members and transgender advocates, highlighting the tragedy and violence faced by the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender community.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article uses Lathan's chosen name and pronouns, as preferred by her family, which is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in line with the policy guidelines.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article does not identify Lathan as transgender unless it provides </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">necessary and relevant clarity or context, which is in line with the policy guidelines.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article does not use</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">offensive terms to refer to trans people and avoids language that perpetuates negative or incorrect perceptions of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">gender identities.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article includes an explanation of the risks and vulnerabilities faced by transgender </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">people, including bias, unemployment, and homelessness, which is relevant to the story and helps to provide </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article quotes transgender advocates, including Tori Cooper, who highlights the impact of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anti-trans violence on the mental health and well-being of transgender people.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article also includes a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">statement from Baltimore Mayor Brandon Scott, who commits to tracking down the perpetrators and doing due diligence</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in the case, which suggests a commitment to justice and transparency.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The overall tone of the article is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">respectful and sympathetic to Lathan and her family, and it highlights the importance of valuing all life, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">regardless of gender identity or expression.'</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'g5fcXc54DwdCegXHsLhnU3'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'sonnet'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'trans_simplified'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"This article reports on the murder of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Tai'Vion Lathan, a 24-year-old Black transgender woman in Baltimore, focusing on her life, personality, and the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">impact of her death on family and community. The content places her death in the broader context of violence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">against transgender people, particularly transgender women of color, and connects to current political climate and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">legislation affecting transgender rights.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The content correctly uses Tai'Vion's chosen name and feminine </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pronouns consistently throughout. There are no references to deadnames or inappropriate pronouns.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">identifies Lathan as transgender in a relevant context, as it relates to a pattern of violence against transgender </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">people and provides important statistical context about the broader issue of anti-trans violence.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">used is respectful and appropriate, avoiding offensive terms or stereotypes. The article centers Lathan's humanity,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">describing her personality, aspirations, and relationships.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article avoids language that diminishes gender </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">identity. It presents Lathan's gender straightforwardly without qualifying terms like 'identifies as' or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">comparisons to 'biological' gender.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article appropriately includes context about systemic discrimination and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">violence against transgender people, citing relevant statistics and explaining how prejudice and discrimination can</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">make transgender people more vulnerable to violence.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The focus remains primarily on Lathan as a person, with her</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">family relationships, career aspirations, and personality traits prominently featured. Medical transition is not </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">mentioned at all, appropriately keeping the focus on her life and tragic death.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article responsibly reports </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">on violence against a transgender person while avoiding sensationalism and including important context about </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">broader patterns of discrimination and violence.'</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'83Ka5kU2vXRXGiM5jE5cTz'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gemini15pro'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_tja'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The article discusses the murder of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Tai'Vion Lathan, a 24-year-old Black transgender woman, in Baltimore. It highlights the increasing violence against</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender people, particularly Black transgender women, and connects this violence to the rise of anti-trans </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">legislation across the US.  The article centers Lathan's identity as a person, emphasizing her personality, family,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and aspirations, while also providing statistics on violence against transgender individuals and quoting reactions </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from her family and other trans people in Baltimore.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article adheres to the Trans Journalists Association </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">guidelines by prioritizing Tai\\'Vion Lathan\\'s identity as a person, not just as a transgender person.  It avoids </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">deadnaming or misgendering her, instead using her chosen name and pronouns.  The article also avoids focusing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">unnecessarily on her gender identity, mentioning it only when providing context about the broader issue of violence</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">against transgender individuals, as instructed by \"do not call unnecessary attention to a trans person\\'s </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">gender.\"'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article correctly uses terms like \"transgender\" and \"gender-expansive\" and avoids harmful or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">inaccurate terminology such as \"transgenderism\" or \"biological sex,\" adhering to guidelines under \"Politicized or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Inaccurate Phrases.\"'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article adheres to guidelines for breaking news coverage by correctly identifying </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan as transgender, respecting her identity as confirmed by her family (\"identifying transgender people during </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">breaking news\").  It also correctly writes about her in the past using her current name and pronouns (\"writing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">about someone in the past\").'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article includes relevant statistics and information about anti-trans </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">legislation and violence against transgender individuals, as recommended by \"reporting on anti-trans government </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">policies\" and \"reporting on crimes involving trans people.\" The article rightfully centers Lathan\\'s story while </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">including important context regarding violence faced by the transgender community. It amplifies the concerns of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">trans people about their safety and the negative impact of discriminatory legislation, following the guideline </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"trans people  not their parents, children, friends, colleagues, or critics  should be at the heart of stories </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">written about them.\"'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article demonstrates trauma-informed reporting practices by focusing on Lathan\\'s </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">humanity and avoiding sensationalizing details about her death, in line with \"practicing trauma-informed </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reporting.\"'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article does not include irrelevant or unnecessary questions about Lathan\\'s medical history or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">personal life, abiding by \"take care not to ask irrelevant or unnecessary questions.\"'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The article correctly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">identifies the increasing violence against trans people in the US and the role of anti-trans legislation without </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">making generalizations about the \"trans community\", as per \"there is no single \\'trans community\\'.\"'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The content</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">does not pertain to specific topical guidelines such as health care, sports, or asylum seekers and refugees; </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">therefore no further analysis is needed.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article adheres to guidelines for photography and visual media. It </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">doesn't include photos that could endanger sources, uses file photos carefully, and avoids inappropriate stock </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">images.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article uses correct and respectful language throughout. It adheres to the TJA guidelines by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">accurately representing the diversity of the trans community, centering the voices of trans people, and providing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">essential context about violence against transgender people. It avoids misgendering or deadnaming, and effectively </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">uses Lathan's story to shed light on larger issues affecting transgender Americans. The inclusion of family </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">perspectives enriches the portrayal of Lathan as a person while highlighting the profound impact of her loss.\"</span><span style=\"font-weight: bold\">]}</span>, \n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'YwZkx33qZBuZ9VTcvgj79Q'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt4o'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_tja'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'The content discusses the murder of TaiVion Lathan, a 24-year-old transgender woman in Baltimore, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">emphasizing the personal grief of her family and friends, while also providing broader context on the violence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">faced by transgender communities, especially Black transgender women.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The content addresses the gender identity </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of TaiVion Lathan appropriately, using correct pronouns and respecting her identity as a transgender woman. This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complies with the guidance to use a person's current pronouns and name.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'TaiVion Lathan is introduced as a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"transgender woman\", which is appropriate and avoids unnecessary specification like using \\'identifies as\\', as per</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">guidelines. The use of \\'transgender\\' is pertinent given the mention of violence faced by this community.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">article ensures that Lathans gender identity is represented respectfully and does not use or reveal any deadname. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The content does not exhibit the need to deadname, nor does it veer into the territory of unwarranted attention to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">her being transgender.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The content cites statistics and information from the Human Rights Campaign </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">appropriately, presenting data on violence against transgender individuals without sensationalizing or indulging in</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">misleading narratives.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The content includes quotes from community members and activists, presenting a balanced </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">view without suggesting that simply being transgender is a political act, which aligns with not using terms like </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'transgenderism'.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Details about Lathans life, like her interests and relationships, are included, providing a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">fuller humanizing context and avoiding the simplification or reduction of her identity to just her gender.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">article correctly identifies the systemic issues of violence faced by transgender and gender-expansive people, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">includes information on anti-trans legislation, adding necessary context rather than treating these topics as a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">simple culture war.'</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'avpi7qAUFkiGzBT7ncDvdj'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'haiku'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_tja'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"The content provided describes the tragic death of Tai'Vion Lathan, a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">24-year-old Black transgender woman, who was found fatally shot in an alley in Baltimore. The article provides </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">details about Lathan's life, including her loving relationship with her mother, her creative interests, and her </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">plans to become a nurse. It also contextualizes Lathan's death within the broader issue of violence against </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender and gender-expansive people in the United States, noting that at least 24 such individuals have been </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">killed so far this year, with a disproportionate number being Black transgender women. The article highlights the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ongoing threats and lack of safety that transgender people, especially transgender people of color, face due to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">anti-trans rhetoric, legislation, and violence.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The content does not appear to violate any of the Trans </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Journalists Association's guidelines. The article appropriately uses Lathan's correct name and pronouns, avoids </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">unnecessary focus on her appearance or transition, and centers her identity as a person rather than just her </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transgender status. It also provides relevant context about the challenges and risks that transgender people face, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">particularly those who are Black, without sensationalizing or exoticizing the subject matter.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article also </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">includes quotes from Lathan's family members and a local transgender advocate, demonstrating an effort to center </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the perspectives and experiences of the transgender community. It also highlights the ongoing investigation into </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Lathan's death and the reward being offered for information, indicating a commitment to transparency and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">accountability.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Overall, the content appears to be a sensitive and well-researched reporting on the tragic loss </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of Tai'Vion Lathan, framing her story within the broader context of violence against transgender individuals in the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">United States. The article adheres to the Trans Journalists Association's guidelines for accurately and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">respectfully covering stories about transgender people.\"</span><span style=\"font-weight: bold\">]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'SJ5epKyMvZQ96qRcXikoL3'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'llama31_70b'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_tja'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[]}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'G47VXzzw2BndGvLtCG9wzk'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'sonnet'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans_tja'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"This news article reports on the murder of Tai'Vion Lathan, a 24-year-old Black transgender woman in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Baltimore. The article focuses on her humanity, her relationships, and her aspirations while also providing context</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">about the broader pattern of violence against transgender people, particularly trans women of color.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"The article</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">adheres to best practices by centering Lathan's humanity and using her correct name and pronouns throughout. Family</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">members are quoted speaking about her life, personality, and future plans rather than focusing solely on her death </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">or gender identity.\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The reporting appropriately includes broader context about violence against trans people and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">statistics about anti-trans violence, particularly affecting Black trans women. The article also responsibly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">connects this context to current anti-trans legislation and systemic issues without sensationalizing.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">article follows guidelines about speaking to trans people about trans issues by including quotes from other trans </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">community members and advocacy organizations. It avoids deadnaming or inappropriate questions about medical </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">details.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The coverage treats the crime with appropriate seriousness and includes practical information about the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">investigation and how to submit tips, while also highlighting systemic issues in solving crimes against trans </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">people.'</span><span style=\"font-weight: bold\">]}])]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;35mlist\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'J6SqUtdwyQX5uuLk5hWCYa'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'gemini15pro'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_cte'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \n",
       "\u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The article discusses the murder of Tai'Vion Lathan, a Black transgender woman, \u001b[0m\n",
       "\u001b[32mhighlighting the increased violence faced by the transgender community, particularly transgender women of color.  \u001b[0m\n",
       "\u001b[32mIt uses Lathan's correct name and pronouns throughout the piece. The article aims to raise awareness about this \u001b[0m\n",
       "\u001b[32missue and advocate for justice and policy change to protect transgender individuals. The article's tone is \u001b[0m\n",
       "\u001b[32mrespectful and aims to humanize Lathan, emphasizing her personality, family, and aspirations.\"\u001b[0m, \u001b[32m\"The content \u001b[0m\n",
       "\u001b[32mconsistently uses Tai'Vion Lathan's chosen name and pronouns \u001b[0m\u001b[32m(\u001b[0m\u001b[32mshe/her\u001b[0m\u001b[32m)\u001b[0m\u001b[32m throughout the article, as requested by her \u001b[0m\n",
       "\u001b[32mfamily. This aligns with the provided guidelines from the Associated Press Stylebook and the New York Times Style \u001b[0m\n",
       "\u001b[32mBook.\"\u001b[0m, \u001b[32m'The article specifically discusses the violence faced by transgender people, especially transgender women \u001b[0m\n",
       "\u001b[32mof color. It highlights the statistics on transgender homicides and discusses the broader context of legislative \u001b[0m\n",
       "\u001b[32mattacks on transgender rights and healthcare. The language used is respectful and aims to raise awareness of the \u001b[0m\n",
       "\u001b[32missue.'\u001b[0m, \u001b[32m\"The article focuses on the tragic murder of a transgender woman and the broader issues faced by the \u001b[0m\n",
       "\u001b[32mtransgender community. By highlighting Lathan's personal life, aspirations, and the grief of her family, the \u001b[0m\n",
       "\u001b[32marticle humanizes her and counters the dehumanization often experienced by transgender individuals.\"\u001b[0m, \u001b[32m'The article \u001b[0m\n",
       "\u001b[32mpromotes respect and understanding of transgender people by using accurate terminology and highlighting the \u001b[0m\n",
       "\u001b[32mimportance of recognizing their full humanity, beyond their gender identity. It also advocates for justice and \u001b[0m\n",
       "\u001b[32mpolicy change to protect transgender individuals from violence and discrimination.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \n",
       "\u001b[32m'Qgi5p3fnPShknhHsTNBf2X'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'gpt4o'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_cte'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \n",
       "\u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'The content is a news report covering the death of TaiVion Lathan, a transgender woman, who was \u001b[0m\n",
       "\u001b[32mmurdered in Baltimore. It discusses the circumstances of her death, the grief of her family, and provides \u001b[0m\n",
       "\u001b[32mstatistics on violence against transgender individuals, especially Black transgender women.'\u001b[0m, \u001b[32m\"According to the \u001b[0m\n",
       "\u001b[32mguidelines, the pronouns and names used should be those preferred by the individual. The content uses 'TaiVion \u001b[0m\n",
       "\u001b[32mLathan,' also known as 'Tai' and uses 'her' and 'she' pronouns throughout, indicating adherence to this guideline \u001b[0m\n",
       "\u001b[32mas there are no signs to contrary regarding Lathan's preferred pronouns.\"\u001b[0m, \u001b[32m\"The content does cite TaiVion Lathan's\u001b[0m\n",
       "\u001b[32mtransgender status, but it is pertinent to the context, as the article addresses violence against transgender \u001b[0m\n",
       "\u001b[32mindividuals and highlights ongoing societal issues faced by this community. Therefore, this mention is justified as\u001b[0m\n",
       "\u001b[32mit provides context that is necessary for understanding the motive of the crime and its broader social \u001b[0m\n",
       "\u001b[32mimplications.\"\u001b[0m, \u001b[32m\"According to the guidelines, terminology related to transgender individuals should be used \u001b[0m\n",
       "\u001b[32msensitively and accurately. Terms like 'transgender woman' are used in the article, which aligns correctly with \u001b[0m\n",
       "\u001b[32mguideline terminology.\"\u001b[0m, \u001b[32m\"The article provides national context concerning issues faced by transgender people, such\u001b[0m\n",
       "\u001b[32mas violence and anti-trans legislation, which align with key issues identified within the guidelines. It \u001b[0m\n",
       "\u001b[32msensitively incorporates this information to elevate public awareness of the broader context in which TaiVion \u001b[0m\n",
       "\u001b[32mLathan's murder occurred.\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'h2yUoJ6ii2YUwdJ5cgvF8z'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'haiku'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_cte'\u001b[0m, \n",
       "\u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The content provided is a news article reporting on the tragic \u001b[0m\n",
       "\u001b[32mmurder of a 24-year-old transgender woman named Tai'Vion Lathan in Baltimore, Maryland. The article provides \u001b[0m\n",
       "\u001b[32mdetails about Lathan's life, the circumstances of her death, and the broader context of violence faced by \u001b[0m\n",
       "\u001b[32mtransgender people, especially transgender women of color. The article highlights the alarming rates of violence \u001b[0m\n",
       "\u001b[32mand homicide targeting the transgender community, and calls for justice, transparency, and an end to the harmful \u001b[0m\n",
       "\u001b[32mrhetoric and policies that contribute to this ongoing crisis.\"\u001b[0m, \u001b[32m\"The article clearly identifies Tai'Vion Lathan as \u001b[0m\n",
       "\u001b[32ma transgender woman and uses her correct name and pronouns throughout. This is in line with best practices for \u001b[0m\n",
       "\u001b[32mreporting on transgender individuals, as outlined in the Associated Press Stylebook and New York Times Style Book, \u001b[0m\n",
       "\u001b[32mwhich recommend using a person's preferred name and pronouns.\"\u001b[0m, \u001b[32m\"The article also provides important context about \u001b[0m\n",
       "\u001b[32mthe broader challenges and barriers faced by transgender people, including lack of access to healthcare, \u001b[0m\n",
       "\u001b[32mdifficulties updating identity documents, employment discrimination, and vulnerability to violence. These details \u001b[0m\n",
       "\u001b[32mhelp situate Lathan's tragic death within the systemic issues and discrimination that transgender individuals, \u001b[0m\n",
       "\u001b[32mespecially transgender women of color, continue to face.\"\u001b[0m, \u001b[32m'The article highlights the alarming statistics around \u001b[0m\n",
       "\u001b[32mviolence targeting transgender people, noting that at least 24 transgender and gender-expansive people have been \u001b[0m\n",
       "\u001b[32mkilled in the US so far in 2024, with a disproportionate impact on Black transgender women. This data is sourced \u001b[0m\n",
       "\u001b[32mfrom the Human Rights Campaign, a reputable LGBTQ+ advocacy organization.'\u001b[0m, \u001b[32m\"Overall, the article appears to be a \u001b[0m\n",
       "\u001b[32msensitive and well-researched report on the death of Tai'Vion Lathan, presenting the facts in a way that honors her\u001b[0m\n",
       "\u001b[32mmemory, acknowledges the broader context of violence facing the transgender community, and calls for justice and \u001b[0m\n",
       "\u001b[32maction to address this ongoing crisis.\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'J9c3extkYp7rz79foP5Mud'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'llama31_70b'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \n",
       "\u001b[32m'trans_cte'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The content appears to be a news article about the\u001b[0m\n",
       "\u001b[32mmurder of a 24-year-old transgender woman named Tai'Vion Lathan in Baltimore. The article provides details about \u001b[0m\n",
       "\u001b[32mthe victim's life, the circumstances of her death, and the investigation into the crime. The tone of the article is\u001b[0m\n",
       "\u001b[32minformative and somber, with a focus on highlighting the tragedy of the event and the need for justice.\"\u001b[0m, \u001b[32m\"The \u001b[0m\n",
       "\u001b[32marticle uses the name and pronouns that the victim's family and friends use to refer to her, which is consistent \u001b[0m\n",
       "\u001b[32mwith the policy guidelines for reporting on transgender individuals. The article also provides context about the \u001b[0m\n",
       "\u001b[32mvictim's life and identity, including her interests and plans for the future.\"\u001b[0m, \u001b[32m\"The article quotes individuals who\u001b[0m\n",
       "\u001b[32mknew the victim and advocates for the transgender community, which adds depth and perspective to the story. The \u001b[0m\n",
       "\u001b[32mquotes also highlight the impact of the victim's death on her loved ones and the broader community.\"\u001b[0m, \u001b[32m'The article \u001b[0m\n",
       "\u001b[32mprovides information about the investigation into the crime and the efforts of law enforcement to solve the case. \u001b[0m\n",
       "\u001b[32mThe article also mentions the reward being offered for information leading to an arrest and the efforts of \u001b[0m\n",
       "\u001b[32mcommunity advocates to raise awareness about the case.'\u001b[0m, \u001b[32m'The article does not contain any language or content that\u001b[0m\n",
       "\u001b[32mis derogatory or discriminatory towards transgender individuals. The tone is respectful and sensitive to the victim\u001b[0m\n",
       "\u001b[32mand her community.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'jvJLvWhMxQTSFGNZYKMpbo'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'sonnet'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_cte'\u001b[0m, \u001b[32m'template'\u001b[0m: \n",
       "\u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"This is a news article reporting on the murder of Tai'Vion Lathan, a \u001b[0m\n",
       "\u001b[32m24-year-old Black transgender woman in Baltimore. The article provides details about her life, personality, and \u001b[0m\n",
       "\u001b[32mrelationships, while also contextualizing her death within the broader pattern of violence against transgender \u001b[0m\n",
       "\u001b[32mpeople, particularly trans women of color.\"\u001b[0m, \u001b[32m\"The article exemplifies best practices in reporting on transgender \u001b[0m\n",
       "\u001b[32mindividuals by consistently using Lathan's correct name and pronouns \u001b[0m\u001b[32m(\u001b[0m\u001b[32mshe/her\u001b[0m\u001b[32m)\u001b[0m\u001b[32m throughout. Family members and other\u001b[0m\n",
       "\u001b[32msources are quoted using appropriate pronouns and her chosen name, showing respect for her identity.\"\u001b[0m, \u001b[32m\"The article\u001b[0m\n",
       "\u001b[32mappropriately addresses the pertinence of Lathan's transgender status by connecting it to broader patterns of \u001b[0m\n",
       "\u001b[32mviolence against transgender people, particularly women of color. It includes relevant statistics and context about\u001b[0m\n",
       "\u001b[32manti-trans violence and legislation, making her identity relevant to understanding the broader social context of \u001b[0m\n",
       "\u001b[32mher death.\"\u001b[0m, \u001b[32m\"The coverage humanizes Lathan by focusing on her personal qualities, aspirations, and relationships, \u001b[0m\n",
       "\u001b[32mrather than sensationalizing her identity or death. Her great aunt's quote specifically addresses the importance of\u001b[0m\n",
       "\u001b[32mseeing beyond the 'transgender' label to recognize Lathan's full humanity.\"\u001b[0m, \u001b[32m'The reporting follows journalistic \u001b[0m\n",
       "\u001b[32mbest practices by including broader context about violence against transgender people, relevant statistics, and \u001b[0m\n",
       "\u001b[32mexpert perspectives while maintaining focus on Lathan as an individual. It appropriately balances personal details \u001b[0m\n",
       "\u001b[32mwith broader social implications.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'L69vaSDRcwJvTPrQfAXuMM'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'gemini15pro'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \n",
       "\u001b[32m'trans_factored'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The article reports on the murder of TaiVion\u001b[0m\n",
       "\u001b[32mLathan, a Black transgender woman, in Baltimore. It highlights the increasing violence against transgender \u001b[0m\n",
       "\u001b[32mindividuals, especially Black transgender women, in the US, connecting it to the rise of anti-trans legislation and\u001b[0m\n",
       "\u001b[32mrhetoric. The article emphasizes the need to remember Lathan's humanity and not reduce her identity to her being \u001b[0m\n",
       "\u001b[32mtransgender.\"\u001b[0m, \u001b[32m'The article explicitly states Lathan\\'s transgender identity, which is essential to understanding \u001b[0m\n",
       "\u001b[32mthe context of the violence she faced and the broader issue of violence against transgender people, particularly \u001b[0m\n",
       "\u001b[32mBlack transgender women. This does not violate the \"UNNECESSARY IDENTIFICATION\" rule, as her identity is central to\u001b[0m\n",
       "\u001b[32mthe story and sheds light on a systemic issue.'\u001b[0m, \u001b[32m'The article consistently uses Lathan\\'s chosen name and pronouns.\u001b[0m\n",
       "\u001b[32mIt also respects her identity by quoting her great aunt\\'s plea to remember her as a person beyond her transgender \u001b[0m\n",
       "\u001b[32midentity. Thus, the \"USES INCORRECT NAME OR PRONOUNS\" rule is not violated.'\u001b[0m, \u001b[32m'The article uses accurate and \u001b[0m\n",
       "\u001b[32mrespectful language, referring to Lathan as a \"transgender woman\" and using her chosen name and pronouns. It \u001b[0m\n",
       "\u001b[32mdoesn\\'t use outdated or offensive terms, nor does it compare her to \"real\" or \"biological\" women. Therefore, \u001b[0m\n",
       "\u001b[32mthere\\'s no violation of the \"USES INACCURATE PHRASES / DESCRIPTORS\" rule.'\u001b[0m, \u001b[32m'The article avoids politicized \u001b[0m\n",
       "\u001b[32mphrases like \"gender ideology\" or \"trans agenda.\" Instead, it focuses on the violence and discrimination faced by \u001b[0m\n",
       "\u001b[32mtransgender individuals, citing statistics and quoting advocates. Hence, it doesn\\'t violate the \"USES POLITICISED \u001b[0m\n",
       "\u001b[32mPHRASES\" rule.'\u001b[0m, \u001b[32m'The article does not perpetuate harmful narratives about transgender people. It highlights the \u001b[0m\n",
       "\u001b[32msystemic violence against them and avoids associating transgender identity with negative connotations like \u001b[0m\n",
       "\u001b[32m\"grooming\" or suggesting it\\'s a trend or a response to trauma. Thus, no violation of \"USES HARMFUL NARRATIVES\" is \u001b[0m\n",
       "\u001b[32mobserved.'\u001b[0m, \u001b[32m'The article does not make assumptions about anyone\\'s gender identity but reports the facts of \u001b[0m\n",
       "\u001b[32mLathan\\'s case accurately. Therefore, the \"ASSUMES GENDER IDENTITY\" rule is not violated.'\u001b[0m, \u001b[32m'The article doesn\\'t \u001b[0m\n",
       "\u001b[32mfocus on Lathan\\'s medical history or transition details. It focuses on her life, personality, and the tragedy of \u001b[0m\n",
       "\u001b[32mher death. Hence, it doesn\\'t violate the \"INAPPROPRIATE MEDICALISATION\" rule.'\u001b[0m, \u001b[32m'The article effectively frames \u001b[0m\n",
       "\u001b[32mthe violence against Lathan within the context of systemic violence and discrimination against transgender people, \u001b[0m\n",
       "\u001b[32mespecially Black transgender women. It highlights the increased vulnerability of this community to hate crimes, \u001b[0m\n",
       "\u001b[32mpoverty, and homelessness, advocating for a systemic understanding of the issue. Thus, it doesn\\'t violate the \"NOT\u001b[0m\n",
       "\u001b[32mFRAMED AS SYSTEMIC\" rule.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'LhMEwM6XQRP56YEtwrDbZL'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'gpt4o'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_factored'\u001b[0m, \n",
       "\u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'The content centers around the murder of TaiVion Lathan, a \u001b[0m\n",
       "\u001b[32mtransgender woman, in Baltimore and addresses larger issues of violence against transgender individuals, \u001b[0m\n",
       "\u001b[32mparticularly women of color.'\u001b[0m, \u001b[32m'The content does mention Lathans transgender status; however, it is relevant to \u001b[0m\n",
       "\u001b[32mthe story, as the article discusses the broader context of violence against transgender individuals, making this \u001b[0m\n",
       "\u001b[32midentification essential and not unnecessary.'\u001b[0m, \u001b[32m\"The article uses TaiVion Lathan's chosen name and pronouns \u001b[0m\n",
       "\u001b[32mconsistently and correctly, demonstrating respect for her identity by not using any incorrect name or pronouns.\"\u001b[0m, \n",
       "\u001b[32m\"The language employed in the content is accurate and respectful, avoiding outdated or inaccurate descriptors. It \u001b[0m\n",
       "\u001b[32muses terms like 'transgender' appropriately without employing potentially misleading phrases like 'identifies \u001b[0m\n",
       "\u001b[32mas.'\"\u001b[0m, \u001b[32m'The article refrains from using politically charged or harmful language when discussing transgender issues,\u001b[0m\n",
       "\u001b[32mfocusing instead on the violence faced by transgender individuals and the political factors that may contribute to \u001b[0m\n",
       "\u001b[32mthese challenges.'\u001b[0m, \u001b[32m'Harmful narratives are largely avoided in the coverage, as the article emphasizes systemic \u001b[0m\n",
       "\u001b[32missues affecting the transgender community rather than scapegoating or stereotyping. It references structural \u001b[0m\n",
       "\u001b[32mdiscrimination and the increased vulnerability of transgender individuals due to societal factors.'\u001b[0m, \u001b[32m'The content \u001b[0m\n",
       "\u001b[32mdoes not make assumptions about gender identity beyond what is clearly specified, focusing instead on reported \u001b[0m\n",
       "\u001b[32mfacts and commentary from relevant parties, thus avoiding stigmatizing language.'\u001b[0m, \u001b[32m\"Inappropriate medicalization is\u001b[0m\n",
       "\u001b[32mavoided as the focus is on Lathan's life, the circumstances of her death, and the systemic issues facing \u001b[0m\n",
       "\u001b[32mtransgender individuals, rather than unnecessarily emphasizing medical aspects of her gender identity.\"\u001b[0m, \u001b[32m'The \u001b[0m\n",
       "\u001b[32marticle frames the violence against Lathan within systemic issues, referencing statistics on violence against the \u001b[0m\n",
       "\u001b[32mtransgender community and advocacy calls for justice and law enforcement prioritization, suggesting a broader \u001b[0m\n",
       "\u001b[32mpattern of discrimination and violence.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'N4HjvnrKBPYiz2smuo9sVe'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'haiku'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \n",
       "\u001b[32m'trans_factored'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The content provided appears to be a news \u001b[0m\n",
       "\u001b[32marticle reporting on the tragic murder of a 24-year-old transgender woman named Tai'Vion Lathan in Baltimore, \u001b[0m\n",
       "\u001b[32mMaryland. The article provides details about Lathan's life, the circumstances of her death, and the broader context\u001b[0m\n",
       "\u001b[32mof violence faced by the transgender community, especially transgender women of color. The article aims to honor \u001b[0m\n",
       "\u001b[32mLathan's memory and advocate for justice and transparency in the investigation of her killing.\"\u001b[0m, \u001b[32m\"The article \u001b[0m\n",
       "\u001b[32madheres to the policy criteria by using Lathan's correct name and pronouns, and avoiding unnecessary identification\u001b[0m\n",
       "\u001b[32mof her transgender identity. It describes her as a 'person' and 'beautiful person' rather than solely defining her \u001b[0m\n",
       "\u001b[32mby her gender identity. The article also acknowledges the systemic violence and discrimination faced by the \u001b[0m\n",
       "\u001b[32mtransgender community, particularly the disproportionately high rates of violence against transgender women of \u001b[0m\n",
       "\u001b[32mcolor.\"\u001b[0m, \u001b[32m\"The article avoids using politicized or inaccurate phrases, such as 'gender ideology' or \u001b[0m\n",
       "\u001b[32m'detransitioner', and does not suggest Lathan's identity is a mental disorder or a response to trauma. Instead, it \u001b[0m\n",
       "\u001b[32mframes her death as part of the broader epidemic of violence against transgender individuals.\"\u001b[0m, \u001b[32m\"The article does \u001b[0m\n",
       "\u001b[32mnot make assumptions about Lathan's gender identity, and appropriately refers to her as a transgender woman. It \u001b[0m\n",
       "\u001b[32malso refrains from unnecessarily focusing on or sensationalizing medical aspects of her identity or transition.\"\u001b[0m, \n",
       "\u001b[32m\"Overall, the article appears to be a respectful and responsible reporting of Lathan's tragic death, highlighting \u001b[0m\n",
       "\u001b[32mthe broader systemic issues facing the transgender community while centering her humanity and the loss felt by her \u001b[0m\n",
       "\u001b[32mloved ones.\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'SP5WURPDRPNemWMuCW565u'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'llama31_70b'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_factored'\u001b[0m, \u001b[32m'template'\u001b[0m: \n",
       "\u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The content is a news article reporting on the murder of a 24-year-old \u001b[0m\n",
       "\u001b[32mtransgender woman, Tai'Vion Lathan, in Baltimore. The article provides context about Lathan's life, her family, and\u001b[0m\n",
       "\u001b[32mthe circumstances of her death. The tone of the article is informative and somber, with a focus on highlighting the\u001b[0m\n",
       "\u001b[32mviolence and discrimination faced by the transgender community.\"\u001b[0m, \u001b[32m'The article uses respectful language when \u001b[0m\n",
       "\u001b[32mreferring to Lathan, using her chosen name and pronouns. It also avoids sensationalizing or exploiting her death, \u001b[0m\n",
       "\u001b[32minstead focusing on the impact of her loss on her family and community.'\u001b[0m, \u001b[32m'The article provides statistics and \u001b[0m\n",
       "\u001b[32mcontext about the violence faced by transgender people, particularly transgender women of color. It highlights the \u001b[0m\n",
       "\u001b[32mimportance of addressing this issue and holding perpetrators accountable.'\u001b[0m, \u001b[32m\"The article includes quotes from \u001b[0m\n",
       "\u001b[32mLathan's family and community members, which adds a personal touch and emphasizes the human impact of her death. It\u001b[0m\n",
       "\u001b[32malso includes a quote from a transgender advocate, which provides additional context and perspective on the \u001b[0m\n",
       "\u001b[32missue.\"\u001b[0m, \u001b[32m\"The article does not use politicized or inflammatory language, and instead focuses on presenting a \u001b[0m\n",
       "\u001b[32mfactual and respectful account of Lathan's death and its impact on the community.\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \n",
       "\u001b[32m'6YK46HTtJmNPc4br8gWpYi'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'sonnet'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_factored'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \n",
       "\u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"This is a news article reporting the murder of Tai'Vion Lathan, a 24-year-old Black transgender woman \u001b[0m\n",
       "\u001b[32min Baltimore. The article focuses on her life, family's grief, and places her death in the broader context of \u001b[0m\n",
       "\u001b[32mviolence against transgender people, particularly trans women of color.\"\u001b[0m, \u001b[32m\"The article appropriately identifies \u001b[0m\n",
       "\u001b[32mLathan's transgender identity as it's relevant to both the pattern of violence against trans women and the systemic\u001b[0m\n",
       "\u001b[32missues facing the community. The disclosure appears consensual given family members' direct quotes and advocacy.\"\u001b[0m, \n",
       "\u001b[32m\"The article consistently uses correct pronouns \u001b[0m\u001b[32m(\u001b[0m\u001b[32mshe/her\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and her chosen name throughout. Family members' quotes \u001b[0m\n",
       "\u001b[32mdemonstrate respect for her identity while emphasizing her humanity beyond her transgender identity.\"\u001b[0m, \u001b[32m'The \u001b[0m\n",
       "\u001b[32mlanguage used is accurate and respectful, avoiding problematic terms or phrases. The article appropriately \u001b[0m\n",
       "\u001b[32mdiscusses transgender identity and violence without sensationalizing or using politicized language.'\u001b[0m, \u001b[32m'The article \u001b[0m\n",
       "\u001b[32meffectively frames the issue systemically, providing statistics on anti-trans violence, discussing broader \u001b[0m\n",
       "\u001b[32mpolitical context, and including perspectives from advocacy organizations. It highlights the disproportionate \u001b[0m\n",
       "\u001b[32mimpact on Black trans women and trans women of color.'\u001b[0m, \u001b[32m'The article appropriately avoids unnecessary medical \u001b[0m\n",
       "\u001b[32mdetails or assumptions about gender identity, focusing instead on Lathan as a person and the broader social context\u001b[0m\n",
       "\u001b[32mof anti-trans violence.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'j4wyNL3Hx5Hp2cUhmRjFcS'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'gemini15pro'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_glaad'\u001b[0m, \n",
       "\u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The article discusses the tragic murder of Tai'Vion Lathan, a \u001b[0m\n",
       "\u001b[32m24-year-old Black transgender woman in Baltimore. It highlights the increasing violence against transgender people,\u001b[0m\n",
       "\u001b[32mparticularly Black transgender women, and connects this violence to the hostile political climate and \u001b[0m\n",
       "\u001b[32mdiscriminatory legislation targeting the transgender community.  The article uses respectful language, emphasizing \u001b[0m\n",
       "\u001b[32mLathan's humanity and individuality beyond her gender identity, while also providing context about the broader \u001b[0m\n",
       "\u001b[32missues faced by transgender individuals.  It includes quotes from Lathan's family, community advocates, and other \u001b[0m\n",
       "\u001b[32mtransgender individuals, centering their perspectives on the tragedy and its implications.\"\u001b[0m, \u001b[32m\"The article \u001b[0m\n",
       "\u001b[32mconsistently uses Tai'Vion Lathan's chosen name and correct pronouns \u001b[0m\u001b[32m(\u001b[0m\u001b[32mshe/her\u001b[0m\u001b[32m)\u001b[0m\u001b[32m throughout. It also avoids using her\u001b[0m\n",
       "\u001b[32mbirth name, respecting her identity.  This adheres to the guideline of always using a transgender person's chosen \u001b[0m\n",
       "\u001b[32mname and pronouns.\"\u001b[0m, \u001b[32m'The article avoids using any offensive or outdated terminology.  It does not use terms like \u001b[0m\n",
       "\u001b[32m\"sex change\" or \"born a man.\" Instead, it uses respectful and accurate language when referring to Lathan\\'s gender \u001b[0m\n",
       "\u001b[32midentity, such as \"transgender woman.\" This is consistent with the guidelines to use accurate terminology and \u001b[0m\n",
       "\u001b[32mrespectful language.'\u001b[0m, \u001b[32m\"The article avoids focusing solely on Lathan's transition or medical history. It highlights\u001b[0m\n",
       "\u001b[32mher personality, interests, and aspirations, demonstrating a commitment to portraying her as a whole person rather \u001b[0m\n",
       "\u001b[32mthan reducing her identity to her transgender status.  This goes beyond the transition narrative and focuses on her\u001b[0m\n",
       "\u001b[32mlife and the impact of her death on her loved ones and community.\"\u001b[0m, \u001b[32m'The article includes statistics and \u001b[0m\n",
       "\u001b[32minformation about the broader issues facing transgender people, such as violence, discrimination, and the impact of\u001b[0m\n",
       "\u001b[32manti-trans legislation. This provides important context and educates readers about the challenges faced by the \u001b[0m\n",
       "\u001b[32mtransgender community.'\u001b[0m, \u001b[32m'The article avoids sensationalizing Lathan\\'s story. It doesn\\'t include \"before and \u001b[0m\n",
       "\u001b[32mafter\" photos or other clichd imagery that could reduce her to stereotypes. It focuses instead on the human impact\u001b[0m\n",
       "\u001b[32mof her death and the need for justice. This avoids sensationalizing her story and respects her as a person.'\u001b[0m, \u001b[32m\"The \u001b[0m\n",
       "\u001b[32marticle centers the voices of transgender people, including quotes from Lathan's family, community advocates, and \u001b[0m\n",
       "\u001b[32mother transgender individuals in Baltimore.  It allows them to speak for themselves about the impact of violence \u001b[0m\n",
       "\u001b[32mand discrimination, rather than relying solely on non-transgender voices.\"\u001b[0m, \u001b[32m'The article briefly mentions \u001b[0m\n",
       "\u001b[32mstatistics about violence against transgender people, particularly Black transgender women, and the increasing \u001b[0m\n",
       "\u001b[32mnumber of anti-trans bills introduced across the country.  This information is relevant and emphasizes the larger \u001b[0m\n",
       "\u001b[32mcontext of violence and discrimination that transgender individuals face, especially considering the rise in \u001b[0m\n",
       "\u001b[32manti-trans legislation.  It relates her story to a larger context of societal discrimination.'\u001b[0m, \u001b[32m'The article \u001b[0m\n",
       "\u001b[32mfocuses on the impact of Lathan\\'s death on her loved ones and the community. It respectfully quotes her great \u001b[0m\n",
       "\u001b[32maunt, who urges people to remember Lathan\\'s humanity beyond her gender identity, and her great-aunt Mary Robinson \u001b[0m\n",
       "\u001b[32mwho stated that \"All life is valued.\" The article also includes quotes from Desiree Bandz, a transgender woman in \u001b[0m\n",
       "\u001b[32mBaltimore, who speaks about her fears and concerns for her safety in the current political climate. This centering \u001b[0m\n",
       "\u001b[32mof personal experiences and emotional impact aligns with the guidelines to present transgender people as whole \u001b[0m\n",
       "\u001b[32mindividuals with families, aspirations, and communities.'\u001b[0m, \u001b[32m\"The article fulfills all the criteria for respectful \u001b[0m\n",
       "\u001b[32mand accurate reporting on transgender people. It uses accurate terminology, avoids offensive language and \u001b[0m\n",
       "\u001b[32mstereotypes, centers transgender voices, provides relevant context about the broader issues affecting the \u001b[0m\n",
       "\u001b[32mcommunity, and respects Lathan's humanity and individuality. It also connects her story to the larger issue of \u001b[0m\n",
       "\u001b[32mviolence and discrimination against transgender people.\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'KewwasgRkGfXJD5WzKtW98'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'gpt4o'\u001b[0m, \n",
       "\u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_glaad'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The content reports on the tragic \u001b[0m\n",
       "\u001b[32mdeath of TaiVion Lathan, a transgender woman, emphasizing her personal attributes, the circumstances of her death,\u001b[0m\n",
       "\u001b[32mand the broader context of violence faced by transgender people. It is presented in a respectful manner, \u001b[0m\n",
       "\u001b[32mhighlighting the individual's humanity and the systemic issues faced by transgender people.\"\u001b[0m, \u001b[32m\"The article avoids \u001b[0m\n",
       "\u001b[32musing defamatory or offensive terms and respects TaiVion Lathan's chosen name and pronouns throughout. There are \u001b[0m\n",
       "\u001b[32mno instances of deadnaming, and the language used does not cast doubt on her gender identity.\"\u001b[0m, \u001b[32m\"The content does \u001b[0m\n",
       "\u001b[32mnot sensationalize TaiVion's identity; it integrates her story within the larger context of violence against the \u001b[0m\n",
       "\u001b[32mtransgender community, without resorting to clichs or inaccurate representations of transgender lives.\"\u001b[0m, \u001b[32m'There is\u001b[0m\n",
       "\u001b[32ma notable emphasis on violence against transgender people and the legislative climate contributing to their \u001b[0m\n",
       "\u001b[32mvulnerabilities. This aligns with the guidelines to address social issues affecting transgender communities.'\u001b[0m, \u001b[32m'No \u001b[0m\n",
       "\u001b[32munnecessary focus on medical aspects of transitioning or sensationalized visuals is present in the article. The \u001b[0m\n",
       "\u001b[32mfocus is on the broader societal issues and the impact of violence and legislation.'\u001b[0m, \u001b[32m'The content includes input \u001b[0m\n",
       "\u001b[32mfrom transgender voices and advocacy groups, providing insight into the challenges faced by the community and \u001b[0m\n",
       "\u001b[32mreinforcing the importance of justice and societal change.'\u001b[0m, \u001b[32m'The article provides a comprehensive view that \u001b[0m\n",
       "\u001b[32mextends beyond TaiVions transgender identity by explaining broader systemic issues such as violence and \u001b[0m\n",
       "\u001b[32mlegislative backlash that affect transgender communities.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'QKfj3BcdQQHNPoLoQiKqCV'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'haiku'\u001b[0m, \n",
       "\u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_glaad'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The content provided describes the \u001b[0m\n",
       "\u001b[32mtragic death of Tai'Vion Lathan, a 24-year-old transgender woman who was found fatally shot in an alley in \u001b[0m\n",
       "\u001b[32mBaltimore. The article provides details about Lathan's life, her family's mourning, and the broader context of \u001b[0m\n",
       "\u001b[32mviolence against transgender individuals, especially transgender women of color. The content does not appear to \u001b[0m\n",
       "\u001b[32mcontain any inappropriate or defamatory material, and instead aims to respectfully honor Lathan's memory and raise \u001b[0m\n",
       "\u001b[32mawareness about the ongoing challenges and risks faced by the transgender community.\"\u001b[0m, \u001b[32m\"The article uses Tai'Vion \u001b[0m\n",
       "\u001b[32mLathan's chosen name and correct pronouns \u001b[0m\u001b[32m(\u001b[0m\u001b[32mshe/her\u001b[0m\u001b[32m)\u001b[0m\u001b[32m throughout, which aligns with the policy guidelines on \u001b[0m\n",
       "\u001b[32mrespecting transgender individuals' names and pronouns. There is no indication that the article 'deadnames' Lathan \u001b[0m\n",
       "\u001b[32mor uses any other disrespectful language.\"\u001b[0m, \u001b[32m\"The article also provides relevant context about the disproportionate \u001b[0m\n",
       "\u001b[32mrates of violence and discrimination experienced by transgender people, especially transgender women of color. This\u001b[0m\n",
       "\u001b[32mhelps readers understand the broader societal issues that contribute to tragedies like Lathan's death.\"\u001b[0m, \n",
       "\u001b[32m\"Furthermore, the article includes quotes from Lathan's family members and community advocates who emphasize the \u001b[0m\n",
       "\u001b[32mneed to remember Lathan as a full, complex person and not solely define her by her gender identity. This approach \u001b[0m\n",
       "\u001b[32mis consistent with the policy guidelines on moving beyond reductive 'transition narratives' and instead integrating\u001b[0m\n",
       "\u001b[32mtransgender individuals into stories that reflect the diversity of their lives and experiences.\"\u001b[0m, \u001b[32m\"Overall, the \u001b[0m\n",
       "\u001b[32mcontent appears to be a respectful and thoughtful portrayal of Tai'Vion Lathan's life and death, while also raising\u001b[0m\n",
       "\u001b[32mawareness about the urgent need to address the violence and discrimination faced by transgender people. The article\u001b[0m\n",
       "\u001b[32maligns with the policy guidelines in its use of language, framing, and contextual information.\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \n",
       "\u001b[32m'2XByL8zYDciEaYBEQHTE8o'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'llama31_70b'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_glaad'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m,\n",
       "\u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The content is a news article about the murder of a 24-year-old transgender woman, Tai'Vion Lathan, in\u001b[0m\n",
       "\u001b[32mBaltimore. The article provides details about Lathan's life, her family's reaction to her death, and the \u001b[0m\n",
       "\u001b[32minvestigation into her murder.\"\u001b[0m, \u001b[32m'The article highlights the high rate of violence against transgender people, \u001b[0m\n",
       "\u001b[32mparticularly Black transgender women, and the lack of justice and transparency in many of these cases.'\u001b[0m, \u001b[32m'The \u001b[0m\n",
       "\u001b[32marticle also mentions the introduction of legislation seeking to restrict transgender health care and rights, which\u001b[0m\n",
       "\u001b[32mis seen as contributing to the violence and marginalization of transgender people.'\u001b[0m, \u001b[32m'The article quotes a \u001b[0m\n",
       "\u001b[32mrepresentative from the Human Rights Campaign, who emphasizes the need to end the harmful rhetoric and policies \u001b[0m\n",
       "\u001b[32mthat make it less safe for transgender people to live and thrive.'\u001b[0m, \u001b[32m\"The article also includes a personal account \u001b[0m\n",
       "\u001b[32mfrom a 30-year-old transgender woman living in Baltimore, who expresses her fear and distress about Lathan's death \u001b[0m\n",
       "\u001b[32mand the overall safety of transgender people in America.\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'WrMfq3bLUvAPMGAoWrmhDG'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'sonnet'\u001b[0m, \n",
       "\u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_glaad'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"This is a news article about the \u001b[0m\n",
       "\u001b[32mmurder of Tai'Vion Lathan, a 24-year-old transgender woman who was found fatally shot in Baltimore. The article \u001b[0m\n",
       "\u001b[32mfocuses on her life, her personality, and her family's grief while also contextualizing her death within the \u001b[0m\n",
       "\u001b[32mbroader pattern of violence against transgender people, particularly Black trans women.\"\u001b[0m, \u001b[32m\"The article follows best\u001b[0m\n",
       "\u001b[32mpractices for transgender coverage by consistently using Lathan's correct name and pronouns \u001b[0m\u001b[32m(\u001b[0m\u001b[32mshe/her\u001b[0m\u001b[32m)\u001b[0m\u001b[32m throughout. \u001b[0m\n",
       "\u001b[32mIt avoids deadnaming or inappropriate questions about medical transition, focusing instead on her life, \u001b[0m\n",
       "\u001b[32mpersonality, and relationships.\"\u001b[0m, \u001b[32m\"The article appropriately integrates expert voices from the transgender \u001b[0m\n",
       "\u001b[32mcommunity, including the Human Rights Campaign's trans justice initiative director and another trans woman from \u001b[0m\n",
       "\u001b[32mBaltimore. It provides relevant context about violence against trans people and current anti-trans legislation.\"\u001b[0m, \n",
       "\u001b[32m\"The piece effectively humanizes Lathan through family quotes and personal details while avoiding sensationalistic \u001b[0m\n",
       "\u001b[32melements. Her great aunt's quote specifically addresses the importance of seeing Lathan as a complete person beyond\u001b[0m\n",
       "\u001b[32mher transgender identity.\"\u001b[0m, \u001b[32m'The story responsibly includes current statistics and context about anti-trans \u001b[0m\n",
       "\u001b[32mviolence, particularly affecting Black trans women, while also providing practical information about the ongoing \u001b[0m\n",
       "\u001b[32minvestigation and how to submit tips.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'jJemEpkyrTXQ8MLCi9Lja4'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'gemini15pro'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \n",
       "\u001b[32m'trans_hrc'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The article discusses the murder of Tai'Vion \u001b[0m\n",
       "\u001b[32mLathan, a 24-year-old Black transgender woman, in Baltimore. It highlights the increasing violence against \u001b[0m\n",
       "\u001b[32mtransgender people, especially Black transgender women, and the context of discriminatory legislation. The article \u001b[0m\n",
       "\u001b[32maims to raise awareness about this issue and advocate for respect and safety for transgender individuals.  It is \u001b[0m\n",
       "\u001b[32mimportant to analyze the language used to determine if it adheres to guidelines for respectful reporting on \u001b[0m\n",
       "\u001b[32mtransgender people.\"\u001b[0m, \u001b[32m'The article consistently uses Tai\\'Vion Lathan\\'s chosen name and pronouns \u001b[0m\u001b[32m(\u001b[0m\u001b[32mshe/her\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mrespecting her gender identity.  It also shares her personal story, hobbies, and aspirations, which demonstrates \u001b[0m\n",
       "\u001b[32madherence to guidance about putting the person at the center of the story rather than just their identity. The \u001b[0m\n",
       "\u001b[32marticle also avoids contrasting transgender women with \"real\" or \"biological\" women.'\u001b[0m, \u001b[32m'The article accurately \u001b[0m\n",
       "\u001b[32mdescribes the meaning of \"transgender,\" aligning with established definitions such as the one provided by the HRC. \u001b[0m\n",
       "\u001b[32mIt explicitly states that Lathan \"was a person, and a beautiful person at that,\" reinforcing the idea that her \u001b[0m\n",
       "\u001b[32midentity does not make her less human.'\u001b[0m, \u001b[32m\"The article uses language that clarifies the difference between gender \u001b[0m\n",
       "\u001b[32midentity, gender expression, and sexual orientation. While the article does not explicitly discuss these terms in \u001b[0m\n",
       "\u001b[32mdetail, its overall approach reflects an understanding of these concepts by focusing on Lathan's gender identity \u001b[0m\n",
       "\u001b[32mand lived experiences as a trans woman, without delving into irrelevant aspects like sexual orientation.  This \u001b[0m\n",
       "\u001b[32madheres to the guidelines.\"\u001b[0m, \u001b[32m'The article discusses Lathan\\'s transition with respect and sensitivity.  It does not\u001b[0m\n",
       "\u001b[32mdisclose details about her medical history or transition process without consent, adhering to the guidelines around\u001b[0m\n",
       "\u001b[32mprivacy. The narrative emphasizes that \"transitioning is a very personal process, and everyone has a right to \u001b[0m\n",
       "\u001b[32mprivacy,\" in accordance with the provided criteria.'\u001b[0m, \u001b[32m'The article acknowledges that transition does not always \u001b[0m\n",
       "\u001b[32minvolve surgery.  It states that Lathan was about to start school to become a nurse, showcasing aspects of her life\u001b[0m\n",
       "\u001b[32mbeyond her transition.'\u001b[0m, \u001b[32m'The article avoids disrespectful language by never contrasting transgender people with \u001b[0m\n",
       "\u001b[32m\"real\" or \"biological\" men and women.  This aligns with the provided guidelines and fosters an inclusive \u001b[0m\n",
       "\u001b[32mnarrative.'\u001b[0m, \u001b[32m\"The article avoids focusing solely on Lathan's transition. It depicts her as a multifaceted \u001b[0m\n",
       "\u001b[32mindividual with passions, relationships, and dreams.  It shares details about her hobbies, love for family and \u001b[0m\n",
       "\u001b[32mgoals. This holistic approach is consistent with the HRC's guidelines.\"\u001b[0m, \u001b[32m'The article discusses the broader context\u001b[0m\n",
       "\u001b[32mof violence against transgender people, the disproportionate impact on Black transgender women, and the connection \u001b[0m\n",
       "\u001b[32mto discriminatory legislation.  This information creates a comprehensive understanding of the issue, rather than \u001b[0m\n",
       "\u001b[32mjust presenting the murder in isolation.'\u001b[0m, \u001b[32m'In conclusion, the article adheres to the provided guidelines for \u001b[0m\n",
       "\u001b[32mreporting on transgender people. It uses respectful language, avoids harmful stereotypes, and focuses on the \u001b[0m\n",
       "\u001b[32mindividual while providing appropriate context.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'9ybBuHRNJGhGSMYWSBgddV'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'gpt4o'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \n",
       "\u001b[32m'trans_hrc'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'The content is a news article reporting on the \u001b[0m\n",
       "\u001b[32mmurder of TaiVion Lathan, a Black transgender woman, in Baltimore. It provides details about her as a person, the \u001b[0m\n",
       "\u001b[32mcircumstances of her death, and the broader societal issues affecting the transgender community, particularly \u001b[0m\n",
       "\u001b[32manti-trans violence and discrimination.'\u001b[0m, \u001b[32m\"The article properly understands and uses the term 'transgender.' It \u001b[0m\n",
       "\u001b[32mrefers to TaiVion Lathan with appropriate gendered terms like 'transgender woman' and uses her preferred name and \u001b[0m\n",
       "\u001b[32mpronouns throughout the piece. It does not misuse terms or suggest 'transgendered,' adhering to preferred language \u001b[0m\n",
       "\u001b[32mguidelines.\"\u001b[0m, \u001b[32m\"The content makes a clear distinction between gender identity and sexual orientation. It discusses \u001b[0m\n",
       "\u001b[32mLathan's gender identity as a transgender woman, focusing on societal challenges faced by transgender individuals, \u001b[0m\n",
       "\u001b[32mwithout making assumptions about her sexual orientation, showing understanding of the difference.\"\u001b[0m, \u001b[32m'The article \u001b[0m\n",
       "\u001b[32mdoes not delve deeply into Lathans transition process; however, the focus on her identity and the violence against\u001b[0m\n",
       "\u001b[32mtrans individuals respects the personal nature of transitioning. There are no inappropriate comments regarding \u001b[0m\n",
       "\u001b[32mmedical or social transition processes, respecting the privacy of the individual.'\u001b[0m, \u001b[32m\"Names and pronouns are used \u001b[0m\n",
       "\u001b[32mrespectfully throughout the article, aligning with number five of the guidelines. Lathan is referred to by her \u001b[0m\n",
       "\u001b[32mchosen name, 'Tai, and female pronouns, without any instances of deadnaming or misgendering.\"\u001b[0m, \u001b[32m'The content \u001b[0m\n",
       "\u001b[32mdiscusses broader societal issues faced by transgender individuals in the United States, such as violence, \u001b[0m\n",
       "\u001b[32mlegislation, and discrimination. It contextualizes Lathans murder within these larger realities, reflecting on \u001b[0m\n",
       "\u001b[32msystemic issues without victim-blaming or misrepresenting her life.'\u001b[0m, \u001b[32m\"There is no language in the article \u001b[0m\n",
       "\u001b[32mcontrasting Lathans identity with 'real' or 'biological' women, avoiding harmful false comparisons. The narrative \u001b[0m\n",
       "\u001b[32mrespects her identity as a transgender woman without undermining her authenticity.\"\u001b[0m, \u001b[32m'The article focuses on Lathan\u001b[0m\n",
       "\u001b[32mas a person, detailing her relationships, interests, and aspirations. It highlights her familys grief and the \u001b[0m\n",
       "\u001b[32mcommunitys response, presenting her as a multifaceted individual rather than just focusing on her transgender \u001b[0m\n",
       "\u001b[32midentity.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'Wwp4eDzZnGtayfAP6fXBnm'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'haiku'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_hrc'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \n",
       "\u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The content provided appears to be a news article reporting on the tragic murder of \u001b[0m\n",
       "\u001b[32ma 24-year-old transgender woman named Tai'Vion Lathan in Baltimore, Maryland. The article provides details about \u001b[0m\n",
       "\u001b[32mLathan's life and personality, the circumstances of her death, the broader context of violence against transgender \u001b[0m\n",
       "\u001b[32mindividuals in the United States, and the reactions and efforts of her family, community, and local authorities. \u001b[0m\n",
       "\u001b[32mThe tone is somber and respectful, focusing on honoring Lathan's memory and advocating for justice and safety for \u001b[0m\n",
       "\u001b[32mthe transgender community.\"\u001b[0m, \u001b[32m\"The article appears to adhere to the guidelines outlined in the provided criteria. It\u001b[0m\n",
       "\u001b[32muses the appropriate terminology to refer to Lathan, including her name, pronouns, and gender identity. It provides\u001b[0m\n",
       "\u001b[32mcontext about the reality of many transgender people's lived experiences, including the disproportionate violence \u001b[0m\n",
       "\u001b[32mand discrimination they face. The article avoids framing Lathan's identity in a way that would be considered \u001b[0m\n",
       "\u001b[32mdisrespectful or dehumanizing.\"\u001b[0m, \u001b[32m\"The article also highlights the broader social and political factors that \u001b[0m\n",
       "\u001b[32mcontribute to the vulnerability of transgender individuals, such as the introduction of anti-transgender \u001b[0m\n",
       "\u001b[32mlegislation at the federal and state levels. It includes quotes from Lathan's loved ones and community advocates \u001b[0m\n",
       "\u001b[32mthat emphasize the need for justice, transparency, and efforts to end the harmful rhetoric and policies that put \u001b[0m\n",
       "\u001b[32mtransgender lives at risk.\"\u001b[0m, \u001b[32m\"Overall, the article appears to be a thoughtful and sensitive portrayal of Lathan's \u001b[0m\n",
       "\u001b[32mlife and death, as well as the ongoing challenges and dangers faced by the transgender community. The content \u001b[0m\n",
       "\u001b[32maligns with the guidelines set forth in the criteria, respecting Lathan's identity and centering her humanity, \u001b[0m\n",
       "\u001b[32mwhile also providing important context and calls to action.\"\u001b[0m, \u001b[32m\"Based on the analysis above, I conclude that the \u001b[0m\n",
       "\u001b[32mcontent does not violate the policy or guidelines provided, and instead represents a conscientious and responsible \u001b[0m\n",
       "\u001b[32mapproach to reporting on the tragic loss of a transgender individual's life.\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'fQxDKGmT4BPTzLf6w333mR'\u001b[0m, \n",
       "\u001b[32m'model'\u001b[0m: \u001b[32m'llama31_70b'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_hrc'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The content \u001b[0m\n",
       "\u001b[32mappears to be a news article reporting on the murder of a 24-year-old transgender woman named Tai'Vion Lathan in \u001b[0m\n",
       "\u001b[32mBaltimore. The article provides context about Lathan's life, her family's reaction to her death, and the \u001b[0m\n",
       "\u001b[32minvestigation into her murder. It also highlights the wider issue of violence against transgender people, \u001b[0m\n",
       "\u001b[32mparticularly transgender women of color, and the impact of anti-trans legislation on the community.\"\u001b[0m, \u001b[32m\"The article \u001b[0m\n",
       "\u001b[32muses respectful language when referring to Lathan, using her preferred name and pronouns. It also avoids \u001b[0m\n",
       "\u001b[32msensationalism and instead focuses on telling Lathan's story and highlighting the human impact of her death.\"\u001b[0m, \u001b[32m'The\u001b[0m\n",
       "\u001b[32marticle provides context about the broader issue of violence against transgender people, citing statistics and \u001b[0m\n",
       "\u001b[32mexpert opinions. It also highlights the impact of anti-trans legislation on the community and the need for greater \u001b[0m\n",
       "\u001b[32mawareness and understanding.'\u001b[0m, \u001b[32m\"The article quotes Lathan's family members and friends, as well as advocates for \u001b[0m\n",
       "\u001b[32mthe transgender community, to provide a more personal and nuanced perspective on the issue. It also includes \u001b[0m\n",
       "\u001b[32minformation about resources and support for the community, such as a GoFundMe campaign to support Lathan's family \u001b[0m\n",
       "\u001b[32mand a hotline for LGBTQ+ people in Baltimore.\"\u001b[0m, \u001b[32m'Overall, the article appears to be a thoughtful and respectful \u001b[0m\n",
       "\u001b[32mreport on a tragic event, and it provides a clear and concise explanation of the issue and its impact on the \u001b[0m\n",
       "\u001b[32mcommunity.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'8DhFjJbedSPYrxiUcKi7VD'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'sonnet'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_hrc'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \n",
       "\u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"This is a news article about the murder of Tai'Vion Lathan, a 24-year-old Black \u001b[0m\n",
       "\u001b[32mtransgender woman in Baltimore. The article primarily focuses on her life, personality, and the impact of her death\u001b[0m\n",
       "\u001b[32mon her family and community, while also providing context about broader violence against transgender people and \u001b[0m\n",
       "\u001b[32mcurrent political climate affecting trans rights.\"\u001b[0m, \u001b[32m\"The article exemplifies respectful coverage by centering \u001b[0m\n",
       "\u001b[32mLathan's humanity and relationships, using her correct name and pronouns throughout, and including meaningful \u001b[0m\n",
       "\u001b[32mquotes from family members that emphasize her personhood beyond her transgender identity. This aligns with criteria\u001b[0m\n",
       "\u001b[32m#5 and #8.\"\u001b[0m, \u001b[32m\"The reporting appropriately provides context about violence against transgender people, particularly \u001b[0m\n",
       "\u001b[32mtrans women of color, and connects to broader societal issues \u001b[0m\u001b[32m(\u001b[0m\u001b[32mcriteria #6\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. It avoids harmful tropes like \u001b[0m\n",
       "\u001b[32msuggesting criminal involvement or deception, and doesn't include deadnaming or misgendering.\"\u001b[0m, \u001b[32m'The article \u001b[0m\n",
       "\u001b[32meffectively balances personal details about Lathan with broader statistical and social context about anti-trans \u001b[0m\n",
       "\u001b[32mviolence and discrimination, following best practices for comprehensive reporting on transgender issues. It \u001b[0m\n",
       "\u001b[32mincludes perspectives from family, advocacy organizations, and other trans community members.'\u001b[0m, \u001b[32m'The coverage \u001b[0m\n",
       "\u001b[32mdemonstrates sensitivity to privacy concerns while still providing newsworthy information about an active criminal \u001b[0m\n",
       "\u001b[32minvestigation. The reporting adheres to all major guidelines about respectful coverage of transgender people and \u001b[0m\n",
       "\u001b[32mviolence against the trans community.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'TsjctZgWjrbRfxVfWtu8pV'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'gemini15pro'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \n",
       "\u001b[32m'trans_simplified'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The article discusses the murder of \u001b[0m\n",
       "\u001b[32mTaiVion Lathan, a Black transgender woman, in Baltimore. It highlights the increasing violence against transgender\u001b[0m\n",
       "\u001b[32mpeople, especially Black transgender women, and connects this violence to the rise of anti-trans legislation. The \u001b[0m\n",
       "\u001b[32marticle aims to raise awareness about the issue and humanize Lathan by sharing details about her life and family's \u001b[0m\n",
       "\u001b[32mgrief.\"\u001b[0m, \u001b[32m\"The article consistently uses Lathan's chosen name, TaiVion, and her correct pronouns \u001b[0m\u001b[32m(\u001b[0m\u001b[32mshe/her\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. It does\u001b[0m\n",
       "\u001b[32mnot identify her as transgender unless it provides necessary context, such as when discussing the broader issue of \u001b[0m\n",
       "\u001b[32mviolence against transgender people.\"\u001b[0m, \u001b[32m'The article explicitly avoids outing Lathan by not revealing any private \u001b[0m\n",
       "\u001b[32minformation that she had not already made public.'\u001b[0m, \u001b[32m'The article does not use any offensive terms to refer to \u001b[0m\n",
       "\u001b[32mLathan or other transgender people. Instead, it uses respectful and accurate language.'\u001b[0m, \u001b[32m'The article avoids \u001b[0m\n",
       "\u001b[32mlanguage that perpetuates negative stereotypes or casts doubt on a person\\'s gender identity. For example, it \u001b[0m\n",
       "\u001b[32mavoids using phrases like \"identifies as\" or putting quotation marks around Lathan\\'s name or pronouns.'\u001b[0m, \u001b[32m'The \u001b[0m\n",
       "\u001b[32marticle does not use any lesser-known terminology related to body parts or biological functions.'\u001b[0m, \u001b[32m'The article \u001b[0m\n",
       "\u001b[32mdoes not publish false narratives about transgender people. Instead, it highlights the violence they face due to \u001b[0m\n",
       "\u001b[32mharmful rhetoric and legislation, citing data from reputable sources like the Human Rights Campaign and Trans \u001b[0m\n",
       "\u001b[32mLegislation Tracker.'\u001b[0m, \u001b[32m\"The article avoids cliches and focuses on Lathan's life and personality rather than her \u001b[0m\n",
       "\u001b[32mmedical transition. It highlights her hobbies, family relationships, and aspirations of becoming a nurse.\"\u001b[0m, \u001b[32m'The \u001b[0m\n",
       "\u001b[32marticle acknowledges the systemic prejudice and discrimination faced by transgender people and how this can \u001b[0m\n",
       "\u001b[32mcontribute to their vulnerability to violence and poverty. It mentions that 54% of transgender people have \u001b[0m\n",
       "\u001b[32mexperienced some form of intimate partner violence.'\u001b[0m, \u001b[32m'Overall, the article adheres to all the provided guidelines \u001b[0m\n",
       "\u001b[32mfor reporting on transgender individuals. It uses respectful language, provides relevant context, and avoids \u001b[0m\n",
       "\u001b[32mharmful stereotypes and false narratives.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'7iAU2nihU5BEwghbxo3DPH'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'gpt4o'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \n",
       "\u001b[32m'trans_simplified'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'The content centers around the murder of \u001b[0m\n",
       "\u001b[32mTaiVion Lathan, a transgender woman, and its impact on her family, the community, and broader society. It \u001b[0m\n",
       "\u001b[32mdiscusses systemic issues related to violence against transgender people and legislative challenges faced by the \u001b[0m\n",
       "\u001b[32mtransgender community.'\u001b[0m, \u001b[32m'The piece respects the guidelines by consistently using TaiVion Lathans chosen name and\u001b[0m\n",
       "\u001b[32mappropriate pronouns throughout the article, ensuring the transgender identity of the individual is acknowledged \u001b[0m\n",
       "\u001b[32mrespectfully.'\u001b[0m, \u001b[32m\"The article identifies Lathan as transgender as a necessary and relevant context for understanding\u001b[0m\n",
       "\u001b[32mthe broader issue of violence against transgender individuals. It does not appear to 'out' Lathan unnecessarily; \u001b[0m\n",
       "\u001b[32minstead, the article includes her identity to highlight systemic violence faced by trans individuals, which aligns \u001b[0m\n",
       "\u001b[32mwith the guideline.\"\u001b[0m, \u001b[32m'There is no use of offensive terms, nor language that perpetuates negative or incorrect \u001b[0m\n",
       "\u001b[32mperceptions of gender identities. The content remains respectful and avoids diminishing a persons gender identity,\u001b[0m\n",
       "\u001b[32mthereby adhering to the policy.'\u001b[0m, \u001b[32m\"The narrative avoids focusing predominantly on medical transition and instead \u001b[0m\n",
       "\u001b[32mcenters on the individual's personal life, relationships, and the tragic event of her murder. The story provides a \u001b[0m\n",
       "\u001b[32mcomprehensive social context, mentioning the specific risks faced by transgender individuals without \u001b[0m\n",
       "\u001b[32msensationalizing their medical or personal histories.\"\u001b[0m, \u001b[32m'The article includes an analysis of systemic patterns of \u001b[0m\n",
       "\u001b[32mprejudice and discrimination, such as the higher risk of violence faced by transgender people, especially trans \u001b[0m\n",
       "\u001b[32mwomen of color, and mentions these in relation to broader legislative challenges and social rhetoric.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \n",
       "\u001b[32m'Twc5veUrBja2D49CqzL9Vh'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'haiku'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_simplified'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \n",
       "\u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The provided content appears to be a news article reporting on the tragic death of a 24-year-old \u001b[0m\n",
       "\u001b[32mtransgender woman named Tai'Vion Lathan, who was fatally shot in Baltimore. The article provides details about \u001b[0m\n",
       "\u001b[32mLathan's life, her family's mourning, the broader context of violence against transgender individuals, and the \u001b[0m\n",
       "\u001b[32mongoing investigation into her death. It highlights the disproportionate impact of anti-transgender violence, \u001b[0m\n",
       "\u001b[32mparticularly on transgender people of color, and the need for greater justice and accountability. The article \u001b[0m\n",
       "\u001b[32mstrikes a respectful and empathetic tone in discussing Lathan's life and the challenges faced by the transgender \u001b[0m\n",
       "\u001b[32mcommunity.\"\u001b[0m, \u001b[32m\"The article adheres to the guidelines by consistently using Tai'Vion Lathan's chosen name and correct\u001b[0m\n",
       "\u001b[32mpronouns \u001b[0m\u001b[32m(\u001b[0m\u001b[32mshe/her\u001b[0m\u001b[32m)\u001b[0m\u001b[32m throughout. It avoids offensive terminology, does not out Lathan as transgender unless relevant \u001b[0m\n",
       "\u001b[32mfor context, and does not make comparisons or use language that casts doubt on her gender identity. The article \u001b[0m\n",
       "\u001b[32mprovides the necessary context about Lathan's life and the broader issues of violence against transgender \u001b[0m\n",
       "\u001b[32mindividuals.\"\u001b[0m, \u001b[32m\"The article also highlights the need for greater transparency and accountability in investigating \u001b[0m\n",
       "\u001b[32mcrimes against transgender individuals, noting that many such cases often go unsolved. It amplifies the voices of \u001b[0m\n",
       "\u001b[32mLathan's family and other transgender community members, emphasizing the devastating impact of this loss and the \u001b[0m\n",
       "\u001b[32mongoing fears and vulnerability experienced by the transgender population.\"\u001b[0m, \u001b[32m\"Overall, the article appears to be a \u001b[0m\n",
       "\u001b[32mthoughtful and respectful reporting of Tai'Vion Lathan's tragic death, while also drawing attention to the systemic\u001b[0m\n",
       "\u001b[32missues of prejudice, discrimination, and violence that transgender individuals, especially transgender people of \u001b[0m\n",
       "\u001b[32mcolor, face. The content adheres to the provided guidelines and presents the information in a way that is sensitive\u001b[0m\n",
       "\u001b[32mand centers the humanity of the victim.\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'6Uqw3cWBLEGTz2cvj9iE5V'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'llama31_70b'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \n",
       "\u001b[32m'trans_simplified'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The content provided is a news article \u001b[0m\n",
       "\u001b[32mreporting on the murder of a 24-year-old transgender woman, Tai'Vion Lathan, in Baltimore. The article includes \u001b[0m\n",
       "\u001b[32mquotes from Lathan's family members and transgender advocates, highlighting the tragedy and violence faced by the \u001b[0m\n",
       "\u001b[32mtransgender community.\"\u001b[0m, \u001b[32m\"The article uses Lathan's chosen name and pronouns, as preferred by her family, which is \u001b[0m\n",
       "\u001b[32min line with the policy guidelines.\"\u001b[0m, \u001b[32m'The article does not identify Lathan as transgender unless it provides \u001b[0m\n",
       "\u001b[32mnecessary and relevant clarity or context, which is in line with the policy guidelines.'\u001b[0m, \u001b[32m'The article does not use\u001b[0m\n",
       "\u001b[32moffensive terms to refer to trans people and avoids language that perpetuates negative or incorrect perceptions of \u001b[0m\n",
       "\u001b[32mgender identities.'\u001b[0m, \u001b[32m'The article includes an explanation of the risks and vulnerabilities faced by transgender \u001b[0m\n",
       "\u001b[32mpeople, including bias, unemployment, and homelessness, which is relevant to the story and helps to provide \u001b[0m\n",
       "\u001b[32mcontext.'\u001b[0m, \u001b[32m'The article quotes transgender advocates, including Tori Cooper, who highlights the impact of \u001b[0m\n",
       "\u001b[32manti-trans violence on the mental health and well-being of transgender people.'\u001b[0m, \u001b[32m'The article also includes a \u001b[0m\n",
       "\u001b[32mstatement from Baltimore Mayor Brandon Scott, who commits to tracking down the perpetrators and doing due diligence\u001b[0m\n",
       "\u001b[32min the case, which suggests a commitment to justice and transparency.'\u001b[0m, \u001b[32m'The overall tone of the article is \u001b[0m\n",
       "\u001b[32mrespectful and sympathetic to Lathan and her family, and it highlights the importance of valuing all life, \u001b[0m\n",
       "\u001b[32mregardless of gender identity or expression.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'g5fcXc54DwdCegXHsLhnU3'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'sonnet'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \n",
       "\u001b[32m'trans_simplified'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"This article reports on the murder of \u001b[0m\n",
       "\u001b[32mTai'Vion Lathan, a 24-year-old Black transgender woman in Baltimore, focusing on her life, personality, and the \u001b[0m\n",
       "\u001b[32mimpact of her death on family and community. The content places her death in the broader context of violence \u001b[0m\n",
       "\u001b[32magainst transgender people, particularly transgender women of color, and connects to current political climate and \u001b[0m\n",
       "\u001b[32mlegislation affecting transgender rights.\"\u001b[0m, \u001b[32m\"The content correctly uses Tai'Vion's chosen name and feminine \u001b[0m\n",
       "\u001b[32mpronouns consistently throughout. There are no references to deadnames or inappropriate pronouns.\"\u001b[0m, \u001b[32m'The article \u001b[0m\n",
       "\u001b[32midentifies Lathan as transgender in a relevant context, as it relates to a pattern of violence against transgender \u001b[0m\n",
       "\u001b[32mpeople and provides important statistical context about the broader issue of anti-trans violence.'\u001b[0m, \u001b[32m\"The language \u001b[0m\n",
       "\u001b[32mused is respectful and appropriate, avoiding offensive terms or stereotypes. The article centers Lathan's humanity,\u001b[0m\n",
       "\u001b[32mdescribing her personality, aspirations, and relationships.\"\u001b[0m, \u001b[32m\"The article avoids language that diminishes gender \u001b[0m\n",
       "\u001b[32midentity. It presents Lathan's gender straightforwardly without qualifying terms like 'identifies as' or \u001b[0m\n",
       "\u001b[32mcomparisons to 'biological' gender.\"\u001b[0m, \u001b[32m'The article appropriately includes context about systemic discrimination and\u001b[0m\n",
       "\u001b[32mviolence against transgender people, citing relevant statistics and explaining how prejudice and discrimination can\u001b[0m\n",
       "\u001b[32mmake transgender people more vulnerable to violence.'\u001b[0m, \u001b[32m'The focus remains primarily on Lathan as a person, with her\u001b[0m\n",
       "\u001b[32mfamily relationships, career aspirations, and personality traits prominently featured. Medical transition is not \u001b[0m\n",
       "\u001b[32mmentioned at all, appropriately keeping the focus on her life and tragic death.'\u001b[0m, \u001b[32m'The article responsibly reports \u001b[0m\n",
       "\u001b[32mon violence against a transgender person while avoiding sensationalism and including important context about \u001b[0m\n",
       "\u001b[32mbroader patterns of discrimination and violence.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'83Ka5kU2vXRXGiM5jE5cTz'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'gemini15pro'\u001b[0m, \n",
       "\u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_tja'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The article discusses the murder of \u001b[0m\n",
       "\u001b[32mTai'Vion Lathan, a 24-year-old Black transgender woman, in Baltimore. It highlights the increasing violence against\u001b[0m\n",
       "\u001b[32mtransgender people, particularly Black transgender women, and connects this violence to the rise of anti-trans \u001b[0m\n",
       "\u001b[32mlegislation across the US.  The article centers Lathan's identity as a person, emphasizing her personality, family,\u001b[0m\n",
       "\u001b[32mand aspirations, while also providing statistics on violence against transgender individuals and quoting reactions \u001b[0m\n",
       "\u001b[32mfrom her family and other trans people in Baltimore.\"\u001b[0m, \u001b[32m'The article adheres to the Trans Journalists Association \u001b[0m\n",
       "\u001b[32mguidelines by prioritizing Tai\\'Vion Lathan\\'s identity as a person, not just as a transgender person.  It avoids \u001b[0m\n",
       "\u001b[32mdeadnaming or misgendering her, instead using her chosen name and pronouns.  The article also avoids focusing \u001b[0m\n",
       "\u001b[32munnecessarily on her gender identity, mentioning it only when providing context about the broader issue of violence\u001b[0m\n",
       "\u001b[32magainst transgender individuals, as instructed by \"do not call unnecessary attention to a trans person\\'s \u001b[0m\n",
       "\u001b[32mgender.\"'\u001b[0m, \u001b[32m'The article correctly uses terms like \"transgender\" and \"gender-expansive\" and avoids harmful or \u001b[0m\n",
       "\u001b[32minaccurate terminology such as \"transgenderism\" or \"biological sex,\" adhering to guidelines under \"Politicized or \u001b[0m\n",
       "\u001b[32mInaccurate Phrases.\"'\u001b[0m, \u001b[32m'The article adheres to guidelines for breaking news coverage by correctly identifying \u001b[0m\n",
       "\u001b[32mLathan as transgender, respecting her identity as confirmed by her family \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\"identifying transgender people during \u001b[0m\n",
       "\u001b[32mbreaking news\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.  It also correctly writes about her in the past using her current name and pronouns \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\"writing \u001b[0m\n",
       "\u001b[32mabout someone in the past\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m, \u001b[32m'The article includes relevant statistics and information about anti-trans \u001b[0m\n",
       "\u001b[32mlegislation and violence against transgender individuals, as recommended by \"reporting on anti-trans government \u001b[0m\n",
       "\u001b[32mpolicies\" and \"reporting on crimes involving trans people.\" The article rightfully centers Lathan\\'s story while \u001b[0m\n",
       "\u001b[32mincluding important context regarding violence faced by the transgender community. It amplifies the concerns of \u001b[0m\n",
       "\u001b[32mtrans people about their safety and the negative impact of discriminatory legislation, following the guideline \u001b[0m\n",
       "\u001b[32m\"trans people  not their parents, children, friends, colleagues, or critics  should be at the heart of stories \u001b[0m\n",
       "\u001b[32mwritten about them.\"'\u001b[0m, \u001b[32m'The article demonstrates trauma-informed reporting practices by focusing on Lathan\\'s \u001b[0m\n",
       "\u001b[32mhumanity and avoiding sensationalizing details about her death, in line with \"practicing trauma-informed \u001b[0m\n",
       "\u001b[32mreporting.\"'\u001b[0m, \u001b[32m'The article does not include irrelevant or unnecessary questions about Lathan\\'s medical history or \u001b[0m\n",
       "\u001b[32mpersonal life, abiding by \"take care not to ask irrelevant or unnecessary questions.\"'\u001b[0m, \u001b[32m'The article correctly \u001b[0m\n",
       "\u001b[32midentifies the increasing violence against trans people in the US and the role of anti-trans legislation without \u001b[0m\n",
       "\u001b[32mmaking generalizations about the \"trans community\", as per \"there is no single \\'trans community\\'.\"'\u001b[0m, \u001b[32m'The content\u001b[0m\n",
       "\u001b[32mdoes not pertain to specific topical guidelines such as health care, sports, or asylum seekers and refugees; \u001b[0m\n",
       "\u001b[32mtherefore no further analysis is needed.'\u001b[0m, \u001b[32m\"The article adheres to guidelines for photography and visual media. It \u001b[0m\n",
       "\u001b[32mdoesn't include photos that could endanger sources, uses file photos carefully, and avoids inappropriate stock \u001b[0m\n",
       "\u001b[32mimages.\"\u001b[0m, \u001b[32m\"The article uses correct and respectful language throughout. It adheres to the TJA guidelines by \u001b[0m\n",
       "\u001b[32maccurately representing the diversity of the trans community, centering the voices of trans people, and providing \u001b[0m\n",
       "\u001b[32messential context about violence against transgender people. It avoids misgendering or deadnaming, and effectively \u001b[0m\n",
       "\u001b[32muses Lathan's story to shed light on larger issues affecting transgender Americans. The inclusion of family \u001b[0m\n",
       "\u001b[32mperspectives enriches the portrayal of Lathan as a person while highlighting the profound impact of her loss.\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \n",
       "\u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'YwZkx33qZBuZ9VTcvgj79Q'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'gpt4o'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_tja'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \n",
       "\u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'The content discusses the murder of TaiVion Lathan, a 24-year-old transgender woman in Baltimore, \u001b[0m\n",
       "\u001b[32memphasizing the personal grief of her family and friends, while also providing broader context on the violence \u001b[0m\n",
       "\u001b[32mfaced by transgender communities, especially Black transgender women.'\u001b[0m, \u001b[32m\"The content addresses the gender identity \u001b[0m\n",
       "\u001b[32mof TaiVion Lathan appropriately, using correct pronouns and respecting her identity as a transgender woman. This \u001b[0m\n",
       "\u001b[32mcomplies with the guidance to use a person's current pronouns and name.\"\u001b[0m, \u001b[32m'TaiVion Lathan is introduced as a \u001b[0m\n",
       "\u001b[32m\"transgender woman\", which is appropriate and avoids unnecessary specification like using \\'identifies as\\', as per\u001b[0m\n",
       "\u001b[32mguidelines. The use of \\'transgender\\' is pertinent given the mention of violence faced by this community.'\u001b[0m, \u001b[32m'The \u001b[0m\n",
       "\u001b[32marticle ensures that Lathans gender identity is represented respectfully and does not use or reveal any deadname. \u001b[0m\n",
       "\u001b[32mThe content does not exhibit the need to deadname, nor does it veer into the territory of unwarranted attention to \u001b[0m\n",
       "\u001b[32mher being transgender.'\u001b[0m, \u001b[32m'The content cites statistics and information from the Human Rights Campaign \u001b[0m\n",
       "\u001b[32mappropriately, presenting data on violence against transgender individuals without sensationalizing or indulging in\u001b[0m\n",
       "\u001b[32mmisleading narratives.'\u001b[0m, \u001b[32m\"The content includes quotes from community members and activists, presenting a balanced \u001b[0m\n",
       "\u001b[32mview without suggesting that simply being transgender is a political act, which aligns with not using terms like \u001b[0m\n",
       "\u001b[32m'transgenderism'.\"\u001b[0m, \u001b[32m'Details about Lathans life, like her interests and relationships, are included, providing a \u001b[0m\n",
       "\u001b[32mfuller humanizing context and avoiding the simplification or reduction of her identity to just her gender.'\u001b[0m, \u001b[32m'The \u001b[0m\n",
       "\u001b[32marticle correctly identifies the systemic issues of violence faced by transgender and gender-expansive people, and \u001b[0m\n",
       "\u001b[32mincludes information on anti-trans legislation, adding necessary context rather than treating these topics as a \u001b[0m\n",
       "\u001b[32msimple culture war.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'avpi7qAUFkiGzBT7ncDvdj'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'haiku'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_tja'\u001b[0m, \u001b[32m'template'\u001b[0m: \n",
       "\u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"The content provided describes the tragic death of Tai'Vion Lathan, a \u001b[0m\n",
       "\u001b[32m24-year-old Black transgender woman, who was found fatally shot in an alley in Baltimore. The article provides \u001b[0m\n",
       "\u001b[32mdetails about Lathan's life, including her loving relationship with her mother, her creative interests, and her \u001b[0m\n",
       "\u001b[32mplans to become a nurse. It also contextualizes Lathan's death within the broader issue of violence against \u001b[0m\n",
       "\u001b[32mtransgender and gender-expansive people in the United States, noting that at least 24 such individuals have been \u001b[0m\n",
       "\u001b[32mkilled so far this year, with a disproportionate number being Black transgender women. The article highlights the \u001b[0m\n",
       "\u001b[32mongoing threats and lack of safety that transgender people, especially transgender people of color, face due to \u001b[0m\n",
       "\u001b[32manti-trans rhetoric, legislation, and violence.\"\u001b[0m, \u001b[32m\"The content does not appear to violate any of the Trans \u001b[0m\n",
       "\u001b[32mJournalists Association's guidelines. The article appropriately uses Lathan's correct name and pronouns, avoids \u001b[0m\n",
       "\u001b[32munnecessary focus on her appearance or transition, and centers her identity as a person rather than just her \u001b[0m\n",
       "\u001b[32mtransgender status. It also provides relevant context about the challenges and risks that transgender people face, \u001b[0m\n",
       "\u001b[32mparticularly those who are Black, without sensationalizing or exoticizing the subject matter.\"\u001b[0m, \u001b[32m\"The article also \u001b[0m\n",
       "\u001b[32mincludes quotes from Lathan's family members and a local transgender advocate, demonstrating an effort to center \u001b[0m\n",
       "\u001b[32mthe perspectives and experiences of the transgender community. It also highlights the ongoing investigation into \u001b[0m\n",
       "\u001b[32mLathan's death and the reward being offered for information, indicating a commitment to transparency and \u001b[0m\n",
       "\u001b[32maccountability.\"\u001b[0m, \u001b[32m\"Overall, the content appears to be a sensitive and well-researched reporting on the tragic loss \u001b[0m\n",
       "\u001b[32mof Tai'Vion Lathan, framing her story within the broader context of violence against transgender individuals in the\u001b[0m\n",
       "\u001b[32mUnited States. The article adheres to the Trans Journalists Association's guidelines for accurately and \u001b[0m\n",
       "\u001b[32mrespectfully covering stories about transgender people.\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \u001b[32m'SJ5epKyMvZQ96qRcXikoL3'\u001b[0m, \u001b[32m'model'\u001b[0m: \n",
       "\u001b[32m'llama31_70b'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_tja'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \n",
       "\u001b[32m'G47VXzzw2BndGvLtCG9wzk'\u001b[0m, \u001b[32m'model'\u001b[0m: \u001b[32m'sonnet'\u001b[0m, \u001b[32m'criteria'\u001b[0m: \u001b[32m'trans_tja'\u001b[0m, \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m, \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m, \n",
       "\u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"This news article reports on the murder of Tai'Vion Lathan, a 24-year-old Black transgender woman in \u001b[0m\n",
       "\u001b[32mBaltimore. The article focuses on her humanity, her relationships, and her aspirations while also providing context\u001b[0m\n",
       "\u001b[32mabout the broader pattern of violence against transgender people, particularly trans women of color.\"\u001b[0m, \u001b[32m\"The article\u001b[0m\n",
       "\u001b[32madheres to best practices by centering Lathan's humanity and using her correct name and pronouns throughout. Family\u001b[0m\n",
       "\u001b[32mmembers are quoted speaking about her life, personality, and future plans rather than focusing solely on her death \u001b[0m\n",
       "\u001b[32mor gender identity.\"\u001b[0m, \u001b[32m'The reporting appropriately includes broader context about violence against trans people and\u001b[0m\n",
       "\u001b[32mstatistics about anti-trans violence, particularly affecting Black trans women. The article also responsibly \u001b[0m\n",
       "\u001b[32mconnects this context to current anti-trans legislation and systemic issues without sensationalizing.'\u001b[0m, \u001b[32m'The \u001b[0m\n",
       "\u001b[32marticle follows guidelines about speaking to trans people about trans issues by including quotes from other trans \u001b[0m\n",
       "\u001b[32mcommunity members and advocacy organizations. It avoids deadnaming or inappropriate questions about medical \u001b[0m\n",
       "\u001b[32mdetails.'\u001b[0m, \u001b[32m'The coverage treats the crime with appropriate seriousness and includes practical information about the\u001b[0m\n",
       "\u001b[32minvestigation and how to submit tips, while also highlighting systemic issues in solving crimes against trans \u001b[0m\n",
       "\u001b[32mpeople.'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect the dataset so we can make sure the inputs look ok\n",
    "rprint(orchestrator._dataset.sample().answers.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_YNpFkj with job ZoRBmAyKKxiPZhU4CyYZ76.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_YNpFkj with job ZoRBmAyKKxiPZhU4CyYZ76.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_YNpFkj with job g3xmDrZgfLEFrdrLxnqoww.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_YNpFkj with job g3xmDrZgfLEFrdrLxnqoww.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_YNpFkj with job krEPHsEQPy9s7M8ovNw7C2.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_YNpFkj with job krEPHsEQPy9s7M8ovNw7C2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_YNpFkj with job ZWwGDBMAgEMYk8gVQqvgb6.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_YNpFkj with job ZWwGDBMAgEMYk8gVQqvgb6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_YNpFkj with job 49MSKBDybHw97NjJxRRwDb.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_YNpFkj with job 49MSKBDybHw97NjJxRRwDb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_YNpFkj with job FaoN77yLoK3PLgU2sb7qwf.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_YNpFkj with job FaoN77yLoK3PLgU2sb7qwf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_YNpFkj with job NftXAxps5mcfpjpnqfUYBY.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_YNpFkj with job NftXAxps5mcfpjpnqfUYBY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_YNpFkj with job NMsjuM9Ktg6wV3s7rM4fTA.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_YNpFkj with job NMsjuM9Ktg6wV3s7rM4fTA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_YNpFkj with job ibcGvP9exq57CVw8XNtgbp.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_YNpFkj with job ibcGvP9exq57CVw8XNtgbp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_Tevgtc with job H8toXyF4fRKmPyMh9JK6PP.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_Tevgtc with job H8toXyF4fRKmPyMh9JK6PP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_Tevgtc with job PU7P4ME82pcGTUXCGciZFS.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_Tevgtc with job PU7P4ME82pcGTUXCGciZFS.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_Tevgtc with job XWebYmDTmZMPg3QWFHbxWv.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_Tevgtc with job XWebYmDTmZMPg3QWFHbxWv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_Tevgtc with job WmpPvsJ6SszheqZx9zZLaV.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_Tevgtc with job WmpPvsJ6SszheqZx9zZLaV.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_Tevgtc with job BiaJLLMayQCPsw4iTwpWa5.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_Tevgtc with job BiaJLLMayQCPsw4iTwpWa5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_Tevgtc with job GjCsk4o6gKfpuLLAPo9vfA.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_Tevgtc with job GjCsk4o6gKfpuLLAPo9vfA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:53\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_Tevgtc with job 75ZeJotbWS7y2VjnV8AMUj.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_Tevgtc with job 75ZeJotbWS7y2VjnV8AMUj.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:53\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_Tevgtc with job aenoXfvz5vkHgLuBDUYCS4.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_Tevgtc with job aenoXfvz5vkHgLuBDUYCS4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:53\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_Tevgtc with job RPXNH3r4FGAnwM2XnLLJJ4.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_Tevgtc with job RPXNH3r4FGAnwM2XnLLJJ4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_bDKuvn with job CyYTvsE9PZMfohF7EG4fex.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_bDKuvn with job CyYTvsE9PZMfohF7EG4fex.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_bDKuvn with job a3aGDdwgdhtW76zbf5LP4y.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_bDKuvn with job a3aGDdwgdhtW76zbf5LP4y.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:38:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 24.42 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 24.42 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_YNpFkj completed job g3xmDrZgfLEFrdrLxnqoww successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_YNpFkj completed job g3xmDrZgfLEFrdrLxnqoww successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_bDKuvn with job RBnFU3UrCyXBkhj9GfX96x.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_bDKuvn with job RBnFU3UrCyXBkhj9GfX96x.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 27.17 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 27.17 seconds\n",
      "I0000 00:00:1730860752.938060 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_YNpFkj completed job krEPHsEQPy9s7M8ovNw7C2 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_YNpFkj completed job krEPHsEQPy9s7M8ovNw7C2 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_bDKuvn with job 7gEWDewkxm45JH2ZkQEvjo.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_bDKuvn with job 7gEWDewkxm45JH2ZkQEvjo.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 23.90 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 23.90 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_Tevgtc completed job PU7P4ME82pcGTUXCGciZFS successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_Tevgtc completed job PU7P4ME82pcGTUXCGciZFS successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 26.81 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 26.81 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730860758.717951 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_Tevgtc completed job XWebYmDTmZMPg3QWFHbxWv successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_Tevgtc completed job XWebYmDTmZMPg3QWFHbxWv successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 30.56 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 30.56 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730860761.332542 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_Tevgtc completed job H8toXyF4fRKmPyMh9JK6PP successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_Tevgtc completed job H8toXyF4fRKmPyMh9JK6PP successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 31.53 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 31.53 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730860763.766427 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_Tevgtc completed job WmpPvsJ6SszheqZx9zZLaV successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_Tevgtc completed job WmpPvsJ6SszheqZx9zZLaV successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_bDKuvn with job hJJ29P99GgzBgPqFddsoDs.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_bDKuvn with job hJJ29P99GgzBgPqFddsoDs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_bDKuvn with job cc5wXEgPtaKQh7YoRbwy7x.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_bDKuvn with job cc5wXEgPtaKQh7YoRbwy7x.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_bDKuvn with job LGVAyU3KSXDdGwHYb8ZYZH.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_bDKuvn with job LGVAyU3KSXDdGwHYb8ZYZH.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_bDKuvn with job iUQcvaaoEH3snuwHk6kJxq.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_bDKuvn with job iUQcvaaoEH3snuwHk6kJxq.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 40.91 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 40.91 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_YNpFkj completed job ZWwGDBMAgEMYk8gVQqvgb6 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_YNpFkj completed job ZWwGDBMAgEMYk8gVQqvgb6 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 16.66 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 16.66 seconds\n",
      "I0000 00:00:1730860769.526774 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:32\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:32\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_YNpFkj completed job 49MSKBDybHw97NjJxRRwDb successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_YNpFkj completed job 49MSKBDybHw97NjJxRRwDb successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:32\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 34.92 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 34.92 seconds\n",
      "I0000 00:00:1730860772.033765 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_bDKuvn completed job CyYTvsE9PZMfohF7EG4fex successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_bDKuvn completed job CyYTvsE9PZMfohF7EG4fex successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 36.94 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 36.94 seconds\n",
      "I0000 00:00:1730860774.346753 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_bDKuvn completed job a3aGDdwgdhtW76zbf5LP4y successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_bDKuvn completed job a3aGDdwgdhtW76zbf5LP4y successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_bDKuvn with job UYT4jFks5biF7mKVJATPBf.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_bDKuvn with job UYT4jFks5biF7mKVJATPBf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_LDGRPJ with job L76MGPh7wwJBxe8Sm4c6n8.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_LDGRPJ with job L76MGPh7wwJBxe8Sm4c6n8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_LDGRPJ with job daMEz2BjXUnXhnCC6NUfET.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_LDGRPJ with job daMEz2BjXUnXhnCC6NUfET.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_LDGRPJ with job VNtRGmdw9pVDmcJ4k6XqDQ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_LDGRPJ with job VNtRGmdw9pVDmcJ4k6XqDQ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 26.56 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 26.56 seconds\n",
      "I0000 00:00:1730860781.986809 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860782.396980 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_YNpFkj completed job FaoN77yLoK3PLgU2sb7qwf successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_YNpFkj completed job FaoN77yLoK3PLgU2sb7qwf successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_LDGRPJ with job EMYeDfqCratJvQMfdLQ8Qk.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_LDGRPJ with job EMYeDfqCratJvQMfdLQ8Qk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 29.03 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 29.03 seconds\n",
      "I0000 00:00:1730860784.469573 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860784.865399 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_bDKuvn completed job 7gEWDewkxm45JH2ZkQEvjo successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_bDKuvn completed job 7gEWDewkxm45JH2ZkQEvjo successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_LDGRPJ with job Hyz77Ct9cKUR6B4hTFd8DY.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_LDGRPJ with job Hyz77Ct9cKUR6B4hTFd8DY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 10.12 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 10.12 seconds\n",
      "I0000 00:00:1730860786.940169 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860787.348024 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_YNpFkj completed job NftXAxps5mcfpjpnqfUYBY successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_YNpFkj completed job NftXAxps5mcfpjpnqfUYBY successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_LDGRPJ with job g3vrjjF7wLMp39wzQXafGp.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_LDGRPJ with job g3vrjjF7wLMp39wzQXafGp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 37.61 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 37.61 seconds\n",
      "I0000 00:00:1730860791.676576 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860792.114060 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:53\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_bDKuvn completed job RBnFU3UrCyXBkhj9GfX96x successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1730860794.031274 28636356 ssl_transport_security_utils.cc:116] Corruption detected.\n",
      "DEBUG:buttermilk:Agent lc_judge_bDKuvn completed job RBnFU3UrCyXBkhj9GfX96x successfully.\n",
      "E0000 00:00:1730860794.031314 28636356 ssl_transport_security_utils.cc:73] error:100003fc:SSL routines:OPENSSL_internal:SSLV3_ALERT_BAD_RECORD_MAC\n",
      "E0000 00:00:1730860794.031316 28636356 secure_endpoint.cc:300] Decryption error: TSI_DATA_CORRUPTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_LDGRPJ with job SA9kjs79CBrYaNDLnfuHNQ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:google.cloud.logging_v2.handlers.transports.background_thread:Failed to submit 1 logs.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/bm/lib/python3.11/site-packages/google/cloud/logging_v2/handlers/transports/background_thread.py\", line 115, in _safely_commit_batch\n",
      "    batch.commit()\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/bm/lib/python3.11/site-packages/google/cloud/logging_v2/logger.py\", line 468, in commit\n",
      "    client.logging_api.write_entries(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/bm/lib/python3.11/site-packages/google/cloud/logging_v2/_gapic.py\", line 163, in write_entries\n",
      "    self._gapic_api.write_log_entries(request=request)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/bm/lib/python3.11/site-packages/google/cloud/logging_v2/services/logging_service_v2/client.py\", line 966, in write_log_entries\n",
      "    response = rpc(\n",
      "               ^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/bm/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n",
      "    return wrapped_func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/bm/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
      "    return retry_target(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/bm/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
      "    _retry_error_helper(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/bm/lib/python3.11/site-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
      "    raise final_exc from source_exc\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/bm/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
      "    result = target()\n",
      "             ^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/bm/lib/python3.11/site-packages/google/api_core/timeout.py\", line 120, in func_with_timeout\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/bm/lib/python3.11/site-packages/google/api_core/grpc_helpers.py\", line 78, in error_remapped_callable\n",
      "    raise exceptions.from_grpc_error(exc) from exc\n",
      "google.api_core.exceptions.Unknown: None Stream removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_LDGRPJ with job SA9kjs79CBrYaNDLnfuHNQ.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 9.77 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 9.77 seconds\n",
      "I0000 00:00:1730860794.173642 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860794.603753 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x5a799cf55b6ff6d542487cf0f14d8beb\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xe8589e2a6f92a55e185bbced84369795\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xf019f2c7b5162a5ad25c4eb0531b6112\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xc482188d30d943925f09c6fc8aff41bb\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xf26ac307e404a67030ab60c5ec1d08c7\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x9c7e86dda45aa56318efd0157d536b4e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x256d998c770c81f630d334305193b2d0\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x62f0cabd9aa59305f65ec8bbb6559ff9\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xa9892156c281e4e56fda38b88445c825\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x0faac6e99b60930538829098e9faeccc\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x0fc6041d50f6964839140f9b97b4e400\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x2c23fec0cf25fb3df52e40742eddfd8a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x352cb31fc62cd8eea651a00690399172\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x4d909915688382e73d56f912ff72ab23\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xd1a446540dd8532043d29793741f4caf\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x8d3a9331de8a59c5cc9b8c6c64b708ea\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x6d915b43884b9cccbbc31a703a6ebd4d\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xde07711ee790e4414fd42fef91d94ed1\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xadfb6ed9535ad956d25e0c5523d7ac9d\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x5672ca0baca0d77a1b9b73f1e5f84f8e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x3507c0033b0734f7d4c055c1ca576b1b\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xb266aacbdcb0ed44ca852b5819621ebc\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xa3b266d880ca67bb4efee1b0315c0265\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x5539c45314948265adcec146f70f5fee\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xf695e1b8ab008e3748e559def410a27c\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x181ec7899dc599b3fb668be2cdc456a4\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x0f73c124eb5bf42ba8943be782da426f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xdb4c19906bb49117d6083873271a2ca3\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x5723edb65c6b5a791e5d3cea10af88bb\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x455fc39d6e8106d1f93435ae62bb339c\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xa1a02d7654df9995126fea01c3ca8531\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xf09c6e015ce2c53aa10be2a0e60c4731\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x6117a3d3bbb1616e8baefa1a0f740459\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x8828c3a39f5d0fab4b5dc229c41b5ca2\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xaf93af61e94578985a83585a94febca2\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xd04559e8a402b2407bea88675629e2c1\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xefa75de2b9a2cd13a1b6d6c3e73ce7b0\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x9c6c876fe5951758fe7a2304dc5f69f9\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xcd32e3cc847cb2b08aa07ba65f3b19de\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x4c693977b02b71904691ce23f1b21f2c\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xdc756f2cfdf4010e30cb85a69b215ab7\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x5faaf681e48f184a54c00a54873dedc3\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x0ca80874096300edc28e0d086cef3853\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xd0f76b03a5eaf83b5a46eb9a9d598e76\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xa24eac4ccadbd3f464cb70df2c3bb3a8\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x45448d18140bac795b4ad1e66a4d22ae\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xca1abe8cee8202f6d3985996cdef04f9\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x00d49f49f5a490a98ff9325718bc73c0\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xaf389915cf1e0c53bebdc144f7312220\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xd7fe172805fb8623b3d5104bee808b65\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x0ecbd9538fb2f3a6c32cb6c589a7ca84\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x0fe6e375e6d94bb1ef79630f93f2aeff\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x8bd71995131c44a5efd0e3face9882ce\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x5bfb52af907f79cbe9d531cb546292b2\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xf018609099262b4f0a65e9ed5ddd9b80\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xd4e1bbd317ef503e8638973265055e37\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xc49310dc75d831bfddb2ee3bc4927695\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x70991f4ece2c36409341f25a3e9608df\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:55\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_LDGRPJ completed job EMYeDfqCratJvQMfdLQ8Qk successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_LDGRPJ completed job EMYeDfqCratJvQMfdLQ8Qk successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_LDGRPJ with job VChduaAiFLyMyUSRRNtvSH.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_LDGRPJ with job VChduaAiFLyMyUSRRNtvSH.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 19.77 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 19.77 seconds\n",
      "I0000 00:00:1730860796.689490 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860797.101322 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_YNpFkj completed job NMsjuM9Ktg6wV3s7rM4fTA successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_YNpFkj completed job NMsjuM9Ktg6wV3s7rM4fTA successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:39:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 32.33 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 32.33 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730860799.045324 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860799.504610 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:00\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_Tevgtc completed job GjCsk4o6gKfpuLLAPo9vfA successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_Tevgtc completed job GjCsk4o6gKfpuLLAPo9vfA successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 34.88 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 34.88 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730860801.530699 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860801.978660 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_Tevgtc completed job BiaJLLMayQCPsw4iTwpWa5 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_Tevgtc completed job BiaJLLMayQCPsw4iTwpWa5 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 37.16 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 37.16 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730860804.029306 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860804.533327 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_Tevgtc completed job aenoXfvz5vkHgLuBDUYCS4 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_Tevgtc completed job aenoXfvz5vkHgLuBDUYCS4 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 39.58 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 39.58 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730860806.478262 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860806.894465 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_Tevgtc completed job 75ZeJotbWS7y2VjnV8AMUj successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_Tevgtc completed job 75ZeJotbWS7y2VjnV8AMUj successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_judge_LDGRPJ with job NopNYFKadD2wAeQw6Z9VFz.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_judge_LDGRPJ with job NopNYFKadD2wAeQw6Z9VFz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 27.51 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 27.51 seconds\n",
      "I0000 00:00:1730860808.947565 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860809.369491 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_LDGRPJ completed job daMEz2BjXUnXhnCC6NUfET successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_LDGRPJ completed job daMEz2BjXUnXhnCC6NUfET successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 30.00 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 30.00 seconds\n",
      "I0000 00:00:1730860811.405369 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860811.863947 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_LDGRPJ completed job L76MGPh7wwJBxe8Sm4c6n8 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_LDGRPJ completed job L76MGPh7wwJBxe8Sm4c6n8 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 26.93 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 26.93 seconds\n",
      "I0000 00:00:1730860813.836583 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860814.275952 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_bDKuvn completed job LGVAyU3KSXDdGwHYb8ZYZH successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_bDKuvn completed job LGVAyU3KSXDdGwHYb8ZYZH successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 34.81 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 34.81 seconds\n",
      "I0000 00:00:1730860816.323297 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860816.753569 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_bDKuvn completed job cc5wXEgPtaKQh7YoRbwy7x successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_bDKuvn completed job cc5wXEgPtaKQh7YoRbwy7x successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 37.34 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 37.34 seconds\n",
      "I0000 00:00:1730860818.780042 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860819.190154 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_bDKuvn completed job hJJ29P99GgzBgPqFddsoDs successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_bDKuvn completed job hJJ29P99GgzBgPqFddsoDs successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 39.92 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 39.92 seconds\n",
      "I0000 00:00:1730860822.351253 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860822.796984 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_LDGRPJ completed job VNtRGmdw9pVDmcJ4k6XqDQ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_LDGRPJ completed job VNtRGmdw9pVDmcJ4k6XqDQ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:24\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 40.41 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 40.41 seconds\n",
      "I0000 00:00:1730860824.791139 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860825.206643 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_YNpFkj completed job ibcGvP9exq57CVw8XNtgbp successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_YNpFkj completed job ibcGvP9exq57CVw8XNtgbp successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:27\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 30.55 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 30.55 seconds\n",
      "I0000 00:00:1730860827.181484 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860827.611637 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_LDGRPJ completed job Hyz77Ct9cKUR6B4hTFd8DY successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_LDGRPJ completed job Hyz77Ct9cKUR6B4hTFd8DY successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m templating.py[  50] \u001b[1;30mDEBUG\u001b[0m \u001b[32mUnable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Unable to decode template as Prompty: Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template., e.args=('Illegal formatting of prompty. The prompt file is in markdown format and can be divided into two parts, the first part is in YAML format and contains connection and model information. The second part is the prompt template.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 39.23 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 39.23 seconds\n",
      "I0000 00:00:1730860836.798182 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_bDKuvn completed job iUQcvaaoEH3snuwHk6kJxq successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_bDKuvn completed job iUQcvaaoEH3snuwHk6kJxq successfully.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 9.24 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 9.24 seconds\n",
      "I0000 00:00:1730860838.810628 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860839.253755 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_LDGRPJ completed job NopNYFKadD2wAeQw6Z9VFz successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_LDGRPJ completed job NopNYFKadD2wAeQw6Z9VFz successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 16.44 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 16.44 seconds\n",
      "I0000 00:00:1730860841.209044 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860841.681712 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_LDGRPJ completed job VChduaAiFLyMyUSRRNtvSH successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_LDGRPJ completed job VChduaAiFLyMyUSRRNtvSH successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 29.85 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 29.85 seconds\n",
      "I0000 00:00:1730860843.672405 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860844.175527 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:45\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_LDGRPJ completed job g3vrjjF7wLMp39wzQXafGp successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_LDGRPJ completed job g3vrjjF7wLMp39wzQXafGp successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 32.32 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 32.32 seconds\n",
      "I0000 00:00:1730860846.147495 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730860846.687445 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:47\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_LDGRPJ completed job SA9kjs79CBrYaNDLnfuHNQ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_LDGRPJ completed job SA9kjs79CBrYaNDLnfuHNQ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 39.75 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 39.75 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730860848.611726 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_Tevgtc completed job RPXNH3r4FGAnwM2XnLLJJ4 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_Tevgtc completed job RPXNH3r4FGAnwM2XnLLJJ4 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 26.22 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 26.22 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:53\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:40:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_bDKuvn completed job UYT4jFks5biF7mKVJATPBf successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_bDKuvn completed job UYT4jFks5biF7mKVJATPBf successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:49:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 628.04 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 628.04 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:49:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:49:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:49:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_judge_YNpFkj completed job ZoRBmAyKKxiPZhU4CyYZ76 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_judge_YNpFkj completed job ZoRBmAyKKxiPZhU4CyYZ76 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:49:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[ 106] \u001b[1;30mINFO\u001b[0m Completed run 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Completed run 1 of 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 12:49:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[ 110] \u001b[1;30mINFO\u001b[0m All tasks have completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:All tasks have completed.\n"
     ]
    }
   ],
   "source": [
    "await orchestrator.run_tasks()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third step, we summarise the answers, similarities, and differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:08:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m buttermilk.py[ 376] \u001b[1;30mINFO\u001b[0m Query stats: Ran in 0:00:03.769667 seconds, cache hit: False, billed 22.02 MB, approx cost $1.1e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Query stats: Ran in 0:00:03.769667 seconds, cache hit: False, billed 22.02 MB, approx cost $1.1e-05.\n"
     ]
    }
   ],
   "source": [
    "# Create an orchestrator to conduct all combinations of jobs we want to run\n",
    "from buttermilk.runner.orchestrator import MultiFlowOrchestrator\n",
    "orchestrator = MultiFlowOrchestrator(step=cfg.step[2], data=cfg.data, save=cfg.save, source=cfg.source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_H2Cy74 with job ZCss8xW3KHbnFdkAJ3hUoN.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_H2Cy74 with job ZCss8xW3KHbnFdkAJ3hUoN.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_H2Cy74 with job dLzUUufZDsER7RGHeYAXb7.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_H2Cy74 with job dLzUUufZDsER7RGHeYAXb7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_H2Cy74 with job GmzCUd8FM47PRQgvLYWSAE.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_H2Cy74 with job GmzCUd8FM47PRQgvLYWSAE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_H2Cy74 with job mYbsNakNw3d84n8xxHwzZL.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_H2Cy74 with job mYbsNakNw3d84n8xxHwzZL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_H2Cy74 with job SWHLVUJqvBVSLJ6FfEvNjQ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_H2Cy74 with job SWHLVUJqvBVSLJ6FfEvNjQ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_H2Cy74 with job LV4BzFGa8RHkdC7tr3HtAu.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_H2Cy74 with job LV4BzFGa8RHkdC7tr3HtAu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:05\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_H2Cy74 with job jja36q59hMKfN5ze4fgtU9.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_H2Cy74 with job jja36q59hMKfN5ze4fgtU9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_H2Cy74 with job 2EJSWfqe38ZrJ6N4RY34iZ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_H2Cy74 with job 2EJSWfqe38ZrJ6N4RY34iZ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_H2Cy74 with job gv64fKvaDq69TVwvqx6iHR.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_H2Cy74 with job gv64fKvaDq69TVwvqx6iHR.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Jotr2a with job bumfhFvpAYhvXJwbMwESPk.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Jotr2a with job bumfhFvpAYhvXJwbMwESPk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Jotr2a with job RaaSQGQeD5WiMzqpghBnLG.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Jotr2a with job RaaSQGQeD5WiMzqpghBnLG.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Jotr2a with job FKK4aZhUDWS8uJQQniTmtK.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Jotr2a with job FKK4aZhUDWS8uJQQniTmtK.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Jotr2a with job be4Q7hEc4kd3MUMHCizyeZ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Jotr2a with job be4Q7hEc4kd3MUMHCizyeZ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Jotr2a with job nMXqMVQMDbWdCnxkbWYJJx.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Jotr2a with job nMXqMVQMDbWdCnxkbWYJJx.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Jotr2a with job Uc485R8JFF8RFLdnix8ZJm.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Jotr2a with job Uc485R8JFF8RFLdnix8ZJm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Jotr2a with job 55kjRXban7dv8CiToFPGXb.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Jotr2a with job 55kjRXban7dv8CiToFPGXb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Jotr2a with job ZruHc74U3jtFAp834BrneY.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Jotr2a with job ZruHc74U3jtFAp834BrneY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Jotr2a with job XR9HTajBpML9bG2yNPuySb.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Jotr2a with job XR9HTajBpML9bG2yNPuySb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_44M9g2 with job CfKM9Uo8BLZThgrC9fpjaY.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_44M9g2 with job CfKM9Uo8BLZThgrC9fpjaY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_44M9g2 with job X7KZtBwjjBwDPSnkciDvS3.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_44M9g2 with job X7KZtBwjjBwDPSnkciDvS3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 19.91 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 19.91 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:32\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Jotr2a completed job bumfhFvpAYhvXJwbMwESPk successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Jotr2a completed job bumfhFvpAYhvXJwbMwESPk successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_44M9g2 with job RwzVnJNtpKGUFbJYrMeKYD.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_44M9g2 with job RwzVnJNtpKGUFbJYrMeKYD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 29.95 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 29.95 seconds\n",
      "I0000 00:00:1730869774.024138 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_H2Cy74 completed job dLzUUufZDsER7RGHeYAXb7 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_H2Cy74 completed job dLzUUufZDsER7RGHeYAXb7 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 31.61 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 31.61 seconds\n",
      "I0000 00:00:1730869776.484997 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_H2Cy74 completed job mYbsNakNw3d84n8xxHwzZL successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_H2Cy74 completed job mYbsNakNw3d84n8xxHwzZL successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_44M9g2 with job a2F5fPk4Wbg3durSRWTJbb.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_44M9g2 with job a2F5fPk4Wbg3durSRWTJbb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_44M9g2 with job bqaNvBA2fFobyTYfXtZFs2.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_44M9g2 with job bqaNvBA2fFobyTYfXtZFs2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 34.53 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 34.53 seconds\n",
      "I0000 00:00:1730869779.087639 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_H2Cy74 completed job GmzCUd8FM47PRQgvLYWSAE successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_H2Cy74 completed job GmzCUd8FM47PRQgvLYWSAE successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 29.05 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 29.05 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730869781.451571 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:43\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Jotr2a completed job be4Q7hEc4kd3MUMHCizyeZ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Jotr2a completed job be4Q7hEc4kd3MUMHCizyeZ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_44M9g2 with job GZZE5XqcYPB4gDN9GuAcbC.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_44M9g2 with job GZZE5XqcYPB4gDN9GuAcbC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_44M9g2 with job emYozW9dHNMSLQVSKd7XD3.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_44M9g2 with job emYozW9dHNMSLQVSKd7XD3.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 27.45 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 27.45 seconds\n",
      "I0000 00:00:1730869784.168570 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_44M9g2 completed job X7KZtBwjjBwDPSnkciDvS3 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_44M9g2 completed job X7KZtBwjjBwDPSnkciDvS3 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 30.40 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 30.40 seconds\n",
      "I0000 00:00:1730869786.751671 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_44M9g2 completed job CfKM9Uo8BLZThgrC9fpjaY successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_44M9g2 completed job CfKM9Uo8BLZThgrC9fpjaY successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_44M9g2 with job WPuoMVaRtqWxCXTAevy6gg.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_44M9g2 with job WPuoMVaRtqWxCXTAevy6gg.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_44M9g2 with job DPD7Gu5A2WgvV5w842MM7R.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_44M9g2 with job DPD7Gu5A2WgvV5w842MM7R.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 37.11 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 37.11 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730869789.152691 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:50\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Jotr2a completed job FKK4aZhUDWS8uJQQniTmtK successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Jotr2a completed job FKK4aZhUDWS8uJQQniTmtK successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 40.07 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 40.07 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730869791.691867 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:53\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Jotr2a completed job RaaSQGQeD5WiMzqpghBnLG successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Jotr2a completed job RaaSQGQeD5WiMzqpghBnLG successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 50.45 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 50.45 seconds\n",
      "I0000 00:00:1730869794.165297 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:55\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_H2Cy74 completed job ZCss8xW3KHbnFdkAJ3hUoN successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_H2Cy74 completed job ZCss8xW3KHbnFdkAJ3hUoN successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 22.55 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 22.55 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730869796.437808 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Jotr2a completed job nMXqMVQMDbWdCnxkbWYJJx successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Jotr2a completed job nMXqMVQMDbWdCnxkbWYJJx successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_h5QtST with job ktWzSM4NkqFBYnefSXSPPu.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_h5QtST with job ktWzSM4NkqFBYnefSXSPPu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_h5QtST with job VsRBsR9doPQDJY9uLU33Rv.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_h5QtST with job VsRBsR9doPQDJY9uLU33Rv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_h5QtST with job n94geMn5epqVvh5S6m3kqp.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_h5QtST with job n94geMn5epqVvh5S6m3kqp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_h5QtST with job Jt49Cm3TQf7kmQrgQCqAzF.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_h5QtST with job Jt49Cm3TQf7kmQrgQCqAzF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:09:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 20.80 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 20.80 seconds\n",
      "I0000 00:00:1730869799.780711 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869800.218856 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_H2Cy74 completed job SWHLVUJqvBVSLJ6FfEvNjQ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_H2Cy74 completed job SWHLVUJqvBVSLJ6FfEvNjQ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_h5QtST with job 9c6mSvveH9D27hvMXonZQi.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_h5QtST with job 9c6mSvveH9D27hvMXonZQi.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 18.22 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 18.22 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730869802.288899 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869802.765519 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Jotr2a completed job Uc485R8JFF8RFLdnix8ZJm successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Jotr2a completed job Uc485R8JFF8RFLdnix8ZJm successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_h5QtST with job n3VmMBmcN7zYEBHfE6m3oU.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_h5QtST with job n3VmMBmcN7zYEBHfE6m3oU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 25.93 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 25.93 seconds\n",
      "I0000 00:00:1730869804.939762 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869805.417707 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:06\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_44M9g2 completed job a2F5fPk4Wbg3durSRWTJbb successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_44M9g2 completed job a2F5fPk4Wbg3durSRWTJbb successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_h5QtST with job ADKDJryBAigy4aGTpf8Jg7.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_h5QtST with job ADKDJryBAigy4aGTpf8Jg7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 8.42 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 8.42 seconds\n",
      "I0000 00:00:1730869807.584220 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869808.043491 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_H2Cy74 completed job 2EJSWfqe38ZrJ6N4RY34iZ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_H2Cy74 completed job 2EJSWfqe38ZrJ6N4RY34iZ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 36.08 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 36.08 seconds\n",
      "I0000 00:00:1730869810.073052 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869810.685335 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_44M9g2 completed job RwzVnJNtpKGUFbJYrMeKYD successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_44M9g2 completed job RwzVnJNtpKGUFbJYrMeKYD successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_h5QtST with job HSdm245NueuhHwmYTA9iCC.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_h5QtST with job HSdm245NueuhHwmYTA9iCC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_h5QtST with job B4ATzSivq2sLxM3aa8rPjN.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_h5QtST with job B4ATzSivq2sLxM3aa8rPjN.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 28.86 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 28.86 seconds\n",
      "I0000 00:00:1730869812.881133 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869813.260323 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_H2Cy74 completed job jja36q59hMKfN5ze4fgtU9 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_H2Cy74 completed job jja36q59hMKfN5ze4fgtU9 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 16.25 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 16.25 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730869815.992615 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869816.424631 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:17\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Jotr2a completed job 55kjRXban7dv8CiToFPGXb successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Jotr2a completed job 55kjRXban7dv8CiToFPGXb successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:18\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 16.29 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 16.29 seconds\n",
      "I0000 00:00:1730869818.552021 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869819.000207 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_H2Cy74 completed job gv64fKvaDq69TVwvqx6iHR successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_H2Cy74 completed job gv64fKvaDq69TVwvqx6iHR successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:20\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 21.72 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 21.72 seconds\n",
      "I0000 00:00:1730869820.952219 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869821.432099 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:22\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_h5QtST completed job n94geMn5epqVvh5S6m3kqp successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_h5QtST completed job n94geMn5epqVvh5S6m3kqp successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:23\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 24.26 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 24.26 seconds\n",
      "I0000 00:00:1730869823.419990 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869823.928769 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_h5QtST completed job VsRBsR9doPQDJY9uLU33Rv successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_h5QtST completed job VsRBsR9doPQDJY9uLU33Rv successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:25\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 46.96 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 46.96 seconds\n",
      "I0000 00:00:1730869826.328205 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869826.813795 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_H2Cy74 completed job LV4BzFGa8RHkdC7tr3HtAu successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_H2Cy74 completed job LV4BzFGa8RHkdC7tr3HtAu successfully.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 29.75 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 29.75 seconds\n",
      "I0000 00:00:1730869828.848793 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869829.148055 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_h5QtST completed job ktWzSM4NkqFBYnefSXSPPu successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_h5QtST completed job ktWzSM4NkqFBYnefSXSPPu successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:31\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 42.04 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 42.04 seconds\n",
      "I0000 00:00:1730869831.869440 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869832.296193 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_44M9g2 completed job bqaNvBA2fFobyTYfXtZFs2 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_44M9g2 completed job bqaNvBA2fFobyTYfXtZFs2 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 45.22 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 45.22 seconds\n",
      "I0000 00:00:1730869834.373359 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869834.813767 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_44M9g2 completed job GZZE5XqcYPB4gDN9GuAcbC successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_44M9g2 completed job GZZE5XqcYPB4gDN9GuAcbC successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 37.61 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 37.61 seconds\n",
      "I0000 00:00:1730869836.877291 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869837.267097 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:38\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_h5QtST completed job Jt49Cm3TQf7kmQrgQCqAzF successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_h5QtST completed job Jt49Cm3TQf7kmQrgQCqAzF successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 40.05 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 40.05 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730869839.888810 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869840.315242 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Jotr2a completed job ZruHc74U3jtFAp834BrneY successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Jotr2a completed job ZruHc74U3jtFAp834BrneY successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 43.17 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 43.17 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730869842.416535 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869842.995082 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:44\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Jotr2a completed job XR9HTajBpML9bG2yNPuySb successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Jotr2a completed job XR9HTajBpML9bG2yNPuySb successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 9.85 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 9.85 seconds\n",
      "I0000 00:00:1730869846.666950 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869847.104160 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_h5QtST completed job ADKDJryBAigy4aGTpf8Jg7 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_h5QtST completed job ADKDJryBAigy4aGTpf8Jg7 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 42.10 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 42.10 seconds\n",
      "I0000 00:00:1730869849.607915 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869850.034040 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_44M9g2 completed job emYozW9dHNMSLQVSKd7XD3 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_44M9g2 completed job emYozW9dHNMSLQVSKd7XD3 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 28.71 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 28.71 seconds\n",
      "I0000 00:00:1730869854.710743 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869855.159408 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_h5QtST completed job n3VmMBmcN7zYEBHfE6m3oU successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_h5QtST completed job n3VmMBmcN7zYEBHfE6m3oU successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 44.43 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 44.43 seconds\n",
      "I0000 00:00:1730869857.215143 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869857.662791 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:58\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_44M9g2 completed job WPuoMVaRtqWxCXTAevy6gg successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_44M9g2 completed job WPuoMVaRtqWxCXTAevy6gg successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:10:59\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 10.06 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 10.06 seconds\n",
      "I0000 00:00:1730869859.655532 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869860.086739 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:11:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:11:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:11:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_h5QtST completed job B4ATzSivq2sLxM3aa8rPjN successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_h5QtST completed job B4ATzSivq2sLxM3aa8rPjN successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:11:02\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 36.21 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 36.21 seconds\n",
      "I0000 00:00:1730869862.188255 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869862.631208 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:11:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:11:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:11:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_h5QtST completed job 9c6mSvveH9D27hvMXonZQi successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_h5QtST completed job 9c6mSvveH9D27hvMXonZQi successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:11:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with sonnet in 34.31 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with sonnet in 34.31 seconds\n",
      "I0000 00:00:1730869874.189662 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869874.719604 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:11:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:11:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:11:16\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_44M9g2 completed job DPD7Gu5A2WgvV5w842MM7R successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_44M9g2 completed job DPD7Gu5A2WgvV5w842MM7R successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:11:17\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gemini15pro in 35.53 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gemini15pro in 35.53 seconds\n",
      "I0000 00:00:1730869879.132104 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730869879.712824 28635378 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:11:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:11:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:11:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_h5QtST completed job HSdm245NueuhHwmYTA9iCC successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_h5QtST completed job HSdm245NueuhHwmYTA9iCC successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:11:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[ 106] \u001b[1;30mINFO\u001b[0m Completed run 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Completed run 1 of 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 15:11:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[ 110] \u001b[1;30mINFO\u001b[0m All tasks have completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:All tasks have completed.\n"
     ]
    }
   ],
   "source": [
    "await orchestrator.run_tasks()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
