{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/bm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:15:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m buttermilk.py[ 297] \u001b[1;30mINFO\u001b[0m {'message': \"Logging setup for: 20241106T0115Z-M8Tk-J5HW6L4KT6-suzor. Ready for data collection, saving log to Google Cloud Logs (Resource(type='generic_task', labels={'project_id': 'dmrc-platforms', 'location': 'us-central1', 'namespace': 'automod', 'job': 'score', 'task_id': '20241106T0115Z-M8Tk-J5HW6L4KT6-suzor'})). Default save directory for data in this run is: gs://dmrc-analysis/runs/automod/score/20241106T0115Z-M8Tk-J5HW6L4KT6-suzor\", 'project': 'automod', 'job': 'score', 'run_id': '20241106T0115Z-M8Tk-J5HW6L4KT6-suzor', 'save_dir': 'gs://dmrc-analysis/runs/automod/score/20241106T0115Z-M8Tk-J5HW6L4KT6-suzor', 'ip': '159.196.210.27', 'node_name': 'J5HW6L4KT6', 'username': 'suzor'}\n",
      "\u001b[32m2024-11-06 11:15:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m buttermilk.py[ 305] \u001b[1;30mDEBUG\u001b[0m \u001b[32mButtermilk version is: 0.2.0\u001b[0m\n",
      "Starting prompt flow service...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730855729.651663 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start prompt flow service on 127.0.0.1:23333, version: 1.16.1.\n",
      "You can stop the prompt flow service with the following command:'\u001b[1mpf service stop\u001b[0m'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'automod'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'job'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'notebook'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'secret_provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'azure'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'logger'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'tracing'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'verbose'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'models_secret'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'models'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'save_dest'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'save_dir'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-analysis'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'region'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us-central1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'bucket'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-analysis'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'azure'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'vault'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://suzorvault.vault.azure.net/'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'resource_group'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'rg-suzor_ai'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'aws'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'secret_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'secret'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'region'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us-east-1'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'step'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'num_runs'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'concurrent'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'agent'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'lc'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judge'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'trans_cte'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'trans_tja'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'trans_glaad'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'trans_hrc'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'trans_simplified'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'trans_factored'</span>\n",
       "                <span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'formatting'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'json_rules'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'haiku'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'llama31_70b'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gpt4o'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sonnet'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gemini15pro'</span><span style=\"font-weight: bold\">]</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'synth'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'num_runs'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'concurrent'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'agent'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'lc_judge'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'synthesise'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'trans_simplified'</span><span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'formatting'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'json_rules'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'haiku'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gpt4o'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sonnet'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gemini15pro'</span><span style=\"font-weight: bold\">]</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'answers'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'answers'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'meta'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'meta'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'previous runs'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'job'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'dataset'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-analysis.toxicity.flow'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'max_records_per_group'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'filter'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'group'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'record.record_id'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.flow'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template_vars.criteria'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'parameters.model'</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'columns'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'answers'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'job_id'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.reasons'</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'meta'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.flow'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template_vars.criteria'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'parameters.model'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'prediction'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.prediction'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'labels'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.labels'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'confidence'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.confidence'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">}</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'eval'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'num_runs'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'concurrent'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'agent'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'lc'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'differences'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'trans_simplified'</span><span style=\"font-weight: bold\">]</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'haiku'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gpt4o'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sonnet'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gemini15pro'</span><span style=\"font-weight: bold\">]</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'answers'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'answers'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'meta'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'meta'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'previous runs and synth'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'job'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'dataset'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-analysis.toxicity.flow'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'max_records_per_group'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'filter'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.flow'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'judger'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'synth'</span><span style=\"font-weight: bold\">]}</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'group'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'parameters.model'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'record.record_id'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.flow'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template'</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template_vars.criteria'</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'columns'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'answers'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'job_id'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.flow'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.reasons'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>,\n",
       "                        <span style=\"color: #008000; text-decoration-color: #008000\">'meta'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.flow'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'template'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'criteria'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'agent_info.template_vars.criteria'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'parameters.model'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'prediction'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.prediction'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'labels'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.labels'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'confidence'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'outputs.confidence'</span>,\n",
       "                            <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span>\n",
       "                        <span style=\"font-weight: bold\">}</span>\n",
       "                    <span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">}</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'run'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'platform'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'local'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'trans'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'trans news articles'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'file'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'uri'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gs://dmrc-platforms/data/tja_train.jsonl'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'columns'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'save'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'bq'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'destination'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dmrc-analysis.toxicity.flow'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'schema'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'flow.json'</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'name'\u001b[0m: \u001b[32m'automod'\u001b[0m,\n",
       "    \u001b[32m'job'\u001b[0m: \u001b[32m'score'\u001b[0m,\n",
       "    \u001b[32m'source'\u001b[0m: \u001b[32m'notebook'\u001b[0m,\n",
       "    \u001b[32m'secret_provider'\u001b[0m: \u001b[32m'azure'\u001b[0m,\n",
       "    \u001b[32m'logger'\u001b[0m: \u001b[32m'gcp'\u001b[0m,\n",
       "    \u001b[32m'tracing'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'verbose'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'models_secret'\u001b[0m: \u001b[32m'models'\u001b[0m,\n",
       "    \u001b[32m'save_dest'\u001b[0m: \u001b[32m'gcp'\u001b[0m,\n",
       "    \u001b[32m'save_dir'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'gcp'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'project'\u001b[0m: \u001b[32m'dmrc-analysis'\u001b[0m, \u001b[32m'region'\u001b[0m: \u001b[32m'us-central1'\u001b[0m, \u001b[32m'bucket'\u001b[0m: \u001b[32m'dmrc-analysis'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'azure'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'vault'\u001b[0m: \u001b[32m'https://suzorvault.vault.azure.net/'\u001b[0m, \u001b[32m'resource_group'\u001b[0m: \u001b[32m'rg-suzor_ai'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'aws'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'secret_name'\u001b[0m: \u001b[32m'secret'\u001b[0m, \u001b[32m'region'\u001b[0m: \u001b[32m'us-east-1'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'step'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'flow'\u001b[0m: \u001b[32m'judger'\u001b[0m,\n",
       "            \u001b[32m'num_runs'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "            \u001b[32m'concurrent'\u001b[0m: \u001b[1;36m20\u001b[0m,\n",
       "            \u001b[32m'agent'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'name'\u001b[0m: \u001b[32m'lc'\u001b[0m,\n",
       "                \u001b[32m'template'\u001b[0m: \u001b[32m'judge'\u001b[0m,\n",
       "                \u001b[32m'criteria'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "                    \u001b[32m'trans_cte'\u001b[0m,\n",
       "                    \u001b[32m'trans_tja'\u001b[0m,\n",
       "                    \u001b[32m'trans_glaad'\u001b[0m,\n",
       "                    \u001b[32m'trans_hrc'\u001b[0m,\n",
       "                    \u001b[32m'trans_simplified'\u001b[0m,\n",
       "                    \u001b[32m'trans_factored'\u001b[0m\n",
       "                \u001b[1m]\u001b[0m,\n",
       "                \u001b[32m'formatting'\u001b[0m: \u001b[32m'json_rules'\u001b[0m,\n",
       "                \u001b[32m'model'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'haiku'\u001b[0m, \u001b[32m'llama31_70b'\u001b[0m, \u001b[32m'gpt4o'\u001b[0m, \u001b[32m'sonnet'\u001b[0m, \u001b[32m'gemini15pro'\u001b[0m\u001b[1m]\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'parameters'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'record_id'\u001b[0m: \u001b[32m'record_id'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'content'\u001b[0m, \u001b[32m'title'\u001b[0m: \u001b[32m'title'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'flow'\u001b[0m: \u001b[32m'synth'\u001b[0m,\n",
       "            \u001b[32m'num_runs'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "            \u001b[32m'concurrent'\u001b[0m: \u001b[1;36m20\u001b[0m,\n",
       "            \u001b[32m'agent'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'name'\u001b[0m: \u001b[32m'lc_judge'\u001b[0m,\n",
       "                \u001b[32m'template'\u001b[0m: \u001b[32m'synthesise'\u001b[0m,\n",
       "                \u001b[32m'criteria'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'trans_simplified'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                \u001b[32m'formatting'\u001b[0m: \u001b[32m'json_rules'\u001b[0m,\n",
       "                \u001b[32m'model'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'haiku'\u001b[0m, \u001b[32m'gpt4o'\u001b[0m, \u001b[32m'sonnet'\u001b[0m, \u001b[32m'gemini15pro'\u001b[0m\u001b[1m]\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'parameters'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'answers'\u001b[0m: \u001b[32m'answers'\u001b[0m, \u001b[32m'meta'\u001b[0m: \u001b[32m'meta'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'judger'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'name'\u001b[0m: \u001b[32m'previous runs'\u001b[0m,\n",
       "                    \u001b[32m'type'\u001b[0m: \u001b[32m'job'\u001b[0m,\n",
       "                    \u001b[32m'dataset'\u001b[0m: \u001b[32m'dmrc-analysis.toxicity.flow'\u001b[0m,\n",
       "                    \u001b[32m'max_records_per_group'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "                    \u001b[32m'filter'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'agent_info.flow'\u001b[0m: \u001b[32m'judger'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[32m'group'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'record_id'\u001b[0m: \u001b[32m'record.record_id'\u001b[0m,\n",
       "                        \u001b[32m'flow'\u001b[0m: \u001b[32m'agent_info.flow'\u001b[0m,\n",
       "                        \u001b[32m'template'\u001b[0m: \u001b[32m'agent_info.template'\u001b[0m,\n",
       "                        \u001b[32m'criteria'\u001b[0m: \u001b[32m'agent_info.template_vars.criteria'\u001b[0m,\n",
       "                        \u001b[32m'model'\u001b[0m: \u001b[32m'parameters.model'\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m,\n",
       "                    \u001b[32m'columns'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'answers'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'id'\u001b[0m: \u001b[32m'job_id'\u001b[0m,\n",
       "                            \u001b[32m'model'\u001b[0m: \u001b[32m'model'\u001b[0m,\n",
       "                            \u001b[32m'criteria'\u001b[0m: \u001b[32m'criteria'\u001b[0m,\n",
       "                            \u001b[32m'template'\u001b[0m: \u001b[32m'template'\u001b[0m,\n",
       "                            \u001b[32m'flow'\u001b[0m: \u001b[32m'flow'\u001b[0m,\n",
       "                            \u001b[32m'reasons'\u001b[0m: \u001b[32m'outputs.reasons'\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m,\n",
       "                        \u001b[32m'meta'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'flow'\u001b[0m: \u001b[32m'agent_info.flow'\u001b[0m,\n",
       "                            \u001b[32m'template'\u001b[0m: \u001b[32m'agent_info.template'\u001b[0m,\n",
       "                            \u001b[32m'criteria'\u001b[0m: \u001b[32m'agent_info.template_vars.criteria'\u001b[0m,\n",
       "                            \u001b[32m'model'\u001b[0m: \u001b[32m'parameters.model'\u001b[0m,\n",
       "                            \u001b[32m'prediction'\u001b[0m: \u001b[32m'outputs.prediction'\u001b[0m,\n",
       "                            \u001b[32m'labels'\u001b[0m: \u001b[32m'outputs.labels'\u001b[0m,\n",
       "                            \u001b[32m'confidence'\u001b[0m: \u001b[32m'outputs.confidence'\u001b[0m,\n",
       "                            \u001b[32m'timestamp'\u001b[0m: \u001b[32m'timestamp'\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'flow'\u001b[0m: \u001b[32m'eval'\u001b[0m,\n",
       "            \u001b[32m'num_runs'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "            \u001b[32m'concurrent'\u001b[0m: \u001b[1;36m20\u001b[0m,\n",
       "            \u001b[32m'agent'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'name'\u001b[0m: \u001b[32m'lc'\u001b[0m,\n",
       "                \u001b[32m'template'\u001b[0m: \u001b[32m'differences'\u001b[0m,\n",
       "                \u001b[32m'criteria'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'trans_simplified'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                \u001b[32m'model'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'haiku'\u001b[0m, \u001b[32m'gpt4o'\u001b[0m, \u001b[32m'sonnet'\u001b[0m, \u001b[32m'gemini15pro'\u001b[0m\u001b[1m]\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'parameters'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'answers'\u001b[0m: \u001b[32m'answers'\u001b[0m, \u001b[32m'meta'\u001b[0m: \u001b[32m'meta'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'judger'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'name'\u001b[0m: \u001b[32m'previous runs and synth'\u001b[0m,\n",
       "                    \u001b[32m'type'\u001b[0m: \u001b[32m'job'\u001b[0m,\n",
       "                    \u001b[32m'dataset'\u001b[0m: \u001b[32m'dmrc-analysis.toxicity.flow'\u001b[0m,\n",
       "                    \u001b[32m'max_records_per_group'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "                    \u001b[32m'filter'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'agent_info.flow'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'judger'\u001b[0m, \u001b[32m'synth'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,\n",
       "                    \u001b[32m'group'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'model'\u001b[0m: \u001b[32m'parameters.model'\u001b[0m,\n",
       "                        \u001b[32m'record_id'\u001b[0m: \u001b[32m'record.record_id'\u001b[0m,\n",
       "                        \u001b[32m'flow'\u001b[0m: \u001b[32m'agent_info.flow'\u001b[0m,\n",
       "                        \u001b[32m'template'\u001b[0m: \u001b[32m'agent_info.template'\u001b[0m,\n",
       "                        \u001b[32m'criteria'\u001b[0m: \u001b[32m'agent_info.template_vars.criteria'\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m,\n",
       "                    \u001b[32m'columns'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                        \u001b[32m'answers'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'id'\u001b[0m: \u001b[32m'job_id'\u001b[0m,\n",
       "                            \u001b[32m'flow'\u001b[0m: \u001b[32m'agent_info.flow'\u001b[0m,\n",
       "                            \u001b[32m'reasons'\u001b[0m: \u001b[32m'outputs.reasons'\u001b[0m,\n",
       "                            \u001b[32m'model'\u001b[0m: \u001b[32m'model'\u001b[0m,\n",
       "                            \u001b[32m'criteria'\u001b[0m: \u001b[32m'criteria'\u001b[0m,\n",
       "                            \u001b[32m'template'\u001b[0m: \u001b[32m'template'\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m,\n",
       "                        \u001b[32m'meta'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                            \u001b[32m'flow'\u001b[0m: \u001b[32m'agent_info.flow'\u001b[0m,\n",
       "                            \u001b[32m'template'\u001b[0m: \u001b[32m'agent_info.template'\u001b[0m,\n",
       "                            \u001b[32m'criteria'\u001b[0m: \u001b[32m'agent_info.template_vars.criteria'\u001b[0m,\n",
       "                            \u001b[32m'model'\u001b[0m: \u001b[32m'parameters.model'\u001b[0m,\n",
       "                            \u001b[32m'prediction'\u001b[0m: \u001b[32m'outputs.prediction'\u001b[0m,\n",
       "                            \u001b[32m'labels'\u001b[0m: \u001b[32m'outputs.labels'\u001b[0m,\n",
       "                            \u001b[32m'confidence'\u001b[0m: \u001b[32m'outputs.confidence'\u001b[0m,\n",
       "                            \u001b[32m'timestamp'\u001b[0m: \u001b[32m'timestamp'\u001b[0m\n",
       "                        \u001b[1m}\u001b[0m\n",
       "                    \u001b[1m}\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'run'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'local'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'trans'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'trans news articles'\u001b[0m,\n",
       "            \u001b[32m'type'\u001b[0m: \u001b[32m'file'\u001b[0m,\n",
       "            \u001b[32m'uri'\u001b[0m: \u001b[32m'gs://dmrc-platforms/data/tja_train.jsonl'\u001b[0m,\n",
       "            \u001b[32m'columns'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'record_id'\u001b[0m: \u001b[32m'id'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'text'\u001b[0m, \u001b[32m'title'\u001b[0m: \u001b[32m'name'\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'save'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'bq'\u001b[0m, \u001b[32m'destination'\u001b[0m: \u001b[32m'dmrc-analysis.toxicity.flow'\u001b[0m, \u001b[32m'schema'\u001b[0m: \u001b[32m'flow.json'\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from buttermilk import BM\n",
    "from promptflow.tracing import trace, start_trace\n",
    "from rich import print as rprint\n",
    "\n",
    "import os\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Load config, specifying overrides for our particular job\n",
    "with initialize(version_base=None, config_path=\"./conf\"):\n",
    "    cfg = compose(config_name='config',\n",
    "                  overrides=[\"+data=trans\", \"+step=trans\", \"+save=bq\", \"job=score\",\"source=notebook\"])\n",
    "\n",
    "# Load the main ButterMilk singleton instance\n",
    "# This takes care of credentials, save paths, and other defaults\n",
    "bm = BM(cfg=cfg)\n",
    "\n",
    "# Print config\n",
    "rprint(OmegaConf.to_container(bm.cfg, resolve=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step assesses content against our criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an orchestrator to conduct all combinations of jobs we want to run\n",
    "from buttermilk.runner.orchestrator import MultiFlowOrchestrator\n",
    "orchestrator = MultiFlowOrchestrator(step=cfg.step[0], data=cfg.data, save=cfg.save, source=cfg.source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:15:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job cLWruB8mzRSZNGYQ7mHPPV.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job cLWruB8mzRSZNGYQ7mHPPV.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:00\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job XSG8q7NYvpXe6Egjd6J538.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job XSG8q7NYvpXe6Egjd6J538.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job dxFeXFd8b23dkKuyt9ASr4.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job dxFeXFd8b23dkKuyt9ASr4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:28\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job h2yUoJ6ii2YUwdJ5cgvF8z.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job h2yUoJ6ii2YUwdJ5cgvF8z.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job 53roc2dk5JgdJpRKHL4w8p.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job 53roc2dk5JgdJpRKHL4w8p.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job JfkvvzGyWazCE7VeNAoPdZ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job JfkvvzGyWazCE7VeNAoPdZ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job 57DFDLQVdgLoDMTXx5dqgN.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job 57DFDLQVdgLoDMTXx5dqgN.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job HL5jomi8aeeHVUPR8RWQP4.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job HL5jomi8aeeHVUPR8RWQP4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_Y63Jb8 with job aw5XUVNj4Npjgjra7eY6pi.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_Y63Jb8 with job aw5XUVNj4Npjgjra7eY6pi.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job QLps4nSkZ8rePzvwaSjEkD.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job QLps4nSkZ8rePzvwaSjEkD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job J9c3extkYp7rz79foP5Mud.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job J9c3extkYp7rz79foP5Mud.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job HPzxnLTV29tQpyZZNS3zqL.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job HPzxnLTV29tQpyZZNS3zqL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job BvhWs8pSrsMkSmnvraqyCz.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job BvhWs8pSrsMkSmnvraqyCz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job LGy5Lik33erZZY5wFLHLjJ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job LGy5Lik33erZZY5wFLHLjJ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job 7QnTxYgeVJXnBxyCbbuaPp.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job 7QnTxYgeVJXnBxyCbbuaPp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job EcWp7EsGugcWd5x3Dyqkg6.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job EcWp7EsGugcWd5x3Dyqkg6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job nVWYR9kDTCwjc8cMbMwosS.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job nVWYR9kDTCwjc8cMbMwosS.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_XZwVr8 with job fZPBVFDncBy4k9XAwknyiy.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_XZwVr8 with job fZPBVFDncBy4k9XAwknyiy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job 2uSTV8fpvrfLeRWbPZg4Co.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job 2uSTV8fpvrfLeRWbPZg4Co.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job 4RqF8a9sfvVT2aty8vbrM7.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job 4RqF8a9sfvVT2aty8vbrM7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:17:41\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x6834095d7a656943108d1e84fd24e6ab\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xf18cb89aba1622f3e4d0456833fe3d4a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x23146f9a4f6a6208a7ccc0e70677690f\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xb2de2b7be7690b0d894dc0931601e26e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x7a830fc7284d144f3aea8559a267f590\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x8517cb5879d3f5498f994a1354eb54bf\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x815ffe1ffc5e6ea3766370137fa70770\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xf0d0167f11ebb98ac7b19d81d000d356\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x54f43324387a72f5a82683de421bcc04\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x9e0c59b2ff77fef2540baadd20ba7911\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xc006efd0bad4c3ea0b3fad8d8f1c04b3\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x97f9c59ea30999a4e33604f44e00211d\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xc371b3ff9ebe3379535f08eea0b0bd8e\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0xbb43175dd5e09c4cd65ac21fa5b041e3\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x8547e7efe787550902c8d992de33535b\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x51778613a4cc168e8bb98e73d0cd2059\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x5e68f186f3d389a1f87d459f4c287354\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x528d851c57a8e3976bcef8e04162b4e0\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x16c85236b59ea0654500665e26d59c5a\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x6c039670eeadcea5b9a3f2503ae29258\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=automod&uiTraceId=0x47ed4023ff74fdf57d645c1a88e0f3ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 67.10 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 67.10 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Y63Jb8 completed job cLWruB8mzRSZNGYQ7mHPPV successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Y63Jb8 completed job cLWruB8mzRSZNGYQ7mHPPV successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:33\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 64.08 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 64.08 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Y63Jb8 completed job h2yUoJ6ii2YUwdJ5cgvF8z successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Y63Jb8 completed job h2yUoJ6ii2YUwdJ5cgvF8z successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:35\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 66.81 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 66.81 seconds\n",
      "I0000 00:00:1730855915.327291 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Y63Jb8 completed job XSG8q7NYvpXe6Egjd6J538 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Y63Jb8 completed job XSG8q7NYvpXe6Egjd6J538 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:37\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 63.27 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 63.27 seconds\n",
      "I0000 00:00:1730855917.739350 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_XZwVr8 completed job QLps4nSkZ8rePzvwaSjEkD successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_XZwVr8 completed job QLps4nSkZ8rePzvwaSjEkD successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:39\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 70.96 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 70.96 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Y63Jb8 completed job dxFeXFd8b23dkKuyt9ASr4 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Y63Jb8 completed job dxFeXFd8b23dkKuyt9ASr4 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job YB4Z5Du3NQUempEnFu4dHc.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job YB4Z5Du3NQUempEnFu4dHc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job Qgi5p3fnPShknhHsTNBf2X.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job Qgi5p3fnPShknhHsTNBf2X.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job eQxSgghpeXdWoXo62iexuh.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job eQxSgghpeXdWoXo62iexuh.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job gMpQ2ztNHAeamezPaa4Bv4.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job gMpQ2ztNHAeamezPaa4Bv4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:42\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job fWqy7b8vrhTMHH2L2YiJw4.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job fWqy7b8vrhTMHH2L2YiJw4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 73.68 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 73.68 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_XZwVr8 completed job HPzxnLTV29tQpyZZNS3zqL successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_XZwVr8 completed job HPzxnLTV29tQpyZZNS3zqL successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 77.44 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 77.44 seconds\n",
      "I0000 00:00:1730855932.243629 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_XZwVr8 completed job J9c3extkYp7rz79foP5Mud successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_XZwVr8 completed job J9c3extkYp7rz79foP5Mud successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job JSmi3ZMA3PFVa6Ahe2V4Pt.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job JSmi3ZMA3PFVa6Ahe2V4Pt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:18:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_MLvzy7 with job au2yh7SCwA554Zbced6diJ.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_MLvzy7 with job au2yh7SCwA554Zbced6diJ.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:07\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 86.70 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 86.70 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:09\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MLvzy7 completed job 2uSTV8fpvrfLeRWbPZg4Co successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MLvzy7 completed job 2uSTV8fpvrfLeRWbPZg4Co successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job iz5ZSzhxx2xj7uXs4tsRKE.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job iz5ZSzhxx2xj7uXs4tsRKE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 89.51 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 89.51 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:12\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MLvzy7 completed job 4RqF8a9sfvVT2aty8vbrM7 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MLvzy7 completed job 4RqF8a9sfvVT2aty8vbrM7 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 97.55 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 97.55 seconds\n",
      "I0000 00:00:1730855953.055125 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:14\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_XZwVr8 completed job BvhWs8pSrsMkSmnvraqyCz successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_XZwVr8 completed job BvhWs8pSrsMkSmnvraqyCz successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job aCzJSiwe2BXrrtYtzFXoze.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job aCzJSiwe2BXrrtYtzFXoze.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job jgSUYsRrKUqzh2cRWTNKzD.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job jgSUYsRrKUqzh2cRWTNKzD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:15\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:26\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 31.09 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 31.09 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:29\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_XZwVr8 completed job EcWp7EsGugcWd5x3Dyqkg6 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_XZwVr8 completed job EcWp7EsGugcWd5x3Dyqkg6 successfully.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with llama31_70b...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with llama31_70b...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job jvJLvWhMxQTSFGNZYKMpbo.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job jvJLvWhMxQTSFGNZYKMpbo.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:30\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with sonnet...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with sonnet...\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:34\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 39.94 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 39.94 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:36\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_XZwVr8 completed job 7QnTxYgeVJXnBxyCbbuaPp successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_XZwVr8 completed job 7QnTxYgeVJXnBxyCbbuaPp successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:40\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job PpiGK775bA6eRBpu8DpX8e.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job PpiGK775bA6eRBpu8DpX8e.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:46\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 64.03 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 64.03 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:48\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Y63Jb8 completed job 53roc2dk5JgdJpRKHL4w8p successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Y63Jb8 completed job 53roc2dk5JgdJpRKHL4w8p successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with haiku...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with haiku...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job Vsxk6umGsVoegJ85r929vN.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job Vsxk6umGsVoegJ85r929vN.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:49\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 66.85 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 66.85 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:51\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_XZwVr8 completed job LGy5Lik33erZZY5wFLHLjJ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_XZwVr8 completed job LGy5Lik33erZZY5wFLHLjJ successfully.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job fChArPAKhm6yDCEDFq8btB.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job fChArPAKhm6yDCEDFq8btB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:52\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 69.30 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 69.30 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:53\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MLvzy7 completed job Qgi5p3fnPShknhHsTNBf2X successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MLvzy7 completed job Qgi5p3fnPShknhHsTNBf2X successfully.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job PAxZfpLHrkrMFVfzvqCBKh.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job PAxZfpLHrkrMFVfzvqCBKh.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:54\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 72.24 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 72.24 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:56\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_MLvzy7 completed job YB4Z5Du3NQUempEnFu4dHc successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_MLvzy7 completed job YB4Z5Du3NQUempEnFu4dHc successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gpt4o...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gpt4o...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:19:57\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_NuPAyP with job AUNA6ujTciFxLZmuPqejAb.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_NuPAyP with job AUNA6ujTciFxLZmuPqejAb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:01\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with llama31_70b in 46.26 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with llama31_70b in 46.26 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:03\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_XZwVr8 completed job nVWYR9kDTCwjc8cMbMwosS successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_XZwVr8 completed job nVWYR9kDTCwjc8cMbMwosS successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:04\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_hyJL3P with job BzPGqaspXeMLWHrZdsbXpV.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_hyJL3P with job BzPGqaspXeMLWHrZdsbXpV.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:08\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 86.19 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 86.19 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:10\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Y63Jb8 completed job JfkvvzGyWazCE7VeNAoPdZ successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Y63Jb8 completed job JfkvvzGyWazCE7VeNAoPdZ successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_hyJL3P with job UdVHmPWtCyJLHkRtDPxVjp.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_hyJL3P with job UdVHmPWtCyJLHkRtDPxVjp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:11\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with haiku in 88.73 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with haiku in 88.73 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 184] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Inserting 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m save.py[ 191] \u001b[1;30mINFO\u001b[0m Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Successfully pushed 1 rows to BigQuery table dmrc-analysis.toxicity.flow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  89] \u001b[1;30mDEBUG\u001b[0m \u001b[32mAgent lc_Y63Jb8 completed job HL5jomi8aeeHVUPR8RWQP4 successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Agent lc_Y63Jb8 completed job HL5jomi8aeeHVUPR8RWQP4 successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m orchestrator.py[  81] \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting task for Agent lc_hyJL3P with job DushFYBE2asAkCZD4Hsux9.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Starting task for Agent lc_hyJL3P with job DushFYBE2asAkCZD4Hsux9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:13\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 204] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoking chain with gemini15pro...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoking chain with gemini15pro...\n",
      "I0000 00:00:1730856019.541340 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-06 11:20:21\u001b[0m \u001b[35mJ5HW6L4KT6\u001b[0m \u001b[34mbuttermilk\u001b[0m lc.py[ 215] \u001b[1;30mDEBUG\u001b[0m \u001b[32mInvoked chain with gpt4o in 65.75 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:buttermilk:Invoked chain with gpt4o in 65.75 seconds\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "I0000 00:00:1730856021.740277 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1730856022.169509 28160940 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    }
   ],
   "source": [
    "await orchestrator.run_tasks()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second step is a synthesis of previous draft answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an orchestrator to conduct all combinations of jobs we want to run\n",
    "from buttermilk.runner.orchestrator import MultiFlowOrchestrator\n",
    "orchestrator = MultiFlowOrchestrator(step=cfg.step[1], data=cfg.data, save=cfg.save, source=cfg.source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the dataset so we can make sure the inputs look ok\n",
    "rprint(orchestrator._dataset.sample().answers.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await orchestrator.run_tasks()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third step, we summarise the answers, similarities, and differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an orchestrator to conduct all combinations of jobs we want to run\n",
    "from buttermilk.runner.orchestrator import MultiFlowOrchestrator\n",
    "orchestrator = MultiFlowOrchestrator(step=cfg.step[2], data=cfg.data, save=cfg.save, source=cfg.source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await orchestrator.run_tasks()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
