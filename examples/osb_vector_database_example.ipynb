{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSB Vector Database Example\n",
    "\n",
    "This notebook demonstrates how to create and use a vector database from Oversight Board full text data using Buttermilk's ChromaDB integration.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll show how to:\n",
    "1. Load OSB JSON data using existing data loaders\n",
    "2. Generate embeddings and create a ChromaDB vector store\n",
    "3. Use the generic RAG agent for interactive question answering\n",
    "4. Demonstrate semantic search capabilities\n",
    "\n",
    "This example uses the generic infrastructure that works with any JSON dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration Setup\n",
    "\n",
    "First, let's set up the configuration for our OSB vector database pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 15:56:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m bm_init.py:778 Logging set up for run: platform='local' name='bm_api' job='osb_vectorise' run_id='20250617T0556Z-7Dcu-docker-desktop-debian' ip=None node_name='docker-desktop' save_dir='/tmp/tmpxn1i2ou8/bm_api/osb_vectorise/20250617T0556Z-7Dcu-docker-desktop-debian' flow_api=None. Save directory: /tmp/tmpxn1i2ou8/bm_api/osb_vectorise/20250617T0556Z-7Dcu-docker-desktop-debian\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized Buttermilk <span style=\"font-weight: bold\">(</span>bm<span style=\"font-weight: bold\">)</span> with configuration:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized Buttermilk \u001b[1m(\u001b[0mbm\u001b[1m)\u001b[0m with configuration:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'platform'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'local'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'bm_api'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'job'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'osb_vectorise'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'run_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'20250617T0556Z-7Dcu-docker-desktop-debian'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'docker-desktop'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'save_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/tmp/tmpxn1i2ou8/bm_api/osb_vectorise/20250617T0556Z-7Dcu-docker-desktop-debian'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'connections'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'secret_provider'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'models_secret'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dev__llm__connections'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'credentials_secret'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dev__shared_credentials'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'logger_cfg'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'location'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us-central1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'verbose'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'pubsub'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'jobs_subscription'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'jobs-sub'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'status_subscription'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'flow-sub'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'status_topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'jobs_topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'jobs'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'clouds'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'quota_project_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'vertex'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'region'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us-central1'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'location'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us-central1'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'bucket'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-de'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'tracing'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'enabled'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'api_key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'weave'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'otlp_headers'</span>: <span style=\"font-weight: bold\">{}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'datasets'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'save_dir_base'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/tmp/tmpxn1i2ou8'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'platform'\u001b[0m: \u001b[32m'local'\u001b[0m,\n",
       "    \u001b[32m'name'\u001b[0m: \u001b[32m'bm_api'\u001b[0m,\n",
       "    \u001b[32m'job'\u001b[0m: \u001b[32m'osb_vectorise'\u001b[0m,\n",
       "    \u001b[32m'run_id'\u001b[0m: \u001b[32m'20250617T0556Z-7Dcu-docker-desktop-debian'\u001b[0m,\n",
       "    \u001b[32m'node_name'\u001b[0m: \u001b[32m'docker-desktop'\u001b[0m,\n",
       "    \u001b[32m'save_dir'\u001b[0m: \u001b[32m'/tmp/tmpxn1i2ou8/bm_api/osb_vectorise/20250617T0556Z-7Dcu-docker-desktop-debian'\u001b[0m,\n",
       "    \u001b[32m'connections'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'secret_provider'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m,\n",
       "        \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m,\n",
       "        \u001b[32m'models_secret'\u001b[0m: \u001b[32m'dev__llm__connections'\u001b[0m,\n",
       "        \u001b[32m'credentials_secret'\u001b[0m: \u001b[32m'dev__shared_credentials'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'logger_cfg'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m, \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m, \u001b[32m'location'\u001b[0m: \u001b[32m'us-central1'\u001b[0m, \u001b[32m'verbose'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'pubsub'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m,\n",
       "        \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m,\n",
       "        \u001b[32m'jobs_subscription'\u001b[0m: \u001b[32m'jobs-sub'\u001b[0m,\n",
       "        \u001b[32m'status_subscription'\u001b[0m: \u001b[32m'flow-sub'\u001b[0m,\n",
       "        \u001b[32m'status_topic'\u001b[0m: \u001b[32m'flow'\u001b[0m,\n",
       "        \u001b[32m'jobs_topic'\u001b[0m: \u001b[32m'jobs'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'clouds'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m, \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m, \u001b[32m'quota_project_id'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'type'\u001b[0m: \u001b[32m'vertex'\u001b[0m,\n",
       "            \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m,\n",
       "            \u001b[32m'region'\u001b[0m: \u001b[32m'us-central1'\u001b[0m,\n",
       "            \u001b[32m'location'\u001b[0m: \u001b[32m'us-central1'\u001b[0m,\n",
       "            \u001b[32m'bucket'\u001b[0m: \u001b[32m'prosocial-de'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'tracing'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'enabled'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'api_key'\u001b[0m: \u001b[32m''\u001b[0m, \u001b[32m'provider'\u001b[0m: \u001b[32m'weave'\u001b[0m, \u001b[32m'otlp_headers'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'datasets'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'save_dir_base'\u001b[0m: \u001b[32m'/tmp/tmpxn1i2ou8'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 15:56:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m nb.py:59 Starting interactive run for bm_api job osb_vectorise in notebook\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🚀 Buttermilk initialized for JSON-to-Vector tutorial\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🚀 Buttermilk initialized for JSON-to-Vector tutorial\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'osb_json'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcs'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gs://prosocial-public/osb/03_osb_fulltext_summaries.json'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'columns'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fulltext'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'result'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'result'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'location'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'location'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'case_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'case_date'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'topics'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'topics'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'standards'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'standards'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'recommendations'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'recommendations'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'job_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'job_id'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span><span style=\"font-weight: bold\">}}}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'osb_vector'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'chromadb'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'persist_directory'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gs://prosocial-dev/data/osb/chromadb'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'collection_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'osb_fulltext'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'embedding_model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gemini-embedding-001'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'dimensionality'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'multi_field_embedding'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content_field'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1200</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_overlap'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'additional_fields'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source_field'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source_field'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'case_description'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source_field'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'reasoning'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source_field'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'recommendations'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'recommendations'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span><span style=\"font-weight: bold\">}]}}}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'osb_json'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'gcs'\u001b[0m, \u001b[32m'path'\u001b[0m: \u001b[32m'gs://prosocial-public/osb/03_osb_fulltext_summaries.json'\u001b[0m, \u001b[32m'columns'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'record_id'\u001b[0m: \u001b[32m'record_id'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'fulltext'\u001b[0m, \u001b[32m'metadata'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'title'\u001b[0m, \u001b[32m'description'\u001b[0m: \u001b[32m'content'\u001b[0m, \u001b[32m'result'\u001b[0m: \u001b[32m'result'\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'type'\u001b[0m, \u001b[32m'location'\u001b[0m: \u001b[32m'location'\u001b[0m, \u001b[32m'case_date'\u001b[0m: \u001b[32m'case_date'\u001b[0m, \u001b[32m'topics'\u001b[0m: \u001b[32m'topics'\u001b[0m, \u001b[32m'standards'\u001b[0m: \u001b[32m'standards'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[32m'reasons'\u001b[0m, \u001b[32m'recommendations'\u001b[0m: \u001b[32m'recommendations'\u001b[0m, \u001b[32m'job_id'\u001b[0m: \u001b[32m'job_id'\u001b[0m, \u001b[32m'timestamp'\u001b[0m: \u001b[32m'timestamp'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'osb_vector'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'chromadb'\u001b[0m, \u001b[32m'persist_directory'\u001b[0m: \u001b[32m'gs://prosocial-dev/data/osb/chromadb'\u001b[0m, \u001b[32m'collection_name'\u001b[0m: \u001b[32m'osb_fulltext'\u001b[0m, \u001b[32m'embedding_model'\u001b[0m: \u001b[32m'gemini-embedding-001'\u001b[0m, \u001b[32m'dimensionality'\u001b[0m: \u001b[1;36m3072\u001b[0m, \u001b[32m'multi_field_embedding'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'content_field'\u001b[0m: \u001b[32m'content'\u001b[0m, \u001b[32m'chunk_size'\u001b[0m: \u001b[1;36m1200\u001b[0m, \u001b[32m'chunk_overlap'\u001b[0m: \u001b[1;36m400\u001b[0m, \u001b[32m'additional_fields'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'source_field'\u001b[0m: \u001b[32m'title'\u001b[0m, \u001b[32m'chunk_type'\u001b[0m: \u001b[32m'title'\u001b[0m, \u001b[32m'min_length'\u001b[0m: \u001b[1;36m10\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'source_field'\u001b[0m: \u001b[32m'description'\u001b[0m, \u001b[32m'chunk_type'\u001b[0m: \u001b[32m'case_description'\u001b[0m, \u001b[32m'min_length'\u001b[0m: \u001b[1;36m50\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'source_field'\u001b[0m: \u001b[32m'reasons'\u001b[0m, \u001b[32m'chunk_type'\u001b[0m: \u001b[32m'reasoning'\u001b[0m, \u001b[32m'min_length'\u001b[0m: \u001b[1;36m100\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'source_field'\u001b[0m: \u001b[32m'recommendations'\u001b[0m, \u001b[32m'chunk_type'\u001b[0m: \u001b[32m'recommendations'\u001b[0m, \u001b[32m'min_length'\u001b[0m: \u001b[1;36m50\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 15:56:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m save.py:641 Successfully dumped data to local disk (JSON): /tmp/tmpxn1i2ou8/bm_api/osb_vectorise/20250617T0556Z-7Dcu-docker-desktop-debian/tmp_73vlg2h.json.\n",
      "\u001b[32m2025-06-17 15:56:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m save.py:215 Successfully saved data using dump_to_disk to: /tmp/tmpxn1i2ou8/bm_api/osb_vectorise/20250617T0556Z-7Dcu-docker-desktop-debian/tmp_73vlg2h.json.\n",
      "\u001b[32m2025-06-17 15:56:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m bm_init.py:864 {'message': 'Successfully saved data to: /tmp/tmpxn1i2ou8/bm_api/osb_vectorise/20250617T0556Z-7Dcu-docker-desktop-debian/tmp_73vlg2h.json', 'uri': '/tmp/tmpxn1i2ou8/bm_api/osb_vectorise/20250617T0556Z-7Dcu-docker-desktop-debian/tmp_73vlg2h.json', 'run_id': '20250617T0556Z-7Dcu-docker-desktop-debian'}\n"
     ]
    }
   ],
   "source": [
    "from rich import print\n",
    "from rich.pretty import pprint\n",
    "import asyncio\n",
    "import json\n",
    "from pathlib import Path\n",
    "import hydra\n",
    "from hydra import compose, initialize_config_dir\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "# Buttermilk imports - updated for unified storage system\n",
    "from buttermilk import logger\n",
    "from buttermilk.data.vector import ChromaDBEmbeddings, DefaultTextSplitter\n",
    "from buttermilk.agents.rag.rag_agent import RagAgent\n",
    "from buttermilk._core.config import AgentConfig\n",
    "from buttermilk._core.storage_config import StorageConfig  # New unified config\n",
    "from buttermilk._core.types import Record  # Enhanced Record with vector capabilities\n",
    "\n",
    "from buttermilk.utils.nb import init\n",
    "from buttermilk._core.dmrc import get_bm, set_bm\n",
    "\n",
    "# Initialize Buttermilk\n",
    "cfg = init(job=\"osb_vectorise\", overrides=[\"+storage=osb\", \"+agents=rag_generic\", \"+llms=lite\"])\n",
    "bm = get_bm()\n",
    "\n",
    "print(\"🚀 Buttermilk initialized for JSON-to-Vector tutorial\")\n",
    "pprint(cfg.storage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Components\n",
    "\n",
    "Let's create the storage, vector store, and text splitter components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 15:57:32\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:275 Loading embedding model: gemini-embedding-001\n",
      "\u001b[32m2025-06-17 15:57:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:283 Initializing ChromaDB client at: gs://prosocial-dev/data/osb/chromadb\n",
      "\u001b[32m2025-06-17 15:57:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:288 Using ChromaDB collection: osb_fulltext\n",
      "\u001b[32m2025-06-17 15:57:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:294 🔄 Auto-sync enabled: every 50 records OR every 10 minutes\n",
      "\u001b[32m2025-06-17 15:57:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m bm_init.py:994 🔄 Auto-initializing remote storage: gs://prosocial-dev/data/osb/chromadb\n",
      "\u001b[32m2025-06-17 15:57:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:359 ⏰ Local cache is 6.2 hours old, checking for updates...\n",
      "\u001b[32m2025-06-17 15:57:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:362 🔄 Syncing remote ChromaDB: gs://prosocial-dev/data/osb/chromadb\n",
      "\u001b[32m2025-06-17 15:57:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:318 ✅ ChromaDB cache ready at: /home/debian/.cache/buttermilk/chromadb/gs___prosocial-dev_data_osb_chromadb\n",
      "\u001b[32m2025-06-17 15:57:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:554 📖 Found existing collection 'osb_fulltext'\n",
      "\u001b[32m2025-06-17 15:57:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:574 ✅ Collection 'osb_fulltext' ready (7270 embeddings)\n",
      "\u001b[32m2025-06-17 15:57:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m bm_init.py:996 ✅ Storage ready for use\n",
      "\u001b[32m2025-06-17 15:57:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the clean BM API for all storage types\n",
    "source = bm.get_storage(cfg.storage.osb_json)\n",
    "\n",
    "# ✨ NEW: Auto-initialized storage (recommended for ChromaDB with remote storage)\n",
    "vectorstore = await bm.get_storage_async(cfg.storage.osb_vector)\n",
    "\n",
    "\n",
    "# Create text splitter\n",
    "chunker = DefaultTextSplitter(chunk_size=1200, chunk_overlap=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">📥 Loading live OSB data from GCS<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "📥 Loading live OSB data from GCS\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔗 Data source: gs:<span style=\"color: #800080; text-decoration-color: #800080\">//prosocial-public/osb/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">03_osb_fulltext_summaries.json</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔗 Data source: gs:\u001b[35m/\u001b[0m\u001b[35m/prosocial-public/osb/\u001b[0m\u001b[95m03_osb_fulltext_summaries.json\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">📚 Loading all documents from live dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "📚 Loading all documents from live dataset\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m file.py:298 \u001b[33mError converting data to Record at index 38: 2 validation errors for Record\n",
      "content.str\n",
      "  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "content.json-or-python[json=list[union[str,is-instance[Image]]],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]\n",
      "  Input should be an instance of Sequence [type=is_instance_of, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m file.py:298 \u001b[33mError converting data to Record at index 95: 2 validation errors for Record\n",
      "content.str\n",
      "  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "content.json-or-python[json=list[union[str,is-instance[Image]]],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]\n",
      "  Input should be an instance of Sequence [type=is_instance_of, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m file.py:298 \u001b[33mError converting data to Record at index 110: 2 validation errors for Record\n",
      "content.str\n",
      "  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "content.json-or-python[json=list[union[str,is-instance[Image]]],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]\n",
      "  Input should be an instance of Sequence [type=is_instance_of, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "✅ Loaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span> live OSB documents for vector processing\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "✅ Loaded \u001b[1;36m172\u001b[0m live OSB documents for vector processing\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load live OSB data from GCS\n",
    "print(\"📥 Loading live OSB data from GCS...\")\n",
    "\n",
    "print(f\"🔗 Data source: {source.path}\")\n",
    "\n",
    "# Load documents (limit for demo, remove limit for full production run)\n",
    "records = []\n",
    "doc_limit = None  # Set to None for full dataset\n",
    "\n",
    "print(f\"📚 Loading {doc_limit or 'all'} documents from live dataset...\")\n",
    "\n",
    "for record in source:\n",
    "    # Enhanced Record already has all needed capabilities - no conversion needed!\n",
    "    # The content field is what gets processed for vectors via text_content property\n",
    "    records.append(record)\n",
    "\n",
    "    if doc_limit and len(records) >= doc_limit:\n",
    "        break\n",
    "\n",
    "\n",
    "print(f\"\\n✅ Loaded {len(records)} live OSB documents for vector processing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Record</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">record_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'IG-1BMH3DQ6'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'job_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2hiUVzCPm446gHESkhkEsN'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1732142478414</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'result'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'leave up'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'summary'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'topics'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'War and conflict'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Dangerous organizations'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Human rights'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Prisoners of war'</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'standards'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Dangerous individuals and organizations'</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'location'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Ukraine'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'case_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2023-02-01'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">\"The Dangerous Organizations and Individuals policy prohibits content that 'praises,' 'substantively supports,' or 'represents' individuals and organizations designated as dangerous. However, an exception allows for discussions about the human rights of designated individuals or entities unless the content includes praise, substantive support, or representation of these entities.\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'The post discusses the captivity and unknown conditions of Azov Regiment soldiers, which constitutes a human rights issue. Calling attention to the status of prisoners of war and advocating for their return falls squarely within the policy exception for human rights discussions.'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'In January 2023, the Azov Regiment was removed from the Dangerous Organizations and Individuals list, as Meta distinguished them from certain far-right nationalist elements within the broader Azov movement. Therefore, the content does not fall under the prohibitive standards.'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Even if the Azov Regiment remained a designated dangerous organization, this content would be permitted under the human rights discussion exception. The post focuses exclusively on the welfare and rights of captured soldiers, without praising or supporting the organization's ideology or actions.\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'The use of the Azov Regiment symbol in this context serves to identify the subject matter of the human rights discussion rather than to promote or represent the organization. When organizational symbols are used to identify the subjects of legitimate human rights advocacy, rather than to promote the organization itself, such use falls within the scope of permitted discussion.'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'recommendations'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'Meta should update its internal guidelines and training for content moderators when any new policy is adopted, ensuring clarity and accuracy in enforcement.'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Meta should provide more transparency regarding error rates related to the 'praise' and 'support' of dangerous individuals and organizations.\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'Meta should implement an internal audit procedure to learn from automated enforcement mistakes to prevent future errors.'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Azov Removal'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">alt_text</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">ground_truth</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">uri</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\"result\": \"upheld\", \"title\": \"Azov Removal\",\"abstract\": \"A user appealed Meta\\'s decision to remove an Instagram post asking,\\n\"where is Azov?\" in Ukrainian. The post\\\\\\'s caption calls for soldiers of\\nthe Azov Regiment in Russian captivity to be returned.\",\"type\": \"Summary\",\"topic\": \"War and conflict\", \"standards\": [\"Dangerous individuals and organizations\",], \"location\": \"Ukraine\", \"Platform\": \"Instagram\",}\\n\\n\"type\": \"summary\", *Summary decisions examine cases in\\nwhich Meta has reversed its original decision on a piece of content\\nafter the Board brought it to the company\\'s attention. These decisions\\ninclude information about Meta\\'s acknowledged errors. They are approved\\nby a Board Member panel, not the full Board. They do not involve a\\npublic comment process and do not have precedential value for the Board.\\nSummary decisions provide transparency on Meta\\'s corrections and\\nhighlight areas in which the company could improve its policy\\nenforcement.*\\n\\n## Case Summary\\n\\nA user appealed Meta\\'s decision to remove an Instagram post asking,\\n\"where is Azov?\" in Ukrainian. The post\\\\\\'s caption calls for soldiers of\\nthe Azov Regiment in Russian captivity to be returned. After the Board\\nbrought the appeal to Meta\\'s attention, the company reversed its\\noriginal decision and restored the post.\\n\\n## Case Description and Background\\n\\nIn December 2022, an Instagram user created a post with an image of the\\nAzov Regiment symbol. Overlaying the symbol was text in Ukrainian\\nasking, \"where is Azov?\" The caption stated that more than 700 Azov\\nsoldiers remain in Russian captivity, with their conditions unknown. The\\nuser calls for their return, stating: \"we must scream until all the\\nAzovs are back from captivity!\"\\n\\nThe user appealed the removal of the post, emphasizing the importance of\\nsharing information during times of war. The user also highlighted that\\nthe content did not violate Meta\\'s policies, since Meta allows content\\ncommenting on the Azov Regiment. The post received nearly 800 views and\\nwas detected by Meta\\'s automated systems.\\n\\nMeta originally removed the post from Facebook under its [Dangerous\\nOrganizations and Individuals (DOI)\\npolicy](https://transparency.fb.com/en-gb/policies/community-standards/dangerous-individuals-organizations/), which prohibits\\ncontent that \"praises,\" \"substantively supports\" or \"represents\"\\nindividuals and organizations that Meta designates as dangerous.\\nHowever, Meta allows \"discussions about the human rights of designated\\nindividuals or members of designated dangerous entities, unless the\\ncontent includes other praise, substantive support or representation of\\ndesignated entities or other policy violations, such as incitement to\\nviolence.\"\\n\\nMeta told the Board that it removed the Azov Regiment from its Dangerous\\nOrganizations and Individuals list in January 2023. A [*Washington Post*\\narticle](https://www.washingtonpost.com/technology/2023/01/21/meta-azov-regiment-facebook-oversight/) states that Meta now\\ndraws a distinction between the Azov Regiment, which it views as under\\nformal control of the Ukrainian government, and other elements of the\\nbroader Azov movement, some which the company considers far-right\\nnationalists and still designates as dangerous.\\n\\nAfter the Board brought this case to Meta\\'s attention, the company\\ndetermined that its removal was incorrect and restored the content to\\nInstagram. The company acknowledged that the Azov Regiment is no longer\\ndesignated as a dangerous organization. Additionally, Meta recognized\\nthat regardless of the Azov Regiment\\'s designation, this post falls\\nunder the exception that allows references to dangerous individuals and\\norganizations when discussing the human rights of individuals and\\nmembers of designated entities.\\n\\n## Board Authority and Scope\\n\\nThe Board has authority to review Meta\\'s decision following an appeal\\nfrom the person whose content was removed (Charter Article 2, Section 1;\\nBylaws Article 3, Section 1).\\n\\nWhen Meta acknowledges that it made an error and reverses its decision\\non a case under consideration for Board review, the Board may select\\nthat case for a summary decision (Bylaws Article 2, Section 2.1.3). The\\nBoard reviews the original decision to increase understanding of the\\ncontent moderation processes involved, reduce errors and increase\\nfairness for Facebook and Instagram users.\\n\\n## Case Significance\\n\\nThis case highlights shortcomings in the updating of Meta\\'s Dangerous\\nOrganizations and Individuals list and its enforcement, which raises\\ngreater concerns during times of war. The case also illustrates the\\nsystemic challenges in enforcing exceptions to Meta\\'s policy on\\nDangerous Organizations and Individuals.\\n\\nPreviously, the Board issued a recommendation stating that Meta\\'s\\nDangerous Organizations and Individuals policy should allow users to\\ndiscuss alleged human rights abuses of members of dangerous\\norganizations ( [Öcalan\\'s\\nIsolation](https://www.oversightboard.com/decision/ig-i9dp23ib/) decision, recommendation no. 5),\\nwhich Meta committed to implement. Furthermore, the Azov Regiment was\\nremoved from Meta\\'s Dangerous Organizations and Individuals list in\\nJanuary 2023. The Board has issued a recommendation stating that, when\\nany new policy is adopted, internal guidance and training should be\\nprovided to content moderators ( [Öcalan\\'s\\nIsolation](https://www.oversightboard.com/decision/ig-i9dp23ib/) decision, recommendation no. 8).\\nThe Board has also issued recommendations on the enforcement accuracy of\\nMeta\\'s policies by calling for further transparency regarding\\nenforcement error rates on the \"praise\" and \"support\" of dangerous\\nindividuals and organizations ( [Öcalan\\'s\\nIsolation](https://www.oversightboard.com/decision/ig-i9dp23ib/) decision, recommendation no.\\n12), and the implementation of an internal audit procedure to learn from\\npast automated enforcement mistakes ( [Breast Cancer Symptoms and\\nNudity](https://www.oversightboard.com/decision/ig-7thr3si1/) decision, recommendation no. 5).\\nFully implementing these recommendations could help Meta decrease the\\nnumber of similar content moderation errors.\\n\\n## Decision\\n\\nThe Board overturns Meta\\'s original decision to remove the content. The\\nBoard acknowledges Meta\\'s correction of its initial error once the Board\\nbrought the case to Meta\\'s attention.\\n\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">mime</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text/plain'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">file_path</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">chunks</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">chunks_path</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">images</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">text_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\"result\": \"upheld\", \"title\": \"Azov Removal\",\"abstract\": \"A user appealed Meta\\'s decision to remove an Instagram post asking,\\n\"where is Azov?\" in Ukrainian. The post\\\\\\'s caption calls for soldiers of\\nthe Azov Regiment in Russian captivity to be returned.\",\"type\": \"Summary\",\"topic\": \"War and conflict\", \"standards\": [\"Dangerous individuals and organizations\",], \"location\": \"Ukraine\", \"Platform\": \"Instagram\",}\\n\\n\"type\": \"summary\", *Summary decisions examine cases in\\nwhich Meta has reversed its original decision on a piece of content\\nafter the Board brought it to the company\\'s attention. These decisions\\ninclude information about Meta\\'s acknowledged errors. They are approved\\nby a Board Member panel, not the full Board. They do not involve a\\npublic comment process and do not have precedential value for the Board.\\nSummary decisions provide transparency on Meta\\'s corrections and\\nhighlight areas in which the company could improve its policy\\nenforcement.*\\n\\n## Case Summary\\n\\nA user appealed Meta\\'s decision to remove an Instagram post asking,\\n\"where is Azov?\" in Ukrainian. The post\\\\\\'s caption calls for soldiers of\\nthe Azov Regiment in Russian captivity to be returned. After the Board\\nbrought the appeal to Meta\\'s attention, the company reversed its\\noriginal decision and restored the post.\\n\\n## Case Description and Background\\n\\nIn December 2022, an Instagram user created a post with an image of the\\nAzov Regiment symbol. Overlaying the symbol was text in Ukrainian\\nasking, \"where is Azov?\" The caption stated that more than 700 Azov\\nsoldiers remain in Russian captivity, with their conditions unknown. The\\nuser calls for their return, stating: \"we must scream until all the\\nAzovs are back from captivity!\"\\n\\nThe user appealed the removal of the post, emphasizing the importance of\\nsharing information during times of war. The user also highlighted that\\nthe content did not violate Meta\\'s policies, since Meta allows content\\ncommenting on the Azov Regiment. The post received nearly 800 views and\\nwas detected by Meta\\'s automated systems.\\n\\nMeta originally removed the post from Facebook under its [Dangerous\\nOrganizations and Individuals (DOI)\\npolicy](https://transparency.fb.com/en-gb/policies/community-standards/dangerous-individuals-organizations/), which prohibits\\ncontent that \"praises,\" \"substantively supports\" or \"represents\"\\nindividuals and organizations that Meta designates as dangerous.\\nHowever, Meta allows \"discussions about the human rights of designated\\nindividuals or members of designated dangerous entities, unless the\\ncontent includes other praise, substantive support or representation of\\ndesignated entities or other policy violations, such as incitement to\\nviolence.\"\\n\\nMeta told the Board that it removed the Azov Regiment from its Dangerous\\nOrganizations and Individuals list in January 2023. A [*Washington Post*\\narticle](https://www.washingtonpost.com/technology/2023/01/21/meta-azov-regiment-facebook-oversight/) states that Meta now\\ndraws a distinction between the Azov Regiment, which it views as under\\nformal control of the Ukrainian government, and other elements of the\\nbroader Azov movement, some which the company considers far-right\\nnationalists and still designates as dangerous.\\n\\nAfter the Board brought this case to Meta\\'s attention, the company\\ndetermined that its removal was incorrect and restored the content to\\nInstagram. The company acknowledged that the Azov Regiment is no longer\\ndesignated as a dangerous organization. Additionally, Meta recognized\\nthat regardless of the Azov Regiment\\'s designation, this post falls\\nunder the exception that allows references to dangerous individuals and\\norganizations when discussing the human rights of individuals and\\nmembers of designated entities.\\n\\n## Board Authority and Scope\\n\\nThe Board has authority to review Meta\\'s decision following an appeal\\nfrom the person whose content was removed (Charter Article 2, Section 1;\\nBylaws Article 3, Section 1).\\n\\nWhen Meta acknowledges that it made an error and reverses its decision\\non a case under consideration for Board review, the Board may select\\nthat case for a summary decision (Bylaws Article 2, Section 2.1.3). The\\nBoard reviews the original decision to increase understanding of the\\ncontent moderation processes involved, reduce errors and increase\\nfairness for Facebook and Instagram users.\\n\\n## Case Significance\\n\\nThis case highlights shortcomings in the updating of Meta\\'s Dangerous\\nOrganizations and Individuals list and its enforcement, which raises\\ngreater concerns during times of war. The case also illustrates the\\nsystemic challenges in enforcing exceptions to Meta\\'s policy on\\nDangerous Organizations and Individuals.\\n\\nPreviously, the Board issued a recommendation stating that Meta\\'s\\nDangerous Organizations and Individuals policy should allow users to\\ndiscuss alleged human rights abuses of members of dangerous\\norganizations ( [Öcalan\\'s\\nIsolation](https://www.oversightboard.com/decision/ig-i9dp23ib/) decision, recommendation no. 5),\\nwhich Meta committed to implement. Furthermore, the Azov Regiment was\\nremoved from Meta\\'s Dangerous Organizations and Individuals list in\\nJanuary 2023. The Board has issued a recommendation stating that, when\\nany new policy is adopted, internal guidance and training should be\\nprovided to content moderators ( [Öcalan\\'s\\nIsolation](https://www.oversightboard.com/decision/ig-i9dp23ib/) decision, recommendation no. 8).\\nThe Board has also issued recommendations on the enforcement accuracy of\\nMeta\\'s policies by calling for further transparency regarding\\nenforcement error rates on the \"praise\" and \"support\" of dangerous\\nindividuals and organizations ( [Öcalan\\'s\\nIsolation](https://www.oversightboard.com/decision/ig-i9dp23ib/) decision, recommendation no.\\n12), and the implementation of an internal audit procedure to learn from\\npast automated enforcement mistakes ( [Breast Cancer Symptoms and\\nNudity](https://www.oversightboard.com/decision/ig-7thr3si1/) decision, recommendation no. 5).\\nFully implementing these recommendations could help Meta decrease the\\nnumber of similar content moderation errors.\\n\\n## Decision\\n\\nThe Board overturns Meta\\'s original decision to remove the content. The\\nBoard acknowledges Meta\\'s correction of its initial error once the Board\\nbrought the case to Meta\\'s attention.\\n\\n'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mRecord\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mrecord_id\u001b[0m=\u001b[32m'IG-1BMH3DQ6'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'job_id'\u001b[0m: \u001b[32m'2hiUVzCPm446gHESkhkEsN'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'timestamp'\u001b[0m: \u001b[1;36m1732142478414\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'result'\u001b[0m: \u001b[32m'leave up'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'summary'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'topics'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'War and conflict'\u001b[0m, \u001b[32m'Dangerous organizations'\u001b[0m, \u001b[32m'Human rights'\u001b[0m, \u001b[32m'Prisoners of war'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'standards'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'Dangerous individuals and organizations'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'location'\u001b[0m: \u001b[32m'Ukraine'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'case_date'\u001b[0m: \u001b[32m'2023-02-01'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'reasons'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m\"The Dangerous Organizations and Individuals policy prohibits content that 'praises,' 'substantively supports,' or 'represents' individuals and organizations designated as dangerous. However, an exception allows for discussions about the human rights of designated individuals or entities unless the content includes praise, substantive support, or representation of these entities.\"\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'The post discusses the captivity and unknown conditions of Azov Regiment soldiers, which constitutes a human rights issue. Calling attention to the status of prisoners of war and advocating for their return falls squarely within the policy exception for human rights discussions.'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'In January 2023, the Azov Regiment was removed from the Dangerous Organizations and Individuals list, as Meta distinguished them from certain far-right nationalist elements within the broader Azov movement. Therefore, the content does not fall under the prohibitive standards.'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m\"Even if the Azov Regiment remained a designated dangerous organization, this content would be permitted under the human rights discussion exception. The post focuses exclusively on the welfare and rights of captured soldiers, without praising or supporting the organization's ideology or actions.\"\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'The use of the Azov Regiment symbol in this context serves to identify the subject matter of the human rights discussion rather than to promote or represent the organization. When organizational symbols are used to identify the subjects of legitimate human rights advocacy, rather than to promote the organization itself, such use falls within the scope of permitted discussion.'\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'recommendations'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'Meta should update its internal guidelines and training for content moderators when any new policy is adopted, ensuring clarity and accuracy in enforcement.'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m\"Meta should provide more transparency regarding error rates related to the 'praise' and 'support' of dangerous individuals and organizations.\"\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'Meta should implement an internal audit procedure to learn from automated enforcement mistakes to prevent future errors.'\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Azov Removal'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33malt_text\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mground_truth\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33muri\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mcontent\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"result\": \"upheld\", \"title\": \"Azov Removal\",\"abstract\": \"A user appealed Meta\\'s decision to remove an Instagram post asking,\\n\"where is Azov?\" in Ukrainian. The post\\\\\\'s caption calls for soldiers of\\nthe Azov Regiment in Russian captivity to be returned.\",\"type\": \"Summary\",\"topic\": \"War and conflict\", \"standards\": \u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"Dangerous individuals and organizations\",\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \"location\": \"Ukraine\", \"Platform\": \"Instagram\",\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n\"type\": \"summary\", *Summary decisions examine cases in\\nwhich Meta has reversed its original decision on a piece of content\\nafter the Board brought it to the company\\'s attention. These decisions\\ninclude information about Meta\\'s acknowledged errors. They are approved\\nby a Board Member panel, not the full Board. They do not involve a\\npublic comment process and do not have precedential value for the Board.\\nSummary decisions provide transparency on Meta\\'s corrections and\\nhighlight areas in which the company could improve its policy\\nenforcement.*\\n\\n## Case Summary\\n\\nA user appealed Meta\\'s decision to remove an Instagram post asking,\\n\"where is Azov?\" in Ukrainian. The post\\\\\\'s caption calls for soldiers of\\nthe Azov Regiment in Russian captivity to be returned. After the Board\\nbrought the appeal to Meta\\'s attention, the company reversed its\\noriginal decision and restored the post.\\n\\n## Case Description and Background\\n\\nIn December 2022, an Instagram user created a post with an image of the\\nAzov Regiment symbol. Overlaying the symbol was text in Ukrainian\\nasking, \"where is Azov?\" The caption stated that more than 700 Azov\\nsoldiers remain in Russian captivity, with their conditions unknown. The\\nuser calls for their return, stating: \"we must scream until all the\\nAzovs are back from captivity!\"\\n\\nThe user appealed the removal of the post, emphasizing the importance of\\nsharing information during times of war. The user also highlighted that\\nthe content did not violate Meta\\'s policies, since Meta allows content\\ncommenting on the Azov Regiment. The post received nearly 800 views and\\nwas detected by Meta\\'s automated systems.\\n\\nMeta originally removed the post from Facebook under its \u001b[0m\u001b[32m[\u001b[0m\u001b[32mDangerous\\nOrganizations and Individuals \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDOI\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\npolicy\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://transparency.fb.com/en-gb/policies/community-standards/dangerous-individuals-organizations/\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which prohibits\\ncontent that \"praises,\" \"substantively supports\" or \"represents\"\\nindividuals and organizations that Meta designates as dangerous.\\nHowever, Meta allows \"discussions about the human rights of designated\\nindividuals or members of designated dangerous entities, unless the\\ncontent includes other praise, substantive support or representation of\\ndesignated entities or other policy violations, such as incitement to\\nviolence.\"\\n\\nMeta told the Board that it removed the Azov Regiment from its Dangerous\\nOrganizations and Individuals list in January 2023. A \u001b[0m\u001b[32m[\u001b[0m\u001b[32m*Washington Post*\\narticle\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://www.washingtonpost.com/technology/2023/01/21/meta-azov-regiment-facebook-oversight/\u001b[0m\u001b[32m)\u001b[0m\u001b[32m states that Meta now\\ndraws a distinction between the Azov Regiment, which it views as under\\nformal control of the Ukrainian government, and other elements of the\\nbroader Azov movement, some which the company considers far-right\\nnationalists and still designates as dangerous.\\n\\nAfter the Board brought this case to Meta\\'s attention, the company\\ndetermined that its removal was incorrect and restored the content to\\nInstagram. The company acknowledged that the Azov Regiment is no longer\\ndesignated as a dangerous organization. Additionally, Meta recognized\\nthat regardless of the Azov Regiment\\'s designation, this post falls\\nunder the exception that allows references to dangerous individuals and\\norganizations when discussing the human rights of individuals and\\nmembers of designated entities.\\n\\n## Board Authority and Scope\\n\\nThe Board has authority to review Meta\\'s decision following an appeal\\nfrom the person whose content was removed \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCharter Article 2, Section 1;\\nBylaws Article 3, Section 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\nWhen Meta acknowledges that it made an error and reverses its decision\\non a case under consideration for Board review, the Board may select\\nthat case for a summary decision \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBylaws Article 2, Section 2.1.3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The\\nBoard reviews the original decision to increase understanding of the\\ncontent moderation processes involved, reduce errors and increase\\nfairness for Facebook and Instagram users.\\n\\n## Case Significance\\n\\nThis case highlights shortcomings in the updating of Meta\\'s Dangerous\\nOrganizations and Individuals list and its enforcement, which raises\\ngreater concerns during times of war. The case also illustrates the\\nsystemic challenges in enforcing exceptions to Meta\\'s policy on\\nDangerous Organizations and Individuals.\\n\\nPreviously, the Board issued a recommendation stating that Meta\\'s\\nDangerous Organizations and Individuals policy should allow users to\\ndiscuss alleged human rights abuses of members of dangerous\\norganizations \u001b[0m\u001b[32m(\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32mÖcalan\\'s\\nIsolation\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://www.oversightboard.com/decision/ig-i9dp23ib/\u001b[0m\u001b[32m)\u001b[0m\u001b[32m decision, recommendation no. 5\u001b[0m\u001b[32m)\u001b[0m\u001b[32m,\\nwhich Meta committed to implement. Furthermore, the Azov Regiment was\\nremoved from Meta\\'s Dangerous Organizations and Individuals list in\\nJanuary 2023. The Board has issued a recommendation stating that, when\\nany new policy is adopted, internal guidance and training should be\\nprovided to content moderators \u001b[0m\u001b[32m(\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32mÖcalan\\'s\\nIsolation\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://www.oversightboard.com/decision/ig-i9dp23ib/\u001b[0m\u001b[32m)\u001b[0m\u001b[32m decision, recommendation no. 8\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nThe Board has also issued recommendations on the enforcement accuracy of\\nMeta\\'s policies by calling for further transparency regarding\\nenforcement error rates on the \"praise\" and \"support\" of dangerous\\nindividuals and organizations \u001b[0m\u001b[32m(\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32mÖcalan\\'s\\nIsolation\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://www.oversightboard.com/decision/ig-i9dp23ib/\u001b[0m\u001b[32m)\u001b[0m\u001b[32m decision, recommendation no.\\n12\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and the implementation of an internal audit procedure to learn from\\npast automated enforcement mistakes \u001b[0m\u001b[32m(\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32mBreast Cancer Symptoms and\\nNudity\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://www.oversightboard.com/decision/ig-7thr3si1/\u001b[0m\u001b[32m)\u001b[0m\u001b[32m decision, recommendation no. 5\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nFully implementing these recommendations could help Meta decrease the\\nnumber of similar content moderation errors.\\n\\n## Decision\\n\\nThe Board overturns Meta\\'s original decision to remove the content. The\\nBoard acknowledges Meta\\'s correction of its initial error once the Board\\nbrought the case to Meta\\'s attention.\\n\\n'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mmime\u001b[0m=\u001b[32m'text/plain'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mfile_path\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mchunks\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mchunks_path\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mimages\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mtext_content\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"result\": \"upheld\", \"title\": \"Azov Removal\",\"abstract\": \"A user appealed Meta\\'s decision to remove an Instagram post asking,\\n\"where is Azov?\" in Ukrainian. The post\\\\\\'s caption calls for soldiers of\\nthe Azov Regiment in Russian captivity to be returned.\",\"type\": \"Summary\",\"topic\": \"War and conflict\", \"standards\": \u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"Dangerous individuals and organizations\",\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \"location\": \"Ukraine\", \"Platform\": \"Instagram\",\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n\"type\": \"summary\", *Summary decisions examine cases in\\nwhich Meta has reversed its original decision on a piece of content\\nafter the Board brought it to the company\\'s attention. These decisions\\ninclude information about Meta\\'s acknowledged errors. They are approved\\nby a Board Member panel, not the full Board. They do not involve a\\npublic comment process and do not have precedential value for the Board.\\nSummary decisions provide transparency on Meta\\'s corrections and\\nhighlight areas in which the company could improve its policy\\nenforcement.*\\n\\n## Case Summary\\n\\nA user appealed Meta\\'s decision to remove an Instagram post asking,\\n\"where is Azov?\" in Ukrainian. The post\\\\\\'s caption calls for soldiers of\\nthe Azov Regiment in Russian captivity to be returned. After the Board\\nbrought the appeal to Meta\\'s attention, the company reversed its\\noriginal decision and restored the post.\\n\\n## Case Description and Background\\n\\nIn December 2022, an Instagram user created a post with an image of the\\nAzov Regiment symbol. Overlaying the symbol was text in Ukrainian\\nasking, \"where is Azov?\" The caption stated that more than 700 Azov\\nsoldiers remain in Russian captivity, with their conditions unknown. The\\nuser calls for their return, stating: \"we must scream until all the\\nAzovs are back from captivity!\"\\n\\nThe user appealed the removal of the post, emphasizing the importance of\\nsharing information during times of war. The user also highlighted that\\nthe content did not violate Meta\\'s policies, since Meta allows content\\ncommenting on the Azov Regiment. The post received nearly 800 views and\\nwas detected by Meta\\'s automated systems.\\n\\nMeta originally removed the post from Facebook under its \u001b[0m\u001b[32m[\u001b[0m\u001b[32mDangerous\\nOrganizations and Individuals \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDOI\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\npolicy\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://transparency.fb.com/en-gb/policies/community-standards/dangerous-individuals-organizations/\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which prohibits\\ncontent that \"praises,\" \"substantively supports\" or \"represents\"\\nindividuals and organizations that Meta designates as dangerous.\\nHowever, Meta allows \"discussions about the human rights of designated\\nindividuals or members of designated dangerous entities, unless the\\ncontent includes other praise, substantive support or representation of\\ndesignated entities or other policy violations, such as incitement to\\nviolence.\"\\n\\nMeta told the Board that it removed the Azov Regiment from its Dangerous\\nOrganizations and Individuals list in January 2023. A \u001b[0m\u001b[32m[\u001b[0m\u001b[32m*Washington Post*\\narticle\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://www.washingtonpost.com/technology/2023/01/21/meta-azov-regiment-facebook-oversight/\u001b[0m\u001b[32m)\u001b[0m\u001b[32m states that Meta now\\ndraws a distinction between the Azov Regiment, which it views as under\\nformal control of the Ukrainian government, and other elements of the\\nbroader Azov movement, some which the company considers far-right\\nnationalists and still designates as dangerous.\\n\\nAfter the Board brought this case to Meta\\'s attention, the company\\ndetermined that its removal was incorrect and restored the content to\\nInstagram. The company acknowledged that the Azov Regiment is no longer\\ndesignated as a dangerous organization. Additionally, Meta recognized\\nthat regardless of the Azov Regiment\\'s designation, this post falls\\nunder the exception that allows references to dangerous individuals and\\norganizations when discussing the human rights of individuals and\\nmembers of designated entities.\\n\\n## Board Authority and Scope\\n\\nThe Board has authority to review Meta\\'s decision following an appeal\\nfrom the person whose content was removed \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCharter Article 2, Section 1;\\nBylaws Article 3, Section 1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\nWhen Meta acknowledges that it made an error and reverses its decision\\non a case under consideration for Board review, the Board may select\\nthat case for a summary decision \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBylaws Article 2, Section 2.1.3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The\\nBoard reviews the original decision to increase understanding of the\\ncontent moderation processes involved, reduce errors and increase\\nfairness for Facebook and Instagram users.\\n\\n## Case Significance\\n\\nThis case highlights shortcomings in the updating of Meta\\'s Dangerous\\nOrganizations and Individuals list and its enforcement, which raises\\ngreater concerns during times of war. The case also illustrates the\\nsystemic challenges in enforcing exceptions to Meta\\'s policy on\\nDangerous Organizations and Individuals.\\n\\nPreviously, the Board issued a recommendation stating that Meta\\'s\\nDangerous Organizations and Individuals policy should allow users to\\ndiscuss alleged human rights abuses of members of dangerous\\norganizations \u001b[0m\u001b[32m(\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32mÖcalan\\'s\\nIsolation\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://www.oversightboard.com/decision/ig-i9dp23ib/\u001b[0m\u001b[32m)\u001b[0m\u001b[32m decision, recommendation no. 5\u001b[0m\u001b[32m)\u001b[0m\u001b[32m,\\nwhich Meta committed to implement. Furthermore, the Azov Regiment was\\nremoved from Meta\\'s Dangerous Organizations and Individuals list in\\nJanuary 2023. The Board has issued a recommendation stating that, when\\nany new policy is adopted, internal guidance and training should be\\nprovided to content moderators \u001b[0m\u001b[32m(\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32mÖcalan\\'s\\nIsolation\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://www.oversightboard.com/decision/ig-i9dp23ib/\u001b[0m\u001b[32m)\u001b[0m\u001b[32m decision, recommendation no. 8\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nThe Board has also issued recommendations on the enforcement accuracy of\\nMeta\\'s policies by calling for further transparency regarding\\nenforcement error rates on the \"praise\" and \"support\" of dangerous\\nindividuals and organizations \u001b[0m\u001b[32m(\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32mÖcalan\\'s\\nIsolation\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://www.oversightboard.com/decision/ig-i9dp23ib/\u001b[0m\u001b[32m)\u001b[0m\u001b[32m decision, recommendation no.\\n12\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and the implementation of an internal audit procedure to learn from\\npast automated enforcement mistakes \u001b[0m\u001b[32m(\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32mBreast Cancer Symptoms and\\nNudity\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://www.oversightboard.com/decision/ig-7thr3si1/\u001b[0m\u001b[32m)\u001b[0m\u001b[32m decision, recommendation no. 5\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nFully implementing these recommendations could help Meta decrease the\\nnumber of similar content moderation errors.\\n\\n## Decision\\n\\nThe Board overturns Meta\\'s original decision to remove the content. The\\nBoard acknowledges Meta\\'s correction of its initial error once the Board\\nbrought the case to Meta\\'s attention.\\n\\n'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(records[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration-Driven Multi-Field Vector Store\n",
    "\n",
    "This notebook demonstrates a **configuration-driven approach** for multi-field vector embeddings that works across any data source.\n",
    "\n",
    "### 🧠 **The Problem**\n",
    "Traditional vector stores only embed the main content, leaving rich metadata unsearchable:\n",
    "```python\n",
    "# Traditional approach - metadata trapped\n",
    "record.content = \"Long text...\"        # → Gets embedded ✅\n",
    "record.metadata.summary = \"Key points\"  # → Not searchable ❌\n",
    "```\n",
    "\n",
    "### 🎯 **Our Solution: Enhanced Record with Configuration-Driven Multi-Field Embeddings**\n",
    "The enhanced Record class provides direct vector processing capabilities:\n",
    "```yaml\n",
    "# conf/storage/osb.yaml\n",
    "osb_vector:\n",
    "  type: chromadb\n",
    "  # ... basic config\n",
    "  multi_field_embedding:\n",
    "    content_field: \"content\"\n",
    "    additional_fields:\n",
    "      - source_field: \"summary\"\n",
    "        chunk_type: \"summary\"\n",
    "        min_length: 50\n",
    "      - source_field: \"title\"\n",
    "        chunk_type: \"title\"\n",
    "        min_length: 10\n",
    "```\n",
    "\n",
    "### 🔍 **Search Capabilities**\n",
    "\n",
    "| Search Type | Use Case | Example Query |\n",
    "|-------------|----------|---------------|\n",
    "| **Summary-Only** | High-level concepts | `where={\"content_type\": \"summary\"}` |\n",
    "| **Title-Only** | Topic matching | `where={\"content_type\": \"title\"}` |\n",
    "| **Content-Only** | Detailed analysis | `where={\"content_type\": \"content\"}` |\n",
    "| **Cross-Field** | Comprehensive search | No filter = search everything |\n",
    "| **Hybrid** | Semantic + exact match | `query + where={\"case_number\": \"2024\"}` |\n",
    "\n",
    "### 🏗️ **Benefits**\n",
    "- ✅ **Enhanced Record**: Direct vector capabilities built into Record class\n",
    "- ✅ **Configuration-Driven**: No hardcoded field names\n",
    "- ✅ **Data Source Agnostic**: Works with any Record structure\n",
    "- ✅ **Same Config**: Creation and reading use identical configuration\n",
    "- ✅ **Extensible**: Easy to add new field types for any dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🏭 Starting production vector store with INTELLIGENT SYNC<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🏭 Starting production vector store with INTELLIGENT SYNC\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">📊 Processing <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span> live OSB documents\n",
       "</pre>\n"
      ],
      "text/plain": [
       "📊 Processing \u001b[1;36m172\u001b[0m live OSB documents\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">⚙️  Sync Configuration:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "⚙️  Sync Configuration:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   📦 Sync every <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> records\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   📦 Sync every \u001b[1;36m50\u001b[0m records\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ⏰ Sync every <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> minutes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ⏰ Sync every \u001b[1;36m10\u001b[0m minutes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   🔄 Auto-sync: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   🔄 Auto-sync: \u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: BUN-QBBL<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m1\u001b[0m/\u001b[1;36m172\u001b[0m: BUN-QBBL\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record BUN-QBBLZ8WI: {'content': 10, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 6738, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 13 chunks for record BUN-QBBLZ8WI...\n",
      "\u001b[32m2025-06-17 09:46:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 13 chunks for record BUN-QBBLZ8WI\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m13\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-4294T<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m2\u001b[0m/\u001b[1;36m172\u001b[0m: FB-4294T\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-4294T386: {'content': 56, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 45365, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 59 chunks for record FB-4294T386...\n",
      "\u001b[32m2025-06-17 09:46:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 59 chunks for record FB-4294T386\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">59</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m59\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m56\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-M8D2S<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m3\u001b[0m/\u001b[1;36m172\u001b[0m: FB-M8D2S\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-M8D2SOGS: {'content': 44, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 37450, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 47 chunks for record FB-M8D2SOGS...\n",
      "\u001b[32m2025-06-17 09:46:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 47 chunks for record FB-M8D2SOGS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m47\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m44\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-1BMH3<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m4\u001b[0m/\u001b[1;36m172\u001b[0m: IG-1BMH3\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-1BMH3DQ6: {'content': 8, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 6290, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 11 chunks for record IG-1BMH3DQ6...\n",
      "\u001b[32m2025-06-17 09:46:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 11 chunks for record IG-1BMH3DQ6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m11\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-2AHD0<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m5\u001b[0m/\u001b[1;36m172\u001b[0m: FB-2AHD0\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-2AHD01LX: {'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 6062, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 10 chunks for record FB-2AHD01LX...\n",
      "\u001b[32m2025-06-17 09:46:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 10 chunks for record FB-2AHD01LX\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m10\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m7\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-JRQ1X<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m6\u001b[0m/\u001b[1;36m172\u001b[0m: FB-JRQ1X\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-JRQ1XP2M: {'content': 63, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 51085, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 66 chunks for record FB-JRQ1XP2M...\n",
      "\u001b[32m2025-06-17 09:46:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 66 chunks for record FB-JRQ1XP2M\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m66\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m63\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-515JV<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m7\u001b[0m/\u001b[1;36m172\u001b[0m: FB-515JV\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-515JVE4X: {'content': 88, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 70288, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 91 chunks for record FB-515JVE4X...\n",
      "\u001b[32m2025-06-17 09:46:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 91 chunks for record FB-515JVE4X\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">91</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">88</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m91\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m88\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-QBJDA<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m8\u001b[0m/\u001b[1;36m172\u001b[0m: FB-QBJDA\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-QBJDASCV: {'content': 33, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 26989, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 36 chunks for record FB-QBJDASCV...\n",
      "\u001b[32m2025-06-17 09:46:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 36 chunks for record FB-QBJDASCV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m36\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m33\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-P93JP<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m9\u001b[0m/\u001b[1;36m172\u001b[0m: FB-P93JP\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-P93JPX02: {'content': 48, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 38290, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 51 chunks for record FB-P93JPX02...\n",
      "\u001b[32m2025-06-17 09:46:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 51 chunks for record FB-P93JPX02\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m51\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m48\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-2R3UE<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m10\u001b[0m/\u001b[1;36m172\u001b[0m: IG-2R3UE\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-2R3UEQRR: {'content': 8, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 6470, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 11 chunks for record IG-2R3UEQRR...\n",
      "\u001b[32m2025-06-17 09:46:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 11 chunks for record IG-2R3UEQRR\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m11\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-1RWWJ<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m11\u001b[0m/\u001b[1;36m172\u001b[0m: FB-1RWWJ\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-1RWWJUAT: {'content': 57, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 45240, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:33\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 60 chunks for record FB-1RWWJUAT...\n",
      "\u001b[32m2025-06-17 09:46:33\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 60 chunks for record FB-1RWWJUAT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">57</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m60\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m57\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-YLRV3<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m12\u001b[0m/\u001b[1;36m172\u001b[0m: FB-YLRV3\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:33\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:33\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-YLRV35WD: {'content': 73, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 60148, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:34\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 76 chunks for record FB-YLRV35WD...\n",
      "\u001b[32m2025-06-17 09:46:34\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 76 chunks for record FB-YLRV35WD\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m76\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m73\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-RZL57<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m13\u001b[0m/\u001b[1;36m172\u001b[0m: FB-RZL57\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:34\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:34\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-RZL57QHJ: {'content': 46, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 40569, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:36\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 49 chunks for record FB-RZL57QHJ...\n",
      "\u001b[32m2025-06-17 09:46:36\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 49 chunks for record FB-RZL57QHJ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m49\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m46\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-ZJ7J6<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m14\u001b[0m/\u001b[1;36m172\u001b[0m: IG-ZJ7J6\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:36\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:36\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-ZJ7J6D28: {'content': 81, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 62951, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 84 chunks for record IG-ZJ7J6D28...\n",
      "\u001b[32m2025-06-17 09:46:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 84 chunks for record IG-ZJ7J6D28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">84</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">81</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m84\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m81\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-HFFVZ<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m15\u001b[0m/\u001b[1;36m172\u001b[0m: FB-HFFVZ\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-HFFVZENH: {'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 4967, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 10 chunks for record FB-HFFVZENH...\n",
      "\u001b[32m2025-06-17 09:46:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 10 chunks for record FB-HFFVZENH\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m10\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m7\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-33NK6<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m16\u001b[0m/\u001b[1;36m172\u001b[0m: FB-33NK6\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-33NK66FG: {'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 4880, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:39\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 9 chunks for record FB-33NK66FG...\n",
      "\u001b[32m2025-06-17 09:46:39\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 9 chunks for record FB-33NK66FG\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m9\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-515JV<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m17\u001b[0m/\u001b[1;36m172\u001b[0m: FB-515JV\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:39\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:39\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-515JVE4X: {'content': 88, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 70288, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:41\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 91 chunks for record FB-515JVE4X...\n",
      "\u001b[32m2025-06-17 09:46:41\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 91 chunks for record FB-515JVE4X\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">91</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">88</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m91\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m88\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-JRQ1X<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m18\u001b[0m/\u001b[1;36m172\u001b[0m: FB-JRQ1X\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:41\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:41\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-JRQ1XP2M: {'content': 63, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 51085, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:42\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 66 chunks for record FB-JRQ1XP2M...\n",
      "\u001b[32m2025-06-17 09:46:42\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 66 chunks for record FB-JRQ1XP2M\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m66\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m63\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-2PJ00<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m19\u001b[0m/\u001b[1;36m172\u001b[0m: IG-2PJ00\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:42\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:42\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-2PJ00L4T: {'content': 56, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 47643, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:44\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 59 chunks for record IG-2PJ00L4T...\n",
      "\u001b[32m2025-06-17 09:46:44\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 59 chunks for record IG-2PJ00L4T\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">59</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m59\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m56\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-0U6FL<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m20\u001b[0m/\u001b[1;36m172\u001b[0m: IG-0U6FL\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:44\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:44\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-0U6FLA5B: {'content': 51, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 42972, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:45\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 54 chunks for record IG-0U6FLA5B...\n",
      "\u001b[32m2025-06-17 09:46:45\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 54 chunks for record IG-0U6FLA5B\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">54</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m54\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m51\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-GW8BY<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m21\u001b[0m/\u001b[1;36m172\u001b[0m: FB-GW8BY\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:45\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:45\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-GW8BY1Y3: {'content': 60, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 50792, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:46\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 63 chunks for record FB-GW8BY1Y3...\n",
      "\u001b[32m2025-06-17 09:46:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 63 chunks for record FB-GW8BY1Y3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m63\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m60\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-ONL5Y<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m22\u001b[0m/\u001b[1;36m172\u001b[0m: FB-ONL5Y\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-ONL5YQVE: {'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 5382, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:47\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:47\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 9 chunks for record FB-ONL5YQVE...\n",
      "\u001b[32m2025-06-17 09:46:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 9 chunks for record FB-ONL5YQVE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m10\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m7\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-I04M3<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m23\u001b[0m/\u001b[1;36m172\u001b[0m: FB-I04M3\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-I04M3KVF: {'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 5978, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 9 chunks for record FB-I04M3KVF...\n",
      "\u001b[32m2025-06-17 09:46:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 9 chunks for record FB-I04M3KVF\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m9\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: BUN-QBBL<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m24\u001b[0m/\u001b[1;36m172\u001b[0m: BUN-QBBL\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record BUN-QBBLZ8WI: {'content': 10, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 6738, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 12 chunks for record BUN-QBBLZ8WI...\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 12 chunks for record BUN-QBBLZ8WI\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m13\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-QBJDA<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m25\u001b[0m/\u001b[1;36m172\u001b[0m: FB-QBJDA\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-QBJDASCV: {'content': 33, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 26989, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 3 chunks for record FB-QBJDASCV...\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 3 chunks for record FB-QBJDASCV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m36\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m33\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-T8JDD<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m26\u001b[0m/\u001b[1;36m172\u001b[0m: FB-T8JDD\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-T8JDDDJV: {'content': 86, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 68588, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 49: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 48: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 50: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 45: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 51: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 52: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 58: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 47: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 56: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 53: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 59: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 54: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 55: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 57: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 64: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 60: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 68: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 61: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 62: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 67: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 66: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 76: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 63: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 70: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 74: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 75: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 71: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 65: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 69: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 72: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 73: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 77: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 78: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 79: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 81: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 83: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 80: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 84: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 85: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 82: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 88: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 86: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 87: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 45\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 47\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 48\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 49\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 50\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 51\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 52\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 53\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 54\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 55\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 56\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 57\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 58\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 59\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 60\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 61\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 62\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 63\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 64\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 65\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 66\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 67\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 68\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 69\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 70\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 71\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 72\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 73\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 74\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 75\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 76\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 77\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 78\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 79\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 80\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 81\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 82\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 83\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 84\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 85\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 86\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 87\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 88\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-T8JDDDJV\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">89</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m89\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m86\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-YLRV3<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m27\u001b[0m/\u001b[1;36m172\u001b[0m: FB-YLRV3\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-YLRV35WD: {'content': 73, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 60148, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 45: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 49: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 52: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 47: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 51: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 53: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 48: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 50: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 55: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 56: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 58: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 54: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 57: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 59: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 61: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 62: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 63: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 67: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 60: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 64: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 65: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 71: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 70: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 66: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 72: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 68: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 69: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 75: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 74: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 73: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 45\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 47\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 48\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 49\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 50\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 51\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 52\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 53\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 54\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 55\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 56\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 57\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 58\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 59\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 60\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 61\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 62\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 63\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 64\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 65\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 66\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 67\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 68\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 69\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 70\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 71\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 72\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 73\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 74\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 75\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-YLRV35WD\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m76\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m73\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-ZWQUP<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m28\u001b[0m/\u001b[1;36m172\u001b[0m: FB-ZWQUP\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-ZWQUPZLZ: {'content': 32, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 28593, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-ZWQUPZLZ\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m35\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-S6NRT<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m29\u001b[0m/\u001b[1;36m172\u001b[0m: FB-S6NRT\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-S6NRTDAJ: {'content': 54, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 42401, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 52: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 53: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 54: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 48: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 47: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 55: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 51: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 45: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 49: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 50: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 56: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 45\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 47\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 48\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 49\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 50\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 51\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 52\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 53\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 54\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 55\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 56\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-S6NRTDAJ\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">57</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">54</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m57\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m54\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-7THR3<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m30\u001b[0m/\u001b[1;36m172\u001b[0m: IG-7THR3\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:52\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-7THR3SI1: {'content': 38, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 29881, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record IG-7THR3SI1\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m41\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m38\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-33NK6<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m31\u001b[0m/\u001b[1;36m172\u001b[0m: FB-33NK6\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-33NK66FG: {'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 4880, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-33NK66FG\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m9\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-Q72FD<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m32\u001b[0m/\u001b[1;36m172\u001b[0m: FB-Q72FD\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:53\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-Q72FD6YL: {'content': 40, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 32969, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-Q72FD6YL\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m43\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m40\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-TYE27<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m33\u001b[0m/\u001b[1;36m172\u001b[0m: FB-TYE27\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-TYE2766G: {'content': 42, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 36258, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:54\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-TYE2766G\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m45\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m42\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-J5OOP<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m34\u001b[0m/\u001b[1;36m172\u001b[0m: FB-J5OOP\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-J5OOP3YZ: {'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 5669, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-J5OOP3YZ\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m9\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-FZSE6<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m35\u001b[0m/\u001b[1;36m172\u001b[0m: IG-FZSE6\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-FZSE6J9C: {'content': 50, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 42049, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:55\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 52: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 51: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 45: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 49: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 48: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 47: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 50: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 45\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 47\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 48\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 49\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 50\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 51\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 52\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record IG-FZSE6J9C\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m53\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m50\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-U2HHA<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m36\u001b[0m/\u001b[1;36m172\u001b[0m: FB-U2HHA\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-U2HHA647: {'content': 70, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 56858, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 49: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 51: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 45: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 52: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 47: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 55: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 50: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 56: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 48: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 53: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 54: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 59: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 58: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 60: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 57: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 67: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 68: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 61: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 63: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 62: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 69: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 65: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 64: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 70: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 66: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 72: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 71: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 45\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 47\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 48\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 49\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 50\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 51\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 52\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 53\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 54\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 55\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 56\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 57\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 58\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 59\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 60\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 61\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 62\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 63\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 64\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 65\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 66\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 67\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 68\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 69\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 70\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 71\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 72\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-U2HHA647\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m73\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m70\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-2RDRC<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m37\u001b[0m/\u001b[1;36m172\u001b[0m: FB-2RDRC\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-2RDRCAVQ: {'content': 30, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 22541, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-2RDRCAVQ\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m33\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m30\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: error_38<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m38\u001b[0m/\u001b[1;36m172\u001b[0m: error_38\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record error_38: {'content': 1} (content_length: 259, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record error_38\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> content<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m1\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m content\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-J5OOP<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m39\u001b[0m/\u001b[1;36m172\u001b[0m: FB-J5OOP\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-J5OOP3YZ: {'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 5669, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-J5OOP3YZ\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m9\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-RH16O<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m40\u001b[0m/\u001b[1;36m172\u001b[0m: IG-RH16O\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:46:58\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-RH16OBG3: {'content': 83, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 65298, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 45: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 53: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 54: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 47: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 48: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 55: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 57: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 51: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 49: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 52: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 59: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 50: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 56: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 58: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 63: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 62: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 60: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 61: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 70: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 71: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 64: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 65: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 66: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 67: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 72: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 69: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 68: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 73: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 74: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 79: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 75: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 76: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 78: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 80: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 77: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 81: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 82: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 83: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 84: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 85: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 45\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 47\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 48\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 49\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 50\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 51\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 52\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 53\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 54\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 55\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 56\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 57\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 58\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 59\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 60\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 61\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 62\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 63\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 64\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 65\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 66\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 67\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 68\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 69\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 70\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 71\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 72\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 73\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 74\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 75\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 76\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 77\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 78\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 79\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 80\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 81\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 82\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 83\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 84\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 85\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record IG-RH16OBG3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">83</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m86\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m83\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-AP0NS<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m41\u001b[0m/\u001b[1;36m172\u001b[0m: FB-AP0NS\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-AP0NSBVC: {'content': 46, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 38880, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 45: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 48: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:00\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 47: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 45\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 47\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 48\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-AP0NSBVC\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m49\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m46\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-ZWQUP<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m42\u001b[0m/\u001b[1;36m172\u001b[0m: FB-ZWQUP\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-ZWQUPZLZ: {'content': 32, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 28593, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-ZWQUPZLZ\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m35\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">43</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-T8JDD<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m43\u001b[0m/\u001b[1;36m172\u001b[0m: FB-T8JDD\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-T8JDDDJV: {'content': 86, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 68588, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:01\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 53: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 54: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 45: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 47: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 49: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 50: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 51: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 56: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 55: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 48: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 52: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 59: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 57: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 58: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 61: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 63: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 60: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 62: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 68: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 72: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 65: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 64: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 71: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 66: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 75: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 73: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 67: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 69: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 74: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 79: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 70: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 77: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 76: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 78: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 80: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 81: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 87: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 82: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 88: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 83: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 84: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 85: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 86: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 45\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 47\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 48\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 49\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 50\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 51\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 52\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 53\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 54\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 55\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 56\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 57\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 58\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 59\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 60\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 61\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 62\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 63\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 64\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 65\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 66\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 67\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 68\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 69\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 70\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 71\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 72\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 73\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 74\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 75\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 76\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 77\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 78\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 79\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 80\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 81\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 82\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 83\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 84\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 85\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 86\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 87\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 88\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-T8JDDDJV\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">89</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m89\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m86\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-691QA<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m44\u001b[0m/\u001b[1;36m172\u001b[0m: FB-691QA\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:02\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-691QAMHJ: {'content': 102, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 80333, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 49: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 50: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 45: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 51: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 58: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 47: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 48: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 55: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 53: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 52: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 59: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 54: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 56: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 57: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 60: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 66: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 67: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 61: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 62: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 68: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 63: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 76: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 69: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 64: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 65: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 72: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:03\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 75: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 70: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 71: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 73: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 74: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 77: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 78: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 79: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 83: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 80: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 84: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 82: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 81: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 85: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 86: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 94: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 90: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 87: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 92: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 88: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 89: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 91: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 93: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 95: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 96: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 97: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 98: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 99: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 100: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 101: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 102: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 103: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 104: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 45\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 47\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 48\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 49\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 50\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 51\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 52\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 53\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 54\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 55\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 56\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 57\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 58\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 59\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 60\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 61\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 62\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 63\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 64\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 65\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 66\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 67\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 68\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 69\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 70\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 71\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 72\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 73\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 74\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 75\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 76\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 77\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 78\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 79\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 80\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 81\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 82\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 83\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 84\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 85\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 86\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 87\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 88\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 89\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 90\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 91\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 92\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 93\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 94\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 95\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 96\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 97\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 98\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 99\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 100\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 101\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 102\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 103\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 104\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-691QAMHJ\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">105</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m105\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m102\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-6OKJP<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m45\u001b[0m/\u001b[1;36m172\u001b[0m: FB-6OKJP\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-6OKJPNS3: {'content': 85, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 67780, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:04\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 47: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 56: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 50: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 49: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 48: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 54: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 45: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 51: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 52: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 53: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 55: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 57: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 58: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 59: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 63: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 64: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 60: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 72: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 65: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 61: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 62: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 66: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 69: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 73: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 70: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 68: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 67: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 71: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 74: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 75: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 76: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 77: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 78: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 79: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 80: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 81: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 82: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 83: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 85: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 84: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 86: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 87: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 45\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 47\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 48\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 49\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 50\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 51\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 52\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 53\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 54\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 55\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 56\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 57\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 58\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 59\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 60\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 61\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 62\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 63\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 64\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 65\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 66\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 67\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 68\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 69\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 70\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 71\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 72\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 73\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 74\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 75\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 76\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 77\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 78\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 79\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 80\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 81\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 82\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 83\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 84\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 85\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 86\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 87\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-6OKJPNS3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">88</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m88\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m85\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-P9PR9<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m46\u001b[0m/\u001b[1;36m172\u001b[0m: FB-P9PR9\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:05\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-P9PR9RSA: {'content': 42, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 36215, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-P9PR9RSA\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m45\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m42\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-MFADK<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m47\u001b[0m/\u001b[1;36m172\u001b[0m: FB-MFADK\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-MFADK60O: {'content': 9, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 6847, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-MFADK60O\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m12\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m9\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-2R3UE<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m48\u001b[0m/\u001b[1;36m172\u001b[0m: IG-2R3UE\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-2R3UEQRR: {'content': 8, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 6470, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record IG-2R3UEQRR\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m11\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-M8D2S<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m49\u001b[0m/\u001b[1;36m172\u001b[0m: FB-M8D2S\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-M8D2SOGS: {'content': 44, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 37450, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:07\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 45: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 45\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-M8D2SOGS\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m47\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m44\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-TTXIB<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m50\u001b[0m/\u001b[1;36m172\u001b[0m: FB-TTXIB\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-TTXIBH8S: {'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 5203, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-TTXIBH8S\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m9\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-2AHD0<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m51\u001b[0m/\u001b[1;36m172\u001b[0m: FB-2AHD0\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-2AHD01LX: {'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 6062, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-2AHD01LX\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m10\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m7\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-TYE27<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m52\u001b[0m/\u001b[1;36m172\u001b[0m: FB-TYE27\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-TYE2766G: {'content': 42, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 36258, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:08\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-TYE2766G\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m45\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m42\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-5MC5O<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m53\u001b[0m/\u001b[1;36m172\u001b[0m: IG-5MC5O\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-5MC5OJIL: {'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 6116, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record IG-5MC5OJIL\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m10\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m7\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">54</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-KFLY3<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m54\u001b[0m/\u001b[1;36m172\u001b[0m: IG-KFLY3\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-KFLY3526: {'content': 61, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 49116, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 51: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 45: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 47: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 49: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 58: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 48: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 59: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 50: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 52: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 53: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 54: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 56: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 55: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 57: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 60: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 61: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 62: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 63: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 45\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 47\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 48\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 49\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 50\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 51\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 52\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 53\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 54\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 55\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 56\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 57\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 58\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 59\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 60\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 61\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 62\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 63\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record IG-KFLY3526\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m64\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m61\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-AJTD9<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m55\u001b[0m/\u001b[1;36m172\u001b[0m: FB-AJTD9\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-AJTD9P90: {'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 5584, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-AJTD9P90\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m9\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-H3138<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m56\u001b[0m/\u001b[1;36m172\u001b[0m: IG-H3138\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-H3138H6S: {'content': 69, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 53246, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 45: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 53: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 54: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 48: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 47: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 49: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 50: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 55: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 58: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 56: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 52: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 51: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 57: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:11\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 59: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 63: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 60: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 62: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 71: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 61: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 64: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 70: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 65: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 67: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 66: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 69: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 68: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 45\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 47\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 48\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 49\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 50\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 51\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 52\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 53\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 54\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 55\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 56\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 57\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 58\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 59\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 60\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 61\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 62\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 63\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 64\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 65\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 66\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 67\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 68\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 69\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 70\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 71\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record IG-H3138H6S\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m72\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m69\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">57</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-I964K<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m57\u001b[0m/\u001b[1;36m172\u001b[0m: FB-I964K\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-I964KKM6: {'content': 34, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 28380, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-I964KKM6\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m37\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m34\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-SI0CL<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m58\u001b[0m/\u001b[1;36m172\u001b[0m: FB-SI0CL\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-SI0CLWAX: {'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 5207, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-SI0CLWAX\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m10\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m7\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">59</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-PT5WR<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m59\u001b[0m/\u001b[1;36m172\u001b[0m: IG-PT5WR\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-PT5WRTLW: {'content': 95, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 79630, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 47: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 45: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 53: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 54: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 48: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 49: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 50: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 55: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 56: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 52: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 59: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 51: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 57: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:13\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 58: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 64: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 62: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 70: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 60: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 71: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 61: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 63: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 65: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 68: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 66: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 72: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 69: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 67: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 74: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 77: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 73: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 75: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 79: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 76: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 78: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 80: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 87: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 88: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 81: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 82: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 83: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 84: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 89: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 86: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 90: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 85: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 97: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 94: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 91: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 92: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 96: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 93: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 95: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 45\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 47\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 48\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 49\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 50\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 51\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 52\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 53\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 54\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 55\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 56\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 57\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 58\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 59\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 60\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 61\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 62\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 63\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 64\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 65\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 66\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 67\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 68\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 69\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 70\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 71\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 72\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 73\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 74\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 75\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 76\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 77\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 78\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 79\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 80\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 81\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 82\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 83\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 84\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 85\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 86\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 87\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 88\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 89\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 90\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 91\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 92\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 93\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 94\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 95\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 96\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 97\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record IG-PT5WRTLW\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">95</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m98\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m95\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-AJTD9<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m60\u001b[0m/\u001b[1;36m172\u001b[0m: FB-AJTD9\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-AJTD9P90: {'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 5584, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-AJTD9P90\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m9\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-UK2RU<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m61\u001b[0m/\u001b[1;36m172\u001b[0m: FB-UK2RU\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-UK2RUS24: {'content': 72, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 58830, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 47: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 49: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 50: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 45: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 59: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 51: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 54: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 48: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 57: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 52: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 53: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 55: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 58: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 56: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 65: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 60: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 67: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 66: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 61: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 62: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 69: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 63: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 64: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 68: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 70: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 73: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 71: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 72: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 74: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 45\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 47\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 48\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 49\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 50\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 51\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 52\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 53\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 54\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 55\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 56\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 57\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 58\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 59\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 60\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 61\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 62\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 63\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 64\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 65\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 66\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 67\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 68\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 69\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 70\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 71\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 72\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 73\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 74\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-UK2RUS24\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m75\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m72\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-R9K87<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m62\u001b[0m/\u001b[1;36m172\u001b[0m: FB-R9K87\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:15\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-R9K87402: {'content': 29, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 24329, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:815 \u001b[33mNo chunks with embeddings to store for record FB-R9K87402\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m32\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m29\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-2PJ00<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m63\u001b[0m/\u001b[1;36m172\u001b[0m: IG-2PJ00\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-2PJ00L4T: {'content': 56, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 47643, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:16\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 45: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 42: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 48: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 53: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 52: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 49: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 51: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 50: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 54: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 55: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 57: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 56: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 42\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 45\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 48\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 49\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 50\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 51\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 52\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 53\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 54\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 55\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 56\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 57\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 3 chunks for record IG-2PJ00L4T...\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 3 chunks for record IG-2PJ00L4T\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">59</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m59\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m56\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-H3138<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m64\u001b[0m/\u001b[1;36m172\u001b[0m: IG-H3138\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-H3138H6S: {'content': 69, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 53246, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 16: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:17\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 45: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 43: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 54: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 47: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 53: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 48: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 49: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 56: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 51: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 50: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 55: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 57: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 59: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 62: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 61: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 60: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 69: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 63: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 64: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 65: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 71: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 66: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 67: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 68: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 16\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 45\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 47\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 48\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 49\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 50\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 51\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 53\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 54\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 55\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 56\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 57\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 59\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 60\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 61\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 62\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 63\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 64\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 65\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 66\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 67\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 68\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 69\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 71\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 11 chunks for record IG-H3138H6S...\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 11 chunks for record IG-H3138H6S\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m72\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m69\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">65</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-E1154<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m65\u001b[0m/\u001b[1;36m172\u001b[0m: FB-E1154\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-E1154YLY: {'content': 46, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 37348, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 31: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 26: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 29: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 37: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 39: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 41: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 46: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 47: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 29\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 31\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 39\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 47\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 13 chunks for record FB-E1154YLY...\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 13 chunks for record FB-E1154YLY\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m49\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m46\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-RH16O<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m66\u001b[0m/\u001b[1;36m172\u001b[0m: IG-RH16O\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-RH16OBG3: {'content': 83, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 65298, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:19\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 14: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 15: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 18: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 24: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 32: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 27: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 33: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 36: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 34: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 40: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 50: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 51: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 44: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 52: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 48: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 55: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 54: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 57: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 67: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 61: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 68: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 66: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 70: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 73: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:20\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 71: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 74: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 83: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 78: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 85: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 84: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 15\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 18\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 24\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 32\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 33\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 34\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 48\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 50\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 51\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 52\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 54\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 55\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 57\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 61\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 66\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 67\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 68\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 70\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 71\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 73\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 74\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 78\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 83\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 84\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 85\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 38 chunks for record IG-RH16OBG3...\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 38 chunks for record IG-RH16OBG3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">83</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m86\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m83\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-79KHZ<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m67\u001b[0m/\u001b[1;36m172\u001b[0m: FB-79KHZ\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-79KHZ1P5: {'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 5319, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 6: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 4 chunks for record FB-79KHZ1P5...\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 4 chunks for record FB-79KHZ1P5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m10\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m7\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">68</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-R9K87<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m68\u001b[0m/\u001b[1;36m172\u001b[0m: FB-R9K87\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-R9K87402: {'content': 29, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 24329, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 4: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 10: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 11: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 17: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 5: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 8: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 25: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 28: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 5\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 8\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 11\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 25\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 28\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 17 chunks for record FB-R9K87402...\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 17 chunks for record FB-R9K87402\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m32\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m29\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-I2T65<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m69\u001b[0m/\u001b[1;36m172\u001b[0m: FB-I2T65\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-I2T6526K: {'content': 23, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 20152, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 0: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 9: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 13: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:22\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 3: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 20: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 22: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 0\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 9\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 13\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 20\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 16 chunks for record FB-I2T6526K...\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 16 chunks for record FB-I2T6526K\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m26\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m23\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-TOM6I<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m70\u001b[0m/\u001b[1;36m172\u001b[0m: IG-TOM6I\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-TOM6IXVH: {'content': 93, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 74928, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 1: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 2: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 7: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 19: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 12: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 21: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 23: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 35: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 38: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:23\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 30: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:24\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1130 \u001b[31mError getting embedding for input 56: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:25\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:25\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:25\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 7\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:25\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 12\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:25\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:25\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 21\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:25\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:25\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 30\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:25\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 35\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:25\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 38\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:25\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:890 \u001b[33mFailed to generate embedding for chunk 56\u001b[0m\n",
      "\u001b[32m2025-06-17 09:47:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 85 chunks for record IG-TOM6IXVH...\n",
      "\u001b[32m2025-06-17 09:47:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 85 chunks for record IG-TOM6IXVH\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">93</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m96\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m93\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-1RWWJ<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m71\u001b[0m/\u001b[1;36m172\u001b[0m: FB-1RWWJ\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-1RWWJUAT: {'content': 57, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 45240, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 60 chunks for record FB-1RWWJUAT...\n",
      "\u001b[32m2025-06-17 09:47:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 60 chunks for record FB-1RWWJUAT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">57</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m60\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m57\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-ZJ7J6<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m72\u001b[0m/\u001b[1;36m172\u001b[0m: IG-ZJ7J6\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-ZJ7J6D28: {'content': 81, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 62951, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 84 chunks for record IG-ZJ7J6D28...\n",
      "\u001b[32m2025-06-17 09:47:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 84 chunks for record IG-ZJ7J6D28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">84</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">81</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m84\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m81\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-MBGOT<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m73\u001b[0m/\u001b[1;36m172\u001b[0m: FB-MBGOT\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-MBGOTVN8: {'content': 60, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 48829, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 63 chunks for record FB-MBGOTVN8...\n",
      "\u001b[32m2025-06-17 09:47:30\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 63 chunks for record FB-MBGOTVN8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m63\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m60\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">74</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-2RDRC<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m74\u001b[0m/\u001b[1;36m172\u001b[0m: FB-2RDRC\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:30\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:30\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-2RDRCAVQ: {'content': 30, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 22541, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:30\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 33 chunks for record FB-2RDRCAVQ...\n",
      "\u001b[32m2025-06-17 09:47:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 33 chunks for record FB-2RDRCAVQ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m33\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m30\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: PAO-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2021</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m75\u001b[0m/\u001b[1;36m172\u001b[0m: PAO-\u001b[1;36m2021\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record PAO-2021-01: {'content': 17, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 12551, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 20 chunks for record PAO-2021-01...\n",
      "\u001b[32m2025-06-17 09:47:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 20 chunks for record PAO-2021-01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m20\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m17\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-5MC5O<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m76\u001b[0m/\u001b[1;36m172\u001b[0m: IG-5MC5O\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-5MC5OJIL: {'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 6116, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 10 chunks for record IG-5MC5OJIL...\n",
      "\u001b[32m2025-06-17 09:47:32\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 10 chunks for record IG-5MC5OJIL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m10\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m7\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-691QA<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m77\u001b[0m/\u001b[1;36m172\u001b[0m: FB-691QA\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:32\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:32\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-691QAMHJ: {'content': 102, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 80333, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:34\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 105 chunks for record FB-691QAMHJ...\n",
      "\u001b[32m2025-06-17 09:47:35\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 105 chunks for record FB-691QAMHJ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">105</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m105\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m102\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">78</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-I9DP2<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m78\u001b[0m/\u001b[1;36m172\u001b[0m: IG-I9DP2\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:35\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:35\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-I9DP23IB: {'content': 58, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 46730, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 61 chunks for record IG-I9DP23IB...\n",
      "\u001b[32m2025-06-17 09:47:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 61 chunks for record IG-I9DP23IB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m61\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m58\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-2AHD0<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m79\u001b[0m/\u001b[1;36m172\u001b[0m: FB-2AHD0\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-2AHD01LX: {'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 6062, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 10 chunks for record FB-2AHD01LX...\n",
      "\u001b[32m2025-06-17 09:47:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 10 chunks for record FB-2AHD01LX\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m10\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m7\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-2AHD0<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m80\u001b[0m/\u001b[1;36m172\u001b[0m: FB-2AHD0\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-2AHD01LX: {'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 6062, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 10 chunks for record FB-2AHD01LX...\n",
      "\u001b[32m2025-06-17 09:47:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 10 chunks for record FB-2AHD01LX\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m10\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m7\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">81</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-HFFVZ<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m81\u001b[0m/\u001b[1;36m172\u001b[0m: FB-HFFVZ\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-HFFVZENH: {'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 4967, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:39\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 10 chunks for record FB-HFFVZENH...\n",
      "\u001b[32m2025-06-17 09:47:39\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 10 chunks for record FB-HFFVZENH\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m10\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m7\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">82</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-24CW5<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m82\u001b[0m/\u001b[1;36m172\u001b[0m: IG-24CW5\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:39\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:39\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-24CW5DHI: {'content': 8, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 6245, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:40\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 11 chunks for record IG-24CW5DHI...\n",
      "\u001b[32m2025-06-17 09:47:40\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 11 chunks for record IG-24CW5DHI\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m11\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">83</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-CZHY8<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m83\u001b[0m/\u001b[1;36m172\u001b[0m: FB-CZHY8\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:40\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:40\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-CZHY85JC: {'content': 55, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 45226, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:41\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 58 chunks for record FB-CZHY85JC...\n",
      "\u001b[32m2025-06-17 09:47:42\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 58 chunks for record FB-CZHY85JC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m58\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m55\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">84</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-7UK5F<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m84\u001b[0m/\u001b[1;36m172\u001b[0m: FB-7UK5F\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:42\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:42\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-7UK5F6VG: {'content': 9, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 6306, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:42\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 12 chunks for record FB-7UK5F6VG...\n",
      "\u001b[32m2025-06-17 09:47:43\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 12 chunks for record FB-7UK5F6VG\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m12\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m9\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-1RWWJ<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m85\u001b[0m/\u001b[1;36m172\u001b[0m: FB-1RWWJ\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:43\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:43\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-1RWWJUAT: {'content': 57, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 45240, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:44\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 60 chunks for record FB-1RWWJUAT...\n",
      "\u001b[32m2025-06-17 09:47:45\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 60 chunks for record FB-1RWWJUAT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">57</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m60\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m57\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">86</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: FB-MP4ZC<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m86\u001b[0m/\u001b[1;36m172\u001b[0m: FB-MP4ZC\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:45\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:45\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record FB-MP4ZC4CC: {'content': 57, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 46826, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:46\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 60 chunks for record FB-MP4ZC4CC...\n",
      "\u001b[32m2025-06-17 09:47:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 60 chunks for record FB-MP4ZC4CC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span> chunks <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">57</span> content, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> title, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> reasons, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> recommendations<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ \u001b[1;36m60\u001b[0m chunks \u001b[1m(\u001b[0m\u001b[1;36m57\u001b[0m content, \u001b[1;36m1\u001b[0m title, \u001b[1;36m1\u001b[0m reasons, \u001b[1;36m1\u001b[0m recommendations\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔄 Processing record <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">87</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>: IG-7THR3<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔄 Processing record \u001b[1;36m87\u001b[0m/\u001b[1;36m172\u001b[0m: IG-7THR3\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 09:47:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:162 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 09:47:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-7THR3SI1: {'content': 38, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 29881, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:786 Created chunks for record IG-7THR3SI1: {'content': 38, 'title': 1, 'reasoning': 1, 'recommendations': 1} (content_length: 29881, chunk_size: 1200)\n",
      "\u001b[32m2025-06-17 09:47:48\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:834 Upserting 41 chunks for record IG-7THR3SI1...\n",
      "\u001b[32m2025-06-17 09:47:48\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:845 Successfully stored 41 chunks for record IG-7THR3SI1\n",
      "\u001b[32m2025-06-17 09:47:48\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:404 🔄 Syncing local changes back to remote: /home/debian/.cache/buttermilk/chromadb/gs___prosocial-dev_data_osb_chromadb → gs://prosocial-dev/data/osb/chromadb\n",
      "\u001b[32m2025-06-17 09:47:48\u001b[0m [] \u001b[1;30mINFO\u001b[0m utils.py:824 Uploading ChromaDB from /home/debian/.cache/buttermilk/chromadb/gs___prosocial-dev_data_osb_chromadb to gs://prosocial-dev/data/osb/chromadb\n"
     ]
    }
   ],
   "source": [
    "async def create_production_vector_store():\n",
    "    \"\"\"Production pipeline: Process live OSB data with intelligent batched sync.\"\"\"\n",
    "\n",
    "    print(\"🏭 Starting production vector store with INTELLIGENT SYNC...\")\n",
    "    print(f\"📊 Processing {len(records)} live OSB documents\")\n",
    "\n",
    "    # Configure sync behavior (can be done via config too)\n",
    "    vectorstore.sync_batch_size = 50  # Sync every 10 records for demo (default: 50)\n",
    "    vectorstore.sync_interval_minutes = 10  # Sync every 2 minutes for demo (default: 10)\n",
    "\n",
    "    print(f\"⚙️  Sync Configuration:\")\n",
    "    print(f\"   📦 Sync every {vectorstore.sync_batch_size} records\")\n",
    "    print(f\"   ⏰ Sync every {vectorstore.sync_interval_minutes} minutes\")\n",
    "    print(f\"   🔄 Auto-sync: {not vectorstore.disable_auto_sync}\")\n",
    "\n",
    "    successful_embeddings = 0\n",
    "    failed_embeddings = 0\n",
    "    total_chunks = 0\n",
    "    sync_count = 0\n",
    "\n",
    "    for i, record in enumerate(records):\n",
    "        print(f\"🔄 Processing record {i+1}/{len(records)}: {record.record_id[:8]}...\")\n",
    "\n",
    "        try:\n",
    "            processed_record = await vectorstore.process_record(record)\n",
    "            if processed_record:\n",
    "                successful_embeddings += 1\n",
    "                chunk_count = len(processed_record.chunks)\n",
    "                total_chunks += chunk_count\n",
    "\n",
    "                # Check if sync happened (logged by the vectorstore)\n",
    "                if vectorstore._processed_records_count == 0:  # Counter resets after sync\n",
    "                    sync_count += 1\n",
    "\n",
    "                # Count chunk types for display\n",
    "                chunk_types = {}\n",
    "                for chunk in processed_record.chunks:\n",
    "                    content_type = chunk.metadata.get(\"content_type\", \"content\")\n",
    "                    chunk_types[content_type] = chunk_types.get(content_type, 0) + 1\n",
    "\n",
    "            else:\n",
    "                failed_embeddings += 1\n",
    "                print(f\"   ❌ Processing failed\")\n",
    "\n",
    "        except Exception as e:\n",
    "            failed_embeddings += 1\n",
    "            print(f\"   ❌ Error processing record: {e}\")\n",
    "\n",
    "    # Final sync to ensure all changes are persisted\n",
    "    print(f\"\\n🔄 Performing final sync...\")\n",
    "    final_sync_success = await vectorstore.finalize_processing()\n",
    "    if final_sync_success:\n",
    "        sync_count += 1\n",
    "\n",
    "    # Final results\n",
    "    final_count = vectorstore.collection.count()\n",
    "\n",
    "    print(f\"\\n🎉 INTELLIGENT SYNC Vector Store Created!\")\n",
    "    print(f\"   📊 Records processed: {successful_embeddings + failed_embeddings}\")\n",
    "    print(f\"   ✅ Successfully embedded: {successful_embeddings}\")\n",
    "    print(f\"   ❌ Failed: {failed_embeddings}\")\n",
    "    print(f\"   📦 Total chunks: {total_chunks}\")\n",
    "    print(f\"   🔢 Total embeddings in collection: {final_count}\")\n",
    "\n",
    "\n",
    "results = await create_production_vector_store()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Intelligent Sync System - Major Performance Improvement\n",
    "\n",
    "### **Problem Solved: Excessive Sync Operations**\n",
    "\n",
    "**Before:** The system was syncing to GCS after **every single record**, which was extremely slow:\n",
    "```python\n",
    "# Old approach - SLOW! 💀\n",
    "for record in records:\n",
    "    await vectorstore.process_record(record)\n",
    "    await sync_to_gcs()  # ← This happened 1000x for 1000 records!\n",
    "```\n",
    "\n",
    "**After:** Smart batched sync with configurable thresholds:\n",
    "```python\n",
    "# New approach - FAST! ⚡\n",
    "for record in records:\n",
    "    await vectorstore.process_record(record)\n",
    "    # Only syncs when batch size reached OR time threshold met\n",
    "```\n",
    "\n",
    "### **🧠 Smart Sync Logic**\n",
    "\n",
    "The system now syncs intelligently based on:\n",
    "\n",
    "| Trigger | Default | Configurable | Purpose |\n",
    "|---------|---------|--------------|---------|\n",
    "| **Batch Size** | 50 records | `sync_batch_size` | Prevent data loss |\n",
    "| **Time Interval** | 10 minutes | `sync_interval_minutes` | Ensure periodic saves |\n",
    "| **Final Sync** | Always | `finalize_processing()` | Guarantee data persistence |\n",
    "| **Manual Sync** | On-demand | `sync_to_remote(force=True)` | User control |\n",
    "\n",
    "### **⚙️ Configuration Options**\n",
    "\n",
    "```yaml\n",
    "# conf/storage/osb.yaml\n",
    "osb_vector:\n",
    "  type: chromadb\n",
    "  # ... other config\n",
    "  sync_batch_size: 50          # Sync every 50 records\n",
    "  sync_interval_minutes: 10    # Sync every 10 minutes  \n",
    "  disable_auto_sync: false     # Enable/disable auto-sync\n",
    "```\n",
    "\n",
    "### **📈 Performance Benefits**\n",
    "\n",
    "For **1000 records**:\n",
    "- **Old System**: 1000 sync operations (~16 minutes of sync overhead)\n",
    "- **New System**: ~20 sync operations (~20 seconds of sync overhead)\n",
    "- **Improvement**: **98% reduction** in sync operations = **48x faster**\n",
    "\n",
    "### **🔒 Data Safety**\n",
    "\n",
    "The intelligent sync system maintains data safety through:\n",
    "- ✅ **Batch Thresholds**: Never lose more than `sync_batch_size` records\n",
    "- ✅ **Time Limits**: Automatic sync every `sync_interval_minutes`\n",
    "- ✅ **Final Guarantee**: `finalize_processing()` ensures no data loss\n",
    "- ✅ **Error Handling**: Failed syncs are logged and retried\n",
    "- ✅ **Manual Override**: Force sync anytime with `sync_to_remote(force=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test configuration-driven multi-field search capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔍 Testing Configuration-Driven Multi-Field Search<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔍 Testing Configuration-Driven Multi-Field Search\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "🎯 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. SUMMARY-ONLY SEARCH:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "🎯 \u001b[1;36m1\u001b[0m. SUMMARY-ONLY SEARCH:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Query: <span style=\"color: #008000; text-decoration-color: #008000\">'human rights'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Query: \u001b[32m'human rights'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   📋 Result <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: Brazilian general's speech<span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"font-weight: bold\">(</span>similarity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.408</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   📋 Result \u001b[1;36m1\u001b[0m: Brazilian general's speech\u001b[33m...\u001b[0m \u001b[1m(\u001b[0msimilarity: \u001b[1;36m0.408\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">      📝 Summary: of Action, UN High Commissioner for Human Rights report:\n",
       "    <span style=\"font-weight: bold\">[</span>A/HRC/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>/Add.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "      📝 Summary: of Action, UN High Commissioner for Human Rights report:\n",
       "    \u001b[1m[\u001b[0mA/HRC/\u001b[1;36m22\u001b[0m/\u001b[1;36m17\u001b[0m/Add.\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   📋 Result <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: Brazilian General's Speech<span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"font-weight: bold\">(</span>similarity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.407</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   📋 Result \u001b[1;36m2\u001b[0m: Brazilian General's Speech\u001b[33m...\u001b[0m \u001b[1m(\u001b[0msimilarity: \u001b[1;36m0.407\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">      📝 Summary: of Action, UN High Commissioner for Human Rights report:\n",
       "    <span style=\"font-weight: bold\">[</span>A/HRC/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>/Add.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "      📝 Summary: of Action, UN High Commissioner for Human Rights report:\n",
       "    \u001b[1m[\u001b[0mA/HRC/\u001b[1;36m22\u001b[0m/\u001b[1;36m17\u001b[0m/Add.\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   📋 Result <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: Brazilian general's speech<span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"font-weight: bold\">(</span>similarity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.402</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   📋 Result \u001b[1;36m3\u001b[0m: Brazilian general's speech\u001b[33m...\u001b[0m \u001b[1m(\u001b[0msimilarity: \u001b[1;36m0.402\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">      📝 Summary: -   The right to freedom of opinion and expression: Articles <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>,\n",
       "    Inte<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "      📝 Summary: -   The right to freedom of opinion and expression: Articles \u001b[1;36m19\u001b[0m and \u001b[1;36m20\u001b[0m,\n",
       "    Inte\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"🔍 Testing Configuration-Driven Multi-Field Search...\")\n",
    "\n",
    "# The content_type values come from our configuration:\n",
    "# - \"content\" (main content field)\n",
    "# - \"summary\" (from additional_fields config)\n",
    "# - \"title\" (from additional_fields config)\n",
    "\n",
    "# 1. Search summaries only (high-level concepts)\n",
    "print(\"\\n🎯 1. SUMMARY-ONLY SEARCH:\")\n",
    "print(\"   Query: 'human rights'\")\n",
    "summary_results = vectorstore.collection.query(\n",
    "    query_texts=[\"human rights\"],\n",
    "    # where={\"content_type\": \"summary\"},  # Based on config: source_field=\"summary\"\n",
    "    n_results=3,\n",
    "    include=[\"documents\", \"metadatas\", \"distances\"],\n",
    ")\n",
    "\n",
    "if summary_results[\"ids\"] and summary_results[\"ids\"][0]:\n",
    "    for i, (doc, metadata, distance) in enumerate(\n",
    "        zip(summary_results[\"documents\"][0], summary_results[\"metadatas\"][0], summary_results[\"distances\"][0])\n",
    "    ):\n",
    "        similarity = 1 - distance\n",
    "        title = metadata.get(\"title\", \"Untitled\")\n",
    "        print(f\"   📋 Result {i+1}: {title[:40]}... (similarity: {similarity:.3f})\")\n",
    "        print(f\"      📝 Summary: {doc[:80]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data source configuration for the RAG agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 16:40:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m variants.py:75 \u001b[33mError importing module buttermilk.agents.imagegen: module 'google.genai' has no attribute 'GenerativeModel'\u001b[0m\n",
      "\u001b[32m2025-06-17 16:40:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m variants.py:75 \u001b[33mError importing module buttermilk.agents.scraper: Private attributes must not use valid field names; use sunder names, e.g. '_driver' instead of 'driver'.\u001b[0m\n",
      "\u001b[32m2025-06-17 16:40:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m variants.py:75 \u001b[33mError importing module buttermilk.runner.recoveryrunner: cannot import name 'get_bm' from 'buttermilk._core.bm_init' (/workspaces/buttermilk/buttermilk/_core/bm_init.py)\u001b[0m\n",
      "\u001b[32m2025-06-17 16:40:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m variants.py:75 \u001b[33mError importing module buttermilk.tools.slurp: cannot import name 'SingleAgent' from 'buttermilk._core.agent' (/workspaces/buttermilk/buttermilk/_core/agent.py)\u001b[0m\n",
      "\u001b[32m2025-06-17 16:40:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m variants.py:75 \u001b[33mError importing module buttermilk.toxicity: No module named 'torch'\u001b[0m\n",
      "\u001b[32m2025-06-17 16:40:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m variants.py:68 \u001b[33mAgentRegistry hit error importing buttermilk.toxicity\u001b[0m\n",
      "\u001b[32m2025-06-17 16:40:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m variants.py:75 \u001b[33mError importing module buttermilk.utils.video_frames: libGL.so.1: cannot open shared object file: No such file or directory\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from buttermilk._core.config import (  # Configuration models\n",
    "    AgentVariants,\n",
    ")\n",
    "\n",
    "rag_variants = AgentVariants(**cfg.agents.researcher)\n",
    "configs = rag_variants.get_configs()\n",
    "configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create storage configuration for the RAG agent using unified system\n",
    "storage_config = StorageConfig(\n",
    "    type=\"chromadb\", persist_directory=\"./data/osb_chromadb\", collection_name=\"osb_fulltext\", embedding_model=\"text-embedding-005\", dimensionality=768\n",
    ")\n",
    "\n",
    "# Create agent configuration\n",
    "agent_config = AgentConfig(\n",
    "    role=\"RESEARCHER\",\n",
    "    agent_obj=\"RagAgent\",\n",
    "    description=\"OSB Research Assistant\",\n",
    "    data={\"osb_vector\": storage_config},\n",
    "    variants={\"model\": \"gemini-1.5-flash\"},\n",
    "    parameters={\"template\": \"rag_research\", \"n_results\": 10, \"no_duplicates\": False, \"max_queries\": 3},\n",
    ")\n",
    "\n",
    "# Initialize the RAG agent\n",
    "rag_agent = RagAgent(**agent_config.model_dump())\n",
    "print(\"RAG agent initialized successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Enhanced RAG Agent with intelligent search capabilities\n",
    "from buttermilk.agents.rag.enhanced_rag_agent import EnhancedRagAgent\n",
    "\n",
    "# IMPORTANT: Use the SAME config as your vectorstore to avoid mismatches!\n",
    "storage_config = StorageConfig(\n",
    "    type=\"chromadb\", \n",
    "    persist_directory=vectorstore.persist_directory,  # Use same directory as vectorstore\n",
    "    collection_name=vectorstore.collection_name,      # Use same collection name\n",
    "    embedding_model=vectorstore.embedding_model,      # Use same embedding model\n",
    "    dimensionality=vectorstore.dimensionality         # Use same dimensions\n",
    ")\n",
    "\n",
    "# Create Enhanced RAG agent configuration\n",
    "enhanced_agent_config = AgentConfig(\n",
    "    role=\"ENHANCED_RESEARCHER\",\n",
    "    agent_obj=\"buttermilk.agents.rag.enhanced_rag_agent.EnhancedRagAgent\",\n",
    "    description=\"Enhanced OSB Research Assistant with intelligent search capabilities\",\n",
    "    data={\"vectorstore\": storage_config},\n",
    "    parameters={\n",
    "        \"enable_query_planning\": True,      # Use LLM to analyze queries\n",
    "        \"enable_result_synthesis\": True,    # Use LLM to synthesize results\n",
    "        \"search_strategies\": [\"semantic\", \"title\", \"summary\", \"hybrid\", \"metadata\"],\n",
    "        \"max_search_rounds\": 3,\n",
    "        \"confidence_threshold\": 0.5,\n",
    "        \"max_results_per_strategy\": 5,\n",
    "        \"include_search_explanation\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize the Enhanced RAG agent\n",
    "enhanced_rag_agent = EnhancedRagAgent(**enhanced_agent_config.model_dump())\n",
    "print(\"✅ Enhanced RAG agent initialized successfully\")\n",
    "print(f\"   🧠 Query Planning: {enhanced_agent_config.parameters['enable_query_planning']}\")\n",
    "print(f\"   🔬 Result Synthesis: {enhanced_agent_config.parameters['enable_result_synthesis']}\")\n",
    "print(f\"   🎯 Search Strategies: {len(enhanced_agent_config.parameters['search_strategies'])}\")\n",
    "print(f\"   📁 Directory: {storage_config.persist_directory}\")\n",
    "print(f\"   🏪 Collection: {storage_config.collection_name}\")\n",
    "print(f\"   🧠 Model: {storage_config.embedding_model}\")\n",
    "print(f\"   📐 Dimensions: {storage_config.dimensionality}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search_osb_database(queries):\n",
    "    \"\"\"Search the OSB database with multiple queries.\"\"\"\n",
    "    print(\"\\n=== OSB Database Search Results ===\")\n",
    "\n",
    "    results = await rag_agent.fetch(queries)\n",
    "\n",
    "    for i, (query, result) in enumerate(zip(queries, results)):\n",
    "        print(f\"\\n--- Query {i+1}: {query} ---\")\n",
    "        print(f\"Found {len(result.results)} relevant chunks\")\n",
    "\n",
    "        if result.results:\n",
    "            # Show the top result\n",
    "            top_result = result.results[0]\n",
    "            print(f\"\\nTop Result:\")\n",
    "            print(f\"Document: {top_result.document_title}\")\n",
    "            print(f\"Case Number: {top_result.metadata.get('case_number', 'N/A')}\")\n",
    "            print(f\"Text: {top_result.full_text[:300]}...\")\n",
    "        else:\n",
    "            print(\"No results found\")\n",
    "\n",
    "\n",
    "# Example search queries\n",
    "search_queries = [\n",
    "    \"What are the challenges with automated content moderation?\",\n",
    "    \"How effective are age verification systems?\",\n",
    "    \"What techniques are used to spread misinformation?\",\n",
    "]\n",
    "\n",
    "await search_osb_database(search_queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demonstrate_enhanced_rag():\n",
    "    \"\"\"Demonstrate Enhanced RAG capabilities with intelligent search planning.\"\"\"\n",
    "\n",
    "    print(\"🎯 ENHANCED RAG DEMONSTRATION\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Test queries that showcase different capabilities\n",
    "    test_queries = [\n",
    "        {\n",
    "            \"query\": \"What are the main challenges with content moderation?\",\n",
    "            \"expected_strategy\": \"Should use hybrid search (title + summary + content)\",\n",
    "            \"focus\": \"Broad exploratory query\",\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Find cases about misinformation detection algorithms\",\n",
    "            \"expected_strategy\": \"Should use metadata + title search\",\n",
    "            \"focus\": \"Specific case-focused query\",\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"How do platforms protect user privacy?\",\n",
    "            \"expected_strategy\": \"Should use summary + semantic search\",\n",
    "            \"focus\": \"Policy-focused query\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for i, test in enumerate(test_queries, 1):\n",
    "        print(f\"\\n🔍 TEST {i}: {test['focus']}\")\n",
    "        print(f\"Query: '{test['query']}'\")\n",
    "        print(f\"Expected: {test['expected_strategy']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        try:\n",
    "            # Create AgentInput for the enhanced RAG agent\n",
    "            from buttermilk._core.contract import AgentInput\n",
    "\n",
    "            agent_input = AgentInput(inputs={\"query\": test[\"query\"]}, parameters={}, context=[], records=[])\n",
    "\n",
    "            # Process with Enhanced RAG\n",
    "            result = await enhanced_rag_agent._process(message=agent_input)\n",
    "\n",
    "            print(f\"✅ RESULT:\")\n",
    "            print(f\"   Response: {result.outputs[:200]}...\")\n",
    "\n",
    "            # Show metadata about the search\n",
    "            metadata = result.metadata\n",
    "            print(f\"\\n📊 SEARCH METADATA:\")\n",
    "            print(f\"   Total Results: {metadata.get('total_results', 0)}\")\n",
    "            print(f\"   Strategies Used: {metadata.get('strategies_used', [])}\")\n",
    "            print(f\"   Confidence Score: {metadata.get('confidence_score', 0.0):.2f}\")\n",
    "            print(f\"   Key Themes: {metadata.get('key_themes', [])}\")\n",
    "\n",
    "            if metadata.get(\"search_explanation\"):\n",
    "                print(f\"   Search Strategy: {metadata['search_explanation']}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ ERROR: {e}\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "    print(\"\\n🎉 Enhanced RAG demonstration complete!\")\n",
    "    print(\"\\nKey Benefits Demonstrated:\")\n",
    "    print(\"✅ Intelligent query analysis and search planning\")\n",
    "    print(\"✅ Multi-field search across titles, summaries, and content\")\n",
    "    print(\"✅ LLM-driven result synthesis and ranking\")\n",
    "    print(\"✅ Adaptive search strategies based on query type\")\n",
    "    print(\"✅ Comprehensive metadata and confidence scoring\")\n",
    "    print(\"✅ Smart cache management prevents overwriting local changes\")\n",
    "    print(\"✅ Automatic sync-back to remote storage after embedding operations\")\n",
    "\n",
    "\n",
    "# Run the enhanced RAG demonstration\n",
    "await demonstrate_enhanced_rag()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Chat Interface\n",
    "\n",
    "Now let's create an interactive interface to chat with our OSB knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_with_osb(user_question):\n",
    "    \"\"\"Interactive chat with OSB knowledge base.\"\"\"\n",
    "    print(f\"\\n🔍 User Question: {user_question}\")\n",
    "\n",
    "    # Search for relevant context\n",
    "    search_results = await rag_agent.fetch([user_question])\n",
    "\n",
    "    if search_results and search_results[0].results:\n",
    "        context = search_results[0]\n",
    "        print(f\"\\n📚 Found {len(context.results)} relevant documents\")\n",
    "\n",
    "        # Display relevant chunks\n",
    "        print(\"\\n📋 Relevant Information:\")\n",
    "        for i, result in enumerate(context.results[:3]):  # Show top 3\n",
    "            print(f\"\\n{i+1}. {result.document_title} ({result.metadata.get('case_number', 'N/A')})\")\n",
    "            print(f\"   {result.full_text[:200]}...\")\n",
    "\n",
    "        # In a real implementation, this would be sent to an LLM for synthesis\n",
    "        print(\"\\n🤖 AI Response: [In a real implementation, the retrieved context would be sent to an LLM to generate a synthesized response]\")\n",
    "    else:\n",
    "        print(\"\\n❌ No relevant information found in the OSB database\")\n",
    "\n",
    "\n",
    "# Example chat interactions\n",
    "example_questions = [\n",
    "    \"What are the main issues with current content moderation approaches?\",\n",
    "    \"What recommendations exist for age verification?\",\n",
    "    \"How do platforms detect and counter misinformation?\",\n",
    "]\n",
    "\n",
    "for question in example_questions:\n",
    "    await chat_with_osb(question)\n",
    "    print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Vector Store Analysis\n",
    "\n",
    "Let's analyze our vector store to understand what we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get collection statistics\n",
    "collection = vectorstore.collection\n",
    "count = collection.count()\n",
    "\n",
    "print(f\"\\n=== OSB Vector Store Statistics ===\")\n",
    "print(f\"Collection Name: {vectorstore.collection_name}\")\n",
    "print(f\"Total Chunks: {count}\")\n",
    "print(f\"Embedding Dimensions: {vectorstore.dimensionality}\")\n",
    "print(f\"Embedding Model: {vectorstore.embedding_model}\")\n",
    "\n",
    "# Get a sample of metadata to understand the structure\n",
    "sample_results = collection.get(limit=3, include=[\"metadatas\", \"documents\"])\n",
    "\n",
    "print(f\"\\n=== Sample Metadata Structure ===\")\n",
    "if sample_results[\"metadatas\"]:\n",
    "    sample_metadata = sample_results[\"metadatas\"][0]\n",
    "    print(\"Available metadata fields:\")\n",
    "    for key, value in sample_metadata.items():\n",
    "        print(f\"  - {key}: {type(value).__name__} = {str(value)[:50]}...\")\n",
    "\n",
    "print(f\"\\n=== Storage Locations ===\")\n",
    "print(f\"ChromaDB Directory: {vectorstore.persist_directory}\")\n",
    "print(f\"Embeddings Directory: {vectorstore.arrow_save_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced Search Examples\n",
    "\n",
    "Let's explore some advanced search patterns and filtering capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct ChromaDB queries with metadata filtering\n",
    "async def advanced_search_examples():\n",
    "    \"\"\"Demonstrate advanced search capabilities.\"\"\"\n",
    "    print(\"\\n=== Advanced Search Examples ===\")\n",
    "\n",
    "    # 1. Search with metadata filtering\n",
    "    print(\"\\n1. Search within specific case:\")\n",
    "    results = collection.query(\n",
    "        query_texts=[\"content moderation challenges\"], n_results=5, where={\"case_number\": \"OSB-2024-001\"}, include=[\"documents\", \"metadatas\"]\n",
    "    )\n",
    "    print(f\"   Found {len(results['ids'][0]) if results['ids'] else 0} results in OSB-2024-001\")\n",
    "\n",
    "    # 2. Similarity search across all documents\n",
    "    print(\"\\n2. General similarity search:\")\n",
    "    results = collection.query(query_texts=[\"artificial intelligence and safety\"], n_results=5, include=[\"documents\", \"metadatas\", \"distances\"])\n",
    "\n",
    "    if results[\"ids\"] and results[\"ids\"][0]:\n",
    "        print(f\"   Found {len(results['ids'][0])} results\")\n",
    "        for i, (doc, metadata, distance) in enumerate(zip(results[\"documents\"][0][:3], results[\"metadatas\"][0][:3], results[\"distances\"][0][:3])):\n",
    "            print(f\"   Result {i+1} (similarity: {1-distance:.3f}): {metadata.get('title', 'N/A')}\")\n",
    "            print(f\"     {doc[:100]}...\")\n",
    "\n",
    "    # 3. Multi-query search\n",
    "    print(\"\\n3. Multi-query search:\")\n",
    "    multi_queries = [\"platform safety measures\", \"user protection mechanisms\", \"digital safety standards\"]\n",
    "\n",
    "    for query in multi_queries:\n",
    "        results = collection.query(query_texts=[query], n_results=2, include=[\"metadatas\"])\n",
    "        count = len(results[\"ids\"][0]) if results[\"ids\"] else 0\n",
    "        print(f\"   '{query}': {count} results\")\n",
    "\n",
    "\n",
    "await advanced_search_examples()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Production Considerations\n",
    "\n",
    "Here are key considerations for using this in production:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\"\"\n",
    "=== Production Deployment Checklist ===\n",
    "\n",
    "🔧 Configuration:\n",
    "   ✓ Use GCS for persist_directory: gs://your-bucket/chromadb\n",
    "   ✓ Configure appropriate chunk_size for your content\n",
    "   ✓ Set concurrency based on your compute resources\n",
    "   ✓ Use production embedding models (text-embedding-004/005)\n",
    "\n",
    "📊 Performance:\n",
    "   ✓ Monitor embedding generation costs\n",
    "   ✓ Implement caching for frequently accessed data\n",
    "   ✓ Use batch processing for large datasets\n",
    "   ✓ Configure appropriate timeout values\n",
    "\n",
    "🔒 Security:\n",
    "   ✓ Secure GCS bucket access with proper IAM\n",
    "   ✓ Implement data access controls\n",
    "   ✓ Audit vector store queries\n",
    "   ✓ Protect sensitive metadata\n",
    "\n",
    "🚀 Scalability:\n",
    "   ✓ Plan for vector store size growth\n",
    "   ✓ Implement horizontal scaling for embeddings\n",
    "   ✓ Monitor query performance\n",
    "   ✓ Set up proper logging and monitoring\n",
    "\n",
    "🔄 Maintenance:\n",
    "   ✓ Plan for data updates and reindexing\n",
    "   ✓ Implement backup strategies\n",
    "   ✓ Version control for embeddings and metadata\n",
    "   ✓ Regular quality assessments\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Show next steps\n",
    "print(\n",
    "    \"\"\"\n",
    "=== Next Steps ===\n",
    "\n",
    "1. Scale to Full Dataset:\n",
    "   - Use the osb_vectorize.yaml configuration\n",
    "   - Run: uv run python -m buttermilk.data.vector +run=osb_vectorize\n",
    "\n",
    "2. Deploy RAG Flow:\n",
    "   - Use the osb_rag.yaml flow configuration\n",
    "   - Run: uv run python -m buttermilk.runner.cli +flow=osb_rag +run=api\n",
    "\n",
    "3. Integrate with Frontend:\n",
    "   - Use the Buttermilk web interface\n",
    "   - Connect to WebSocket endpoints for real-time chat\n",
    "\n",
    "4. Monitor and Optimize:\n",
    "   - Track query performance\n",
    "   - Monitor embedding costs\n",
    "   - Tune chunk sizes and retrieval parameters\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔒 Smart Cache Management\n",
    "\n",
    "The vector database now includes smart cache management to prevent overwriting local changes:\n",
    "\n",
    "### **Problem Solved**\n",
    "Previously, re-running embedding cells would download the remote ChromaDB cache and overwrite any local changes, losing newly added embeddings.\n",
    "\n",
    "### **Solution: Smart Cache Management**\n",
    "The system now includes intelligent cache handling:\n",
    "\n",
    "```python\n",
    "async def _smart_cache_management(self, remote_path: str) -> Path:\n",
    "    \"\"\"Smart cache management that prevents overwriting newer local changes.\"\"\"\n",
    "    \n",
    "    # Check if local cache was recently modified (within 1 hour)\n",
    "    if time_since_modified < 3600:  # 1 hour\n",
    "        logger.info(\"🔒 Skipping download to preserve local changes\")\n",
    "        return cache_path\n",
    "    \n",
    "    # Only download if cache is stale\n",
    "    logger.info(\"🔄 Syncing remote ChromaDB\")\n",
    "    return await ensure_chromadb_cache(remote_path)\n",
    "```\n",
    "\n",
    "### **Automatic Sync-Back**\n",
    "After successful embedding operations, local changes are automatically synced to remote storage:\n",
    "\n",
    "```python\n",
    "async def _sync_local_changes_to_remote(self) -> None:\n",
    "    \"\"\"Sync local ChromaDB changes back to remote storage.\"\"\"\n",
    "    \n",
    "    # Only sync if recently modified (indicates recent work)\n",
    "    if time_since_modified < 21600:  # 6 hours\n",
    "        await upload_chromadb_cache(local_path, remote_path)\n",
    "        logger.info(\"✅ Successfully synced local changes to remote storage\")\n",
    "```\n",
    "\n",
    "### **Benefits**\n",
    "- ✅ **Prevents Data Loss**: Local embedding work is preserved\n",
    "- ✅ **Automatic Sync**: Changes are pushed back to remote storage  \n",
    "- ✅ **Time-Based Logic**: Only acts on recently modified caches\n",
    "- ✅ **Transparent Operation**: Clear logging of all cache decisions\n",
    "- ✅ **Production Ready**: Handles concurrent access and failures gracefully\n",
    "\n",
    "### **Usage**\n",
    "This happens automatically - no code changes needed! The smart cache management activates whenever you:\n",
    "1. Run embedding operations in this notebook\n",
    "2. Use the vectorstore in production flows\n",
    "3. Process new documents with the vector pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Production Deployment Guide\n",
    "\n",
    "This vector store is now ready for production use with the unified storage system. Here's how to deploy and use it:\n",
    "\n",
    "### 📋 **For Full Dataset Processing**\n",
    "```python\n",
    "# In cell 7, change this line:\n",
    "doc_limit = 5  # Set to None for full dataset\n",
    "\n",
    "# To:\n",
    "doc_limit = None  # Processes all OSB documents\n",
    "```\n",
    "\n",
    "### 🏭 **Production Usage Examples**\n",
    "\n",
    "#### **Option 1: RAG Agent Integration**\n",
    "```python\n",
    "from buttermilk.agents.rag.rag_agent import RagAgent\n",
    "from buttermilk._core.config import AgentConfig\n",
    "from buttermilk._core.storage_config import StorageConfig\n",
    "\n",
    "# Same config as creation - no changes needed with unified storage!\n",
    "storage_config = StorageConfig(**cfg.storage.osb_vector)\n",
    "\n",
    "agent_config = AgentConfig(\n",
    "    role=\"RESEARCHER\",\n",
    "    agent_obj=\"RagAgent\", \n",
    "    description=\"OSB Knowledge Assistant\",\n",
    "    data={\"osb_vector\": storage_config},\n",
    "    parameters={\"n_results\": 10, \"max_queries\": 3}\n",
    ")\n",
    "\n",
    "rag_agent = RagAgent(**agent_config.model_dump())\n",
    "```\n",
    "\n",
    "#### **Option 2: Direct Storage Access**\n",
    "```python\n",
    "# Create vector store instance (reads existing embeddings) using unified storage\n",
    "production_vectorstore = bm.get_storage(cfg.storage.osb_vector)\n",
    "await production_vectorstore.ensure_cache_initialized()\n",
    "\n",
    "# Perform semantic search\n",
    "results = production_vectorstore.collection.query(\n",
    "    query_texts=[\"platform safety policies\"],\n",
    "    n_results=5\n",
    ")\n",
    "```\n",
    "\n",
    "#### **Option 3: Flow Integration**\n",
    "```yaml\n",
    "# conf/flows/osb_rag.yaml\n",
    "defaults:\n",
    "  - base_flow\n",
    "\n",
    "orchestrator: buttermilk.orchestrators.groupchat.AutogenOrchestrator\n",
    "storage: osb_vector  # References the same storage config\n",
    "agents: [rag_agent, host/sequencer]\n",
    "```\n",
    "\n",
    "### 🏗️ **Enhanced Record Benefits**\n",
    "- ✅ **Direct Processing**: Records processed without conversion steps\n",
    "- ✅ **Vector Fields**: Built-in support for chunks, embeddings, file_path\n",
    "- ✅ **Unified API**: Same Record class used throughout the system\n",
    "- ✅ **Type Safety**: Full Pydantic validation for vector operations\n",
    "\n",
    "### 🔒 **Production Considerations**\n",
    "- ✅ **Persistent Storage**: Vector store saved to `gs://prosocial-public/osb/chromadb`  \n",
    "- ✅ **Config Reuse**: Same `osb.yaml` works for both creation and reading\n",
    "- ✅ **Scalability**: ChromaDB handles thousands of documents efficiently\n",
    "- ✅ **Monitoring**: Check collection count and performance metrics\n",
    "- ✅ **Updates**: Re-run this notebook to add new OSB documents\n",
    "\n",
    "### 💡 **Next Steps**\n",
    "1. **Scale Up**: Remove `doc_limit` to process full OSB dataset\n",
    "2. **Deploy**: Use in RAG agents, search APIs, or analytical workflows  \n",
    "3. **Monitor**: Track embedding quality and search relevance\n",
    "4. **Iterate**: Add new documents by re-running the pipeline\n",
    "\n",
    "### 🔧 **Migration Benefits**\n",
    "This notebook now uses:\n",
    "- ✅ **StorageConfig**: Unified configuration for all storage types\n",
    "- ✅ **Enhanced Record**: Built-in vector processing capabilities  \n",
    "- ✅ **bm.get_storage()**: Unified storage access API\n",
    "- ✅ **process_record()**: Direct Record processing without conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kq161px7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the text splitter behavior with a sample text\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create a test text that should definitely be split\n",
    "test_text = \"This is a test document. \" * 100  # 2500 characters\n",
    "print(f\"Test text length: {len(test_text)} characters\")\n",
    "\n",
    "# Test with the same config as OSB\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,\n",
    "    chunk_overlap=400,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    "    add_start_index=False,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(test_text)\n",
    "print(f\"Number of chunks created: {len(chunks)}\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}: {len(chunk)} characters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1959yzujxs8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a sample of the OSB data to understand the actual field structure\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Let's fetch a small sample of the OSB data to see the actual structure\n",
    "try:\n",
    "    # For security, I'll create a simple test to understand the field structure\n",
    "    # Based on the config, it seems like the JSON has:\n",
    "    # - \"id\" field (maps to record_id)\n",
    "    # - \"full_text\" field (maps to content)\n",
    "    # - \"title\", \"case_number\", \"url\", \"summary\" fields (go to metadata)\n",
    "\n",
    "    print(\"Based on your config, the OSB JSON structure should be:\")\n",
    "    print(\n",
    "        \"\"\"\n",
    "    {\n",
    "        \"id\": \"some-id\",\n",
    "        \"full_text\": \"The main content text that should be chunked\",\n",
    "        \"title\": \"Document title\", \n",
    "        \"case_number\": \"OSB-2024-001\",\n",
    "        \"url\": \"https://...\",\n",
    "        \"summary\": \"Document summary\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nYour current mapping:\")\n",
    "    print(\"- JSON 'id' → Record 'record_id'\")\n",
    "    print(\"- JSON 'full_text' → Record 'content'\")\n",
    "    print(\"- JSON 'title' → Record metadata['title']\")\n",
    "    print(\"- JSON 'summary' → Record metadata['summary']\")\n",
    "    print(\"- JSON 'case_number' → Record metadata['case_number']\")\n",
    "    print(\"- JSON 'url' → Record metadata['url']\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a60qp1mf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's quickly test what happens when we load OSB data with the current config\n",
    "from buttermilk._core.types import Record\n",
    "\n",
    "# Test creating a record like OSB would\n",
    "test_record = Record(\n",
    "    record_id=\"test-123\",\n",
    "    content=\"This is the main content from fulltext field\",\n",
    "    metadata={\"title\": \"Test Document\", \"summary\": \"Test summary\", \"case_number\": \"OSB-2024-001\", \"url\": \"https://example.com\"},\n",
    ")\n",
    "\n",
    "print(\"🔍 Record Fields:\")\n",
    "print(f\"content: {test_record.content[:50]}...\")\n",
    "print(f\"text_content: {test_record.text_content[:50]}...\")\n",
    "print(f\"metadata keys: {list(test_record.metadata.keys())}\")\n",
    "print(f\"metadata: {test_record.metadata}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "buttermilk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
