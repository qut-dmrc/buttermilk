{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSB Vector Database Example\n",
    "\n",
    "This notebook demonstrates how to create and use a vector database from Oversight Board full text data using Buttermilk's ChromaDB integration.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll show how to:\n",
    "1. Load OSB JSON data using existing data loaders\n",
    "2. Generate embeddings and create a ChromaDB vector store\n",
    "3. Use the generic RAG agent for interactive question answering\n",
    "4. Demonstrate semantic search capabilities\n",
    "\n",
    "This example uses the generic infrastructure that works with any JSON dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration Setup\n",
    "\n",
    "First, let's set up the configuration for our OSB vector database pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 05:36:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m bm_init.py:778 Logging set up for run: platform='local' name='bm_api' job='osb_vectorise' run_id='20250616T1936Z-cBN9-docker-desktop-debian' ip=None node_name='docker-desktop' save_dir='/tmp/tmpdnkw9ojy/bm_api/osb_vectorise/20250616T1936Z-cBN9-docker-desktop-debian' flow_api=None. Save directory: /tmp/tmpdnkw9ojy/bm_api/osb_vectorise/20250616T1936Z-cBN9-docker-desktop-debian\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized Buttermilk <span style=\"font-weight: bold\">(</span>bm<span style=\"font-weight: bold\">)</span> with configuration:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized Buttermilk \u001b[1m(\u001b[0mbm\u001b[1m)\u001b[0m with configuration:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'platform'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'local'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'bm_api'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'job'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'osb_vectorise'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'run_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'20250616T1936Z-cBN9-docker-desktop-debian'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'docker-desktop'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'save_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/tmp/tmpdnkw9ojy/bm_api/osb_vectorise/20250616T1936Z-cBN9-docker-desktop-debian'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'connections'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'secret_provider'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'models_secret'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dev__llm__connections'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'credentials_secret'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dev__shared_credentials'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'logger_cfg'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'location'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us-central1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'verbose'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'pubsub'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'jobs_subscription'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'jobs-sub'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'status_subscription'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'flow-sub'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'status_topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'jobs_topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'jobs'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'clouds'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'quota_project_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'vertex'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'region'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us-central1'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'location'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us-central1'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'bucket'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-de'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'tracing'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'enabled'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'api_key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'weave'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'otlp_headers'</span>: <span style=\"font-weight: bold\">{}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'datasets'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'save_dir_base'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/tmp/tmpdnkw9ojy'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'platform'\u001b[0m: \u001b[32m'local'\u001b[0m,\n",
       "    \u001b[32m'name'\u001b[0m: \u001b[32m'bm_api'\u001b[0m,\n",
       "    \u001b[32m'job'\u001b[0m: \u001b[32m'osb_vectorise'\u001b[0m,\n",
       "    \u001b[32m'run_id'\u001b[0m: \u001b[32m'20250616T1936Z-cBN9-docker-desktop-debian'\u001b[0m,\n",
       "    \u001b[32m'node_name'\u001b[0m: \u001b[32m'docker-desktop'\u001b[0m,\n",
       "    \u001b[32m'save_dir'\u001b[0m: \u001b[32m'/tmp/tmpdnkw9ojy/bm_api/osb_vectorise/20250616T1936Z-cBN9-docker-desktop-debian'\u001b[0m,\n",
       "    \u001b[32m'connections'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'secret_provider'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m,\n",
       "        \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m,\n",
       "        \u001b[32m'models_secret'\u001b[0m: \u001b[32m'dev__llm__connections'\u001b[0m,\n",
       "        \u001b[32m'credentials_secret'\u001b[0m: \u001b[32m'dev__shared_credentials'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'logger_cfg'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m, \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m, \u001b[32m'location'\u001b[0m: \u001b[32m'us-central1'\u001b[0m, \u001b[32m'verbose'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'pubsub'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m,\n",
       "        \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m,\n",
       "        \u001b[32m'jobs_subscription'\u001b[0m: \u001b[32m'jobs-sub'\u001b[0m,\n",
       "        \u001b[32m'status_subscription'\u001b[0m: \u001b[32m'flow-sub'\u001b[0m,\n",
       "        \u001b[32m'status_topic'\u001b[0m: \u001b[32m'flow'\u001b[0m,\n",
       "        \u001b[32m'jobs_topic'\u001b[0m: \u001b[32m'jobs'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'clouds'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m, \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m, \u001b[32m'quota_project_id'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'type'\u001b[0m: \u001b[32m'vertex'\u001b[0m,\n",
       "            \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m,\n",
       "            \u001b[32m'region'\u001b[0m: \u001b[32m'us-central1'\u001b[0m,\n",
       "            \u001b[32m'location'\u001b[0m: \u001b[32m'us-central1'\u001b[0m,\n",
       "            \u001b[32m'bucket'\u001b[0m: \u001b[32m'prosocial-de'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'tracing'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'enabled'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'api_key'\u001b[0m: \u001b[32m''\u001b[0m, \u001b[32m'provider'\u001b[0m: \u001b[32m'weave'\u001b[0m, \u001b[32m'otlp_headers'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'datasets'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'save_dir_base'\u001b[0m: \u001b[32m'/tmp/tmpdnkw9ojy'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 05:36:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m nb.py:59 Starting interactive run for bm_api job osb_vectorise in notebook\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🚀 Buttermilk initialized for JSON-to-Vector tutorial\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🚀 Buttermilk initialized for JSON-to-Vector tutorial\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'osb_json'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcs'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gs://prosocial-public/osb/03_osb_fulltext_summaries.json'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'columns'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fulltext'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'result'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'result'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'location'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'location'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'case_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'case_date'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'topics'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'topics'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'standards'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'standards'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'recommendations'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'recommendations'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'job_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'job_id'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span><span style=\"font-weight: bold\">}}}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'osb_vector'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'chromadb'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'persist_directory'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gs://prosocial-dev/data/osb/chromadb'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'collection_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'osb_fulltext'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'embedding_model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gemini-embedding-001'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'dimensionality'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'multi_field_embedding'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content_field'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1200</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_overlap'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'additional_fields'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source_field'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source_field'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'case_description'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source_field'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'reasoning'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source_field'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'recommendations'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'recommendations'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span><span style=\"font-weight: bold\">}]}}}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'osb_json'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'gcs'\u001b[0m, \u001b[32m'path'\u001b[0m: \u001b[32m'gs://prosocial-public/osb/03_osb_fulltext_summaries.json'\u001b[0m, \u001b[32m'columns'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'record_id'\u001b[0m: \u001b[32m'record_id'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'fulltext'\u001b[0m, \u001b[32m'metadata'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'title'\u001b[0m, \u001b[32m'description'\u001b[0m: \u001b[32m'content'\u001b[0m, \u001b[32m'result'\u001b[0m: \u001b[32m'result'\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'type'\u001b[0m, \u001b[32m'location'\u001b[0m: \u001b[32m'location'\u001b[0m, \u001b[32m'case_date'\u001b[0m: \u001b[32m'case_date'\u001b[0m, \u001b[32m'topics'\u001b[0m: \u001b[32m'topics'\u001b[0m, \u001b[32m'standards'\u001b[0m: \u001b[32m'standards'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[32m'reasons'\u001b[0m, \u001b[32m'recommendations'\u001b[0m: \u001b[32m'recommendations'\u001b[0m, \u001b[32m'job_id'\u001b[0m: \u001b[32m'job_id'\u001b[0m, \u001b[32m'timestamp'\u001b[0m: \u001b[32m'timestamp'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'osb_vector'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'chromadb'\u001b[0m, \u001b[32m'persist_directory'\u001b[0m: \u001b[32m'gs://prosocial-dev/data/osb/chromadb'\u001b[0m, \u001b[32m'collection_name'\u001b[0m: \u001b[32m'osb_fulltext'\u001b[0m, \u001b[32m'embedding_model'\u001b[0m: \u001b[32m'gemini-embedding-001'\u001b[0m, \u001b[32m'dimensionality'\u001b[0m: \u001b[1;36m3072\u001b[0m, \u001b[32m'multi_field_embedding'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'content_field'\u001b[0m: \u001b[32m'content'\u001b[0m, \u001b[32m'chunk_size'\u001b[0m: \u001b[1;36m1200\u001b[0m, \u001b[32m'chunk_overlap'\u001b[0m: \u001b[1;36m400\u001b[0m, \u001b[32m'additional_fields'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'source_field'\u001b[0m: \u001b[32m'title'\u001b[0m, \u001b[32m'chunk_type'\u001b[0m: \u001b[32m'title'\u001b[0m, \u001b[32m'min_length'\u001b[0m: \u001b[1;36m10\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'source_field'\u001b[0m: \u001b[32m'description'\u001b[0m, \u001b[32m'chunk_type'\u001b[0m: \u001b[32m'case_description'\u001b[0m, \u001b[32m'min_length'\u001b[0m: \u001b[1;36m50\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'source_field'\u001b[0m: \u001b[32m'reasons'\u001b[0m, \u001b[32m'chunk_type'\u001b[0m: \u001b[32m'reasoning'\u001b[0m, \u001b[32m'min_length'\u001b[0m: \u001b[1;36m100\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'source_field'\u001b[0m: \u001b[32m'recommendations'\u001b[0m, \u001b[32m'chunk_type'\u001b[0m: \u001b[32m'recommendations'\u001b[0m, \u001b[32m'min_length'\u001b[0m: \u001b[1;36m50\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 05:36:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m save.py:641 Successfully dumped data to local disk (JSON): /tmp/tmpdnkw9ojy/bm_api/osb_vectorise/20250616T1936Z-cBN9-docker-desktop-debian/tmp9lyfh_zz.json.\n",
      "\u001b[32m2025-06-17 05:36:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m save.py:215 Successfully saved data using dump_to_disk to: /tmp/tmpdnkw9ojy/bm_api/osb_vectorise/20250616T1936Z-cBN9-docker-desktop-debian/tmp9lyfh_zz.json.\n",
      "\u001b[32m2025-06-17 05:36:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m bm_init.py:864 {'message': 'Successfully saved data to: /tmp/tmpdnkw9ojy/bm_api/osb_vectorise/20250616T1936Z-cBN9-docker-desktop-debian/tmp9lyfh_zz.json', 'uri': '/tmp/tmpdnkw9ojy/bm_api/osb_vectorise/20250616T1936Z-cBN9-docker-desktop-debian/tmp9lyfh_zz.json', 'run_id': '20250616T1936Z-cBN9-docker-desktop-debian'}\n"
     ]
    }
   ],
   "source": [
    "from rich import print\n",
    "from rich.pretty import pprint\n",
    "import asyncio\n",
    "import json\n",
    "from pathlib import Path\n",
    "import hydra\n",
    "from hydra import compose, initialize_config_dir\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "# Buttermilk imports - updated for unified storage system\n",
    "from buttermilk import logger\n",
    "from buttermilk.data.vector import ChromaDBEmbeddings, DefaultTextSplitter\n",
    "from buttermilk.agents.rag.rag_agent import RagAgent\n",
    "from buttermilk._core.config import AgentConfig\n",
    "from buttermilk._core.storage_config import StorageConfig  # New unified config\n",
    "from buttermilk._core.types import Record  # Enhanced Record with vector capabilities\n",
    "\n",
    "from buttermilk.utils.nb import init\n",
    "from buttermilk._core.dmrc import get_bm, set_bm\n",
    "\n",
    "# Initialize Buttermilk\n",
    "cfg = init(job=\"osb_vectorise\", overrides=[\"+storage=osb\", \"+agents=rag_generic\", \"+llms=lite\"])\n",
    "bm = get_bm()\n",
    "\n",
    "print(\"🚀 Buttermilk initialized for JSON-to-Vector tutorial\")\n",
    "pprint(cfg.storage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Components\n",
    "\n",
    "Let's create the storage, vector store, and text splitter components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use the clean BM API for all storage types\n",
    "source = bm.get_storage(cfg.storage.osb_json)\n",
    "\n",
    "# ✨ NEW: Auto-initialized storage (recommended for ChromaDB with remote storage)\n",
    "vectorstore = await bm.get_storage_async(cfg.storage.osb_vector)\n",
    "\n",
    "\n",
    "# Create text splitter\n",
    "chunker = DefaultTextSplitter(chunk_size=1200, chunk_overlap=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load live OSB data from GCS\n",
    "print(\"📥 Loading live OSB data from GCS...\")\n",
    "\n",
    "print(f\"🔗 Data source: {source.path}\")\n",
    "\n",
    "# Load documents (limit for demo, remove limit for full production run)\n",
    "records = []\n",
    "doc_limit = 10  # Set to None for full dataset\n",
    "\n",
    "print(f\"📚 Loading {doc_limit or 'all'} documents from live dataset...\")\n",
    "\n",
    "for record in source:\n",
    "    # Enhanced Record already has all needed capabilities - no conversion needed!\n",
    "    # The content field is what gets processed for vectors via text_content property\n",
    "    records.append(record)\n",
    "\n",
    "    if doc_limit and len(records) >= doc_limit:\n",
    "        break\n",
    "\n",
    "\n",
    "print(f\"\\n✅ Loaded {len(records)} live OSB documents for vector processing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(records[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration-Driven Multi-Field Vector Store\n",
    "\n",
    "This notebook demonstrates a **configuration-driven approach** for multi-field vector embeddings that works across any data source.\n",
    "\n",
    "### 🧠 **The Problem**\n",
    "Traditional vector stores only embed the main content, leaving rich metadata unsearchable:\n",
    "```python\n",
    "# Traditional approach - metadata trapped\n",
    "record.content = \"Long text...\"        # → Gets embedded ✅\n",
    "record.metadata.summary = \"Key points\"  # → Not searchable ❌\n",
    "```\n",
    "\n",
    "### 🎯 **Our Solution: Enhanced Record with Configuration-Driven Multi-Field Embeddings**\n",
    "The enhanced Record class provides direct vector processing capabilities:\n",
    "```yaml\n",
    "# conf/storage/osb.yaml\n",
    "osb_vector:\n",
    "  type: chromadb\n",
    "  # ... basic config\n",
    "  multi_field_embedding:\n",
    "    content_field: \"content\"\n",
    "    additional_fields:\n",
    "      - source_field: \"summary\"\n",
    "        chunk_type: \"summary\"\n",
    "        min_length: 50\n",
    "      - source_field: \"title\"\n",
    "        chunk_type: \"title\"\n",
    "        min_length: 10\n",
    "```\n",
    "\n",
    "### 🔍 **Search Capabilities**\n",
    "\n",
    "| Search Type | Use Case | Example Query |\n",
    "|-------------|----------|---------------|\n",
    "| **Summary-Only** | High-level concepts | `where={\"content_type\": \"summary\"}` |\n",
    "| **Title-Only** | Topic matching | `where={\"content_type\": \"title\"}` |\n",
    "| **Content-Only** | Detailed analysis | `where={\"content_type\": \"content\"}` |\n",
    "| **Cross-Field** | Comprehensive search | No filter = search everything |\n",
    "| **Hybrid** | Semantic + exact match | `query + where={\"case_number\": \"2024\"}` |\n",
    "\n",
    "### 🏗️ **Benefits**\n",
    "- ✅ **Enhanced Record**: Direct vector capabilities built into Record class\n",
    "- ✅ **Configuration-Driven**: No hardcoded field names\n",
    "- ✅ **Data Source Agnostic**: Works with any Record structure\n",
    "- ✅ **Same Config**: Creation and reading use identical configuration\n",
    "- ✅ **Extensible**: Easy to add new field types for any dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_production_vector_store():\n",
    "    \"\"\"Production pipeline: Process live OSB data with configuration-driven multi-field embedding.\"\"\"\n",
    "\n",
    "    print(\"🏭 Starting production vector store (configuration-driven)...\")\n",
    "    print(f\"📊 Processing {len(records)} live OSB documents\")\n",
    "\n",
    "    successful_embeddings = 0\n",
    "    failed_embeddings = 0\n",
    "    total_chunks = 0\n",
    "\n",
    "    for i, record in enumerate(records):\n",
    "\n",
    "        try:\n",
    "            processed_record = await vectorstore.process_record(record)\n",
    "            if processed_record:\n",
    "                successful_embeddings += 1\n",
    "                chunk_count = len(processed_record.chunks)\n",
    "                total_chunks += chunk_count\n",
    "\n",
    "                # Count chunk types for display\n",
    "                chunk_types = {}\n",
    "                for chunk in processed_record.chunks:\n",
    "                    content_type = chunk.metadata.get(\"content_type\", \"content\")\n",
    "                    chunk_types[content_type] = chunk_types.get(content_type, 0) + 1\n",
    "\n",
    "            else:\n",
    "                failed_embeddings += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            failed_embeddings += 1\n",
    "            print(f\"   ❌ Error processing record: {e}\")\n",
    "\n",
    "    # Final results\n",
    "    final_count = vectorstore.collection.count()\n",
    "\n",
    "    print(f\"\\n🎉 Configuration-Driven Vector Store Created!\")\n",
    "    print(f\"   📊 Records processed: {successful_embeddings + failed_embeddings}\")\n",
    "    print(f\"   ✅ Successfully embedded: {successful_embeddings}\")\n",
    "    print(f\"   ❌ Failed: {failed_embeddings}\")\n",
    "    print(f\"   📦 Total chunks: {total_chunks}\")\n",
    "    print(f\"   🔢 Total embeddings in collection: {final_count}\")\n",
    "    print(f\"   🏪 Collection: '{vectorstore.collection_name}'\")\n",
    "    print(f\"   ⚙️  Multi-field config: {vectorstore.multi_field_config is not None}\")\n",
    "\n",
    "    return {\n",
    "        \"successful_records\": successful_embeddings,\n",
    "        \"failed_records\": failed_embeddings,\n",
    "        \"total_chunks\": total_chunks,\n",
    "        \"final_embedding_count\": final_count,\n",
    "    }\n",
    "\n",
    "\n",
    "# Create the production vector store using configuration and enhanced Records\n",
    "results = await create_production_vector_store()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test configuration-driven multi-field search capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 Testing Configuration-Driven Multi-Field Search...\")\n",
    "\n",
    "# The content_type values come from our configuration:\n",
    "# - \"content\" (main content field)\n",
    "# - \"summary\" (from additional_fields config)\n",
    "# - \"title\" (from additional_fields config)\n",
    "\n",
    "# 1. Search summaries only (high-level concepts)\n",
    "print(\"\\n🎯 1. SUMMARY-ONLY SEARCH:\")\n",
    "print(\"   Query: 'human rights'\")\n",
    "summary_results = vectorstore.collection.query(\n",
    "    query_texts=[\"human rights\"],\n",
    "    # where={\"content_type\": \"summary\"},  # Based on config: source_field=\"summary\"\n",
    "    n_results=3,\n",
    "    include=[\"documents\", \"metadatas\", \"distances\"],\n",
    ")\n",
    "\n",
    "if summary_results[\"ids\"] and summary_results[\"ids\"][0]:\n",
    "    for i, (doc, metadata, distance) in enumerate(\n",
    "        zip(summary_results[\"documents\"][0], summary_results[\"metadatas\"][0], summary_results[\"distances\"][0])\n",
    "    ):\n",
    "        similarity = 1 - distance\n",
    "        title = metadata.get(\"title\", \"Untitled\")\n",
    "        print(f\"   📋 Result {i+1}: {title[:40]}... (similarity: {similarity:.3f})\")\n",
    "        print(f\"      📝 Summary: {doc[:80]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data source configuration for the RAG agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_agent = AgentVariants(**cfg.agents.researcher)\n",
    "rag_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create storage configuration for the RAG agent using unified system\n",
    "storage_config = StorageConfig(\n",
    "    type=\"chromadb\", persist_directory=\"./data/osb_chromadb\", collection_name=\"osb_fulltext\", embedding_model=\"text-embedding-005\", dimensionality=768\n",
    ")\n",
    "\n",
    "# Create agent configuration\n",
    "agent_config = AgentConfig(\n",
    "    role=\"RESEARCHER\",\n",
    "    agent_obj=\"RagAgent\",\n",
    "    description=\"OSB Research Assistant\",\n",
    "    data={\"osb_vector\": storage_config},\n",
    "    variants={\"model\": \"gemini-1.5-flash\"},\n",
    "    parameters={\"template\": \"rag_research\", \"n_results\": 10, \"no_duplicates\": False, \"max_queries\": 3},\n",
    ")\n",
    "\n",
    "# Initialize the RAG agent\n",
    "rag_agent = RagAgent(**agent_config.model_dump())\n",
    "print(\"RAG agent initialized successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Enhanced RAG Agent with intelligent search capabilities\n",
    "from buttermilk.agents.rag.enhanced_rag_agent import EnhancedRagAgent\n",
    "\n",
    "# IMPORTANT: Use the SAME config as your vectorstore to avoid mismatches!\n",
    "storage_config = StorageConfig(\n",
    "    type=\"chromadb\", \n",
    "    persist_directory=vectorstore.persist_directory,  # Use same directory as vectorstore\n",
    "    collection_name=vectorstore.collection_name,      # Use same collection name\n",
    "    embedding_model=vectorstore.embedding_model,      # Use same embedding model\n",
    "    dimensionality=vectorstore.dimensionality         # Use same dimensions\n",
    ")\n",
    "\n",
    "# Create Enhanced RAG agent configuration\n",
    "enhanced_agent_config = AgentConfig(\n",
    "    role=\"ENHANCED_RESEARCHER\",\n",
    "    agent_obj=\"buttermilk.agents.rag.enhanced_rag_agent.EnhancedRagAgent\",\n",
    "    description=\"Enhanced OSB Research Assistant with intelligent search capabilities\",\n",
    "    data={\"vectorstore\": storage_config},\n",
    "    parameters={\n",
    "        \"enable_query_planning\": True,      # Use LLM to analyze queries\n",
    "        \"enable_result_synthesis\": True,    # Use LLM to synthesize results\n",
    "        \"search_strategies\": [\"semantic\", \"title\", \"summary\", \"hybrid\", \"metadata\"],\n",
    "        \"max_search_rounds\": 3,\n",
    "        \"confidence_threshold\": 0.5,\n",
    "        \"max_results_per_strategy\": 5,\n",
    "        \"include_search_explanation\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize the Enhanced RAG agent\n",
    "enhanced_rag_agent = EnhancedRagAgent(**enhanced_agent_config.model_dump())\n",
    "print(\"✅ Enhanced RAG agent initialized successfully\")\n",
    "print(f\"   🧠 Query Planning: {enhanced_agent_config.parameters['enable_query_planning']}\")\n",
    "print(f\"   🔬 Result Synthesis: {enhanced_agent_config.parameters['enable_result_synthesis']}\")\n",
    "print(f\"   🎯 Search Strategies: {len(enhanced_agent_config.parameters['search_strategies'])}\")\n",
    "print(f\"   📁 Directory: {storage_config.persist_directory}\")\n",
    "print(f\"   🏪 Collection: {storage_config.collection_name}\")\n",
    "print(f\"   🧠 Model: {storage_config.embedding_model}\")\n",
    "print(f\"   📐 Dimensions: {storage_config.dimensionality}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search_osb_database(queries):\n",
    "    \"\"\"Search the OSB database with multiple queries.\"\"\"\n",
    "    print(\"\\n=== OSB Database Search Results ===\")\n",
    "\n",
    "    results = await rag_agent.fetch(queries)\n",
    "\n",
    "    for i, (query, result) in enumerate(zip(queries, results)):\n",
    "        print(f\"\\n--- Query {i+1}: {query} ---\")\n",
    "        print(f\"Found {len(result.results)} relevant chunks\")\n",
    "\n",
    "        if result.results:\n",
    "            # Show the top result\n",
    "            top_result = result.results[0]\n",
    "            print(f\"\\nTop Result:\")\n",
    "            print(f\"Document: {top_result.document_title}\")\n",
    "            print(f\"Case Number: {top_result.metadata.get('case_number', 'N/A')}\")\n",
    "            print(f\"Text: {top_result.full_text[:300]}...\")\n",
    "        else:\n",
    "            print(\"No results found\")\n",
    "\n",
    "\n",
    "# Example search queries\n",
    "search_queries = [\n",
    "    \"What are the challenges with automated content moderation?\",\n",
    "    \"How effective are age verification systems?\",\n",
    "    \"What techniques are used to spread misinformation?\",\n",
    "]\n",
    "\n",
    "await search_osb_database(search_queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demonstrate_enhanced_rag():\n",
    "    \"\"\"Demonstrate Enhanced RAG capabilities with intelligent search planning.\"\"\"\n",
    "\n",
    "    print(\"🎯 ENHANCED RAG DEMONSTRATION\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Test queries that showcase different capabilities\n",
    "    test_queries = [\n",
    "        {\n",
    "            \"query\": \"What are the main challenges with content moderation?\",\n",
    "            \"expected_strategy\": \"Should use hybrid search (title + summary + content)\",\n",
    "            \"focus\": \"Broad exploratory query\",\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Find cases about misinformation detection algorithms\",\n",
    "            \"expected_strategy\": \"Should use metadata + title search\",\n",
    "            \"focus\": \"Specific case-focused query\",\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"How do platforms protect user privacy?\",\n",
    "            \"expected_strategy\": \"Should use summary + semantic search\",\n",
    "            \"focus\": \"Policy-focused query\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for i, test in enumerate(test_queries, 1):\n",
    "        print(f\"\\n🔍 TEST {i}: {test['focus']}\")\n",
    "        print(f\"Query: '{test['query']}'\")\n",
    "        print(f\"Expected: {test['expected_strategy']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        try:\n",
    "            # Create AgentInput for the enhanced RAG agent\n",
    "            from buttermilk._core.contract import AgentInput\n",
    "\n",
    "            agent_input = AgentInput(inputs={\"query\": test[\"query\"]}, parameters={}, context=[], records=[])\n",
    "\n",
    "            # Process with Enhanced RAG\n",
    "            result = await enhanced_rag_agent._process(message=agent_input)\n",
    "\n",
    "            print(f\"✅ RESULT:\")\n",
    "            print(f\"   Response: {result.outputs[:200]}...\")\n",
    "\n",
    "            # Show metadata about the search\n",
    "            metadata = result.metadata\n",
    "            print(f\"\\n📊 SEARCH METADATA:\")\n",
    "            print(f\"   Total Results: {metadata.get('total_results', 0)}\")\n",
    "            print(f\"   Strategies Used: {metadata.get('strategies_used', [])}\")\n",
    "            print(f\"   Confidence Score: {metadata.get('confidence_score', 0.0):.2f}\")\n",
    "            print(f\"   Key Themes: {metadata.get('key_themes', [])}\")\n",
    "\n",
    "            if metadata.get(\"search_explanation\"):\n",
    "                print(f\"   Search Strategy: {metadata['search_explanation']}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ ERROR: {e}\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "    print(\"\\n🎉 Enhanced RAG demonstration complete!\")\n",
    "    print(\"\\nKey Benefits Demonstrated:\")\n",
    "    print(\"✅ Intelligent query analysis and search planning\")\n",
    "    print(\"✅ Multi-field search across titles, summaries, and content\")\n",
    "    print(\"✅ LLM-driven result synthesis and ranking\")\n",
    "    print(\"✅ Adaptive search strategies based on query type\")\n",
    "    print(\"✅ Comprehensive metadata and confidence scoring\")\n",
    "    print(\"✅ Smart cache management prevents overwriting local changes\")\n",
    "    print(\"✅ Automatic sync-back to remote storage after embedding operations\")\n",
    "\n",
    "\n",
    "# Run the enhanced RAG demonstration\n",
    "await demonstrate_enhanced_rag()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Chat Interface\n",
    "\n",
    "Now let's create an interactive interface to chat with our OSB knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_with_osb(user_question):\n",
    "    \"\"\"Interactive chat with OSB knowledge base.\"\"\"\n",
    "    print(f\"\\n🔍 User Question: {user_question}\")\n",
    "\n",
    "    # Search for relevant context\n",
    "    search_results = await rag_agent.fetch([user_question])\n",
    "\n",
    "    if search_results and search_results[0].results:\n",
    "        context = search_results[0]\n",
    "        print(f\"\\n📚 Found {len(context.results)} relevant documents\")\n",
    "\n",
    "        # Display relevant chunks\n",
    "        print(\"\\n📋 Relevant Information:\")\n",
    "        for i, result in enumerate(context.results[:3]):  # Show top 3\n",
    "            print(f\"\\n{i+1}. {result.document_title} ({result.metadata.get('case_number', 'N/A')})\")\n",
    "            print(f\"   {result.full_text[:200]}...\")\n",
    "\n",
    "        # In a real implementation, this would be sent to an LLM for synthesis\n",
    "        print(\"\\n🤖 AI Response: [In a real implementation, the retrieved context would be sent to an LLM to generate a synthesized response]\")\n",
    "    else:\n",
    "        print(\"\\n❌ No relevant information found in the OSB database\")\n",
    "\n",
    "\n",
    "# Example chat interactions\n",
    "example_questions = [\n",
    "    \"What are the main issues with current content moderation approaches?\",\n",
    "    \"What recommendations exist for age verification?\",\n",
    "    \"How do platforms detect and counter misinformation?\",\n",
    "]\n",
    "\n",
    "for question in example_questions:\n",
    "    await chat_with_osb(question)\n",
    "    print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Vector Store Analysis\n",
    "\n",
    "Let's analyze our vector store to understand what we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get collection statistics\n",
    "collection = vectorstore.collection\n",
    "count = collection.count()\n",
    "\n",
    "print(f\"\\n=== OSB Vector Store Statistics ===\")\n",
    "print(f\"Collection Name: {vectorstore.collection_name}\")\n",
    "print(f\"Total Chunks: {count}\")\n",
    "print(f\"Embedding Dimensions: {vectorstore.dimensionality}\")\n",
    "print(f\"Embedding Model: {vectorstore.embedding_model}\")\n",
    "\n",
    "# Get a sample of metadata to understand the structure\n",
    "sample_results = collection.get(limit=3, include=[\"metadatas\", \"documents\"])\n",
    "\n",
    "print(f\"\\n=== Sample Metadata Structure ===\")\n",
    "if sample_results[\"metadatas\"]:\n",
    "    sample_metadata = sample_results[\"metadatas\"][0]\n",
    "    print(\"Available metadata fields:\")\n",
    "    for key, value in sample_metadata.items():\n",
    "        print(f\"  - {key}: {type(value).__name__} = {str(value)[:50]}...\")\n",
    "\n",
    "print(f\"\\n=== Storage Locations ===\")\n",
    "print(f\"ChromaDB Directory: {vectorstore.persist_directory}\")\n",
    "print(f\"Embeddings Directory: {vectorstore.arrow_save_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced Search Examples\n",
    "\n",
    "Let's explore some advanced search patterns and filtering capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct ChromaDB queries with metadata filtering\n",
    "async def advanced_search_examples():\n",
    "    \"\"\"Demonstrate advanced search capabilities.\"\"\"\n",
    "    print(\"\\n=== Advanced Search Examples ===\")\n",
    "\n",
    "    # 1. Search with metadata filtering\n",
    "    print(\"\\n1. Search within specific case:\")\n",
    "    results = collection.query(\n",
    "        query_texts=[\"content moderation challenges\"], n_results=5, where={\"case_number\": \"OSB-2024-001\"}, include=[\"documents\", \"metadatas\"]\n",
    "    )\n",
    "    print(f\"   Found {len(results['ids'][0]) if results['ids'] else 0} results in OSB-2024-001\")\n",
    "\n",
    "    # 2. Similarity search across all documents\n",
    "    print(\"\\n2. General similarity search:\")\n",
    "    results = collection.query(query_texts=[\"artificial intelligence and safety\"], n_results=5, include=[\"documents\", \"metadatas\", \"distances\"])\n",
    "\n",
    "    if results[\"ids\"] and results[\"ids\"][0]:\n",
    "        print(f\"   Found {len(results['ids'][0])} results\")\n",
    "        for i, (doc, metadata, distance) in enumerate(zip(results[\"documents\"][0][:3], results[\"metadatas\"][0][:3], results[\"distances\"][0][:3])):\n",
    "            print(f\"   Result {i+1} (similarity: {1-distance:.3f}): {metadata.get('title', 'N/A')}\")\n",
    "            print(f\"     {doc[:100]}...\")\n",
    "\n",
    "    # 3. Multi-query search\n",
    "    print(\"\\n3. Multi-query search:\")\n",
    "    multi_queries = [\"platform safety measures\", \"user protection mechanisms\", \"digital safety standards\"]\n",
    "\n",
    "    for query in multi_queries:\n",
    "        results = collection.query(query_texts=[query], n_results=2, include=[\"metadatas\"])\n",
    "        count = len(results[\"ids\"][0]) if results[\"ids\"] else 0\n",
    "        print(f\"   '{query}': {count} results\")\n",
    "\n",
    "\n",
    "await advanced_search_examples()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Production Considerations\n",
    "\n",
    "Here are key considerations for using this in production:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\"\"\n",
    "=== Production Deployment Checklist ===\n",
    "\n",
    "🔧 Configuration:\n",
    "   ✓ Use GCS for persist_directory: gs://your-bucket/chromadb\n",
    "   ✓ Configure appropriate chunk_size for your content\n",
    "   ✓ Set concurrency based on your compute resources\n",
    "   ✓ Use production embedding models (text-embedding-004/005)\n",
    "\n",
    "📊 Performance:\n",
    "   ✓ Monitor embedding generation costs\n",
    "   ✓ Implement caching for frequently accessed data\n",
    "   ✓ Use batch processing for large datasets\n",
    "   ✓ Configure appropriate timeout values\n",
    "\n",
    "🔒 Security:\n",
    "   ✓ Secure GCS bucket access with proper IAM\n",
    "   ✓ Implement data access controls\n",
    "   ✓ Audit vector store queries\n",
    "   ✓ Protect sensitive metadata\n",
    "\n",
    "🚀 Scalability:\n",
    "   ✓ Plan for vector store size growth\n",
    "   ✓ Implement horizontal scaling for embeddings\n",
    "   ✓ Monitor query performance\n",
    "   ✓ Set up proper logging and monitoring\n",
    "\n",
    "🔄 Maintenance:\n",
    "   ✓ Plan for data updates and reindexing\n",
    "   ✓ Implement backup strategies\n",
    "   ✓ Version control for embeddings and metadata\n",
    "   ✓ Regular quality assessments\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Show next steps\n",
    "print(\n",
    "    \"\"\"\n",
    "=== Next Steps ===\n",
    "\n",
    "1. Scale to Full Dataset:\n",
    "   - Use the osb_vectorize.yaml configuration\n",
    "   - Run: uv run python -m buttermilk.data.vector +run=osb_vectorize\n",
    "\n",
    "2. Deploy RAG Flow:\n",
    "   - Use the osb_rag.yaml flow configuration\n",
    "   - Run: uv run python -m buttermilk.runner.cli +flow=osb_rag +run=api\n",
    "\n",
    "3. Integrate with Frontend:\n",
    "   - Use the Buttermilk web interface\n",
    "   - Connect to WebSocket endpoints for real-time chat\n",
    "\n",
    "4. Monitor and Optimize:\n",
    "   - Track query performance\n",
    "   - Monitor embedding costs\n",
    "   - Tune chunk sizes and retrieval parameters\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔒 Smart Cache Management\n",
    "\n",
    "The vector database now includes smart cache management to prevent overwriting local changes:\n",
    "\n",
    "### **Problem Solved**\n",
    "Previously, re-running embedding cells would download the remote ChromaDB cache and overwrite any local changes, losing newly added embeddings.\n",
    "\n",
    "### **Solution: Smart Cache Management**\n",
    "The system now includes intelligent cache handling:\n",
    "\n",
    "```python\n",
    "async def _smart_cache_management(self, remote_path: str) -> Path:\n",
    "    \"\"\"Smart cache management that prevents overwriting newer local changes.\"\"\"\n",
    "    \n",
    "    # Check if local cache was recently modified (within 1 hour)\n",
    "    if time_since_modified < 3600:  # 1 hour\n",
    "        logger.info(\"🔒 Skipping download to preserve local changes\")\n",
    "        return cache_path\n",
    "    \n",
    "    # Only download if cache is stale\n",
    "    logger.info(\"🔄 Syncing remote ChromaDB\")\n",
    "    return await ensure_chromadb_cache(remote_path)\n",
    "```\n",
    "\n",
    "### **Automatic Sync-Back**\n",
    "After successful embedding operations, local changes are automatically synced to remote storage:\n",
    "\n",
    "```python\n",
    "async def _sync_local_changes_to_remote(self) -> None:\n",
    "    \"\"\"Sync local ChromaDB changes back to remote storage.\"\"\"\n",
    "    \n",
    "    # Only sync if recently modified (indicates recent work)\n",
    "    if time_since_modified < 21600:  # 6 hours\n",
    "        await upload_chromadb_cache(local_path, remote_path)\n",
    "        logger.info(\"✅ Successfully synced local changes to remote storage\")\n",
    "```\n",
    "\n",
    "### **Benefits**\n",
    "- ✅ **Prevents Data Loss**: Local embedding work is preserved\n",
    "- ✅ **Automatic Sync**: Changes are pushed back to remote storage  \n",
    "- ✅ **Time-Based Logic**: Only acts on recently modified caches\n",
    "- ✅ **Transparent Operation**: Clear logging of all cache decisions\n",
    "- ✅ **Production Ready**: Handles concurrent access and failures gracefully\n",
    "\n",
    "### **Usage**\n",
    "This happens automatically - no code changes needed! The smart cache management activates whenever you:\n",
    "1. Run embedding operations in this notebook\n",
    "2. Use the vectorstore in production flows\n",
    "3. Process new documents with the vector pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Production Deployment Guide\n",
    "\n",
    "This vector store is now ready for production use with the unified storage system. Here's how to deploy and use it:\n",
    "\n",
    "### 📋 **For Full Dataset Processing**\n",
    "```python\n",
    "# In cell 7, change this line:\n",
    "doc_limit = 5  # Set to None for full dataset\n",
    "\n",
    "# To:\n",
    "doc_limit = None  # Processes all OSB documents\n",
    "```\n",
    "\n",
    "### 🏭 **Production Usage Examples**\n",
    "\n",
    "#### **Option 1: RAG Agent Integration**\n",
    "```python\n",
    "from buttermilk.agents.rag.rag_agent import RagAgent\n",
    "from buttermilk._core.config import AgentConfig\n",
    "from buttermilk._core.storage_config import StorageConfig\n",
    "\n",
    "# Same config as creation - no changes needed with unified storage!\n",
    "storage_config = StorageConfig(**cfg.storage.osb_vector)\n",
    "\n",
    "agent_config = AgentConfig(\n",
    "    role=\"RESEARCHER\",\n",
    "    agent_obj=\"RagAgent\", \n",
    "    description=\"OSB Knowledge Assistant\",\n",
    "    data={\"osb_vector\": storage_config},\n",
    "    parameters={\"n_results\": 10, \"max_queries\": 3}\n",
    ")\n",
    "\n",
    "rag_agent = RagAgent(**agent_config.model_dump())\n",
    "```\n",
    "\n",
    "#### **Option 2: Direct Storage Access**\n",
    "```python\n",
    "# Create vector store instance (reads existing embeddings) using unified storage\n",
    "production_vectorstore = bm.get_storage(cfg.storage.osb_vector)\n",
    "await production_vectorstore.ensure_cache_initialized()\n",
    "\n",
    "# Perform semantic search\n",
    "results = production_vectorstore.collection.query(\n",
    "    query_texts=[\"platform safety policies\"],\n",
    "    n_results=5\n",
    ")\n",
    "```\n",
    "\n",
    "#### **Option 3: Flow Integration**\n",
    "```yaml\n",
    "# conf/flows/osb_rag.yaml\n",
    "defaults:\n",
    "  - base_flow\n",
    "\n",
    "orchestrator: buttermilk.orchestrators.groupchat.AutogenOrchestrator\n",
    "storage: osb_vector  # References the same storage config\n",
    "agents: [rag_agent, host/sequencer]\n",
    "```\n",
    "\n",
    "### 🏗️ **Enhanced Record Benefits**\n",
    "- ✅ **Direct Processing**: Records processed without conversion steps\n",
    "- ✅ **Vector Fields**: Built-in support for chunks, embeddings, file_path\n",
    "- ✅ **Unified API**: Same Record class used throughout the system\n",
    "- ✅ **Type Safety**: Full Pydantic validation for vector operations\n",
    "\n",
    "### 🔒 **Production Considerations**\n",
    "- ✅ **Persistent Storage**: Vector store saved to `gs://prosocial-public/osb/chromadb`  \n",
    "- ✅ **Config Reuse**: Same `osb.yaml` works for both creation and reading\n",
    "- ✅ **Scalability**: ChromaDB handles thousands of documents efficiently\n",
    "- ✅ **Monitoring**: Check collection count and performance metrics\n",
    "- ✅ **Updates**: Re-run this notebook to add new OSB documents\n",
    "\n",
    "### 💡 **Next Steps**\n",
    "1. **Scale Up**: Remove `doc_limit` to process full OSB dataset\n",
    "2. **Deploy**: Use in RAG agents, search APIs, or analytical workflows  \n",
    "3. **Monitor**: Track embedding quality and search relevance\n",
    "4. **Iterate**: Add new documents by re-running the pipeline\n",
    "\n",
    "### 🔧 **Migration Benefits**\n",
    "This notebook now uses:\n",
    "- ✅ **StorageConfig**: Unified configuration for all storage types\n",
    "- ✅ **Enhanced Record**: Built-in vector processing capabilities  \n",
    "- ✅ **bm.get_storage()**: Unified storage access API\n",
    "- ✅ **process_record()**: Direct Record processing without conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kq161px7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the text splitter behavior with a sample text\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create a test text that should definitely be split\n",
    "test_text = \"This is a test document. \" * 100  # 2500 characters\n",
    "print(f\"Test text length: {len(test_text)} characters\")\n",
    "\n",
    "# Test with the same config as OSB\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,\n",
    "    chunk_overlap=400,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    "    add_start_index=False,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(test_text)\n",
    "print(f\"Number of chunks created: {len(chunks)}\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}: {len(chunk)} characters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1959yzujxs8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a sample of the OSB data to understand the actual field structure\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Let's fetch a small sample of the OSB data to see the actual structure\n",
    "try:\n",
    "    # For security, I'll create a simple test to understand the field structure\n",
    "    # Based on the config, it seems like the JSON has:\n",
    "    # - \"id\" field (maps to record_id)\n",
    "    # - \"full_text\" field (maps to content)\n",
    "    # - \"title\", \"case_number\", \"url\", \"summary\" fields (go to metadata)\n",
    "\n",
    "    print(\"Based on your config, the OSB JSON structure should be:\")\n",
    "    print(\n",
    "        \"\"\"\n",
    "    {\n",
    "        \"id\": \"some-id\",\n",
    "        \"full_text\": \"The main content text that should be chunked\",\n",
    "        \"title\": \"Document title\", \n",
    "        \"case_number\": \"OSB-2024-001\",\n",
    "        \"url\": \"https://...\",\n",
    "        \"summary\": \"Document summary\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nYour current mapping:\")\n",
    "    print(\"- JSON 'id' → Record 'record_id'\")\n",
    "    print(\"- JSON 'full_text' → Record 'content'\")\n",
    "    print(\"- JSON 'title' → Record metadata['title']\")\n",
    "    print(\"- JSON 'summary' → Record metadata['summary']\")\n",
    "    print(\"- JSON 'case_number' → Record metadata['case_number']\")\n",
    "    print(\"- JSON 'url' → Record metadata['url']\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a60qp1mf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's quickly test what happens when we load OSB data with the current config\n",
    "from buttermilk._core.types import Record\n",
    "\n",
    "# Test creating a record like OSB would\n",
    "test_record = Record(\n",
    "    record_id=\"test-123\",\n",
    "    content=\"This is the main content from fulltext field\",\n",
    "    metadata={\"title\": \"Test Document\", \"summary\": \"Test summary\", \"case_number\": \"OSB-2024-001\", \"url\": \"https://example.com\"},\n",
    ")\n",
    "\n",
    "print(\"🔍 Record Fields:\")\n",
    "print(f\"content: {test_record.content[:50]}...\")\n",
    "print(f\"text_content: {test_record.text_content[:50]}...\")\n",
    "print(f\"metadata keys: {list(test_record.metadata.keys())}\")\n",
    "print(f\"metadata: {test_record.metadata}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "buttermilk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
