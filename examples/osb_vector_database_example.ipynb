{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSB Vector Database Example\n",
    "\n",
    "This notebook demonstrates how to create and use a vector database from Oversight Board full text data using Buttermilk's ChromaDB integration.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll show how to:\n",
    "1. Load OSB JSON data using existing data loaders\n",
    "2. Generate embeddings and create a ChromaDB vector store\n",
    "3. Use the generic RAG agent for interactive question answering\n",
    "4. Demonstrate semantic search capabilities\n",
    "\n",
    "This example uses the generic infrastructure that works with any JSON dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration Setup\n",
    "\n",
    "First, let's set up the configuration for our OSB vector database pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-16 19:29:56\u001b[0m [] \u001b[1;30mINFO\u001b[0m bm_init.py:745 Logging set up for run: platform='local' name='bm_api' job='osb_vectorise' run_id='20250616T0929Z-F6n2-docker-desktop-debian' ip=None node_name='docker-desktop' save_dir='/tmp/tmpdvnhck_1/bm_api/osb_vectorise/20250616T0929Z-F6n2-docker-desktop-debian' flow_api=None. Save directory: /tmp/tmpdvnhck_1/bm_api/osb_vectorise/20250616T0929Z-F6n2-docker-desktop-debian\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized Buttermilk <span style=\"font-weight: bold\">(</span>bm<span style=\"font-weight: bold\">)</span> with configuration:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized Buttermilk \u001b[1m(\u001b[0mbm\u001b[1m)\u001b[0m with configuration:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'platform'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'local'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'bm_api'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'job'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'osb_vectorise'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'run_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'20250616T0929Z-F6n2-docker-desktop-debian'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'docker-desktop'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'save_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/tmp/tmpdvnhck_1/bm_api/osb_vectorise/20250616T0929Z-F6n2-docker-desktop-debian'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'connections'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'secret_provider'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'models_secret'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dev__llm__connections'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'credentials_secret'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dev__shared_credentials'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'logger_cfg'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'location'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us-central1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'verbose'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'pubsub'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'jobs_subscription'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'jobs-sub'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'status_subscription'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'flow-sub'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'status_topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'jobs_topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'jobs'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'clouds'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'quota_project_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'vertex'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'region'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us-central1'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'location'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us-central1'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'bucket'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-de'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'tracing'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'enabled'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'api_key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'weave'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'otlp_headers'</span>: <span style=\"font-weight: bold\">{}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'datasets'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'save_dir_base'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/tmp/tmpdvnhck_1'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'platform'\u001b[0m: \u001b[32m'local'\u001b[0m,\n",
       "    \u001b[32m'name'\u001b[0m: \u001b[32m'bm_api'\u001b[0m,\n",
       "    \u001b[32m'job'\u001b[0m: \u001b[32m'osb_vectorise'\u001b[0m,\n",
       "    \u001b[32m'run_id'\u001b[0m: \u001b[32m'20250616T0929Z-F6n2-docker-desktop-debian'\u001b[0m,\n",
       "    \u001b[32m'node_name'\u001b[0m: \u001b[32m'docker-desktop'\u001b[0m,\n",
       "    \u001b[32m'save_dir'\u001b[0m: \u001b[32m'/tmp/tmpdvnhck_1/bm_api/osb_vectorise/20250616T0929Z-F6n2-docker-desktop-debian'\u001b[0m,\n",
       "    \u001b[32m'connections'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'secret_provider'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m,\n",
       "        \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m,\n",
       "        \u001b[32m'models_secret'\u001b[0m: \u001b[32m'dev__llm__connections'\u001b[0m,\n",
       "        \u001b[32m'credentials_secret'\u001b[0m: \u001b[32m'dev__shared_credentials'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'logger_cfg'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m, \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m, \u001b[32m'location'\u001b[0m: \u001b[32m'us-central1'\u001b[0m, \u001b[32m'verbose'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'pubsub'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m,\n",
       "        \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m,\n",
       "        \u001b[32m'jobs_subscription'\u001b[0m: \u001b[32m'jobs-sub'\u001b[0m,\n",
       "        \u001b[32m'status_subscription'\u001b[0m: \u001b[32m'flow-sub'\u001b[0m,\n",
       "        \u001b[32m'status_topic'\u001b[0m: \u001b[32m'flow'\u001b[0m,\n",
       "        \u001b[32m'jobs_topic'\u001b[0m: \u001b[32m'jobs'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'clouds'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m, \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m, \u001b[32m'quota_project_id'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'type'\u001b[0m: \u001b[32m'vertex'\u001b[0m,\n",
       "            \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m,\n",
       "            \u001b[32m'region'\u001b[0m: \u001b[32m'us-central1'\u001b[0m,\n",
       "            \u001b[32m'location'\u001b[0m: \u001b[32m'us-central1'\u001b[0m,\n",
       "            \u001b[32m'bucket'\u001b[0m: \u001b[32m'prosocial-de'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'tracing'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'enabled'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'api_key'\u001b[0m: \u001b[32m''\u001b[0m, \u001b[32m'provider'\u001b[0m: \u001b[32m'weave'\u001b[0m, \u001b[32m'otlp_headers'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'datasets'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'save_dir_base'\u001b[0m: \u001b[32m'/tmp/tmpdvnhck_1'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-16 19:29:56\u001b[0m [] \u001b[1;30mINFO\u001b[0m nb.py:59 Starting interactive run for bm_api job osb_vectorise in notebook\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🚀 Buttermilk initialized for JSON-to-Vector tutorial\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🚀 Buttermilk initialized for JSON-to-Vector tutorial\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'osb_json'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcs'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gs://prosocial-public/osb/03_osb_fulltext_summaries.json'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'columns'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'full_text'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'case_number'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'case_number'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'url'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'summary'</span><span style=\"font-weight: bold\">}}}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'osb_vector'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'chromadb'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'persist_directory'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gs://prosocial-public/osb/chromadb'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'collection_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'osb_fulltext'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'embedding_model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gemini-embedding-001'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'dimensionality'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span><span style=\"font-weight: bold\">}}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'osb_json'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'gcs'\u001b[0m, \u001b[32m'path'\u001b[0m: \u001b[32m'gs://prosocial-public/osb/03_osb_fulltext_summaries.json'\u001b[0m, \u001b[32m'columns'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'record_id'\u001b[0m: \u001b[32m'id'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'full_text'\u001b[0m, \u001b[32m'metadata'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'title'\u001b[0m, \u001b[32m'case_number'\u001b[0m: \u001b[32m'case_number'\u001b[0m, \u001b[32m'url'\u001b[0m: \u001b[32m'url'\u001b[0m, \u001b[32m'summary'\u001b[0m: \u001b[32m'summary'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'osb_vector'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'chromadb'\u001b[0m, \u001b[32m'persist_directory'\u001b[0m: \u001b[32m'gs://prosocial-public/osb/chromadb'\u001b[0m, \u001b[32m'collection_name'\u001b[0m: \u001b[32m'osb_fulltext'\u001b[0m, \u001b[32m'embedding_model'\u001b[0m: \u001b[32m'gemini-embedding-001'\u001b[0m, \u001b[32m'dimensionality'\u001b[0m: \u001b[1;36m3072\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-16 19:29:56\u001b[0m [] \u001b[1;30mINFO\u001b[0m save.py:641 Successfully dumped data to local disk (JSON): /tmp/tmpdvnhck_1/bm_api/osb_vectorise/20250616T0929Z-F6n2-docker-desktop-debian/tmpxbjvgc6j.json.\n",
      "\u001b[32m2025-06-16 19:29:56\u001b[0m [] \u001b[1;30mINFO\u001b[0m save.py:215 Successfully saved data using dump_to_disk to: /tmp/tmpdvnhck_1/bm_api/osb_vectorise/20250616T0929Z-F6n2-docker-desktop-debian/tmpxbjvgc6j.json.\n",
      "\u001b[32m2025-06-16 19:29:56\u001b[0m [] \u001b[1;30mINFO\u001b[0m bm_init.py:831 {'message': 'Successfully saved data to: /tmp/tmpdvnhck_1/bm_api/osb_vectorise/20250616T0929Z-F6n2-docker-desktop-debian/tmpxbjvgc6j.json', 'uri': '/tmp/tmpdvnhck_1/bm_api/osb_vectorise/20250616T0929Z-F6n2-docker-desktop-debian/tmpxbjvgc6j.json', 'run_id': '20250616T0929Z-F6n2-docker-desktop-debian'}\n"
     ]
    }
   ],
   "source": [
    "from rich import print\n",
    "from rich.pretty import pprint\n",
    "import asyncio\n",
    "import json\n",
    "from pathlib import Path\n",
    "import hydra\n",
    "from hydra import compose, initialize_config_dir\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "# Buttermilk imports\n",
    "from buttermilk import logger\n",
    "from buttermilk.data.vector import ChromaDBEmbeddings, InputDocument, DefaultTextSplitter\n",
    "from buttermilk.agents.rag.rag_agent import RagAgent\n",
    "from buttermilk._core.config import AgentConfig, DataSourceConfig\n",
    "\n",
    "from buttermilk.utils.nb import init\n",
    "from buttermilk._core.dmrc import get_bm, set_bm\n",
    "from buttermilk._core.config import DataSourceConfig\n",
    "from buttermilk._core.types import Record\n",
    "from buttermilk.data.loaders import create_data_loader\n",
    "from buttermilk.data.vector import ChromaDBEmbeddings, InputDocument, DefaultTextSplitter, list_to_async_iterator\n",
    "\n",
    "# Initialize Buttermilk\n",
    "cfg = init(job=\"osb_vectorise\", overrides=[\"+storage=osb\"])\n",
    "bm = get_bm()\n",
    "\n",
    "print(\"🚀 Buttermilk initialized for JSON-to-Vector tutorial\")\n",
    "pprint(cfg.storage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Components\n",
    "\n",
    "Let's create the storage, vector store, and text splitter components."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Now we can use the clean BM API for all storage types\nsource = bm.get_storage(cfg.storage.osb_json)\nvectorstore = bm.get_storage(cfg.storage.osb_vector)\n\n# Create text splitter\nchunker = DefaultTextSplitter(chunk_size=2000, chunk_overlap=500)\n\nprint(\"✅ All storage components initialized via BM API\")\nprint(f\"Source: {type(source).__name__}\")\nprint(f\"Vector store: {type(vectorstore).__name__}\")\nprint(f\"Text splitter: {type(chunker).__name__}\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Ensure cache is initialized for remote ChromaDB\nawait vectorstore.ensure_cache_initialized()\n\nprint(\"✅ ChromaDB cache ready for processing\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load OSB Data\n",
    "\n",
    "Now let's load the OSB JSON data and convert it to InputDocument format."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Load actual OSB data using the data loader\nprint(\"📥 Loading OSB data from GCS...\")\n\n# Create data loader from source storage\nfrom buttermilk.data.loaders import create_data_loader\nfrom buttermilk._core.config import DataSourceConfig\n\n# Convert storage config to data source config\nsource_config = DataSourceConfig(**cfg.storage.osb_json)\ndata_loader = create_data_loader(source_config)\n\n# Get records from the data loader\nrecords = []\nasync for record in data_loader.load():\n    records.append(record)\n    if len(records) >= 3:  # Just process first 3 for demo\n        break\n\nprint(f\"✅ Loaded {len(records)} OSB records\")\n\n# Convert Records to InputDocument format\ndocuments = []\nfor record in records:\n    doc = InputDocument(\n        record_id=record.record_id,\n        title=record.metadata.get('title', 'Untitled'),\n        full_text=record.content if isinstance(record.content, str) else str(record.content),\n        metadata=record.metadata,\n        file_path=\"\",\n    )\n    documents.append(doc)\n    print(f\"- {doc.record_id}: {doc.title[:50]}...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process Documents: Chunking and Embedding\n",
    "\n",
    "Now we'll chunk the documents and generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_documents():\n",
    "    \"\"\"Process documents through the complete pipeline.\"\"\"\n",
    "    processed_docs = []\n",
    "\n",
    "    for doc in documents:\n",
    "        print(f\"\\nProcessing document: {doc.record_id}\")\n",
    "\n",
    "        # Step 1: Chunk the document\n",
    "        chunked_doc = await chunker.process(doc)\n",
    "        if not chunked_doc:\n",
    "            print(f\"Failed to chunk document {doc.record_id}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Created {len(chunked_doc.chunks)} chunks\")\n",
    "\n",
    "        # Step 2: Generate embeddings and store\n",
    "        processed_doc = await vectorstore.process(chunked_doc)\n",
    "        if processed_doc:\n",
    "            processed_docs.append(processed_doc)\n",
    "            print(f\"Successfully embedded and stored document {doc.record_id}\")\n",
    "        else:\n",
    "            print(f\"Failed to process document {doc.record_id}\")\n",
    "\n",
    "    return processed_docs\n",
    "\n",
    "\n",
    "# Run the processing pipeline\n",
    "processed_documents = await process_documents()\n",
    "print(f\"\\nProcessed {len(processed_documents)} documents successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize RAG Agent\n",
    "\n",
    "Now let's create a generic RAG agent to query our OSB vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data source configuration for the RAG agent\n",
    "data_config = DataSourceConfig(\n",
    "    type=\"chromadb\", persist_directory=\"./data/osb_chromadb\", collection_name=\"osb_fulltext\", embedding_model=\"text-embedding-005\", dimensionality=768\n",
    ")\n",
    "\n",
    "# Create agent configuration\n",
    "agent_config = AgentConfig(\n",
    "    role=\"RESEARCHER\",\n",
    "    agent_obj=\"RagAgent\",\n",
    "    description=\"OSB Research Assistant\",\n",
    "    data={\"osb_vector\": data_config},\n",
    "    variants={\"model\": \"gemini-1.5-flash\"},\n",
    "    parameters={\"template\": \"rag_research\", \"n_results\": 10, \"no_duplicates\": False, \"max_queries\": 3},\n",
    ")\n",
    "\n",
    "# Initialize the RAG agent\n",
    "rag_agent = RagAgent(**agent_config.model_dump())\n",
    "print(\"RAG agent initialized successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Semantic Search Examples\n",
    "\n",
    "Let's demonstrate the semantic search capabilities of our OSB vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def search_osb_database(queries):\n",
    "    \"\"\"Search the OSB database with multiple queries.\"\"\"\n",
    "    print(\"\\n=== OSB Database Search Results ===\")\n",
    "\n",
    "    results = await rag_agent.fetch(queries)\n",
    "\n",
    "    for i, (query, result) in enumerate(zip(queries, results)):\n",
    "        print(f\"\\n--- Query {i+1}: {query} ---\")\n",
    "        print(f\"Found {len(result.results)} relevant chunks\")\n",
    "\n",
    "        if result.results:\n",
    "            # Show the top result\n",
    "            top_result = result.results[0]\n",
    "            print(f\"\\nTop Result:\")\n",
    "            print(f\"Document: {top_result.document_title}\")\n",
    "            print(f\"Case Number: {top_result.metadata.get('case_number', 'N/A')}\")\n",
    "            print(f\"Text: {top_result.full_text[:300]}...\")\n",
    "        else:\n",
    "            print(\"No results found\")\n",
    "\n",
    "\n",
    "# Example search queries\n",
    "search_queries = [\n",
    "    \"What are the challenges with automated content moderation?\",\n",
    "    \"How effective are age verification systems?\",\n",
    "    \"What techniques are used to spread misinformation?\",\n",
    "]\n",
    "\n",
    "await search_osb_database(search_queries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Chat Interface\n",
    "\n",
    "Now let's create an interactive interface to chat with our OSB knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_with_osb(user_question):\n",
    "    \"\"\"Interactive chat with OSB knowledge base.\"\"\"\n",
    "    print(f\"\\n🔍 User Question: {user_question}\")\n",
    "\n",
    "    # Search for relevant context\n",
    "    search_results = await rag_agent.fetch([user_question])\n",
    "\n",
    "    if search_results and search_results[0].results:\n",
    "        context = search_results[0]\n",
    "        print(f\"\\n📚 Found {len(context.results)} relevant documents\")\n",
    "\n",
    "        # Display relevant chunks\n",
    "        print(\"\\n📋 Relevant Information:\")\n",
    "        for i, result in enumerate(context.results[:3]):  # Show top 3\n",
    "            print(f\"\\n{i+1}. {result.document_title} ({result.metadata.get('case_number', 'N/A')})\")\n",
    "            print(f\"   {result.full_text[:200]}...\")\n",
    "\n",
    "        # In a real implementation, this would be sent to an LLM for synthesis\n",
    "        print(\"\\n🤖 AI Response: [In a real implementation, the retrieved context would be sent to an LLM to generate a synthesized response]\")\n",
    "    else:\n",
    "        print(\"\\n❌ No relevant information found in the OSB database\")\n",
    "\n",
    "\n",
    "# Example chat interactions\n",
    "example_questions = [\n",
    "    \"What are the main issues with current content moderation approaches?\",\n",
    "    \"What recommendations exist for age verification?\",\n",
    "    \"How do platforms detect and counter misinformation?\",\n",
    "]\n",
    "\n",
    "for question in example_questions:\n",
    "    await chat_with_osb(question)\n",
    "    print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Vector Store Analysis\n",
    "\n",
    "Let's analyze our vector store to understand what we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get collection statistics\n",
    "collection = vectorstore.collection\n",
    "count = collection.count()\n",
    "\n",
    "print(f\"\\n=== OSB Vector Store Statistics ===\")\n",
    "print(f\"Collection Name: {vectorstore.collection_name}\")\n",
    "print(f\"Total Chunks: {count}\")\n",
    "print(f\"Embedding Dimensions: {vectorstore.dimensionality}\")\n",
    "print(f\"Embedding Model: {vectorstore.embedding_model}\")\n",
    "\n",
    "# Get a sample of metadata to understand the structure\n",
    "sample_results = collection.get(limit=3, include=[\"metadatas\", \"documents\"])\n",
    "\n",
    "print(f\"\\n=== Sample Metadata Structure ===\")\n",
    "if sample_results[\"metadatas\"]:\n",
    "    sample_metadata = sample_results[\"metadatas\"][0]\n",
    "    print(\"Available metadata fields:\")\n",
    "    for key, value in sample_metadata.items():\n",
    "        print(f\"  - {key}: {type(value).__name__} = {str(value)[:50]}...\")\n",
    "\n",
    "print(f\"\\n=== Storage Locations ===\")\n",
    "print(f\"ChromaDB Directory: {vectorstore.persist_directory}\")\n",
    "print(f\"Embeddings Directory: {vectorstore.arrow_save_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced Search Examples\n",
    "\n",
    "Let's explore some advanced search patterns and filtering capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct ChromaDB queries with metadata filtering\n",
    "async def advanced_search_examples():\n",
    "    \"\"\"Demonstrate advanced search capabilities.\"\"\"\n",
    "    print(\"\\n=== Advanced Search Examples ===\")\n",
    "\n",
    "    # 1. Search with metadata filtering\n",
    "    print(\"\\n1. Search within specific case:\")\n",
    "    results = collection.query(\n",
    "        query_texts=[\"content moderation challenges\"], n_results=5, where={\"case_number\": \"OSB-2024-001\"}, include=[\"documents\", \"metadatas\"]\n",
    "    )\n",
    "    print(f\"   Found {len(results['ids'][0]) if results['ids'] else 0} results in OSB-2024-001\")\n",
    "\n",
    "    # 2. Similarity search across all documents\n",
    "    print(\"\\n2. General similarity search:\")\n",
    "    results = collection.query(query_texts=[\"artificial intelligence and safety\"], n_results=5, include=[\"documents\", \"metadatas\", \"distances\"])\n",
    "\n",
    "    if results[\"ids\"] and results[\"ids\"][0]:\n",
    "        print(f\"   Found {len(results['ids'][0])} results\")\n",
    "        for i, (doc, metadata, distance) in enumerate(zip(results[\"documents\"][0][:3], results[\"metadatas\"][0][:3], results[\"distances\"][0][:3])):\n",
    "            print(f\"   Result {i+1} (similarity: {1-distance:.3f}): {metadata.get('title', 'N/A')}\")\n",
    "            print(f\"     {doc[:100]}...\")\n",
    "\n",
    "    # 3. Multi-query search\n",
    "    print(\"\\n3. Multi-query search:\")\n",
    "    multi_queries = [\"platform safety measures\", \"user protection mechanisms\", \"digital safety standards\"]\n",
    "\n",
    "    for query in multi_queries:\n",
    "        results = collection.query(query_texts=[query], n_results=2, include=[\"metadatas\"])\n",
    "        count = len(results[\"ids\"][0]) if results[\"ids\"] else 0\n",
    "        print(f\"   '{query}': {count} results\")\n",
    "\n",
    "\n",
    "await advanced_search_examples()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Production Considerations\n",
    "\n",
    "Here are key considerations for using this in production:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\"\"\n",
    "=== Production Deployment Checklist ===\n",
    "\n",
    "🔧 Configuration:\n",
    "   ✓ Use GCS for persist_directory: gs://your-bucket/chromadb\n",
    "   ✓ Configure appropriate chunk_size for your content\n",
    "   ✓ Set concurrency based on your compute resources\n",
    "   ✓ Use production embedding models (text-embedding-004/005)\n",
    "\n",
    "📊 Performance:\n",
    "   ✓ Monitor embedding generation costs\n",
    "   ✓ Implement caching for frequently accessed data\n",
    "   ✓ Use batch processing for large datasets\n",
    "   ✓ Configure appropriate timeout values\n",
    "\n",
    "🔒 Security:\n",
    "   ✓ Secure GCS bucket access with proper IAM\n",
    "   ✓ Implement data access controls\n",
    "   ✓ Audit vector store queries\n",
    "   ✓ Protect sensitive metadata\n",
    "\n",
    "🚀 Scalability:\n",
    "   ✓ Plan for vector store size growth\n",
    "   ✓ Implement horizontal scaling for embeddings\n",
    "   ✓ Monitor query performance\n",
    "   ✓ Set up proper logging and monitoring\n",
    "\n",
    "🔄 Maintenance:\n",
    "   ✓ Plan for data updates and reindexing\n",
    "   ✓ Implement backup strategies\n",
    "   ✓ Version control for embeddings and metadata\n",
    "   ✓ Regular quality assessments\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Show next steps\n",
    "print(\n",
    "    \"\"\"\n",
    "=== Next Steps ===\n",
    "\n",
    "1. Scale to Full Dataset:\n",
    "   - Use the osb_vectorize.yaml configuration\n",
    "   - Run: uv run python -m buttermilk.data.vector +run=osb_vectorize\n",
    "\n",
    "2. Deploy RAG Flow:\n",
    "   - Use the osb_rag.yaml flow configuration\n",
    "   - Run: uv run python -m buttermilk.runner.cli +flow=osb_rag +run=api\n",
    "\n",
    "3. Integrate with Frontend:\n",
    "   - Use the Buttermilk web interface\n",
    "   - Connect to WebSocket endpoints for real-time chat\n",
    "\n",
    "4. Monitor and Optimize:\n",
    "   - Track query performance\n",
    "   - Monitor embedding costs\n",
    "   - Tune chunk sizes and retrieval parameters\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated how to:\n",
    "\n",
    "1. **Load OSB data** using Buttermilk's flexible JSON data loaders\n",
    "2. **Create embeddings** with the ChromaDBEmbeddings pipeline\n",
    "3. **Build a vector database** suitable for semantic search\n",
    "4. **Use the generic RAG agent** for question answering\n",
    "5. **Perform semantic search** with various query patterns\n",
    "6. **Analyze the vector store** structure and contents\n",
    "\n",
    "The key advantage of this approach is that it uses **generic, reusable components** that work with any JSON dataset, not just OSB data. The same patterns can be applied to any document collection for RAG applications.\n",
    "\n",
    "The infrastructure is **production-ready** with features like:\n",
    "- Async processing for scalability\n",
    "- GCS integration for cloud storage\n",
    "- Configurable chunking and embedding parameters\n",
    "- Error handling and retry mechanisms\n",
    "- Comprehensive logging and monitoring\n",
    "\n",
    "This provides a solid foundation for building sophisticated RAG applications with Buttermilk."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}