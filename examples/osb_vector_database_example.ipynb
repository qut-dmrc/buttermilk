{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSB Vector Database Example\n",
    "\n",
    "This notebook demonstrates how to create and use a vector database from Oversight Board full text data using Buttermilk's ChromaDB integration.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll show how to:\n",
    "1. Load OSB JSON data using existing data loaders\n",
    "2. Generate embeddings and create a ChromaDB vector store\n",
    "3. Use the generic RAG agent for interactive question answering\n",
    "4. Demonstrate semantic search capabilities\n",
    "\n",
    "This example uses the generic infrastructure that works with any JSON dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration Setup\n",
    "\n",
    "First, let's set up the configuration for our OSB vector database pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 19:44:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m bm_init.py:778 Logging set up for run: platform='local' name='bm_api' job='osb_vectorise' run_id='20250617T0944Z-QmRL-docker-desktop-debian' ip=None node_name='docker-desktop' save_dir='/tmp/tmpuswp_w0u/bm_api/osb_vectorise/20250617T0944Z-QmRL-docker-desktop-debian' flow_api=None. Save directory: /tmp/tmpuswp_w0u/bm_api/osb_vectorise/20250617T0944Z-QmRL-docker-desktop-debian\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized Buttermilk <span style=\"font-weight: bold\">(</span>bm<span style=\"font-weight: bold\">)</span> with configuration:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized Buttermilk \u001b[1m(\u001b[0mbm\u001b[1m)\u001b[0m with configuration:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'platform'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'local'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'bm_api'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'job'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'osb_vectorise'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'run_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'20250617T0944Z-QmRL-docker-desktop-debian'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'docker-desktop'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'save_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/tmp/tmpuswp_w0u/bm_api/osb_vectorise/20250617T0944Z-QmRL-docker-desktop-debian'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'connections'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'secret_provider'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'models_secret'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dev__llm__connections'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'credentials_secret'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dev__shared_credentials'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'logger_cfg'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'location'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us-central1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'verbose'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'pubsub'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'jobs_subscription'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'jobs-sub'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'status_subscription'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'flow-sub'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'status_topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'flow'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'jobs_topic'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'jobs'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'clouds'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcp'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'quota_project_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'vertex'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'project'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-443205'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'region'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us-central1'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'location'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'us-central1'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'bucket'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prosocial-de'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'tracing'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'enabled'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'api_key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'weave'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'otlp_headers'</span>: <span style=\"font-weight: bold\">{}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'datasets'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'save_dir_base'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/tmp/tmpuswp_w0u'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'platform'\u001b[0m: \u001b[32m'local'\u001b[0m,\n",
       "    \u001b[32m'name'\u001b[0m: \u001b[32m'bm_api'\u001b[0m,\n",
       "    \u001b[32m'job'\u001b[0m: \u001b[32m'osb_vectorise'\u001b[0m,\n",
       "    \u001b[32m'run_id'\u001b[0m: \u001b[32m'20250617T0944Z-QmRL-docker-desktop-debian'\u001b[0m,\n",
       "    \u001b[32m'node_name'\u001b[0m: \u001b[32m'docker-desktop'\u001b[0m,\n",
       "    \u001b[32m'save_dir'\u001b[0m: \u001b[32m'/tmp/tmpuswp_w0u/bm_api/osb_vectorise/20250617T0944Z-QmRL-docker-desktop-debian'\u001b[0m,\n",
       "    \u001b[32m'connections'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'secret_provider'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m,\n",
       "        \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m,\n",
       "        \u001b[32m'models_secret'\u001b[0m: \u001b[32m'dev__llm__connections'\u001b[0m,\n",
       "        \u001b[32m'credentials_secret'\u001b[0m: \u001b[32m'dev__shared_credentials'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'logger_cfg'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m, \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m, \u001b[32m'location'\u001b[0m: \u001b[32m'us-central1'\u001b[0m, \u001b[32m'verbose'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'pubsub'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m,\n",
       "        \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m,\n",
       "        \u001b[32m'jobs_subscription'\u001b[0m: \u001b[32m'jobs-sub'\u001b[0m,\n",
       "        \u001b[32m'status_subscription'\u001b[0m: \u001b[32m'flow-sub'\u001b[0m,\n",
       "        \u001b[32m'status_topic'\u001b[0m: \u001b[32m'flow'\u001b[0m,\n",
       "        \u001b[32m'jobs_topic'\u001b[0m: \u001b[32m'jobs'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'clouds'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'gcp'\u001b[0m, \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m, \u001b[32m'quota_project_id'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'type'\u001b[0m: \u001b[32m'vertex'\u001b[0m,\n",
       "            \u001b[32m'project'\u001b[0m: \u001b[32m'prosocial-443205'\u001b[0m,\n",
       "            \u001b[32m'region'\u001b[0m: \u001b[32m'us-central1'\u001b[0m,\n",
       "            \u001b[32m'location'\u001b[0m: \u001b[32m'us-central1'\u001b[0m,\n",
       "            \u001b[32m'bucket'\u001b[0m: \u001b[32m'prosocial-de'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'tracing'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'enabled'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'api_key'\u001b[0m: \u001b[32m''\u001b[0m, \u001b[32m'provider'\u001b[0m: \u001b[32m'weave'\u001b[0m, \u001b[32m'otlp_headers'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'datasets'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'save_dir_base'\u001b[0m: \u001b[32m'/tmp/tmpuswp_w0u'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 19:44:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m nb.py:59 Starting interactive run for bm_api job osb_vectorise in notebook\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🚀 Buttermilk initialized for JSON-to-Vector tutorial\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🚀 Buttermilk initialized for JSON-to-Vector tutorial\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'osb_json'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gcs'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gs://prosocial-public/osb/03_osb_fulltext_summaries.json'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'columns'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'record_id'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fulltext'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'result'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'result'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'location'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'location'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'case_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'case_date'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'topics'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'topics'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'standards'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'standards'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'recommendations'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'recommendations'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'job_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'job_id'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span><span style=\"font-weight: bold\">}}}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'osb_vector'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'chromadb'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'persist_directory'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gs://prosocial-dev/data/osb/chromadb'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'collection_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'osb_fulltext'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'embedding_model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gemini-embedding-001'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'dimensionality'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3072</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'multi_field_embedding'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'content_field'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1200</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_overlap'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'additional_fields'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source_field'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source_field'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'case_description'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source_field'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'reasons'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'reasoning'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source_field'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'recommendations'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunk_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'recommendations'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span><span style=\"font-weight: bold\">}]}}}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'osb_json'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'gcs'\u001b[0m, \u001b[32m'path'\u001b[0m: \u001b[32m'gs://prosocial-public/osb/03_osb_fulltext_summaries.json'\u001b[0m, \u001b[32m'columns'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'record_id'\u001b[0m: \u001b[32m'record_id'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'fulltext'\u001b[0m, \u001b[32m'metadata'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'title'\u001b[0m, \u001b[32m'description'\u001b[0m: \u001b[32m'content'\u001b[0m, \u001b[32m'result'\u001b[0m: \u001b[32m'result'\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'type'\u001b[0m, \u001b[32m'location'\u001b[0m: \u001b[32m'location'\u001b[0m, \u001b[32m'case_date'\u001b[0m: \u001b[32m'case_date'\u001b[0m, \u001b[32m'topics'\u001b[0m: \u001b[32m'topics'\u001b[0m, \u001b[32m'standards'\u001b[0m: \u001b[32m'standards'\u001b[0m, \u001b[32m'reasons'\u001b[0m: \u001b[32m'reasons'\u001b[0m, \u001b[32m'recommendations'\u001b[0m: \u001b[32m'recommendations'\u001b[0m, \u001b[32m'job_id'\u001b[0m: \u001b[32m'job_id'\u001b[0m, \u001b[32m'timestamp'\u001b[0m: \u001b[32m'timestamp'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'osb_vector'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'chromadb'\u001b[0m, \u001b[32m'persist_directory'\u001b[0m: \u001b[32m'gs://prosocial-dev/data/osb/chromadb'\u001b[0m, \u001b[32m'collection_name'\u001b[0m: \u001b[32m'osb_fulltext'\u001b[0m, \u001b[32m'embedding_model'\u001b[0m: \u001b[32m'gemini-embedding-001'\u001b[0m, \u001b[32m'dimensionality'\u001b[0m: \u001b[1;36m3072\u001b[0m, \u001b[32m'multi_field_embedding'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'content_field'\u001b[0m: \u001b[32m'content'\u001b[0m, \u001b[32m'chunk_size'\u001b[0m: \u001b[1;36m1200\u001b[0m, \u001b[32m'chunk_overlap'\u001b[0m: \u001b[1;36m400\u001b[0m, \u001b[32m'additional_fields'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'source_field'\u001b[0m: \u001b[32m'title'\u001b[0m, \u001b[32m'chunk_type'\u001b[0m: \u001b[32m'title'\u001b[0m, \u001b[32m'min_length'\u001b[0m: \u001b[1;36m10\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'source_field'\u001b[0m: \u001b[32m'description'\u001b[0m, \u001b[32m'chunk_type'\u001b[0m: \u001b[32m'case_description'\u001b[0m, \u001b[32m'min_length'\u001b[0m: \u001b[1;36m50\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'source_field'\u001b[0m: \u001b[32m'reasons'\u001b[0m, \u001b[32m'chunk_type'\u001b[0m: \u001b[32m'reasoning'\u001b[0m, \u001b[32m'min_length'\u001b[0m: \u001b[1;36m100\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'source_field'\u001b[0m: \u001b[32m'recommendations'\u001b[0m, \u001b[32m'chunk_type'\u001b[0m: \u001b[32m'recommendations'\u001b[0m, \u001b[32m'min_length'\u001b[0m: \u001b[1;36m50\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 19:44:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m save.py:641 Successfully dumped data to local disk (JSON): /tmp/tmpuswp_w0u/bm_api/osb_vectorise/20250617T0944Z-QmRL-docker-desktop-debian/tmpd4hbgtkh.json.\n",
      "\u001b[32m2025-06-17 19:44:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m save.py:215 Successfully saved data using dump_to_disk to: /tmp/tmpuswp_w0u/bm_api/osb_vectorise/20250617T0944Z-QmRL-docker-desktop-debian/tmpd4hbgtkh.json.\n",
      "\u001b[32m2025-06-17 19:44:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m bm_init.py:864 {'message': 'Successfully saved data to: /tmp/tmpuswp_w0u/bm_api/osb_vectorise/20250617T0944Z-QmRL-docker-desktop-debian/tmpd4hbgtkh.json', 'uri': '/tmp/tmpuswp_w0u/bm_api/osb_vectorise/20250617T0944Z-QmRL-docker-desktop-debian/tmpd4hbgtkh.json', 'run_id': '20250617T0944Z-QmRL-docker-desktop-debian'}\n"
     ]
    }
   ],
   "source": [
    "from rich import print\n",
    "from rich.pretty import pprint\n",
    "import asyncio\n",
    "import json\n",
    "from pathlib import Path\n",
    "import hydra\n",
    "from hydra import compose, initialize_config_dir\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "# Buttermilk imports - updated for unified storage system\n",
    "from buttermilk import logger\n",
    "from buttermilk.data.vector import ChromaDBEmbeddings, DefaultTextSplitter\n",
    "from buttermilk.agents.rag.rag_agent import RagAgent\n",
    "from buttermilk._core.config import AgentConfig\n",
    "from buttermilk._core.storage_config import StorageConfig  # New unified config\n",
    "from buttermilk._core.types import Record  # Enhanced Record with vector capabilities\n",
    "\n",
    "from buttermilk.utils.nb import init\n",
    "from buttermilk._core.dmrc import get_bm, set_bm\n",
    "\n",
    "# Initialize Buttermilk\n",
    "cfg = init(job=\"osb_vectorise\", overrides=[\"+storage=osb\", \"+agents=rag_generic\", \"+llms=lite\"])\n",
    "bm = get_bm()\n",
    "\n",
    "print(\"🚀 Buttermilk initialized for JSON-to-Vector tutorial\")\n",
    "pprint(cfg.storage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Components\n",
    "\n",
    "Let's create the storage, vector store, and text splitter components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 19:44:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:348 Loading embedding model: gemini-embedding-001\n",
      "\u001b[32m2025-06-17 19:44:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:360 🔄 Embedding retry configured: 5 retries, 1.0-120.0s backoff\n",
      "\u001b[32m2025-06-17 19:44:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:368 Initializing ChromaDB client at: gs://prosocial-dev/data/osb/chromadb\n",
      "\u001b[32m2025-06-17 19:44:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:373 Using ChromaDB collection: osb_fulltext\n",
      "\u001b[32m2025-06-17 19:44:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:379 🔄 Auto-sync enabled: every 50 records OR every 10 minutes\n",
      "\u001b[32m2025-06-17 19:44:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:384 🔍 Deduplication strategy: both\n",
      "\u001b[32m2025-06-17 19:44:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m bm_init.py:994 🔄 Auto-initializing remote storage: gs://prosocial-dev/data/osb/chromadb\n",
      "\u001b[32m2025-06-17 19:44:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:443 📋 Using existing local cache (modified 9.5 minutes ago)\n",
      "\u001b[32m2025-06-17 19:44:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:444 🔒 Skipping download to preserve local changes\n",
      "\u001b[32m2025-06-17 19:44:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:406 ✅ ChromaDB cache ready at: /home/debian/.cache/buttermilk/chromadb/gs___prosocial-dev_data_osb_chromadb\n",
      "\u001b[32m2025-06-17 19:44:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:653 📖 Found existing collection 'osb_fulltext'\n",
      "\u001b[32m2025-06-17 19:44:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:673 ✅ Collection 'osb_fulltext' ready (9218 embeddings)\n",
      "\u001b[32m2025-06-17 19:44:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m bm_init.py:996 ✅ Storage ready for use\n",
      "\u001b[32m2025-06-17 19:44:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the clean BM API for all storage types\n",
    "source = bm.get_storage(cfg.storage.osb_json)\n",
    "\n",
    "# ✨ NEW: Auto-initialized storage (recommended for ChromaDB with remote storage)\n",
    "vectorstore = await bm.get_storage_async(cfg.storage.osb_vector)\n",
    "\n",
    "\n",
    "# Create text splitter\n",
    "chunker = DefaultTextSplitter(chunk_size=1200, chunk_overlap=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">📥 Loading live OSB data from GCS<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "📥 Loading live OSB data from GCS\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔗 Data source: gs:<span style=\"color: #800080; text-decoration-color: #800080\">//prosocial-public/osb/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">03_osb_fulltext_summaries.json</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔗 Data source: gs:\u001b[35m/\u001b[0m\u001b[35m/prosocial-public/osb/\u001b[0m\u001b[95m03_osb_fulltext_summaries.json\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">📚 Loading all documents from live dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "📚 Loading all documents from live dataset\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 19:44:34\u001b[0m [] \u001b[1;30mWARNING\u001b[0m file.py:298 \u001b[33mError converting data to Record at index 38: 2 validation errors for Record\n",
      "content.str\n",
      "  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "content.json-or-python[json=list[union[str,is-instance[Image]]],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]\n",
      "  Input should be an instance of Sequence [type=is_instance_of, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\u001b[0m\n",
      "\u001b[32m2025-06-17 19:44:34\u001b[0m [] \u001b[1;30mWARNING\u001b[0m file.py:298 \u001b[33mError converting data to Record at index 95: 2 validation errors for Record\n",
      "content.str\n",
      "  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "content.json-or-python[json=list[union[str,is-instance[Image]]],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]\n",
      "  Input should be an instance of Sequence [type=is_instance_of, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\u001b[0m\n",
      "\u001b[32m2025-06-17 19:44:34\u001b[0m [] \u001b[1;30mWARNING\u001b[0m file.py:298 \u001b[33mError converting data to Record at index 110: 2 validation errors for Record\n",
      "content.str\n",
      "  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "content.json-or-python[json=list[union[str,is-instance[Image]]],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]\n",
      "  Input should be an instance of Sequence [type=is_instance_of, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/is_instance_of\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "✅ Loaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span> live OSB documents for vector processing\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "✅ Loaded \u001b[1;36m172\u001b[0m live OSB documents for vector processing\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load live OSB data from GCS\n",
    "print(\"📥 Loading live OSB data from GCS...\")\n",
    "\n",
    "print(f\"🔗 Data source: {source.path}\")\n",
    "\n",
    "# Load documents (limit for demo, remove limit for full production run)\n",
    "records = []\n",
    "doc_limit = None  # Set to None for full dataset\n",
    "\n",
    "print(f\"📚 Loading {doc_limit or 'all'} documents from live dataset...\")\n",
    "\n",
    "for record in source:\n",
    "    # Enhanced Record already has all needed capabilities - no conversion needed!\n",
    "    # The content field is what gets processed for vectors via text_content property\n",
    "    records.append(record)\n",
    "\n",
    "    if doc_limit and len(records) >= doc_limit:\n",
    "        break\n",
    "\n",
    "\n",
    "print(f\"\\n✅ Loaded {len(records)} live OSB documents for vector processing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration-Driven Multi-Field Vector Store\n",
    "\n",
    "This notebook demonstrates a **configuration-driven approach** for multi-field vector embeddings that works across any data source.\n",
    "\n",
    "### 🧠 **The Problem**\n",
    "Traditional vector stores only embed the main content, leaving rich metadata unsearchable:\n",
    "```python\n",
    "# Traditional approach - metadata trapped\n",
    "record.content = \"Long text...\"        # → Gets embedded ✅\n",
    "record.metadata.summary = \"Key points\"  # → Not searchable ❌\n",
    "```\n",
    "\n",
    "### 🎯 **Our Solution: Enhanced Record with Configuration-Driven Multi-Field Embeddings**\n",
    "The enhanced Record class provides direct vector processing capabilities:\n",
    "```yaml\n",
    "# conf/storage/osb.yaml\n",
    "osb_vector:\n",
    "  type: chromadb\n",
    "  # ... basic config\n",
    "  multi_field_embedding:\n",
    "    content_field: \"content\"\n",
    "    additional_fields:\n",
    "      - source_field: \"summary\"\n",
    "        chunk_type: \"summary\"\n",
    "        min_length: 50\n",
    "      - source_field: \"title\"\n",
    "        chunk_type: \"title\"\n",
    "        min_length: 10\n",
    "```\n",
    "\n",
    "### 🔍 **Search Capabilities**\n",
    "\n",
    "| Search Type | Use Case | Example Query |\n",
    "|-------------|----------|---------------|\n",
    "| **Summary-Only** | High-level concepts | `where={\"content_type\": \"summary\"}` |\n",
    "| **Title-Only** | Topic matching | `where={\"content_type\": \"title\"}` |\n",
    "| **Content-Only** | Detailed analysis | `where={\"content_type\": \"content\"}` |\n",
    "| **Cross-Field** | Comprehensive search | No filter = search everything |\n",
    "| **Hybrid** | Semantic + exact match | `query + where={\"case_number\": \"2024\"}` |\n",
    "\n",
    "### 🏗️ **Benefits**\n",
    "- ✅ **Enhanced Record**: Direct vector capabilities built into Record class\n",
    "- ✅ **Configuration-Driven**: No hardcoded field names\n",
    "- ✅ **Data Source Agnostic**: Works with any Record structure\n",
    "- ✅ **Same Config**: Creation and reading use identical configuration\n",
    "- ✅ **Extensible**: Easy to add new field types for any dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>️⃣ VALIDATION-ONLY MODE\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36m4\u001b[0m️⃣ VALIDATION-ONLY MODE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 19:44:36\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1215 🔍 Validating 172 records for incremental update...\n",
      "\u001b[32m2025-06-17 19:44:36\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1242 📋 Validation complete: 134 new, 38 existing, 0 conflicts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">📋 Validation-Only Results:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "📋 Validation-Only Results:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   📊 Total Records: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   📊 Total Records: \u001b[1;36m172\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   🆕 Would Process: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">134</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   🆕 Would Process: \u001b[1;36m134\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ⏭️  Would Skip: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ⏭️  Would Skip: \u001b[1;36m38\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ Safe to Add: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ Safe to Add: \u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "⚠️  Sample Warnings:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "⚠️  Sample Warnings:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   - Record BUN-QBBLZ8WI: record_id and content both unchanged\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   - Record BUN-QBBLZ8WI: record_id and content both unchanged\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   - Record FB-4294T386: record_id and content both unchanged\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   - Record FB-4294T386: record_id and content both unchanged\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   - Record FB-M8D2SOGS: record_id and content both unchanged\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   - Record FB-M8D2SOGS: record_id and content both unchanged\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Test validation-only mode\n",
    "print(f\"\\n4️⃣ VALIDATION-ONLY MODE\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "validation_result = await vectorstore.process_batch(records, mode=\"validate_only\")  # Only validate, don't process\n",
    "\n",
    "print(f\"📋 Validation-Only Results:\")\n",
    "print(f\"   📊 Total Records: {validation_result.total_records}\")\n",
    "print(f\"   🆕 Would Process: {validation_result.validation_result['stats']['would_process']}\")\n",
    "print(f\"   ⏭️  Would Skip: {validation_result.validation_result['stats']['would_skip']}\")\n",
    "print(f\"   ✅ Safe to Add: {validation_result.validation_result['safe_to_add']}\")\n",
    "\n",
    "# Show some validation warnings\n",
    "if validation_result.validation_result[\"warnings\"]:\n",
    "    print(f\"\\n⚠️  Sample Warnings:\")\n",
    "    for warning in validation_result.validation_result[\"warnings\"][:3]:\n",
    "        print(f\"   - {warning}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>️⃣ BATCH PROCESSING WITH VALIDATION\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36m3\u001b[0m️⃣ BATCH PROCESSING WITH VALIDATION\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing batch of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span> records<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing batch of \u001b[1;36m172\u001b[0m records\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-17 19:44:54\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1215 🔍 Validating 172 records for incremental update...\n",
      "\u001b[32m2025-06-17 19:44:55\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1242 📋 Validation complete: 172 new, 0 existing, 0 conflicts\n",
      "\u001b[32m2025-06-17 19:44:55\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1307 🏭 Processing batch of 172 records (mode: safe)\n",
      "\u001b[32m2025-06-17 19:44:55\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:44:56\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 13 chunks for record BUN-QBBLZ8WI...\n",
      "\u001b[32m2025-06-17 19:44:57\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 13 chunks for record BUN-QBBLZ8WI\n",
      "\u001b[32m2025-06-17 19:44:57\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record BUN-QBBLZ8WI: 13 chunks ({'content': 10, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1803.9ms\n",
      "\u001b[32m2025-06-17 19:44:57\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:44:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 59 chunks for record FB-4294T386...\n",
      "\u001b[32m2025-06-17 19:44:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 59 chunks for record FB-4294T386\n",
      "\u001b[32m2025-06-17 19:44:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-4294T386: 59 chunks ({'content': 56, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2242.0ms\n",
      "\u001b[32m2025-06-17 19:44:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:00\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 47 chunks for record FB-M8D2SOGS...\n",
      "\u001b[32m2025-06-17 19:45:00\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 47 chunks for record FB-M8D2SOGS\n",
      "\u001b[32m2025-06-17 19:45:00\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-M8D2SOGS: 47 chunks ({'content': 44, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1501.1ms\n",
      "\u001b[32m2025-06-17 19:45:00\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 11 chunks for record IG-1BMH3DQ6...\n",
      "\u001b[32m2025-06-17 19:45:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 11 chunks for record IG-1BMH3DQ6\n",
      "\u001b[32m2025-06-17 19:45:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-1BMH3DQ6: 11 chunks ({'content': 8, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 558.9ms\n",
      "\u001b[32m2025-06-17 19:45:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record FB-2AHD01LX...\n",
      "\u001b[32m2025-06-17 19:45:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record FB-2AHD01LX\n",
      "\u001b[32m2025-06-17 19:45:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-2AHD01LX: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 548.5ms\n",
      "\u001b[32m2025-06-17 19:45:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:03\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 66 chunks for record FB-JRQ1XP2M...\n",
      "\u001b[32m2025-06-17 19:45:03\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 66 chunks for record FB-JRQ1XP2M\n",
      "\u001b[32m2025-06-17 19:45:03\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-JRQ1XP2M: 66 chunks ({'content': 63, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1969.9ms\n",
      "\u001b[32m2025-06-17 19:45:03\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 91 chunks for record FB-515JVE4X...\n",
      "\u001b[32m2025-06-17 19:45:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 91 chunks for record FB-515JVE4X\n",
      "\u001b[32m2025-06-17 19:45:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-515JVE4X: 91 chunks ({'content': 88, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2445.3ms\n",
      "\u001b[32m2025-06-17 19:45:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 36 chunks for record FB-QBJDASCV...\n",
      "\u001b[32m2025-06-17 19:45:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 36 chunks for record FB-QBJDASCV\n",
      "\u001b[32m2025-06-17 19:45:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-QBJDASCV: 36 chunks ({'content': 33, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1040.1ms\n",
      "\u001b[32m2025-06-17 19:45:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 51 chunks for record FB-P93JPX02...\n",
      "\u001b[32m2025-06-17 19:45:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 51 chunks for record FB-P93JPX02\n",
      "\u001b[32m2025-06-17 19:45:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-P93JPX02: 51 chunks ({'content': 48, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1474.4ms\n",
      "\u001b[32m2025-06-17 19:45:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 11 chunks for record IG-2R3UEQRR...\n",
      "\u001b[32m2025-06-17 19:45:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 11 chunks for record IG-2R3UEQRR\n",
      "\u001b[32m2025-06-17 19:45:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-2R3UEQRR: 11 chunks ({'content': 8, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 538.5ms\n",
      "\u001b[32m2025-06-17 19:45:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 60 chunks for record FB-1RWWJUAT...\n",
      "\u001b[32m2025-06-17 19:45:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 60 chunks for record FB-1RWWJUAT\n",
      "\u001b[32m2025-06-17 19:45:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-1RWWJUAT: 60 chunks ({'content': 57, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1664.7ms\n",
      "\u001b[32m2025-06-17 19:45:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 76 chunks for record FB-YLRV35WD...\n",
      "\u001b[32m2025-06-17 19:45:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 76 chunks for record FB-YLRV35WD\n",
      "\u001b[32m2025-06-17 19:45:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-YLRV35WD: 76 chunks ({'content': 73, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1963.8ms\n",
      "\u001b[32m2025-06-17 19:45:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 49 chunks for record FB-RZL57QHJ...\n",
      "\u001b[32m2025-06-17 19:45:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 49 chunks for record FB-RZL57QHJ\n",
      "\u001b[32m2025-06-17 19:45:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-RZL57QHJ: 49 chunks ({'content': 46, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1457.3ms\n",
      "\u001b[32m2025-06-17 19:45:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 84 chunks for record IG-ZJ7J6D28...\n",
      "\u001b[32m2025-06-17 19:45:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 84 chunks for record IG-ZJ7J6D28\n",
      "\u001b[32m2025-06-17 19:45:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-ZJ7J6D28: 84 chunks ({'content': 81, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2344.6ms\n",
      "\u001b[32m2025-06-17 19:45:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record FB-HFFVZENH...\n",
      "\u001b[32m2025-06-17 19:45:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record FB-HFFVZENH\n",
      "\u001b[32m2025-06-17 19:45:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-HFFVZENH: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 569.0ms\n",
      "\u001b[32m2025-06-17 19:45:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 9 chunks for record FB-33NK66FG...\n",
      "\u001b[32m2025-06-17 19:45:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 9 chunks for record FB-33NK66FG\n",
      "\u001b[32m2025-06-17 19:45:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-33NK66FG: 9 chunks ({'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 515.6ms\n",
      "\u001b[32m2025-06-17 19:45:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 91 chunks for record FB-515JVE4X...\n",
      "\u001b[32m2025-06-17 19:45:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 91 chunks for record FB-515JVE4X\n",
      "\u001b[32m2025-06-17 19:45:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-515JVE4X: 91 chunks ({'content': 88, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2400.2ms\n",
      "\u001b[32m2025-06-17 19:45:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 66 chunks for record FB-JRQ1XP2M...\n",
      "\u001b[32m2025-06-17 19:45:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 66 chunks for record FB-JRQ1XP2M\n",
      "\u001b[32m2025-06-17 19:45:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-JRQ1XP2M: 66 chunks ({'content': 63, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1898.5ms\n",
      "\u001b[32m2025-06-17 19:45:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 59 chunks for record IG-2PJ00L4T...\n",
      "\u001b[32m2025-06-17 19:45:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 59 chunks for record IG-2PJ00L4T\n",
      "\u001b[32m2025-06-17 19:45:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-2PJ00L4T: 59 chunks ({'content': 56, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1561.0ms\n",
      "\u001b[32m2025-06-17 19:45:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 54 chunks for record IG-0U6FLA5B...\n",
      "\u001b[32m2025-06-17 19:45:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 54 chunks for record IG-0U6FLA5B\n",
      "\u001b[32m2025-06-17 19:45:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-0U6FLA5B: 54 chunks ({'content': 51, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1498.1ms\n",
      "\u001b[32m2025-06-17 19:45:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 63 chunks for record FB-GW8BY1Y3...\n",
      "\u001b[32m2025-06-17 19:45:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 63 chunks for record FB-GW8BY1Y3\n",
      "\u001b[32m2025-06-17 19:45:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-GW8BY1Y3: 63 chunks ({'content': 60, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1895.2ms\n",
      "\u001b[32m2025-06-17 19:45:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record FB-ONL5YQVE...\n",
      "\u001b[32m2025-06-17 19:45:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record FB-ONL5YQVE\n",
      "\u001b[32m2025-06-17 19:45:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-ONL5YQVE: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 540.5ms\n",
      "\u001b[32m2025-06-17 19:45:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:27\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.9042736771887132 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:30\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.5972374151301354 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:32\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.769250169585762 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:37\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.953059960677312 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 2 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 2\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 8 chunks for record FB-I04M3KVF...\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 8 chunks for record FB-I04M3KVF\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-I04M3KVF: 9 chunks ({'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 20540.8ms\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.2018263624223993 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.71279168338833 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.9618355144646968 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.2643689599967347 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.1232732365282379 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.48913256678284 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.0180299508772497 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.7378393260825975 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.8392729465445194 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.7712049038007658 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.324018065017934 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.7348089320950169 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.493620117783139 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.8872872348756053 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.6356123672378096 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.3268498861960616 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.8226961265278763 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.121861260060877 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.870276383211638 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.988380692282486 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.2728980828064014 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.6555954404370237 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.154196909965834 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.381644671413921 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.527651452319494 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.36048631196723 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.222233064774953 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.283426714066382 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.610587237922757 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.368475051955337 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:59\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.09387605873258 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:45:59\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.781202825887188 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 13 chunks for record BUN-QBBLZ8WI...\n",
      "\u001b[32m2025-06-17 19:46:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 13 chunks for record BUN-QBBLZ8WI\n",
      "\u001b[32m2025-06-17 19:46:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record BUN-QBBLZ8WI: 13 chunks ({'content': 10, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 20693.4ms\n",
      "\u001b[32m2025-06-17 19:46:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:09\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.111640950607112 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 36 chunks for record FB-QBJDASCV...\n",
      "\u001b[32m2025-06-17 19:46:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 36 chunks for record FB-QBJDASCV\n",
      "\u001b[32m2025-06-17 19:46:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-QBJDASCV: 36 chunks ({'content': 33, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2979.7ms\n",
      "\u001b[32m2025-06-17 19:46:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 89 chunks for record FB-T8JDDDJV...\n",
      "\u001b[32m2025-06-17 19:46:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 89 chunks for record FB-T8JDDDJV\n",
      "\u001b[32m2025-06-17 19:46:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-T8JDDDJV: 89 chunks ({'content': 86, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2365.7ms\n",
      "\u001b[32m2025-06-17 19:46:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 76 chunks for record FB-YLRV35WD...\n",
      "\u001b[32m2025-06-17 19:46:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 76 chunks for record FB-YLRV35WD\n",
      "\u001b[32m2025-06-17 19:46:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-YLRV35WD: 76 chunks ({'content': 73, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1951.2ms\n",
      "\u001b[32m2025-06-17 19:46:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 35 chunks for record FB-ZWQUPZLZ...\n",
      "\u001b[32m2025-06-17 19:46:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 35 chunks for record FB-ZWQUPZLZ\n",
      "\u001b[32m2025-06-17 19:46:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-ZWQUPZLZ: 35 chunks ({'content': 32, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1033.8ms\n",
      "\u001b[32m2025-06-17 19:46:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 57 chunks for record FB-S6NRTDAJ...\n",
      "\u001b[32m2025-06-17 19:46:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 57 chunks for record FB-S6NRTDAJ\n",
      "\u001b[32m2025-06-17 19:46:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-S6NRTDAJ: 57 chunks ({'content': 54, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1499.5ms\n",
      "\u001b[32m2025-06-17 19:46:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 41 chunks for record IG-7THR3SI1...\n",
      "\u001b[32m2025-06-17 19:46:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 41 chunks for record IG-7THR3SI1\n",
      "\u001b[32m2025-06-17 19:46:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-7THR3SI1: 41 chunks ({'content': 38, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1370.4ms\n",
      "\u001b[32m2025-06-17 19:46:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 9 chunks for record FB-33NK66FG...\n",
      "\u001b[32m2025-06-17 19:46:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 9 chunks for record FB-33NK66FG\n",
      "\u001b[32m2025-06-17 19:46:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-33NK66FG: 9 chunks ({'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 526.7ms\n",
      "\u001b[32m2025-06-17 19:46:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 43 chunks for record FB-Q72FD6YL...\n",
      "\u001b[32m2025-06-17 19:46:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 43 chunks for record FB-Q72FD6YL\n",
      "\u001b[32m2025-06-17 19:46:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-Q72FD6YL: 43 chunks ({'content': 40, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1399.9ms\n",
      "\u001b[32m2025-06-17 19:46:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 45 chunks for record FB-TYE2766G...\n",
      "\u001b[32m2025-06-17 19:46:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 45 chunks for record FB-TYE2766G\n",
      "\u001b[32m2025-06-17 19:46:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-TYE2766G: 45 chunks ({'content': 42, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1421.1ms\n",
      "\u001b[32m2025-06-17 19:46:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 9 chunks for record FB-J5OOP3YZ...\n",
      "\u001b[32m2025-06-17 19:46:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 9 chunks for record FB-J5OOP3YZ\n",
      "\u001b[32m2025-06-17 19:46:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-J5OOP3YZ: 9 chunks ({'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 540.1ms\n",
      "\u001b[32m2025-06-17 19:46:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 53 chunks for record IG-FZSE6J9C...\n",
      "\u001b[32m2025-06-17 19:46:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 53 chunks for record IG-FZSE6J9C\n",
      "\u001b[32m2025-06-17 19:46:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-FZSE6J9C: 53 chunks ({'content': 50, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1474.5ms\n",
      "\u001b[32m2025-06-17 19:46:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 73 chunks for record FB-U2HHA647...\n",
      "\u001b[32m2025-06-17 19:46:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 73 chunks for record FB-U2HHA647\n",
      "\u001b[32m2025-06-17 19:46:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-U2HHA647: 73 chunks ({'content': 70, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1942.3ms\n",
      "\u001b[32m2025-06-17 19:46:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 33 chunks for record FB-2RDRCAVQ...\n",
      "\u001b[32m2025-06-17 19:46:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 33 chunks for record FB-2RDRCAVQ\n",
      "\u001b[32m2025-06-17 19:46:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-2RDRCAVQ: 33 chunks ({'content': 30, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1006.7ms\n",
      "\u001b[32m2025-06-17 19:46:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 1 chunks for record error_38...\n",
      "\u001b[32m2025-06-17 19:46:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 1 chunks for record error_38\n",
      "\u001b[32m2025-06-17 19:46:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record error_38: 1 chunks ({'content': 1}) in 474.0ms\n",
      "\u001b[32m2025-06-17 19:46:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 9 chunks for record FB-J5OOP3YZ...\n",
      "\u001b[32m2025-06-17 19:46:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 9 chunks for record FB-J5OOP3YZ\n",
      "\u001b[32m2025-06-17 19:46:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-J5OOP3YZ: 9 chunks ({'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 541.2ms\n",
      "\u001b[32m2025-06-17 19:46:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 86 chunks for record IG-RH16OBG3...\n",
      "\u001b[32m2025-06-17 19:46:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 86 chunks for record IG-RH16OBG3\n",
      "\u001b[32m2025-06-17 19:46:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-RH16OBG3: 86 chunks ({'content': 83, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2409.0ms\n",
      "\u001b[32m2025-06-17 19:46:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:33\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 49 chunks for record FB-AP0NSBVC...\n",
      "\u001b[32m2025-06-17 19:46:33\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 49 chunks for record FB-AP0NSBVC\n",
      "\u001b[32m2025-06-17 19:46:33\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-AP0NSBVC: 49 chunks ({'content': 46, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1449.1ms\n",
      "\u001b[32m2025-06-17 19:46:33\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:34\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 35 chunks for record FB-ZWQUPZLZ...\n",
      "\u001b[32m2025-06-17 19:46:34\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 35 chunks for record FB-ZWQUPZLZ\n",
      "\u001b[32m2025-06-17 19:46:34\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-ZWQUPZLZ: 35 chunks ({'content': 32, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1045.2ms\n",
      "\u001b[32m2025-06-17 19:46:34\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:36\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 89 chunks for record FB-T8JDDDJV...\n",
      "\u001b[32m2025-06-17 19:46:36\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 89 chunks for record FB-T8JDDDJV\n",
      "\u001b[32m2025-06-17 19:46:36\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-T8JDDDJV: 89 chunks ({'content': 86, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2396.2ms\n",
      "\u001b[32m2025-06-17 19:46:36\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:39\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 105 chunks for record FB-691QAMHJ...\n",
      "\u001b[32m2025-06-17 19:46:39\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 105 chunks for record FB-691QAMHJ\n",
      "\u001b[32m2025-06-17 19:46:39\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-691QAMHJ: 105 chunks ({'content': 102, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2813.1ms\n",
      "\u001b[32m2025-06-17 19:46:39\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:46:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.7928306018000033 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.0573200958586464 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.5245294530652904 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.662487927139389 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.8816835335610185 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.2570438122853858 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.3319163006419545 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.7722917425283566 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.143703087919808 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.084138689809741 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.016322079253531 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.196013637436627 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.6602524867430377 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.5779990970586788 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.8879570548416402 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.8734838168102073 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.1594521075139672 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.6730075624391725 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.4722297393909383 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.643936158836957 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.205276796190637 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.010970388328355 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.829165306417641 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.318685588057352 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.128008250685225 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.008530760404865 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.264158697951146 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.9178138059598364 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.870432584220177 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.8992703592650857 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.6779459979349234 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:43\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.2531602454489343 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:43\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.5280116279379614 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:43\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.124148864278852 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:43\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.7128989958499012 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:43\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.4800579902551996 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:43\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.8175780249731335 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:44\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.2673107428804338 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:44\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.8973155059671067 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:44\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.9401761075087034 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:44\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.572926498263765 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:44\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.9518167751339135 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:45\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.206842662277753 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:45\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.319378208850054 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:45\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.078429684363885 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:45\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.642094550545362 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:45\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.983770943377287 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:46\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.196913973975375 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:46\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.745709994545077 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:46\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.358489658012215 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:46\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.238610762665836 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:46\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.763025294783256 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:46\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.88599264983443 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:46\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.130253176063733 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:46\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.803447021692213 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:46\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.859925114763933 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:47\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.694265405038115 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:47\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.075296394805171 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:47\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.638859674406114 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.849318982424111 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.555773996410373 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.84927666297901 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.4978328211864715 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.209641138722633 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.49092210041462 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.71328688335461 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.461541603943683 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.049455493344968 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.673179730737042 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.785172802416207 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.423828881755622 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.552722265110996 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.120535998813144 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.46402713459522 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.010106367208415 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.60969206592626 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.159536725021834 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.864745538452413 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.9062721809533545 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.5834957529662392 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.42912902223047 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.596945665183121 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.2804810961338857 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.9316886247777374 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 6 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:59\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 49 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:59\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.7371758605986147 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:46:59\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.182631455525251 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:47:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.8948142282115692 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 19:47:05\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 49\u001b[0m\n",
      "\u001b[32m2025-06-17 19:47:05\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 86 chunks for record FB-6OKJPNS3...\n",
      "\u001b[32m2025-06-17 19:47:05\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 86 chunks for record FB-6OKJPNS3\n",
      "\u001b[32m2025-06-17 19:47:05\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-6OKJPNS3: 88 chunks ({'content': 85, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 25915.9ms\n",
      "\u001b[32m2025-06-17 19:47:05\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:47:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 45 chunks for record FB-P9PR9RSA...\n",
      "\u001b[32m2025-06-17 19:47:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 45 chunks for record FB-P9PR9RSA\n",
      "\u001b[32m2025-06-17 19:47:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-P9PR9RSA: 45 chunks ({'content': 42, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1380.7ms\n",
      "\u001b[32m2025-06-17 19:47:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:47:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 12 chunks for record FB-MFADK60O...\n",
      "\u001b[32m2025-06-17 19:47:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 12 chunks for record FB-MFADK60O\n",
      "\u001b[32m2025-06-17 19:47:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-MFADK60O: 12 chunks ({'content': 9, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 537.5ms\n",
      "\u001b[32m2025-06-17 19:47:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:47:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 11 chunks for record IG-2R3UEQRR...\n",
      "\u001b[32m2025-06-17 19:47:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 11 chunks for record IG-2R3UEQRR\n",
      "\u001b[32m2025-06-17 19:47:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-2R3UEQRR: 11 chunks ({'content': 8, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 495.4ms\n",
      "\u001b[32m2025-06-17 19:47:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:47:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 47 chunks for record FB-M8D2SOGS...\n",
      "\u001b[32m2025-06-17 19:47:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 47 chunks for record FB-M8D2SOGS\n",
      "\u001b[32m2025-06-17 19:47:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-M8D2SOGS: 47 chunks ({'content': 44, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1394.1ms\n",
      "\u001b[32m2025-06-17 19:47:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:47:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 9 chunks for record FB-TTXIBH8S...\n",
      "\u001b[32m2025-06-17 19:47:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 9 chunks for record FB-TTXIBH8S\n",
      "\u001b[32m2025-06-17 19:47:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:492 🔄 Syncing local changes back to remote: /home/debian/.cache/buttermilk/chromadb/gs___prosocial-dev_data_osb_chromadb → gs://prosocial-dev/data/osb/chromadb\n",
      "\u001b[32m2025-06-17 19:47:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m utils.py:824 Uploading ChromaDB from /home/debian/.cache/buttermilk/chromadb/gs___prosocial-dev_data_osb_chromadb to gs://prosocial-dev/data/osb/chromadb\n",
      "\u001b[32m2025-06-17 19:48:45\u001b[0m [] \u001b[1;30mINFO\u001b[0m utils.py:833 Successfully uploaded ChromaDB to gs://prosocial-dev/data/osb/chromadb\n",
      "\u001b[32m2025-06-17 19:48:45\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:496 ✅ Successfully synced local changes to remote storage\n",
      "\u001b[32m2025-06-17 19:48:45\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:556 ✅ Batch sync completed (reset counter to 0)\n",
      "\u001b[32m2025-06-17 19:48:45\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1188 🔄 Performed batch sync after processing record FB-TTXIBH8S\n",
      "\u001b[32m2025-06-17 19:48:45\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-TTXIBH8S: 9 chunks ({'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 96379.5ms\n",
      "\u001b[32m2025-06-17 19:48:45\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:48:46\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record FB-2AHD01LX...\n",
      "\u001b[32m2025-06-17 19:48:46\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record FB-2AHD01LX\n",
      "\u001b[32m2025-06-17 19:48:46\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-2AHD01LX: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 531.4ms\n",
      "\u001b[32m2025-06-17 19:48:46\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:48:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 45 chunks for record FB-TYE2766G...\n",
      "\u001b[32m2025-06-17 19:48:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 45 chunks for record FB-TYE2766G\n",
      "\u001b[32m2025-06-17 19:48:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-TYE2766G: 45 chunks ({'content': 42, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1396.1ms\n",
      "\u001b[32m2025-06-17 19:48:47\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:48:48\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record IG-5MC5OJIL...\n",
      "\u001b[32m2025-06-17 19:48:48\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record IG-5MC5OJIL\n",
      "\u001b[32m2025-06-17 19:48:48\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-5MC5OJIL: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 510.1ms\n",
      "\u001b[32m2025-06-17 19:48:48\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:48:49\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 64 chunks for record IG-KFLY3526...\n",
      "\u001b[32m2025-06-17 19:48:50\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 64 chunks for record IG-KFLY3526\n",
      "\u001b[32m2025-06-17 19:48:50\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-KFLY3526: 64 chunks ({'content': 61, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1873.4ms\n",
      "\u001b[32m2025-06-17 19:48:50\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:48:50\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 9 chunks for record FB-AJTD9P90...\n",
      "\u001b[32m2025-06-17 19:48:50\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 9 chunks for record FB-AJTD9P90\n",
      "\u001b[32m2025-06-17 19:48:50\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-AJTD9P90: 9 chunks ({'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 542.3ms\n",
      "\u001b[32m2025-06-17 19:48:50\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:48:52\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 72 chunks for record IG-H3138H6S...\n",
      "\u001b[32m2025-06-17 19:48:52\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 72 chunks for record IG-H3138H6S\n",
      "\u001b[32m2025-06-17 19:48:52\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-H3138H6S: 72 chunks ({'content': 69, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1959.3ms\n",
      "\u001b[32m2025-06-17 19:48:52\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:48:53\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 37 chunks for record FB-I964KKM6...\n",
      "\u001b[32m2025-06-17 19:48:53\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 37 chunks for record FB-I964KKM6\n",
      "\u001b[32m2025-06-17 19:48:53\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-I964KKM6: 37 chunks ({'content': 34, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1029.7ms\n",
      "\u001b[32m2025-06-17 19:48:53\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:48:54\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record FB-SI0CLWAX...\n",
      "\u001b[32m2025-06-17 19:48:54\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record FB-SI0CLWAX\n",
      "\u001b[32m2025-06-17 19:48:54\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-SI0CLWAX: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 546.0ms\n",
      "\u001b[32m2025-06-17 19:48:54\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:48:56\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 98 chunks for record IG-PT5WRTLW...\n",
      "\u001b[32m2025-06-17 19:48:56\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 98 chunks for record IG-PT5WRTLW\n",
      "\u001b[32m2025-06-17 19:48:56\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-PT5WRTLW: 98 chunks ({'content': 95, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2447.8ms\n",
      "\u001b[32m2025-06-17 19:48:56\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:48:57\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 9 chunks for record FB-AJTD9P90...\n",
      "\u001b[32m2025-06-17 19:48:57\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 9 chunks for record FB-AJTD9P90\n",
      "\u001b[32m2025-06-17 19:48:57\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-AJTD9P90: 9 chunks ({'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 558.2ms\n",
      "\u001b[32m2025-06-17 19:48:57\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:48:58\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 75 chunks for record FB-UK2RUS24...\n",
      "\u001b[32m2025-06-17 19:48:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 75 chunks for record FB-UK2RUS24\n",
      "\u001b[32m2025-06-17 19:48:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-UK2RUS24: 75 chunks ({'content': 72, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1942.2ms\n",
      "\u001b[32m2025-06-17 19:48:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:48:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 32 chunks for record FB-R9K87402...\n",
      "\u001b[32m2025-06-17 19:49:00\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 32 chunks for record FB-R9K87402\n",
      "\u001b[32m2025-06-17 19:49:00\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-R9K87402: 32 chunks ({'content': 29, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 999.2ms\n",
      "\u001b[32m2025-06-17 19:49:00\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:49:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 59 chunks for record IG-2PJ00L4T...\n",
      "\u001b[32m2025-06-17 19:49:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 59 chunks for record IG-2PJ00L4T\n",
      "\u001b[32m2025-06-17 19:49:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-2PJ00L4T: 59 chunks ({'content': 56, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1526.6ms\n",
      "\u001b[32m2025-06-17 19:49:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:49:03\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 72 chunks for record IG-H3138H6S...\n",
      "\u001b[32m2025-06-17 19:49:03\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 72 chunks for record IG-H3138H6S\n",
      "\u001b[32m2025-06-17 19:49:03\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-H3138H6S: 72 chunks ({'content': 69, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1958.8ms\n",
      "\u001b[32m2025-06-17 19:49:03\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:49:04\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 49 chunks for record FB-E1154YLY...\n",
      "\u001b[32m2025-06-17 19:49:04\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 49 chunks for record FB-E1154YLY\n",
      "\u001b[32m2025-06-17 19:49:05\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-E1154YLY: 49 chunks ({'content': 46, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1473.7ms\n",
      "\u001b[32m2025-06-17 19:49:05\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:49:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 86 chunks for record IG-RH16OBG3...\n",
      "\u001b[32m2025-06-17 19:49:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 86 chunks for record IG-RH16OBG3\n",
      "\u001b[32m2025-06-17 19:49:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-RH16OBG3: 86 chunks ({'content': 83, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2322.7ms\n",
      "\u001b[32m2025-06-17 19:49:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:49:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record FB-79KHZ1P5...\n",
      "\u001b[32m2025-06-17 19:49:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record FB-79KHZ1P5\n",
      "\u001b[32m2025-06-17 19:49:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-79KHZ1P5: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 565.1ms\n",
      "\u001b[32m2025-06-17 19:49:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:49:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 32 chunks for record FB-R9K87402...\n",
      "\u001b[32m2025-06-17 19:49:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 32 chunks for record FB-R9K87402\n",
      "\u001b[32m2025-06-17 19:49:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-R9K87402: 32 chunks ({'content': 29, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1004.1ms\n",
      "\u001b[32m2025-06-17 19:49:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:49:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 26 chunks for record FB-I2T6526K...\n",
      "\u001b[32m2025-06-17 19:49:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 26 chunks for record FB-I2T6526K\n",
      "\u001b[32m2025-06-17 19:49:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-I2T6526K: 26 chunks ({'content': 23, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 979.9ms\n",
      "\u001b[32m2025-06-17 19:49:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:49:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 96 chunks for record IG-TOM6IXVH...\n",
      "\u001b[32m2025-06-17 19:49:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 96 chunks for record IG-TOM6IXVH\n",
      "\u001b[32m2025-06-17 19:49:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-TOM6IXVH: 96 chunks ({'content': 93, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2568.2ms\n",
      "\u001b[32m2025-06-17 19:49:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:49:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 60 chunks for record FB-1RWWJUAT...\n",
      "\u001b[32m2025-06-17 19:49:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 60 chunks for record FB-1RWWJUAT\n",
      "\u001b[32m2025-06-17 19:49:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-1RWWJUAT: 60 chunks ({'content': 57, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1513.8ms\n",
      "\u001b[32m2025-06-17 19:49:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:49:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 84 chunks for record IG-ZJ7J6D28...\n",
      "\u001b[32m2025-06-17 19:49:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 84 chunks for record IG-ZJ7J6D28\n",
      "\u001b[32m2025-06-17 19:49:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-ZJ7J6D28: 84 chunks ({'content': 81, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2286.4ms\n",
      "\u001b[32m2025-06-17 19:49:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:49:17\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.259710909787813 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:19\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.7338909372139812 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:22\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.309007170937485 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:27\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.859388668990906 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:37\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 61 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:37\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 61\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 62 chunks for record FB-MBGOTVN8...\n",
      "\u001b[32m2025-06-17 19:49:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 62 chunks for record FB-MBGOTVN8\n",
      "\u001b[32m2025-06-17 19:49:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-MBGOTVN8: 63 chunks ({'content': 60, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 21738.3ms\n",
      "\u001b[32m2025-06-17 19:49:37\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.8161400869461795 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.8859461455055597 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.5308894203620214 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.336999655737075 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.470969122609884 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.9227130826438756 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.1746388302359403 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.3066107833645098 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.388665989871758 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.4064834469670253 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.319825444936421 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.8841606898374355 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.0899663349477757 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.8385911359492728 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.761374453874195 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.4013631736534213 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.2960183225350077 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.1498150022458413 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.027768316052734 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.0750869506594984 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:39\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.4826066609436412 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:39\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.289486017069965 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:39\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.0792955130255066 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:39\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.776722077239424 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:39\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.998655363561527 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.3329092476373168 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.4350172477162326 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.3867255994888668 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.5258098398395408 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.0968370306129747 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.6580197631828995 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.6331724740205424 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.6891460959679288 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.61205487610772 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.3891110480695197 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.8014237714312005 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.8642628764430165 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.678592096411043 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.9756657712529044 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.2235266678940366 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.728193888612092 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.620785549108432 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.809044326994311 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.807418830738662 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.138678352226826 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:43\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.272202330356694 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:43\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.935484918737021 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:43\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.081327087445986 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:43\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.591212430870201 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:43\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.94279022868112 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:43\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.058032562012793 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:43\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.970070452324262 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:43\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.93706397096814 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:44\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.181492994148447 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:44\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.973413642104551 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:44\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.245202882656188 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:44\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.565658180385386 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:45\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.641506605413489 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:45\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.9808658917880635 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:45\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.076387362241893 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:47\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.545555226772578 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.828783802274103 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.194343425546528 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.718840437758258 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.659400066815861 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.047703740777283 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.050747946756985 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.55432101652595 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.369326877661628 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.221688260855872 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:48\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.053063662185505 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.687740234380833 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.21797986120645 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.599843918562101 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.038626616851944 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.07864998384008 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.632050229694938 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.519881173250685 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.01037875551054 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.564554363935315 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 1 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:56\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 19 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.1746903358344758 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 6 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 10 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 14 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:57\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 3 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.838234578604878 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.083245973897385 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.848447695282508 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.1054285893408597 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:49:57\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.5896628682271783 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:50:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 1\u001b[0m\n",
      "\u001b[32m2025-06-17 19:50:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 3\u001b[0m\n",
      "\u001b[32m2025-06-17 19:50:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 6\u001b[0m\n",
      "\u001b[32m2025-06-17 19:50:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 10\u001b[0m\n",
      "\u001b[32m2025-06-17 19:50:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 14\u001b[0m\n",
      "\u001b[32m2025-06-17 19:50:00\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 19\u001b[0m\n",
      "\u001b[32m2025-06-17 19:50:00\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 27 chunks for record FB-2RDRCAVQ...\n",
      "\u001b[32m2025-06-17 19:50:00\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 27 chunks for record FB-2RDRCAVQ\n",
      "\u001b[32m2025-06-17 19:50:00\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-2RDRCAVQ: 33 chunks ({'content': 30, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 22932.3ms\n",
      "\u001b[32m2025-06-17 19:50:00\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 20 chunks for record PAO-2021-01...\n",
      "\u001b[32m2025-06-17 19:50:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 20 chunks for record PAO-2021-01\n",
      "\u001b[32m2025-06-17 19:50:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record PAO-2021-01: 20 chunks ({'content': 17, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 582.8ms\n",
      "\u001b[32m2025-06-17 19:50:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record IG-5MC5OJIL...\n",
      "\u001b[32m2025-06-17 19:50:02\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record IG-5MC5OJIL\n",
      "\u001b[32m2025-06-17 19:50:02\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-5MC5OJIL: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 540.6ms\n",
      "\u001b[32m2025-06-17 19:50:02\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:04\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 105 chunks for record FB-691QAMHJ...\n",
      "\u001b[32m2025-06-17 19:50:04\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 105 chunks for record FB-691QAMHJ\n",
      "\u001b[32m2025-06-17 19:50:04\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-691QAMHJ: 105 chunks ({'content': 102, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2768.1ms\n",
      "\u001b[32m2025-06-17 19:50:04\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 61 chunks for record IG-I9DP23IB...\n",
      "\u001b[32m2025-06-17 19:50:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 61 chunks for record IG-I9DP23IB\n",
      "\u001b[32m2025-06-17 19:50:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-I9DP23IB: 61 chunks ({'content': 58, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1770.0ms\n",
      "\u001b[32m2025-06-17 19:50:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record FB-2AHD01LX...\n",
      "\u001b[32m2025-06-17 19:50:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record FB-2AHD01LX\n",
      "\u001b[32m2025-06-17 19:50:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-2AHD01LX: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 523.2ms\n",
      "\u001b[32m2025-06-17 19:50:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record FB-2AHD01LX...\n",
      "\u001b[32m2025-06-17 19:50:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record FB-2AHD01LX\n",
      "\u001b[32m2025-06-17 19:50:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-2AHD01LX: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 511.7ms\n",
      "\u001b[32m2025-06-17 19:50:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record FB-HFFVZENH...\n",
      "\u001b[32m2025-06-17 19:50:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record FB-HFFVZENH\n",
      "\u001b[32m2025-06-17 19:50:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-HFFVZENH: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 535.3ms\n",
      "\u001b[32m2025-06-17 19:50:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 11 chunks for record IG-24CW5DHI...\n",
      "\u001b[32m2025-06-17 19:50:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 11 chunks for record IG-24CW5DHI\n",
      "\u001b[32m2025-06-17 19:50:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-24CW5DHI: 11 chunks ({'content': 8, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 557.2ms\n",
      "\u001b[32m2025-06-17 19:50:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 58 chunks for record FB-CZHY85JC...\n",
      "\u001b[32m2025-06-17 19:50:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 58 chunks for record FB-CZHY85JC\n",
      "\u001b[32m2025-06-17 19:50:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-CZHY85JC: 58 chunks ({'content': 55, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1505.3ms\n",
      "\u001b[32m2025-06-17 19:50:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 12 chunks for record FB-7UK5F6VG...\n",
      "\u001b[32m2025-06-17 19:50:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 12 chunks for record FB-7UK5F6VG\n",
      "\u001b[32m2025-06-17 19:50:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-7UK5F6VG: 12 chunks ({'content': 9, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 563.3ms\n",
      "\u001b[32m2025-06-17 19:50:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 60 chunks for record FB-1RWWJUAT...\n",
      "\u001b[32m2025-06-17 19:50:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 60 chunks for record FB-1RWWJUAT\n",
      "\u001b[32m2025-06-17 19:50:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-1RWWJUAT: 60 chunks ({'content': 57, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1569.6ms\n",
      "\u001b[32m2025-06-17 19:50:12\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 60 chunks for record FB-MP4ZC4CC...\n",
      "\u001b[32m2025-06-17 19:50:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 60 chunks for record FB-MP4ZC4CC\n",
      "\u001b[32m2025-06-17 19:50:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-MP4ZC4CC: 60 chunks ({'content': 57, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1542.4ms\n",
      "\u001b[32m2025-06-17 19:50:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:15\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 41 chunks for record IG-7THR3SI1...\n",
      "\u001b[32m2025-06-17 19:50:15\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 41 chunks for record IG-7THR3SI1\n",
      "\u001b[32m2025-06-17 19:50:15\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-7THR3SI1: 41 chunks ({'content': 38, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1370.3ms\n",
      "\u001b[32m2025-06-17 19:50:15\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:15\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 5 chunks for record FB-BLKZ1ZI8...\n",
      "\u001b[32m2025-06-17 19:50:15\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 5 chunks for record FB-BLKZ1ZI8\n",
      "\u001b[32m2025-06-17 19:50:15\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-BLKZ1ZI8: 5 chunks ({'content': 4, 'title': 1}) in 552.4ms\n",
      "\u001b[32m2025-06-17 19:50:15\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 53 chunks for record IG-FZSE6J9C...\n",
      "\u001b[32m2025-06-17 19:50:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 53 chunks for record IG-FZSE6J9C\n",
      "\u001b[32m2025-06-17 19:50:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-FZSE6J9C: 53 chunks ({'content': 50, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1488.0ms\n",
      "\u001b[32m2025-06-17 19:50:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 45 chunks for record FB-P9PR9RSA...\n",
      "\u001b[32m2025-06-17 19:50:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 45 chunks for record FB-P9PR9RSA\n",
      "\u001b[32m2025-06-17 19:50:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-P9PR9RSA: 45 chunks ({'content': 42, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1487.0ms\n",
      "\u001b[32m2025-06-17 19:50:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 59 chunks for record FB-4294T386...\n",
      "\u001b[32m2025-06-17 19:50:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 59 chunks for record FB-4294T386\n",
      "\u001b[32m2025-06-17 19:50:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-4294T386: 59 chunks ({'content': 56, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1579.1ms\n",
      "\u001b[32m2025-06-17 19:50:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 33 chunks for record FB-2RDRCAVQ...\n",
      "\u001b[32m2025-06-17 19:50:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 33 chunks for record FB-2RDRCAVQ\n",
      "\u001b[32m2025-06-17 19:50:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-2RDRCAVQ: 33 chunks ({'content': 30, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1036.8ms\n",
      "\u001b[32m2025-06-17 19:50:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 75 chunks for record FB-UK2RUS24...\n",
      "\u001b[32m2025-06-17 19:50:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 75 chunks for record FB-UK2RUS24\n",
      "\u001b[32m2025-06-17 19:50:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-UK2RUS24: 75 chunks ({'content': 72, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1995.1ms\n",
      "\u001b[32m2025-06-17 19:50:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 43 chunks for record IG-WUC3649N...\n",
      "\u001b[32m2025-06-17 19:50:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 43 chunks for record IG-WUC3649N\n",
      "\u001b[32m2025-06-17 19:50:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-WUC3649N: 43 chunks ({'content': 40, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1478.1ms\n",
      "\u001b[32m2025-06-17 19:50:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 1 chunks for record error_95...\n",
      "\u001b[32m2025-06-17 19:50:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 1 chunks for record error_95\n",
      "\u001b[32m2025-06-17 19:50:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record error_95: 1 chunks ({'content': 1}) in 453.4ms\n",
      "\u001b[32m2025-06-17 19:50:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 61 chunks for record IG-I9DP23IB...\n",
      "\u001b[32m2025-06-17 19:50:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 61 chunks for record IG-I9DP23IB\n",
      "\u001b[32m2025-06-17 19:50:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-I9DP23IB: 61 chunks ({'content': 58, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1875.4ms\n",
      "\u001b[32m2025-06-17 19:50:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 60 chunks for record FB-MP4ZC4CC...\n",
      "\u001b[32m2025-06-17 19:50:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 60 chunks for record FB-MP4ZC4CC\n",
      "\u001b[32m2025-06-17 19:50:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-MP4ZC4CC: 60 chunks ({'content': 57, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1533.0ms\n",
      "\u001b[32m2025-06-17 19:50:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record FB-ONL5YQVE...\n",
      "\u001b[32m2025-06-17 19:50:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record FB-ONL5YQVE\n",
      "\u001b[32m2025-06-17 19:50:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-ONL5YQVE: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 522.7ms\n",
      "\u001b[32m2025-06-17 19:50:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 9 chunks for record FB-VJ6FO5UY...\n",
      "\u001b[32m2025-06-17 19:50:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 9 chunks for record FB-VJ6FO5UY\n",
      "\u001b[32m2025-06-17 19:50:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-VJ6FO5UY: 9 chunks ({'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 510.4ms\n",
      "\u001b[32m2025-06-17 19:50:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:50:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 54 chunks for record IG-0U6FLA5B...\n",
      "\u001b[32m2025-06-17 19:50:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 54 chunks for record IG-0U6FLA5B\n",
      "\u001b[32m2025-06-17 19:50:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:492 🔄 Syncing local changes back to remote: /home/debian/.cache/buttermilk/chromadb/gs___prosocial-dev_data_osb_chromadb → gs://prosocial-dev/data/osb/chromadb\n",
      "\u001b[32m2025-06-17 19:50:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m utils.py:824 Uploading ChromaDB from /home/debian/.cache/buttermilk/chromadb/gs___prosocial-dev_data_osb_chromadb to gs://prosocial-dev/data/osb/chromadb\n",
      "\u001b[32m2025-06-17 19:51:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m utils.py:833 Successfully uploaded ChromaDB to gs://prosocial-dev/data/osb/chromadb\n",
      "\u001b[32m2025-06-17 19:51:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:496 ✅ Successfully synced local changes to remote storage\n",
      "\u001b[32m2025-06-17 19:51:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:556 ✅ Batch sync completed (reset counter to 0)\n",
      "\u001b[32m2025-06-17 19:51:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1188 🔄 Performed batch sync after processing record IG-0U6FLA5B\n",
      "\u001b[32m2025-06-17 19:51:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-0U6FLA5B: 54 chunks ({'content': 51, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 89405.8ms\n",
      "\u001b[32m2025-06-17 19:51:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:51:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 9 chunks for record FB-IULHG7JK...\n",
      "\u001b[32m2025-06-17 19:51:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 9 chunks for record FB-IULHG7JK\n",
      "\u001b[32m2025-06-17 19:51:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-IULHG7JK: 9 chunks ({'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 554.2ms\n",
      "\u001b[32m2025-06-17 19:51:59\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 74 chunks for record IG-OZNR5J1Z...\n",
      "\u001b[32m2025-06-17 19:52:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 74 chunks for record IG-OZNR5J1Z\n",
      "\u001b[32m2025-06-17 19:52:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-OZNR5J1Z: 74 chunks ({'content': 71, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1936.5ms\n",
      "\u001b[32m2025-06-17 19:52:01\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:02\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 11 chunks for record IG-24CW5DHI...\n",
      "\u001b[32m2025-06-17 19:52:02\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 11 chunks for record IG-24CW5DHI\n",
      "\u001b[32m2025-06-17 19:52:02\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-24CW5DHI: 11 chunks ({'content': 8, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 543.7ms\n",
      "\u001b[32m2025-06-17 19:52:02\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:03\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 68 chunks for record FB-LXNFAD5F...\n",
      "\u001b[32m2025-06-17 19:52:04\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 68 chunks for record FB-LXNFAD5F\n",
      "\u001b[32m2025-06-17 19:52:04\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-LXNFAD5F: 68 chunks ({'content': 65, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1909.0ms\n",
      "\u001b[32m2025-06-17 19:52:04\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:04\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 26 chunks for record FB-I2T6526K...\n",
      "\u001b[32m2025-06-17 19:52:05\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 26 chunks for record FB-I2T6526K\n",
      "\u001b[32m2025-06-17 19:52:05\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-I2T6526K: 26 chunks ({'content': 23, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 959.6ms\n",
      "\u001b[32m2025-06-17 19:52:05\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 49 chunks for record FB-RZL57QHJ...\n",
      "\u001b[32m2025-06-17 19:52:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 49 chunks for record FB-RZL57QHJ\n",
      "\u001b[32m2025-06-17 19:52:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-RZL57QHJ: 49 chunks ({'content': 46, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1491.3ms\n",
      "\u001b[32m2025-06-17 19:52:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 73 chunks for record FB-U2HHA647...\n",
      "\u001b[32m2025-06-17 19:52:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 73 chunks for record FB-U2HHA647\n",
      "\u001b[32m2025-06-17 19:52:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-U2HHA647: 73 chunks ({'content': 70, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2065.5ms\n",
      "\u001b[32m2025-06-17 19:52:08\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 43 chunks for record FB-E5M6QZGA...\n",
      "\u001b[32m2025-06-17 19:52:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 43 chunks for record FB-E5M6QZGA\n",
      "\u001b[32m2025-06-17 19:52:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-E5M6QZGA: 43 chunks ({'content': 40, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1422.7ms\n",
      "\u001b[32m2025-06-17 19:52:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 9 chunks for record FB-I04M3KVF...\n",
      "\u001b[32m2025-06-17 19:52:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 9 chunks for record FB-I04M3KVF\n",
      "\u001b[32m2025-06-17 19:52:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-I04M3KVF: 9 chunks ({'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 544.9ms\n",
      "\u001b[32m2025-06-17 19:52:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 1 chunks for record error_110...\n",
      "\u001b[32m2025-06-17 19:52:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 1 chunks for record error_110\n",
      "\u001b[32m2025-06-17 19:52:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record error_110: 1 chunks ({'content': 1}) in 470.8ms\n",
      "\u001b[32m2025-06-17 19:52:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 93 chunks for record FB-ZT6AJS4X...\n",
      "\u001b[32m2025-06-17 19:52:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 93 chunks for record FB-ZT6AJS4X\n",
      "\u001b[32m2025-06-17 19:52:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-ZT6AJS4X: 93 chunks ({'content': 90, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2428.7ms\n",
      "\u001b[32m2025-06-17 19:52:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 44 chunks for record FB-XWJQBU9A...\n",
      "\u001b[32m2025-06-17 19:52:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 44 chunks for record FB-XWJQBU9A\n",
      "\u001b[32m2025-06-17 19:52:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-XWJQBU9A: 44 chunks ({'content': 41, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1415.0ms\n",
      "\u001b[32m2025-06-17 19:52:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 59 chunks for record FB-4294T386...\n",
      "\u001b[32m2025-06-17 19:52:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 59 chunks for record FB-4294T386\n",
      "\u001b[32m2025-06-17 19:52:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-4294T386: 59 chunks ({'content': 56, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1533.8ms\n",
      "\u001b[32m2025-06-17 19:52:16\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 56 chunks for record FB-B6NGYREK...\n",
      "\u001b[32m2025-06-17 19:52:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 56 chunks for record FB-B6NGYREK\n",
      "\u001b[32m2025-06-17 19:52:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-B6NGYREK: 56 chunks ({'content': 53, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1543.4ms\n",
      "\u001b[32m2025-06-17 19:52:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:19\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 43 chunks for record FB-E5M6QZGA...\n",
      "\u001b[32m2025-06-17 19:52:19\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 43 chunks for record FB-E5M6QZGA\n",
      "\u001b[32m2025-06-17 19:52:19\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-E5M6QZGA: 43 chunks ({'content': 40, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1445.9ms\n",
      "\u001b[32m2025-06-17 19:52:19\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 84 chunks for record FB-659EAWI8...\n",
      "\u001b[32m2025-06-17 19:52:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 84 chunks for record FB-659EAWI8\n",
      "\u001b[32m2025-06-17 19:52:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-659EAWI8: 84 chunks ({'content': 81, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2360.4ms\n",
      "\u001b[32m2025-06-17 19:52:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 38 chunks for record FB-H6OZKDS3...\n",
      "\u001b[32m2025-06-17 19:52:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 38 chunks for record FB-H6OZKDS3\n",
      "\u001b[32m2025-06-17 19:52:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-H6OZKDS3: 38 chunks ({'content': 35, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1074.8ms\n",
      "\u001b[32m2025-06-17 19:52:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 58 chunks for record FB-L1LANIA7...\n",
      "\u001b[32m2025-06-17 19:52:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 58 chunks for record FB-L1LANIA7\n",
      "\u001b[32m2025-06-17 19:52:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-L1LANIA7: 58 chunks ({'content': 55, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1629.7ms\n",
      "\u001b[32m2025-06-17 19:52:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record FB-2AHD01LX...\n",
      "\u001b[32m2025-06-17 19:52:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record FB-2AHD01LX\n",
      "\u001b[32m2025-06-17 19:52:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-2AHD01LX: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 485.8ms\n",
      "\u001b[32m2025-06-17 19:52:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 93 chunks for record FB-ZT6AJS4X...\n",
      "\u001b[32m2025-06-17 19:52:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 93 chunks for record FB-ZT6AJS4X\n",
      "\u001b[32m2025-06-17 19:52:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-ZT6AJS4X: 93 chunks ({'content': 90, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2388.0ms\n",
      "\u001b[32m2025-06-17 19:52:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 12 chunks for record IG-FEYWNWI2...\n",
      "\u001b[32m2025-06-17 19:52:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 12 chunks for record IG-FEYWNWI2\n",
      "\u001b[32m2025-06-17 19:52:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-FEYWNWI2: 12 chunks ({'content': 9, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 513.5ms\n",
      "\u001b[32m2025-06-17 19:52:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 12 chunks for record FB-7UK5F6VG...\n",
      "\u001b[32m2025-06-17 19:52:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 12 chunks for record FB-7UK5F6VG\n",
      "\u001b[32m2025-06-17 19:52:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-7UK5F6VG: 12 chunks ({'content': 9, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 529.3ms\n",
      "\u001b[32m2025-06-17 19:52:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 33 chunks for record FB-2RDRCAVQ...\n",
      "\u001b[32m2025-06-17 19:52:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 33 chunks for record FB-2RDRCAVQ\n",
      "\u001b[32m2025-06-17 19:52:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-2RDRCAVQ: 33 chunks ({'content': 30, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 986.9ms\n",
      "\u001b[32m2025-06-17 19:52:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record FB-SI0CLWAX...\n",
      "\u001b[32m2025-06-17 19:52:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record FB-SI0CLWAX\n",
      "\u001b[32m2025-06-17 19:52:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-SI0CLWAX: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 528.5ms\n",
      "\u001b[32m2025-06-17 19:52:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:30\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 5 chunks for record FB-BLKZ1ZI8...\n",
      "\u001b[32m2025-06-17 19:52:30\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 5 chunks for record FB-BLKZ1ZI8\n",
      "\u001b[32m2025-06-17 19:52:30\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-BLKZ1ZI8: 5 chunks ({'content': 4, 'title': 1}) in 478.2ms\n",
      "\u001b[32m2025-06-17 19:52:30\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:52:30\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.3116423178523844 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:30\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.1037850582353226 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.7020931156073327 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.846888997923702 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.2994348052133111 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.4137357401427906 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.629114254007823 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.7664418780417808 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.3179793028497748 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.864723876803035 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.2093222705401532 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.757392533281222 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.1320957521083512 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.1925429709637392 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.0656979355239213 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.7225506543909237 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.379421875790298 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.743183686805933 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.5481437540128637 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:31\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.0174335822562108 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:32\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.5515106042611366 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:32\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.5979077938316752 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:32\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.6981929483256706 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:32\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.488400995209883 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:32\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.2077220853457185 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:33\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.8395324111579754 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:33\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.0841178589268825 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:33\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.2492045525361037 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:33\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.646054183750326 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:33\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.932971417181328 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:33\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.05389064703693 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:33\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.9087567896154245 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:33\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.3622190148559334 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:33\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.2212924290492353 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:34\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.458548409830218 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:34\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.9900531922832734 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:34\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.048096581374227 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:34\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.890823885807058 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:34\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.049528786171655 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:34\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.058768789140519 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:35\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.002602785096975 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:35\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.355747736165287 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:35\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.983279534641408 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:35\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.78970111998769 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:36\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.0053029408416565 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:36\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.181026761095786 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:36\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.986821993059024 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:36\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.3133799110755575 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:36\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.17074152296402 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:37\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.5621286662384986 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:37\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.856006664473489 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:37\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.094665969839502 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:37\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.003017086445839 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:37\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.245092614705301 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:37\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.32044599900108 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:37\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.72680275699598 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:37\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.261955932607288 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:37\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.902544709211267 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.7596698253121295 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:38\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.523450132511369 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:39\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.50175867647502 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.938215725940404 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:40\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.434165469785894 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.30031370715514 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.988917395975186 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.526911179908687 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.128540057719245 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.111804192052007 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.963341540320773 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:41\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.830118952686446 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.090248480332596 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.06738420414607 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.99573834908052 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.936424621099253 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.648381282207184 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.556661344601533 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:43\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.41272612062944 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:43\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.88766229012768 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:43\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 9.445206253719661 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:44\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 8.963989326981638 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:49\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 27 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:49\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.2293697827471366 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 4 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 47 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 23 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 17 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.2962879912134975 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 37 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.564075716596086 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.9419403700676168 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.2405676348126033 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.1385506260549203 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 36 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 51 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:50\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.900585379471285 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:50\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 40 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.307629936170591 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.865776329850646 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 43 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 44 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 22 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.9729190021880463 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:51\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.8946361803216716 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:51\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 53 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.0522263945629358 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 46 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.5776064633439377 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.4365085429751776 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.349321222667095 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.5470922015774131 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 41 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:52\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 26 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:52\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.4486201993357897 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.375740738829174 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 50 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.920022021256769 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:53\u001b[0m [] \u001b[1;30mERROR\u001b[0m vector.py:1653 \u001b[31mError getting embedding for input 49 after 5 retries: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai. exc.args=('429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.',)\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.1388402964299196 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.4536173127309424 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.2117329656399254 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:53\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.13202260988255 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.5385428920984476 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.23570899251143 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.197665087904088 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.9758022706548994 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 1.6429915971473497 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.049769634506989 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.6268922904034566 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:54\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.532799985941765 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.7529383125430313 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.832435977532227 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:55\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.420816079518665 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:56\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 3.5870637880378284 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:52:59\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 5.09414136032099 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 4\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 17\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 22\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 23\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 26\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 27\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 36\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 37\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 40\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 41\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 43\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 44\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 46\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 47\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 49\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 50\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 51\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mWARNING\u001b[0m vector.py:1398 \u001b[33mFailed to generate embedding for chunk 53\u001b[0m\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 78 chunks for record IG-TOM6IXVH...\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 78 chunks for record IG-TOM6IXVH\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-TOM6IXVH: 96 chunks ({'content': 93, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 34323.3ms\n",
      "\u001b[32m2025-06-17 19:53:04\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 43 chunks for record IG-WUC3649N...\n",
      "\u001b[32m2025-06-17 19:53:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 43 chunks for record IG-WUC3649N\n",
      "\u001b[32m2025-06-17 19:53:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-WUC3649N: 43 chunks ({'content': 40, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1352.2ms\n",
      "\u001b[32m2025-06-17 19:53:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 13 chunks for record BUN-QBBLZ8WI...\n",
      "\u001b[32m2025-06-17 19:53:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 13 chunks for record BUN-QBBLZ8WI\n",
      "\u001b[32m2025-06-17 19:53:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record BUN-QBBLZ8WI: 13 chunks ({'content': 10, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 551.7ms\n",
      "\u001b[32m2025-06-17 19:53:06\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 9 chunks for record FB-IULHG7JK...\n",
      "\u001b[32m2025-06-17 19:53:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 9 chunks for record FB-IULHG7JK\n",
      "\u001b[32m2025-06-17 19:53:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-IULHG7JK: 9 chunks ({'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 509.4ms\n",
      "\u001b[32m2025-06-17 19:53:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 11 chunks for record IG-1BMH3DQ6...\n",
      "\u001b[32m2025-06-17 19:53:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 11 chunks for record IG-1BMH3DQ6\n",
      "\u001b[32m2025-06-17 19:53:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-1BMH3DQ6: 11 chunks ({'content': 8, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 542.1ms\n",
      "\u001b[32m2025-06-17 19:53:07\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 49 chunks for record FB-AP0NSBVC...\n",
      "\u001b[32m2025-06-17 19:53:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 49 chunks for record FB-AP0NSBVC\n",
      "\u001b[32m2025-06-17 19:53:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-AP0NSBVC: 49 chunks ({'content': 46, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1447.0ms\n",
      "\u001b[32m2025-06-17 19:53:09\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 47 chunks for record FB-6YHRXHZR...\n",
      "\u001b[32m2025-06-17 19:53:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 47 chunks for record FB-6YHRXHZR\n",
      "\u001b[32m2025-06-17 19:53:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-6YHRXHZR: 47 chunks ({'content': 44, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1465.1ms\n",
      "\u001b[32m2025-06-17 19:53:10\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 13 chunks for record BUN-QBBLZ8WI...\n",
      "\u001b[32m2025-06-17 19:53:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 13 chunks for record BUN-QBBLZ8WI\n",
      "\u001b[32m2025-06-17 19:53:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record BUN-QBBLZ8WI: 13 chunks ({'content': 10, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 523.4ms\n",
      "\u001b[32m2025-06-17 19:53:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 12 chunks for record IG-FEYWNWI2...\n",
      "\u001b[32m2025-06-17 19:53:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 12 chunks for record IG-FEYWNWI2\n",
      "\u001b[32m2025-06-17 19:53:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-FEYWNWI2: 12 chunks ({'content': 9, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 542.5ms\n",
      "\u001b[32m2025-06-17 19:53:11\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 84 chunks for record BUN-IH313ZHJ...\n",
      "\u001b[32m2025-06-17 19:53:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 84 chunks for record BUN-IH313ZHJ\n",
      "\u001b[32m2025-06-17 19:53:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record BUN-IH313ZHJ: 84 chunks ({'content': 81, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2321.8ms\n",
      "\u001b[32m2025-06-17 19:53:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:15\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 44 chunks for record FB-XWJQBU9A...\n",
      "\u001b[32m2025-06-17 19:53:15\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 44 chunks for record FB-XWJQBU9A\n",
      "\u001b[32m2025-06-17 19:53:15\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-XWJQBU9A: 44 chunks ({'content': 41, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1437.3ms\n",
      "\u001b[32m2025-06-17 19:53:15\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 91 chunks for record FB-515JVE4X...\n",
      "\u001b[32m2025-06-17 19:53:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 91 chunks for record FB-515JVE4X\n",
      "\u001b[32m2025-06-17 19:53:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-515JVE4X: 91 chunks ({'content': 88, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2414.9ms\n",
      "\u001b[32m2025-06-17 19:53:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:19\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 68 chunks for record FB-LXNFAD5F...\n",
      "\u001b[32m2025-06-17 19:53:19\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 68 chunks for record FB-LXNFAD5F\n",
      "\u001b[32m2025-06-17 19:53:19\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-LXNFAD5F: 68 chunks ({'content': 65, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1890.4ms\n",
      "\u001b[32m2025-06-17 19:53:19\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 84 chunks for record BUN-IH313ZHJ...\n",
      "\u001b[32m2025-06-17 19:53:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 84 chunks for record BUN-IH313ZHJ\n",
      "\u001b[32m2025-06-17 19:53:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record BUN-IH313ZHJ: 84 chunks ({'content': 81, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2298.9ms\n",
      "\u001b[32m2025-06-17 19:53:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 33 chunks for record FB-2RDRCAVQ...\n",
      "\u001b[32m2025-06-17 19:53:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 33 chunks for record FB-2RDRCAVQ\n",
      "\u001b[32m2025-06-17 19:53:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-2RDRCAVQ: 33 chunks ({'content': 30, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1032.7ms\n",
      "\u001b[32m2025-06-17 19:53:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 63 chunks for record FB-MBGOTVN8...\n",
      "\u001b[32m2025-06-17 19:53:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 63 chunks for record FB-MBGOTVN8\n",
      "\u001b[32m2025-06-17 19:53:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-MBGOTVN8: 63 chunks ({'content': 60, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1883.5ms\n",
      "\u001b[32m2025-06-17 19:53:24\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record FB-IZP492PJ...\n",
      "\u001b[32m2025-06-17 19:53:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record FB-IZP492PJ\n",
      "\u001b[32m2025-06-17 19:53:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-IZP492PJ: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 598.3ms\n",
      "\u001b[32m2025-06-17 19:53:25\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 9 chunks for record FB-VJ6FO5UY...\n",
      "\u001b[32m2025-06-17 19:53:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 9 chunks for record FB-VJ6FO5UY\n",
      "\u001b[32m2025-06-17 19:53:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-VJ6FO5UY: 9 chunks ({'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 572.1ms\n",
      "\u001b[32m2025-06-17 19:53:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 84 chunks for record FB-659EAWI8...\n",
      "\u001b[32m2025-06-17 19:53:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 84 chunks for record FB-659EAWI8\n",
      "\u001b[32m2025-06-17 19:53:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-659EAWI8: 84 chunks ({'content': 81, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2441.6ms\n",
      "\u001b[32m2025-06-17 19:53:28\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:30\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 63 chunks for record FB-GW8BY1Y3...\n",
      "\u001b[32m2025-06-17 19:53:30\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 63 chunks for record FB-GW8BY1Y3\n",
      "\u001b[32m2025-06-17 19:53:30\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-GW8BY1Y3: 63 chunks ({'content': 60, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1803.3ms\n",
      "\u001b[32m2025-06-17 19:53:30\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 49 chunks for record FB-E1154YLY...\n",
      "\u001b[32m2025-06-17 19:53:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 49 chunks for record FB-E1154YLY\n",
      "\u001b[32m2025-06-17 19:53:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-E1154YLY: 49 chunks ({'content': 46, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1425.0ms\n",
      "\u001b[32m2025-06-17 19:53:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:32\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 9 chunks for record FB-33NK66FG...\n",
      "\u001b[32m2025-06-17 19:53:32\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 9 chunks for record FB-33NK66FG\n",
      "\u001b[32m2025-06-17 19:53:32\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-33NK66FG: 9 chunks ({'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 518.9ms\n",
      "\u001b[32m2025-06-17 19:53:32\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:32\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 20 chunks for record PAO-2021-01...\n",
      "\u001b[32m2025-06-17 19:53:32\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 20 chunks for record PAO-2021-01\n",
      "\u001b[32m2025-06-17 19:53:32\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record PAO-2021-01: 20 chunks ({'content': 17, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 553.6ms\n",
      "\u001b[32m2025-06-17 19:53:32\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:33\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 12 chunks for record FB-MFADK60O...\n",
      "\u001b[32m2025-06-17 19:53:33\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 12 chunks for record FB-MFADK60O\n",
      "\u001b[32m2025-06-17 19:53:33\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-MFADK60O: 12 chunks ({'content': 9, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 520.1ms\n",
      "\u001b[32m2025-06-17 19:53:33\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:53:34\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 59 chunks for record FB-4294T386...\n",
      "\u001b[32m2025-06-17 19:53:34\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 59 chunks for record FB-4294T386\n",
      "\u001b[32m2025-06-17 19:53:34\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:492 🔄 Syncing local changes back to remote: /home/debian/.cache/buttermilk/chromadb/gs___prosocial-dev_data_osb_chromadb → gs://prosocial-dev/data/osb/chromadb\n",
      "\u001b[32m2025-06-17 19:53:34\u001b[0m [] \u001b[1;30mINFO\u001b[0m utils.py:824 Uploading ChromaDB from /home/debian/.cache/buttermilk/chromadb/gs___prosocial-dev_data_osb_chromadb to gs://prosocial-dev/data/osb/chromadb\n",
      "\u001b[32m2025-06-17 19:55:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m utils.py:833 Successfully uploaded ChromaDB to gs://prosocial-dev/data/osb/chromadb\n",
      "\u001b[32m2025-06-17 19:55:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:496 ✅ Successfully synced local changes to remote storage\n",
      "\u001b[32m2025-06-17 19:55:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:556 ✅ Batch sync completed (reset counter to 0)\n",
      "\u001b[32m2025-06-17 19:55:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1188 🔄 Performed batch sync after processing record FB-4294T386\n",
      "\u001b[32m2025-06-17 19:55:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-4294T386: 59 chunks ({'content': 56, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 100074.9ms\n",
      "\u001b[32m2025-06-17 19:55:13\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 51 chunks for record FB-P93JPX02...\n",
      "\u001b[32m2025-06-17 19:55:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 51 chunks for record FB-P93JPX02\n",
      "\u001b[32m2025-06-17 19:55:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-P93JPX02: 51 chunks ({'content': 48, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1469.0ms\n",
      "\u001b[32m2025-06-17 19:55:14\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 98 chunks for record IG-PT5WRTLW...\n",
      "\u001b[32m2025-06-17 19:55:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 98 chunks for record IG-PT5WRTLW\n",
      "\u001b[32m2025-06-17 19:55:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-PT5WRTLW: 98 chunks ({'content': 95, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2443.6ms\n",
      "\u001b[32m2025-06-17 19:55:17\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 38 chunks for record FB-H6OZKDS3...\n",
      "\u001b[32m2025-06-17 19:55:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 38 chunks for record FB-H6OZKDS3\n",
      "\u001b[32m2025-06-17 19:55:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-H6OZKDS3: 38 chunks ({'content': 35, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1031.9ms\n",
      "\u001b[32m2025-06-17 19:55:18\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 64 chunks for record IG-KFLY3526...\n",
      "\u001b[32m2025-06-17 19:55:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 64 chunks for record IG-KFLY3526\n",
      "\u001b[32m2025-06-17 19:55:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-KFLY3526: 64 chunks ({'content': 61, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1864.6ms\n",
      "\u001b[32m2025-06-17 19:55:20\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 58 chunks for record FB-L1LANIA7...\n",
      "\u001b[32m2025-06-17 19:55:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 58 chunks for record FB-L1LANIA7\n",
      "\u001b[32m2025-06-17 19:55:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-L1LANIA7: 58 chunks ({'content': 55, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1514.0ms\n",
      "\u001b[32m2025-06-17 19:55:21\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record FB-2AHD01LX...\n",
      "\u001b[32m2025-06-17 19:55:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record FB-2AHD01LX\n",
      "\u001b[32m2025-06-17 19:55:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-2AHD01LX: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 547.5ms\n",
      "\u001b[32m2025-06-17 19:55:22\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 58 chunks for record FB-CZHY85JC...\n",
      "\u001b[32m2025-06-17 19:55:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 58 chunks for record FB-CZHY85JC\n",
      "\u001b[32m2025-06-17 19:55:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-CZHY85JC: 58 chunks ({'content': 55, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1510.3ms\n",
      "\u001b[32m2025-06-17 19:55:23\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 91 chunks for record FB-515JVE4X...\n",
      "\u001b[32m2025-06-17 19:55:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 91 chunks for record FB-515JVE4X\n",
      "\u001b[32m2025-06-17 19:55:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-515JVE4X: 91 chunks ({'content': 88, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2428.2ms\n",
      "\u001b[32m2025-06-17 19:55:26\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 37 chunks for record FB-I964KKM6...\n",
      "\u001b[32m2025-06-17 19:55:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 37 chunks for record FB-I964KKM6\n",
      "\u001b[32m2025-06-17 19:55:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-I964KKM6: 37 chunks ({'content': 34, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1063.5ms\n",
      "\u001b[32m2025-06-17 19:55:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record FB-79KHZ1P5...\n",
      "\u001b[32m2025-06-17 19:55:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record FB-79KHZ1P5\n",
      "\u001b[32m2025-06-17 19:55:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-79KHZ1P5: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 523.2ms\n",
      "\u001b[32m2025-06-17 19:55:27\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 60 chunks for record FB-1RWWJUAT...\n",
      "\u001b[32m2025-06-17 19:55:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 60 chunks for record FB-1RWWJUAT\n",
      "\u001b[32m2025-06-17 19:55:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-1RWWJUAT: 60 chunks ({'content': 57, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1521.4ms\n",
      "\u001b[32m2025-06-17 19:55:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 9 chunks for record FB-33NK66FG...\n",
      "\u001b[32m2025-06-17 19:55:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 9 chunks for record FB-33NK66FG\n",
      "\u001b[32m2025-06-17 19:55:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-33NK66FG: 9 chunks ({'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 532.2ms\n",
      "\u001b[32m2025-06-17 19:55:29\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 56 chunks for record FB-B6NGYREK...\n",
      "\u001b[32m2025-06-17 19:55:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 56 chunks for record FB-B6NGYREK\n",
      "\u001b[32m2025-06-17 19:55:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-B6NGYREK: 56 chunks ({'content': 53, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1530.8ms\n",
      "\u001b[32m2025-06-17 19:55:31\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:32\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 33 chunks for record FB-2RDRCAVQ...\n",
      "\u001b[32m2025-06-17 19:55:32\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 33 chunks for record FB-2RDRCAVQ\n",
      "\u001b[32m2025-06-17 19:55:32\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-2RDRCAVQ: 33 chunks ({'content': 30, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1052.5ms\n",
      "\u001b[32m2025-06-17 19:55:32\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:34\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 74 chunks for record IG-OZNR5J1Z...\n",
      "\u001b[32m2025-06-17 19:55:34\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 74 chunks for record IG-OZNR5J1Z\n",
      "\u001b[32m2025-06-17 19:55:34\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record IG-OZNR5J1Z: 74 chunks ({'content': 71, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2049.2ms\n",
      "\u001b[32m2025-06-17 19:55:34\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:35\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 47 chunks for record FB-6YHRXHZR...\n",
      "\u001b[32m2025-06-17 19:55:36\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 47 chunks for record FB-6YHRXHZR\n",
      "\u001b[32m2025-06-17 19:55:36\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-6YHRXHZR: 47 chunks ({'content': 44, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1576.8ms\n",
      "\u001b[32m2025-06-17 19:55:36\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 88 chunks for record FB-6OKJPNS3...\n",
      "\u001b[32m2025-06-17 19:55:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 88 chunks for record FB-6OKJPNS3\n",
      "\u001b[32m2025-06-17 19:55:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-6OKJPNS3: 88 chunks ({'content': 85, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 2382.1ms\n",
      "\u001b[32m2025-06-17 19:55:38\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:39\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 43 chunks for record FB-Q72FD6YL...\n",
      "\u001b[32m2025-06-17 19:55:39\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 43 chunks for record FB-Q72FD6YL\n",
      "\u001b[32m2025-06-17 19:55:39\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-Q72FD6YL: 43 chunks ({'content': 40, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1354.5ms\n",
      "\u001b[32m2025-06-17 19:55:39\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:40\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 9 chunks for record FB-TTXIBH8S...\n",
      "\u001b[32m2025-06-17 19:55:40\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 9 chunks for record FB-TTXIBH8S\n",
      "\u001b[32m2025-06-17 19:55:40\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-TTXIBH8S: 9 chunks ({'content': 6, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 529.8ms\n",
      "\u001b[32m2025-06-17 19:55:40\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:40\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record FB-IZP492PJ...\n",
      "\u001b[32m2025-06-17 19:55:40\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record FB-IZP492PJ\n",
      "\u001b[32m2025-06-17 19:55:40\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-IZP492PJ: 10 chunks ({'content': 7, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 506.3ms\n",
      "\u001b[32m2025-06-17 19:55:40\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:42\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 57 chunks for record FB-S6NRTDAJ...\n",
      "\u001b[32m2025-06-17 19:55:42\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 57 chunks for record FB-S6NRTDAJ\n",
      "\u001b[32m2025-06-17 19:55:42\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record FB-S6NRTDAJ: 57 chunks ({'content': 54, 'title': 1, 'reasoning': 1, 'recommendations': 1}) in 1473.8ms\n",
      "\u001b[32m2025-06-17 19:55:42\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:222 Initialized RecursiveCharacterTextSplitter (chunk_size=1200, chunk_overlap=400)\n",
      "\u001b[32m2025-06-17 19:55:42\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.2383505131648036 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:55:45\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 2.55276022924538 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:55:47\u001b[0m [] \u001b[1;30mWARNING\u001b[0m before_sleep.py:65 \u001b[33mRetrying <unknown> in 4.712776166978914 seconds as it raised RateLimit: 429 Quota exceeded for aiplatform.googleapis.com/embed_content_input_tokens_per_minute_per_base_model with base model: gemini-embedding. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\u001b[0m\n",
      "\u001b[32m2025-06-17 19:55:52\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1169 Upserting 10 chunks for record BUN-8S1H6EU5...\n",
      "\u001b[32m2025-06-17 19:55:53\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1180 Successfully stored 10 chunks for record BUN-8S1H6EU5\n",
      "\u001b[32m2025-06-17 19:55:53\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1102 ✅ Processed record BUN-8S1H6EU5: 10 chunks ({'content': 9, 'title': 1}) in 10623.4ms\n",
      "\u001b[32m2025-06-17 19:55:53\u001b[0m [] \u001b[1;30mINFO\u001b[0m vector.py:1350 ✅ Batch processing complete: 172 processed, 0 skipped, 0 failed in 658102.1ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Batch Results:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Batch Results:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   📊 Total Records: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   📊 Total Records: \u001b[1;36m172\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ✅ Processed: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ✅ Processed: \u001b[1;36m172\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ⏭️  Skipped <span style=\"font-weight: bold\">(</span>existing<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ⏭️  Skipped \u001b[1m(\u001b[0mexisting\u001b[1m)\u001b[0m: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ❌ Failed: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ❌ Failed: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ⏱️  Total Time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">658102.</span>1ms\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ⏱️  Total Time: \u001b[1;36m658102.\u001b[0m1ms\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "📋 Validation Summary:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "📋 Validation Summary:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   🔍 Would Process: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">172</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   🔍 Would Process: \u001b[1;36m172\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ⏭️  Would Skip: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ⏭️  Would Skip: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ⚠️  Warnings: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ⚠️  Warnings: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   🚫 Conflicts: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   🚫 Conflicts: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Test batch processing with validation\n",
    "print(f\"\\n3️⃣ BATCH PROCESSING WITH VALIDATION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(f\"Processing batch of {len(records)} records...\")\n",
    "\n",
    "# NEW API: Batch processing with comprehensive validation\n",
    "batch_result = await vectorstore.process_batch(\n",
    "    records,\n",
    "    mode=\"safe\",  # \"safe\", \"force\", or \"validate_only\"\n",
    "    max_failures=0,  # Fail fast (stop on first failure)\n",
    "    require_all_new=False,  # Don't require all records to be new\n",
    ")\n",
    "\n",
    "print(f\"✅ Batch Results:\")\n",
    "print(f\"   📊 Total Records: {batch_result.total_records}\")\n",
    "print(f\"   ✅ Processed: {batch_result.successful_count}\")\n",
    "print(f\"   ⏭️  Skipped (existing): {batch_result.skipped_count}\")\n",
    "print(f\"   ❌ Failed: {batch_result.failed_count}\")\n",
    "print(f\"   ⏱️  Total Time: {batch_result.processing_time_ms:.1f}ms\")\n",
    "\n",
    "if batch_result.failed_records:\n",
    "    print(f\"   🚫 Failed Records:\")\n",
    "    for record_id, error in batch_result.failed_records:\n",
    "        print(f\"      - {record_id}: {error}\")\n",
    "\n",
    "# Show validation results\n",
    "if batch_result.validation_result:\n",
    "    validation = batch_result.validation_result\n",
    "    print(f\"\\n📋 Validation Summary:\")\n",
    "    print(f\"   🔍 Would Process: {validation['stats']['would_process']}\")\n",
    "    print(f\"   ⏭️  Would Skip: {validation['stats']['would_skip']}\")\n",
    "    print(f\"   ⚠️  Warnings: {len(validation['warnings'])}\")\n",
    "    print(f\"   🚫 Conflicts: {len(validation['conflicts'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Intelligent Sync System - Major Performance Improvement\n",
    "\n",
    "### **Problem Solved: Excessive Sync Operations**\n",
    "\n",
    "**Before:** The system was syncing to GCS after **every single record**, which was extremely slow:\n",
    "```python\n",
    "# Old approach - SLOW! 💀\n",
    "for record in records:\n",
    "    await vectorstore.process_record(record)\n",
    "    await sync_to_gcs()  # ← This happened 1000x for 1000 records!\n",
    "```\n",
    "\n",
    "**After:** Smart batched sync with configurable thresholds:\n",
    "```python\n",
    "# New approach - FAST! ⚡\n",
    "for record in records:\n",
    "    await vectorstore.process_record(record)\n",
    "    # Only syncs when batch size reached OR time threshold met\n",
    "```\n",
    "\n",
    "### **🧠 Smart Sync Logic**\n",
    "\n",
    "The system now syncs intelligently based on:\n",
    "\n",
    "| Trigger | Default | Configurable | Purpose |\n",
    "|---------|---------|--------------|---------|\n",
    "| **Batch Size** | 50 records | `sync_batch_size` | Prevent data loss |\n",
    "| **Time Interval** | 10 minutes | `sync_interval_minutes` | Ensure periodic saves |\n",
    "| **Final Sync** | Always | `finalize_processing()` | Guarantee data persistence |\n",
    "| **Manual Sync** | On-demand | `sync_to_remote(force=True)` | User control |\n",
    "\n",
    "### **⚙️ Configuration Options**\n",
    "\n",
    "```yaml\n",
    "# conf/storage/osb.yaml\n",
    "osb_vector:\n",
    "  type: chromadb\n",
    "  # ... other config\n",
    "  sync_batch_size: 50          # Sync every 50 records\n",
    "  sync_interval_minutes: 10    # Sync every 10 minutes  \n",
    "  disable_auto_sync: false     # Enable/disable auto-sync\n",
    "```\n",
    "\n",
    "### **📈 Performance Benefits**\n",
    "\n",
    "For **1000 records**:\n",
    "- **Old System**: 1000 sync operations (~16 minutes of sync overhead)\n",
    "- **New System**: ~20 sync operations (~20 seconds of sync overhead)\n",
    "- **Improvement**: **98% reduction** in sync operations = **48x faster**\n",
    "\n",
    "### **🔒 Data Safety**\n",
    "\n",
    "The intelligent sync system maintains data safety through:\n",
    "- ✅ **Batch Thresholds**: Never lose more than `sync_batch_size` records\n",
    "- ✅ **Time Limits**: Automatic sync every `sync_interval_minutes`\n",
    "- ✅ **Final Guarantee**: `finalize_processing()` ensures no data loss\n",
    "- ✅ **Error Handling**: Failed syncs are logged and retried\n",
    "- ✅ **Manual Override**: Force sync anytime with `sync_to_remote(force=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test configuration-driven multi-field search capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔍 Testing Configuration-Driven Multi-Field Search<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔍 Testing Configuration-Driven Multi-Field Search\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "🎯 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. SUMMARY-ONLY SEARCH:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "🎯 \u001b[1;36m1\u001b[0m. SUMMARY-ONLY SEARCH:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Query: <span style=\"color: #008000; text-decoration-color: #008000\">'human rights'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Query: \u001b[32m'human rights'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   📋 Result <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: Brazilian general's speech<span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"font-weight: bold\">(</span>similarity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.408</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   📋 Result \u001b[1;36m1\u001b[0m: Brazilian general's speech\u001b[33m...\u001b[0m \u001b[1m(\u001b[0msimilarity: \u001b[1;36m0.408\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">      📝 Summary: of Action, UN High Commissioner for Human Rights report:\n",
       "    <span style=\"font-weight: bold\">[</span>A/HRC/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>/Add.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "      📝 Summary: of Action, UN High Commissioner for Human Rights report:\n",
       "    \u001b[1m[\u001b[0mA/HRC/\u001b[1;36m22\u001b[0m/\u001b[1;36m17\u001b[0m/Add.\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   📋 Result <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: Brazilian general's speech<span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"font-weight: bold\">(</span>similarity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.408</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   📋 Result \u001b[1;36m2\u001b[0m: Brazilian general's speech\u001b[33m...\u001b[0m \u001b[1m(\u001b[0msimilarity: \u001b[1;36m0.408\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">      📝 Summary: of Action, UN High Commissioner for Human Rights report:\n",
       "    <span style=\"font-weight: bold\">[</span>A/HRC/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>/Add.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "      📝 Summary: of Action, UN High Commissioner for Human Rights report:\n",
       "    \u001b[1m[\u001b[0mA/HRC/\u001b[1;36m22\u001b[0m/\u001b[1;36m17\u001b[0m/Add.\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   📋 Result <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: Brazilian General's Speech<span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"font-weight: bold\">(</span>similarity: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.407</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   📋 Result \u001b[1;36m3\u001b[0m: Brazilian General's Speech\u001b[33m...\u001b[0m \u001b[1m(\u001b[0msimilarity: \u001b[1;36m0.407\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">      📝 Summary: of Action, UN High Commissioner for Human Rights report:\n",
       "    <span style=\"font-weight: bold\">[</span>A/HRC/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>/Add.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "      📝 Summary: of Action, UN High Commissioner for Human Rights report:\n",
       "    \u001b[1m[\u001b[0mA/HRC/\u001b[1;36m22\u001b[0m/\u001b[1;36m17\u001b[0m/Add.\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"🔍 Testing Configuration-Driven Multi-Field Search...\")\n",
    "\n",
    "# The content_type values come from our configuration:\n",
    "# - \"content\" (main content field)\n",
    "# - \"summary\" (from additional_fields config)\n",
    "# - \"title\" (from additional_fields config)\n",
    "\n",
    "# 1. Search summaries only (high-level concepts)\n",
    "print(\"\\n🎯 1. SUMMARY-ONLY SEARCH:\")\n",
    "print(\"   Query: 'human rights'\")\n",
    "summary_results = vectorstore.collection.query(\n",
    "    query_texts=[\"human rights\"],\n",
    "    # where={\"content_type\": \"summary\"},  # Based on config: source_field=\"summary\"\n",
    "    n_results=3,\n",
    "    include=[\"documents\", \"metadatas\", \"distances\"],\n",
    ")\n",
    "\n",
    "if summary_results[\"ids\"] and summary_results[\"ids\"][0]:\n",
    "    for i, (doc, metadata, distance) in enumerate(\n",
    "        zip(summary_results[\"documents\"][0], summary_results[\"metadatas\"][0], summary_results[\"distances\"][0])\n",
    "    ):\n",
    "        similarity = 1 - distance\n",
    "        title = metadata.get(\"title\", \"Untitled\")\n",
    "        print(f\"   📋 Result {i+1}: {title[:40]}... (similarity: {similarity:.3f})\")\n",
    "        print(f\"      📝 Summary: {doc[:80]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data source configuration for the RAG agent"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Create Enhanced RAG Agent with intelligent search capabilities\nfrom buttermilk._core.config import (  # Configuration models\n    AgentVariants,\n)\n\n# IMPORTANT: Use the SAME config as your vectorstore to avoid mismatches!\n# Set the data configuration to point to the osb_vector storage\ncfg.agents.researcher.data = {\"osb_vector\": cfg.storage.osb_vector}\n\nprint(f\"🔧 Agent data configuration:\")\nprint(f\"   osb_vector: {cfg.agents.researcher.data['osb_vector']}\")\n\nrag_variants = AgentVariants(**cfg.agents.researcher)\nagents = []\nfor agent_cls, variant_config in rag_variants.get_configs():\n    print(f\"🔍 Initializing agent: {agent_cls.__name__}\")\n    print(f\"   Config data keys: {list(variant_config.data.keys()) if variant_config.data else 'None'}\")\n    \n    # Create agent with properly configured data stores\n    agent = agent_cls(\n        config=variant_config,\n        # Note: Don't pass storage= here as it should use the data configuration\n        text_splitter=chunker,\n    )\n    agents.append(agent)\n    \nprint(f\"✅ Initialized {len(agents)} RAG agents with osb_vector data configuration\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use agents to answer questions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import random\n\n\nasync def demonstrate_enhanced_rag():\n    \"\"\"Demonstrate Enhanced RAG capabilities with intelligent search planning.\"\"\"\n\n    print(\"🎯 ENHANCED RAG DEMONSTRATION\")\n    print(\"=\" * 60)\n\n    # Debug: Check what agents we have and their data configuration\n    print(f\"🔍 Available agents: {len(agents)}\")\n    for i, agent in enumerate(agents):\n        print(f\"   Agent {i}: {type(agent).__name__}\")\n        if hasattr(agent, 'data'):\n            print(f\"      Data keys: {list(agent.data.keys()) if agent.data else 'None'}\")\n        if hasattr(agent, 'config') and hasattr(agent.config, 'data'):\n            print(f\"      Config data keys: {list(agent.config.data.keys()) if agent.config.data else 'None'}\")\n\n    # Test queries that showcase different capabilities\n    test_queries = [\n        {\n            \"query\": \"What are the main challenges with content moderation?\",\n            \"expected_strategy\": \"Should use hybrid search (title + summary + content)\",\n            \"focus\": \"Broad exploratory query\",\n        },\n        {\n            \"query\": \"Find cases about misinformation detection algorithms\",\n            \"expected_strategy\": \"Should use metadata + title search\",\n            \"focus\": \"Specific case-focused query\",\n        },\n        {\n            \"query\": \"How do platforms protect user privacy?\",\n            \"expected_strategy\": \"Should use summary + semantic search\",\n            \"focus\": \"Policy-focused query\",\n        },\n    ]\n\n    for i, test in enumerate(test_queries, 1):\n        print(f\"\\n🔍 TEST {i}: {test['focus']}\")\n        print(f\"Query: '{test['query']}'\")\n        print(f\"Expected: {test['expected_strategy']}\")\n        print(\"-\" * 50)\n\n        # Select an agent that has data configuration\n        enhanced_rag_agent = None\n        for agent in agents:\n            if hasattr(agent, 'data') and agent.data:\n                enhanced_rag_agent = agent\n                break\n        \n        if not enhanced_rag_agent:\n            print(\"❌ No agent found with data configuration - creating one manually...\")\n            \n            # Create a direct RAG agent with proper data configuration\n            from buttermilk.agents.rag.rag_agent import RagAgent\n            from buttermilk._core.config import AgentConfig\n            \n            # Create agent config with proper data store reference\n            agent_config = AgentConfig(\n                role=\"RESEARCHER\",\n                agent_obj=\"RagAgent\",\n                description=\"OSB Research Assistant\",\n                data={\"osb_vector\": cfg.storage.osb_vector},\n                parameters={\"n_results\": 5, \"max_queries\": 3}\n            )\n            \n            enhanced_rag_agent = RagAgent(config=agent_config)\n            print(f\"✅ Created RagAgent with data: {list(enhanced_rag_agent.data.keys())}\")\n\n        try:\n            # Use the agent's search functionality directly instead of _process\n            if hasattr(enhanced_rag_agent, 'search'):\n                results = await enhanced_rag_agent.search(test[\"query\"])\n                print(f\"✅ RESULT:\")\n                print(f\"   Found {len(results)} results\")\n                if results:\n                    print(f\"   Sample: {results[0][:100]}...\")\n            elif hasattr(enhanced_rag_agent, 'fetch'):\n                search_results = await enhanced_rag_agent.fetch([test[\"query\"]])\n                print(f\"✅ RESULT:\")\n                if search_results and search_results[0].results:\n                    print(f\"   Found {len(search_results[0].results)} results\")\n                    print(f\"   Sample: {search_results[0].results[0].full_text[:100]}...\")\n                else:\n                    print(\"   No results found\")\n            else:\n                # Create AgentInput for the enhanced RAG agent\n                from buttermilk._core.contract import AgentInput\n\n                agent_input = AgentInput(inputs={\"query\": test[\"query\"]}, parameters={}, context=[], records=[])\n\n                # Process with Enhanced RAG\n                result = await enhanced_rag_agent._process(message=agent_input)\n\n                print(f\"✅ RESULT:\")\n                print(f\"   Response: {result.outputs[:200]}...\")\n\n                # Show metadata about the search\n                metadata = result.metadata\n                print(f\"\\n📊 SEARCH METADATA:\")\n                print(f\"   Total Results: {metadata.get('total_results', 0)}\")\n                print(f\"   Strategies Used: {metadata.get('strategies_used', [])}\")\n                print(f\"   Confidence Score: {metadata.get('confidence_score', 0.0):.2f}\")\n                print(f\"   Key Themes: {metadata.get('key_themes', [])}\")\n\n                if metadata.get(\"search_explanation\"):\n                    print(f\"   Search Strategy: {metadata['search_explanation']}\")\n\n        except Exception as e:\n            print(f\"❌ ERROR: {e}\")\n            import traceback\n            traceback.print_exc()\n\n        print(\"\\n\" + \"=\" * 60)\n\n    print(\"\\n🎉 Enhanced RAG demonstration complete!\")\n    print(\"\\nKey Benefits Demonstrated:\")\n    print(\"✅ Intelligent query analysis and search planning\")\n    print(\"✅ Multi-field search across titles, summaries, and content\")\n    print(\"✅ LLM-driven result synthesis and ranking\")\n    print(\"✅ Adaptive search strategies based on query type\")\n    print(\"✅ Comprehensive metadata and confidence scoring\")\n    print(\"✅ Smart cache management prevents overwriting local changes\")\n    print(\"✅ Automatic sync-back to remote storage after embedding operations\")\n\n\n# Run the enhanced RAG demonstration\nawait demonstrate_enhanced_rag()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Chat Interface\n",
    "\n",
    "Now let's create an interactive interface to chat with our OSB knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_with_osb(user_question):\n",
    "    \"\"\"Interactive chat with OSB knowledge base.\"\"\"\n",
    "    print(f\"\\n🔍 User Question: {user_question}\")\n",
    "\n",
    "    # Search for relevant context\n",
    "    search_results = await rag_agent.fetch([user_question])\n",
    "\n",
    "    if search_results and search_results[0].results:\n",
    "        context = search_results[0]\n",
    "        print(f\"\\n📚 Found {len(context.results)} relevant documents\")\n",
    "\n",
    "        # Display relevant chunks\n",
    "        print(\"\\n📋 Relevant Information:\")\n",
    "        for i, result in enumerate(context.results[:3]):  # Show top 3\n",
    "            print(f\"\\n{i+1}. {result.document_title} ({result.metadata.get('case_number', 'N/A')})\")\n",
    "            print(f\"   {result.full_text[:200]}...\")\n",
    "\n",
    "        # In a real implementation, this would be sent to an LLM for synthesis\n",
    "        print(\"\\n🤖 AI Response: [In a real implementation, the retrieved context would be sent to an LLM to generate a synthesized response]\")\n",
    "    else:\n",
    "        print(\"\\n❌ No relevant information found in the OSB database\")\n",
    "\n",
    "\n",
    "# Example chat interactions\n",
    "example_questions = [\n",
    "    \"What are the main issues with current content moderation approaches?\",\n",
    "    \"What recommendations exist for age verification?\",\n",
    "    \"How do platforms detect and counter misinformation?\",\n",
    "]\n",
    "\n",
    "for question in example_questions:\n",
    "    await chat_with_osb(question)\n",
    "    print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Vector Store Analysis\n",
    "\n",
    "Let's analyze our vector store to understand what we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get collection statistics\n",
    "collection = vectorstore.collection\n",
    "count = collection.count()\n",
    "\n",
    "print(f\"\\n=== OSB Vector Store Statistics ===\")\n",
    "print(f\"Collection Name: {vectorstore.collection_name}\")\n",
    "print(f\"Total Chunks: {count}\")\n",
    "print(f\"Embedding Dimensions: {vectorstore.dimensionality}\")\n",
    "print(f\"Embedding Model: {vectorstore.embedding_model}\")\n",
    "\n",
    "# Get a sample of metadata to understand the structure\n",
    "sample_results = collection.get(limit=3, include=[\"metadatas\", \"documents\"])\n",
    "\n",
    "print(f\"\\n=== Sample Metadata Structure ===\")\n",
    "if sample_results[\"metadatas\"]:\n",
    "    sample_metadata = sample_results[\"metadatas\"][0]\n",
    "    print(\"Available metadata fields:\")\n",
    "    for key, value in sample_metadata.items():\n",
    "        print(f\"  - {key}: {type(value).__name__} = {str(value)[:50]}...\")\n",
    "\n",
    "print(f\"\\n=== Storage Locations ===\")\n",
    "print(f\"ChromaDB Directory: {vectorstore.persist_directory}\")\n",
    "print(f\"Embeddings Directory: {vectorstore.arrow_save_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced Search Examples\n",
    "\n",
    "Let's explore some advanced search patterns and filtering capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct ChromaDB queries with metadata filtering\n",
    "async def advanced_search_examples():\n",
    "    \"\"\"Demonstrate advanced search capabilities.\"\"\"\n",
    "    print(\"\\n=== Advanced Search Examples ===\")\n",
    "\n",
    "    # 1. Search with metadata filtering\n",
    "    print(\"\\n1. Search within specific case:\")\n",
    "    results = collection.query(\n",
    "        query_texts=[\"content moderation challenges\"], n_results=5, where={\"case_number\": \"OSB-2024-001\"}, include=[\"documents\", \"metadatas\"]\n",
    "    )\n",
    "    print(f\"   Found {len(results['ids'][0]) if results['ids'] else 0} results in OSB-2024-001\")\n",
    "\n",
    "    # 2. Similarity search across all documents\n",
    "    print(\"\\n2. General similarity search:\")\n",
    "    results = collection.query(query_texts=[\"artificial intelligence and safety\"], n_results=5, include=[\"documents\", \"metadatas\", \"distances\"])\n",
    "\n",
    "    if results[\"ids\"] and results[\"ids\"][0]:\n",
    "        print(f\"   Found {len(results['ids'][0])} results\")\n",
    "        for i, (doc, metadata, distance) in enumerate(zip(results[\"documents\"][0][:3], results[\"metadatas\"][0][:3], results[\"distances\"][0][:3])):\n",
    "            print(f\"   Result {i+1} (similarity: {1-distance:.3f}): {metadata.get('title', 'N/A')}\")\n",
    "            print(f\"     {doc[:100]}...\")\n",
    "\n",
    "    # 3. Multi-query search\n",
    "    print(\"\\n3. Multi-query search:\")\n",
    "    multi_queries = [\"platform safety measures\", \"user protection mechanisms\", \"digital safety standards\"]\n",
    "\n",
    "    for query in multi_queries:\n",
    "        results = collection.query(query_texts=[query], n_results=2, include=[\"metadatas\"])\n",
    "        count = len(results[\"ids\"][0]) if results[\"ids\"] else 0\n",
    "        print(f\"   '{query}': {count} results\")\n",
    "\n",
    "\n",
    "await advanced_search_examples()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Production Considerations\n",
    "\n",
    "Here are key considerations for using this in production:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\"\"\n",
    "=== Production Deployment Checklist ===\n",
    "\n",
    "🔧 Configuration:\n",
    "   ✓ Use GCS for persist_directory: gs://your-bucket/chromadb\n",
    "   ✓ Configure appropriate chunk_size for your content\n",
    "   ✓ Set concurrency based on your compute resources\n",
    "   ✓ Use production embedding models (text-embedding-004/005)\n",
    "\n",
    "📊 Performance:\n",
    "   ✓ Monitor embedding generation costs\n",
    "   ✓ Implement caching for frequently accessed data\n",
    "   ✓ Use batch processing for large datasets\n",
    "   ✓ Configure appropriate timeout values\n",
    "\n",
    "🔒 Security:\n",
    "   ✓ Secure GCS bucket access with proper IAM\n",
    "   ✓ Implement data access controls\n",
    "   ✓ Audit vector store queries\n",
    "   ✓ Protect sensitive metadata\n",
    "\n",
    "🚀 Scalability:\n",
    "   ✓ Plan for vector store size growth\n",
    "   ✓ Implement horizontal scaling for embeddings\n",
    "   ✓ Monitor query performance\n",
    "   ✓ Set up proper logging and monitoring\n",
    "\n",
    "🔄 Maintenance:\n",
    "   ✓ Plan for data updates and reindexing\n",
    "   ✓ Implement backup strategies\n",
    "   ✓ Version control for embeddings and metadata\n",
    "   ✓ Regular quality assessments\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Show next steps\n",
    "print(\n",
    "    \"\"\"\n",
    "=== Next Steps ===\n",
    "\n",
    "1. Scale to Full Dataset:\n",
    "   - Use the osb_vectorize.yaml configuration\n",
    "   - Run: uv run python -m buttermilk.data.vector +run=osb_vectorize\n",
    "\n",
    "2. Deploy RAG Flow:\n",
    "   - Use the osb_rag.yaml flow configuration\n",
    "   - Run: uv run python -m buttermilk.runner.cli +flow=osb_rag +run=api\n",
    "\n",
    "3. Integrate with Frontend:\n",
    "   - Use the Buttermilk web interface\n",
    "   - Connect to WebSocket endpoints for real-time chat\n",
    "\n",
    "4. Monitor and Optimize:\n",
    "   - Track query performance\n",
    "   - Monitor embedding costs\n",
    "   - Tune chunk sizes and retrieval parameters\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔒 Smart Cache Management\n",
    "\n",
    "The vector database now includes smart cache management to prevent overwriting local changes:\n",
    "\n",
    "### **Problem Solved**\n",
    "Previously, re-running embedding cells would download the remote ChromaDB cache and overwrite any local changes, losing newly added embeddings.\n",
    "\n",
    "### **Solution: Smart Cache Management**\n",
    "The system now includes intelligent cache handling:\n",
    "\n",
    "```python\n",
    "async def _smart_cache_management(self, remote_path: str) -> Path:\n",
    "    \"\"\"Smart cache management that prevents overwriting newer local changes.\"\"\"\n",
    "    \n",
    "    # Check if local cache was recently modified (within 1 hour)\n",
    "    if time_since_modified < 3600:  # 1 hour\n",
    "        logger.info(\"🔒 Skipping download to preserve local changes\")\n",
    "        return cache_path\n",
    "    \n",
    "    # Only download if cache is stale\n",
    "    logger.info(\"🔄 Syncing remote ChromaDB\")\n",
    "    return await ensure_chromadb_cache(remote_path)\n",
    "```\n",
    "\n",
    "### **Automatic Sync-Back**\n",
    "After successful embedding operations, local changes are automatically synced to remote storage:\n",
    "\n",
    "```python\n",
    "async def _sync_local_changes_to_remote(self) -> None:\n",
    "    \"\"\"Sync local ChromaDB changes back to remote storage.\"\"\"\n",
    "    \n",
    "    # Only sync if recently modified (indicates recent work)\n",
    "    if time_since_modified < 21600:  # 6 hours\n",
    "        await upload_chromadb_cache(local_path, remote_path)\n",
    "        logger.info(\"✅ Successfully synced local changes to remote storage\")\n",
    "```\n",
    "\n",
    "### **Benefits**\n",
    "- ✅ **Prevents Data Loss**: Local embedding work is preserved\n",
    "- ✅ **Automatic Sync**: Changes are pushed back to remote storage  \n",
    "- ✅ **Time-Based Logic**: Only acts on recently modified caches\n",
    "- ✅ **Transparent Operation**: Clear logging of all cache decisions\n",
    "- ✅ **Production Ready**: Handles concurrent access and failures gracefully\n",
    "\n",
    "### **Usage**\n",
    "This happens automatically - no code changes needed! The smart cache management activates whenever you:\n",
    "1. Run embedding operations in this notebook\n",
    "2. Use the vectorstore in production flows\n",
    "3. Process new documents with the vector pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Production Deployment Guide\n",
    "\n",
    "This vector store is now ready for production use with the unified storage system. Here's how to deploy and use it:\n",
    "\n",
    "### 📋 **For Full Dataset Processing**\n",
    "```python\n",
    "# In cell 7, change this line:\n",
    "doc_limit = 5  # Set to None for full dataset\n",
    "\n",
    "# To:\n",
    "doc_limit = None  # Processes all OSB documents\n",
    "```\n",
    "\n",
    "### 🏭 **Production Usage Examples**\n",
    "\n",
    "#### **Option 1: RAG Agent Integration**\n",
    "```python\n",
    "from buttermilk.agents.rag.rag_agent import RagAgent\n",
    "from buttermilk._core.config import AgentConfig\n",
    "from buttermilk._core.storage_config import StorageConfig\n",
    "\n",
    "# Same config as creation - no changes needed with unified storage!\n",
    "storage_config = StorageConfig(**cfg.storage.osb_vector)\n",
    "\n",
    "agent_config = AgentConfig(\n",
    "    role=\"RESEARCHER\",\n",
    "    agent_obj=\"RagAgent\", \n",
    "    description=\"OSB Knowledge Assistant\",\n",
    "    data={\"osb_vector\": storage_config},\n",
    "    parameters={\"n_results\": 10, \"max_queries\": 3}\n",
    ")\n",
    "\n",
    "rag_agent = RagAgent(**agent_config.model_dump())\n",
    "```\n",
    "\n",
    "#### **Option 2: Direct Storage Access**\n",
    "```python\n",
    "# Create vector store instance (reads existing embeddings) using unified storage\n",
    "production_vectorstore = bm.get_storage(cfg.storage.osb_vector)\n",
    "await production_vectorstore.ensure_cache_initialized()\n",
    "\n",
    "# Perform semantic search\n",
    "results = production_vectorstore.collection.query(\n",
    "    query_texts=[\"platform safety policies\"],\n",
    "    n_results=5\n",
    ")\n",
    "```\n",
    "\n",
    "#### **Option 3: Flow Integration**\n",
    "```yaml\n",
    "# conf/flows/osb_rag.yaml\n",
    "defaults:\n",
    "  - base_flow\n",
    "\n",
    "orchestrator: buttermilk.orchestrators.groupchat.AutogenOrchestrator\n",
    "storage: osb_vector  # References the same storage config\n",
    "agents: [rag_agent, host/sequencer]\n",
    "```\n",
    "\n",
    "### 🏗️ **Enhanced Record Benefits**\n",
    "- ✅ **Direct Processing**: Records processed without conversion steps\n",
    "- ✅ **Vector Fields**: Built-in support for chunks, embeddings, file_path\n",
    "- ✅ **Unified API**: Same Record class used throughout the system\n",
    "- ✅ **Type Safety**: Full Pydantic validation for vector operations\n",
    "\n",
    "### 🔒 **Production Considerations**\n",
    "- ✅ **Persistent Storage**: Vector store saved to `gs://prosocial-public/osb/chromadb`  \n",
    "- ✅ **Config Reuse**: Same `osb.yaml` works for both creation and reading\n",
    "- ✅ **Scalability**: ChromaDB handles thousands of documents efficiently\n",
    "- ✅ **Monitoring**: Check collection count and performance metrics\n",
    "- ✅ **Updates**: Re-run this notebook to add new OSB documents\n",
    "\n",
    "### 💡 **Next Steps**\n",
    "1. **Scale Up**: Remove `doc_limit` to process full OSB dataset\n",
    "2. **Deploy**: Use in RAG agents, search APIs, or analytical workflows  \n",
    "3. **Monitor**: Track embedding quality and search relevance\n",
    "4. **Iterate**: Add new documents by re-running the pipeline\n",
    "\n",
    "### 🔧 **Migration Benefits**\n",
    "This notebook now uses:\n",
    "- ✅ **StorageConfig**: Unified configuration for all storage types\n",
    "- ✅ **Enhanced Record**: Built-in vector processing capabilities  \n",
    "- ✅ **bm.get_storage()**: Unified storage access API\n",
    "- ✅ **process_record()**: Direct Record processing without conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 Enhanced Vector Database Summary\n",
    "\n",
    "### ✅ What You Just Saw\n",
    "\n",
    "1. **🔄 Smart Deduplication**: The system automatically detected and skipped existing records, preventing duplicate embeddings\n",
    "\n",
    "2. **📊 Comprehensive Results**: Every operation returns detailed `ProcessingResult` or `BatchProcessingResult` with status, timing, and metadata\n",
    "\n",
    "3. **🔍 Pre-Validation**: Batch operations validate all records before processing, providing early warning of potential issues\n",
    "\n",
    "4. **📁 BM Integration**: Complete integration with existing Buttermilk logging and run management infrastructure\n",
    "\n",
    "5. **⚡ Performance**: Enhanced metadata tracking with provenance for every chunk\n",
    "\n",
    "### 🚀 Production Benefits\n",
    "\n",
    "#### **Before (Old API)**\n",
    "- ❌ No deduplication → wasted compute on existing records\n",
    "- ❌ No validation → failures discovered during processing  \n",
    "- ❌ Limited error information → difficult debugging\n",
    "- ❌ No resume capability → manual tracking required\n",
    "\n",
    "#### **After (New API)**  \n",
    "- ✅ **Smart Skip**: Existing records skipped automatically\n",
    "- ✅ **Safe Updates**: Validation prevents data corruption\n",
    "- ✅ **Rich Results**: Detailed status and error information\n",
    "- ✅ **BM Integration**: Uses existing logging infrastructure\n",
    "- ✅ **Resume Capability**: Add new records safely to existing collections\n",
    "\n",
    "### 🔧 Key Deduplication Strategies\n",
    "\n",
    "| Strategy | Behavior | Use Case |\n",
    "|----------|----------|----------|\n",
    "| `\"record_id\"` | Skip if record ID exists | Fast deduplication based on ID only |\n",
    "| `\"content_hash\"` | Skip if content unchanged | Detect actual content changes |\n",
    "| `\"both\"` | Conservative: skip only if ID exists AND content same | Maximum safety (default) |\n",
    "\n",
    "### 🏭 Production Usage\n",
    "\n",
    "```python\n",
    "# New production-ready workflow\n",
    "batch_result = await vectorstore.process_batch(\n",
    "    new_records,\n",
    "    mode=\"safe\",           # Safe incremental updates\n",
    "    max_failures=5,        # Allow some failures\n",
    "    require_all_new=False  # Mixed new/existing OK\n",
    ")\n",
    "\n",
    "# Check results\n",
    "if batch_result.successful_count > 0:\n",
    "    print(f\"✅ Added {batch_result.successful_count} new records\")\n",
    "    \n",
    "if batch_result.skipped_count > 0:\n",
    "    print(f\"⏭️  Skipped {batch_result.skipped_count} existing records\")\n",
    "\n",
    "# Finalize with BM logging integration\n",
    "await vectorstore.finalize_processing()\n",
    "```\n",
    "\n",
    "The enhanced vector database is now production-ready with comprehensive safety guarantees and efficient resume capability!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Demonstrate BM Integration and Finalization\n",
    "print(f\"\\n5️⃣ BM INTEGRATION & FINALIZATION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Show BM integration\n",
    "print(f\"📊 Records Processed This Session: {vectorstore._processed_records_count}\")\n",
    "print(f\"🔍 Deduplication Cache Size: {len(vectorstore._processed_combinations_cache)} combinations\")\n",
    "\n",
    "# Show BM run information if available\n",
    "try:\n",
    "    from buttermilk._core.dmrc import get_bm\n",
    "    bm = get_bm()\n",
    "    if bm and bm.run_info:\n",
    "        print(f\"📁 BM Run ID: {bm.run_info.run_id}\")\n",
    "        print(f\"💾 BM Save Directory: {bm.run_info.save_dir}\")\n",
    "        print(f\"📍 BM Platform: {bm.run_info.platform}\")\n",
    "    else:\n",
    "        print(f\"⚠️  BM run info not available\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Could not access BM: {e}\")\n",
    "\n",
    "# Finalize processing (uses existing BM logging)\n",
    "print(f\"\\n🔄 Finalizing processing session...\")\n",
    "finalize_success = await vectorstore.finalize_processing()\n",
    "\n",
    "if finalize_success:\n",
    "    print(f\"✅ Finalization successful!\")\n",
    "    print(f\"📊 Final Statistics:\")\n",
    "    print(f\"   🔢 Total embeddings in collection: {vectorstore.collection.count()}\")\n",
    "    print(f\"   📦 Processed records this session: {vectorstore._processed_records_count}\")\n",
    "    print(f\"   🔍 Deduplication strategy: {vectorstore.deduplication_strategy}\")\n",
    "    print(f\"   📈 Cache efficiency: {len(vectorstore._processed_combinations_cache)} combinations cached\")\n",
    "else:\n",
    "    print(f\"❌ Finalization failed!\")\n",
    "\n",
    "print(f\"\\n✅ All processing logged via existing BM infrastructure\")\n",
    "print(f\"💡 Run metadata is automatically saved by Buttermilk to standard locations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔄 Demonstrate Enhanced Vector Database with Resume Functionality\n",
    "\n",
    "print(\"🚀 TESTING ENHANCED VECTOR DATABASE API\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get a small subset of records for testing\n",
    "test_records = records[:5]  # First 5 records\n",
    "\n",
    "print(f\"📋 Testing with {len(test_records)} records\")\n",
    "print(f\"🔍 Using deduplication strategy: {vectorstore.deduplication_strategy}\")\n",
    "\n",
    "# 1. Test single record processing with new API\n",
    "print(f\"\\n1️⃣ SINGLE RECORD PROCESSING (New API)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "single_record = test_records[0]\n",
    "print(f\"Processing record: {single_record.record_id}\")\n",
    "\n",
    "# NEW API: Enhanced process_record with comprehensive results\n",
    "result = await vectorstore.process_record(\n",
    "    single_record,\n",
    "    skip_existing=True,  # Skip if already exists (default: True)\n",
    "    validate_before_process=True,  # Validate before processing (default: True)\n",
    "    force_reprocess=False,  # Don't force reprocessing (default: False)\n",
    ")\n",
    "\n",
    "print(f\"✅ Result Status: {result.status}\")\n",
    "print(f\"📊 Reason: {result.reason}\")\n",
    "print(f\"📦 Chunks Created: {result.chunks_created}\")\n",
    "print(f\"⏱️  Processing Time: {result.processing_time_ms:.1f}ms\")\n",
    "print(f\"🔧 Metadata: {result.metadata}\")\n",
    "\n",
    "# 2. Test the same record again (should be skipped due to deduplication)\n",
    "print(f\"\\n2️⃣ DUPLICATE DETECTION TEST\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(f\"Processing same record again (should be skipped)...\")\n",
    "result2 = await vectorstore.process_record(single_record, skip_existing=True, validate_before_process=True)\n",
    "\n",
    "print(f\"✅ Result Status: {result2.status}\")\n",
    "print(f\"📊 Reason: {result2.reason}\")\n",
    "print(f\"📦 Chunks Created: {result2.chunks_created}\")\n",
    "print(f\"⏱️  Processing Time: {result2.processing_time_ms:.1f}ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 NEW: Enhanced Vector Database with Resume Functionality\n",
    "\n",
    "## Breaking Changes - Enhanced API for Production Use\n",
    "\n",
    "The vector database has been completely redesigned with breaking changes to provide:\n",
    "\n",
    "- ✅ **Smart Deduplication**: Prevent re-creating existing embeddings\n",
    "- ✅ **Resume Capability**: Safely add new records to existing collections  \n",
    "- ✅ **Comprehensive Validation**: Pre-validate batches before processing\n",
    "- ✅ **BM Integration**: Uses existing Buttermilk logging infrastructure\n",
    "- ✅ **Enhanced Metadata**: Complete provenance tracking\n",
    "\n",
    "### ⚠️ Breaking Changes\n",
    "\n",
    "**OLD API (will break):**\n",
    "```python\n",
    "result = await vectorstore.process_record(record)\n",
    "if result:\n",
    "    print(\"Success\")\n",
    "```\n",
    "\n",
    "**NEW API (required):**\n",
    "```python\n",
    "result = await vectorstore.process_record(record, skip_existing=True)\n",
    "if result.status == \"processed\":\n",
    "    print(f\"Success: {result.chunks_created} chunks\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "buttermilk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}