{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare different prompts to extract frames from climate news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-26 18:11:20 26f087537f3a buttermilk buttermilk.py[ 200] INFO Logging setup for: {'function_name': 'default_project', 'job': 'development', 'logs': '20240826T0811Z-cSzT-26f087537f3a-vscode', 'user': 'vscode', 'node': '26f087537f3a'}. Ready for data collection, saving log to Google Cloud Logs (Resource(type='generic_task', labels={'project_id': 'dmrc-platforms', 'location': 'us-central1', 'namespace': 'default_project', 'job': 'development', 'task_id': '20240826T0811Z-cSzT-26f087537f3a-vscode'})). Default save directory for data in this run is: gs://dmrc-analysis/runs/default_project/development/20240826T0811Z-cSzT-26f087537f3a-vscode\n",
      "2024-08-26 18:11:20 26f087537f3a buttermilk 784547862.py[   5] INFO Starting interactive run for climate frames in notebook\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                12 non-null     int64 \n",
      " 1   title             12 non-null     object\n",
      " 2   author            12 non-null     object\n",
      " 3   source            12 non-null     object\n",
      " 4   publication_date  12 non-null     object\n",
      " 5   content           12 non-null     object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 704.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "import buttermilk\n",
    "\n",
    "bm = buttermilk.BM()\n",
    "logger = bm.logger\n",
    "logger.info(\"Starting interactive run for climate frames in notebook\")\n",
    "\n",
    "# In this experiment, we will use four different variations for the prompt:\n",
    "prompt_vars = {\"prompt_template_path\": \"generic.prompty\", \"system_prompt\": \"system_frames.jinja2\", \"output_format\": \"json_frames.jinja2\"}\n",
    "variants = [{\"name\": \"generic_frames\", \"instructions\": \"instructions_frames.jinja2\"},\n",
    "            {\"name\": \"speaker_first_alt\", \"instructions\": \"climate_activism_speakerfirst_alt_output.jinja2\"},\n",
    "            {\"name\": \"speaker_first\", \"instructions\": \"instructions_frames.jinja2\", },\n",
    "            {\"name\": \"climate_activism_frames\", \"instructions\": \"climate_activism.jinja2\"},\n",
    "            ]\n",
    "\n",
    "models = [\"haiku\", \"llama31-8b\"]\n",
    "\n",
    "# Data is generally stored in JSONL format on cloud storage, allowing us to control versions and run anywhere\n",
    "DATASET = \"gs://dmrc-analysis/data/climate_articles.jsonl\"\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_json(DATASET, orient='records', lines=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run locally, uploading trace only to Azure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from promptflow.tracing import start_trace, trace\n",
    "start_trace(collection=\"climate\")\n",
    "\n",
    "from buttermilk.flows.extract import Analyst\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for model in models:\n",
    "    for variant in variants:\n",
    "        flow_vars = prompt_vars.copy()\n",
    "        flow_vars.update(variant)\n",
    "        flow_vars['langchain_model_name'] = model\n",
    "\n",
    "        flow = Analyst(**flow_vars)\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            id_vars = {\"id\": row[\"id\"], \"name\": variant[\"name\"], \"model\": model, \"timestamp\": pd.to_datetime(datetime.datetime.now())}\n",
    "            response = flow(content=row[\"content\"])\n",
    "            response.update(id_vars)\n",
    "            response_df = pd.DataFrame(data=[response])\n",
    "            results = pd.concat([results, response_df])\n",
    "            break\n",
    "        break\n",
    "    break\n",
    "\n",
    "\n",
    "results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "for line in results['analysis'].values:\n",
    "    pp.pprint(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same thing, but this time, submit the run as a batch, running locally, but storing all artifacts on Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/bm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt flow service has started...\n",
      "Prompt flow service has started...\n",
      "2024-08-26 18:11:39 26f087537f3a buttermilk buttermilk.py[ 200] INFO Logging setup for: {'function_name': 'default_project', 'job': 'development', 'logs': '20240826T0811Z-3qai-26f087537f3a-vscode', 'user': 'vscode', 'node': '26f087537f3a'}. Ready for data collection, saving log to Google Cloud Logs (Resource(type='generic_task', labels={'project_id': 'dmrc-platforms', 'location': 'us-central1', 'namespace': 'default_project', 'job': 'development', 'task_id': '20240826T0811Z-3qai-26f087537f3a-vscode'})). Default save directory for data in this run is: gs://dmrc-analysis/runs/default_project/development/20240826T0811Z-3qai-26f087537f3a-vscode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:buttermilk:Logging setup for: {'function_name': 'default_project', 'job': 'development', 'logs': '20240826T0811Z-3qai-26f087537f3a-vscode', 'user': 'vscode', 'node': '26f087537f3a'}. Ready for data collection, saving log to Google Cloud Logs (Resource(type='generic_task', labels={'project_id': 'dmrc-platforms', 'location': 'us-central1', 'namespace': 'default_project', 'job': 'development', 'task_id': '20240826T0811Z-3qai-26f087537f3a-vscode'})). Default save directory for data in this run is: gs://dmrc-analysis/runs/default_project/development/20240826T0811Z-3qai-26f087537f3a-vscode\n",
      "[2024-08-26 18:11:40 +1000][promptflow._sdk._orchestrator.run_submitter][INFO] - Upload run to cloud: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt flow service has started...\n",
      "You can view the traces in local from http://127.0.0.1:23334/v1.0/ui/traces/?#run=20240826T0811Z-cSzT-26f087537f3a-vscode_generic_frames_haiku\n",
      "You can view the traces in azure portal since trace destination is set to: azureml://subscriptions/7e7e056a-4224-4e26-99d2-1e3f9a688c50/resourcegroups/rg-suzor_ai/providers/Microsoft.MachineLearningServices/workspaces/automod. The link will be printed once the run is finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-26 18:11:43 +1000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run 20240826T0811Z-cSzT-26f087537f3a-vscode_generic_frames_haiku, log path: /home/vscode/.promptflow/.runs/20240826T0811Z-cSzT-26f087537f3a-vscode_generic_frames_haiku/logs.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23334/v1.0/ui/traces/?#collection=climate&uiTraceId=0xe683878ebf57d7a9bb2d61742930432b\n",
      "https://ai.azure.com/projecttrace/detail/0xe683878ebf57d7a9bb2d61742930432b?wsid=/subscriptions/7e7e056a-4224-4e26-99d2-1e3f9a688c50/resourceGroups/rg-suzor_ai/providers/Microsoft.MachineLearningServices/workspaces/automod\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23334/v1.0/ui/traces/?#collection=climate&uiTraceId=0x7fd6e485cb28f03e27e0a14518d82a27\n",
      "https://ai.azure.com/projecttrace/detail/0x7fd6e485cb28f03e27e0a14518d82a27?wsid=/subscriptions/7e7e056a-4224-4e26-99d2-1e3f9a688c50/resourceGroups/rg-suzor_ai/providers/Microsoft.MachineLearningServices/workspaces/automod\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23334/v1.0/ui/traces/?#collection=climate&uiTraceId=0x659a5c92aa9b154d6782ba9e40350cf9\n",
      "https://ai.azure.com/projecttrace/detail/0x659a5c92aa9b154d6782ba9e40350cf9?wsid=/subscriptions/7e7e056a-4224-4e26-99d2-1e3f9a688c50/resourceGroups/rg-suzor_ai/providers/Microsoft.MachineLearningServices/workspaces/automod\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23334/v1.0/ui/traces/?#collection=climate&uiTraceId=0xe9fd80e4a4a94e42f3f3045c10192dd4\n",
      "https://ai.azure.com/projecttrace/detail/0xe9fd80e4a4a94e42f3f3045c10192dd4?wsid=/subscriptions/7e7e056a-4224-4e26-99d2-1e3f9a688c50/resourceGroups/rg-suzor_ai/providers/Microsoft.MachineLearningServices/workspaces/automod\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23334/v1.0/ui/traces/?#collection=climate&uiTraceId=0xe026928d29bcf0591bbe9f856628307b\n",
      "https://ai.azure.com/projecttrace/detail/0xe026928d29bcf0591bbe9f856628307b?wsid=/subscriptions/7e7e056a-4224-4e26-99d2-1e3f9a688c50/resourceGroups/rg-suzor_ai/providers/Microsoft.MachineLearningServices/workspaces/automod\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23334/v1.0/ui/traces/?#collection=climate&uiTraceId=0xe62e4cf35fab95b685ffb1d0f58afb05\n",
      "https://ai.azure.com/projecttrace/detail/0xe62e4cf35fab95b685ffb1d0f58afb05?wsid=/subscriptions/7e7e056a-4224-4e26-99d2-1e3f9a688c50/resourceGroups/rg-suzor_ai/providers/Microsoft.MachineLearningServices/workspaces/automod\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23334/v1.0/ui/traces/?#collection=climate&uiTraceId=0x92e1d47886ce38452274eb5a4c996aae\n",
      "https://ai.azure.com/projecttrace/detail/0x92e1d47886ce38452274eb5a4c996aae?wsid=/subscriptions/7e7e056a-4224-4e26-99d2-1e3f9a688c50/resourceGroups/rg-suzor_ai/providers/Microsoft.MachineLearningServices/workspaces/automod\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23334/v1.0/ui/traces/?#collection=climate&uiTraceId=0x63c0de4885dfd752c2b2b8eab5f172e7\n",
      "https://ai.azure.com/projecttrace/detail/0x63c0de4885dfd752c2b2b8eab5f172e7?wsid=/subscriptions/7e7e056a-4224-4e26-99d2-1e3f9a688c50/resourceGroups/rg-suzor_ai/providers/Microsoft.MachineLearningServices/workspaces/automod\n"
     ]
    }
   ],
   "source": [
    "from promptflow.tracing import start_trace, trace\n",
    "from promptflow.client import PFClient as LocalPFClient\n",
    "from buttermilk.flows.extract import Analyst\n",
    "import datetime\n",
    "\n",
    "start_trace(collection=\"climate\")\n",
    "\n",
    "import cloudpathlib\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "# Save the dataset locally\n",
    "\n",
    "with NamedTemporaryFile(delete=False, suffix=\".jsonl\", mode=\"w\") as f:\n",
    "    dataset = f.name\n",
    "cloudpathlib.CloudPath(DATASET).download_to(dataset)\n",
    "\n",
    "start_trace(collection=\"climate\")\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "pflocal = LocalPFClient()\n",
    "\n",
    "#Set to Fork instead of Spawn\n",
    "import os\n",
    "os.environ['PF_BATCH_METHOD']='fork'\n",
    "\n",
    "for model in models:\n",
    "    for variant in variants:\n",
    "        flow_vars = prompt_vars.copy()\n",
    "        flow_vars.update(variant)\n",
    "        flow_vars['langchain_model_name'] = model\n",
    "\n",
    "        flow = Analyst(**flow_vars)\n",
    "        columns = {\"content\": r\"${data.content}\", \"record_id\": r\"${data.id}\"}\n",
    "\n",
    "        run_name = f\"{bm._run_id}_{variant['name']}_{model}\"\n",
    "        run_meta = {\"name\": variant[\"name\"], \"model\": model, \"timestamp\": pd.to_datetime(datetime.datetime.now())}\n",
    "        run = pflocal.run(\n",
    "                flow=flow,\n",
    "                data=dataset,\n",
    "                init_vars=flow_vars,\n",
    "                column_mapping=columns,\n",
    "                stream=False,\n",
    "                name=run_name,display_name=\"Automod\",timeout=150,\n",
    "            )\n",
    "\n",
    "        logger.info(\n",
    "            f\"Run {run.name} completed with status {run.status}. URL: {run._portal_url}.\"\n",
    "        )\n",
    "\n",
    "        details = pflocal.get_details(run_name)\n",
    "\n",
    "        # duplicate run_info metadata for each row\n",
    "        run_meta = pd.DataFrame.from_records([run_meta for _ in range(details.shape[0])])\n",
    "        details = pd.concat([details, run_meta], axis='columns')\n",
    "\n",
    "        results = pd.concat([results, details])\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
